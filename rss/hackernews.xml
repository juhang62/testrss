<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=hnrss.org%2Fnewest%3Fpoints%3D200&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://hnrss.org/newest?points=200" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>Hacker News: Newest</title>
<link>https://news.ycombinator.com/newest</link>
<description>Hacker News RSS</description>
<item>
<title>WeWork sells Meetup</title>
<link>https://techcrunch.com/2020/03/30/wework-sells-off-social-network-meetup-to-alleycorp-and-other-investors/</link>
<guid isPermaLink="true" >https://techcrunch.com/2020/03/30/wework-sells-off-social-network-meetup-to-alleycorp-and-other-investors/</guid>
<description>&lt;p id=&quot;speakable-summary&quot;&gt;&lt;a class=&quot;crunchbase-link&quot; href=&quot;https://crunchbase.com/organization/meetup&quot; target=&quot;_blank&quot; data-type=&quot;organization&quot; data-entity=&quot;meetup&quot;&gt;Meetup,&lt;/a&gt; the social networking platform designed to connect people in person, is being spun out from shared office space provider WeWork, the company confirmed on Monday. The site is being sold to AlleyCorp and other private investors for an undisclosed sum, but one that’s &lt;a href=&quot;https://fortune.com/2020/03/30/softbank-wework-meetup-alleycorp-acquisition/&quot;&gt;reportedly&lt;/a&gt; far less than the $156 million &lt;a href=&quot;https://techcrunch.com/2017/11/27/wework-reportedly-plans-to-buy-meetup/&quot;&gt;acquisition&lt;/a&gt; price WeWork paid for the social network back in 2017.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://fortune.com/2020/03/30/softbank-wework-meetup-alleycorp-acquisition/&quot;&gt;Fortune&lt;/a&gt; (paywalled) was first to break the news of Meetup’s sale. The company has also now put out a &lt;a href=&quot;https://www.prnewswire.com/news-releases/meetup-spins-off-from-wework-301031766.html&quot;&gt;press release&lt;/a&gt; with further details.&lt;/p&gt;
&lt;p&gt;Meetup, which has operated for two-and-a-half years as a &lt;a class=&quot;crunchbase-link&quot; href=&quot;https://crunchbase.com/organization/wework-857c&quot; target=&quot;_blank&quot; data-type=&quot;organization&quot; data-entity=&quot;wework-857c&quot;&gt;WeWork&lt;/a&gt; subsidiary, will divest itself from its parent company and continue to operate, it says. The site today serves 49 million registered members and more than 230,000 organizers who create an average of 15,000 in-person events per day.&lt;/p&gt;
&lt;p&gt;Even before the COVID-19 pandemic, Meetup had been struggling. The company in November &lt;a href=&quot;https://techcrunch.com/2019/11/04/wework-owned-meetup-confirms-restructuring-layoffs/&quot;&gt;announced&lt;/a&gt; a round of layoffs amid other cost-cutting measures. And these had followed &lt;a href=&quot;https://gizmodo.com/the-mess-at-meetup-1822243738&quot;&gt;earlier cuts&lt;/a&gt; of 10% of staff during acquisition negotiations.&lt;/p&gt;
&lt;p&gt;With the COVID-19 pandemic now in full force, fewer people than ever are willing and able to meet in-person, leading to Meetup to position itself today as a place for groups to meet “online during times of crisis,” its release said. That remains to be seen.&lt;/p&gt;
&lt;p&gt;The investor groups in Meetup’s latest acquisition are led by Kevin Ryan’s &lt;a href=&quot;https://alleycorp.com/companies/&quot;&gt;AlleyCorp&lt;/a&gt; and also include other “mission-driven private funds” and “accomplished technology executives,” the company claims.&lt;/p&gt;
&lt;p&gt;The deal will see Ryan joining Meetup as chairman of the Board. David Siegel will remain Meetup CEO and board member, and will continue to lead the company.&lt;/p&gt;
&lt;p&gt;Meetup groups will continue to operate, as will Meetup’s enterprise business solution, Meetup Pro, which has been used by over 1,500 clients to date, including Adobe, Google, Microsoft Azure, IBM, Twitter and Looker, among others.&lt;/p&gt;
&lt;p&gt;“This acquisition provides the long-term capital to ensure that Meetup focuses on what is most important: the organizers who make Meetup successful, our passionate members, and our dedicated employees,” said David Siegel, CEO of Meetup, in a statement. “We are excited to continue on our mission of empowering personal growth through real human connections, and I’m happy to have brought in a team of smart investors who share and support the same values,” he said.&lt;/p&gt;
&lt;p&gt;WeWork’s intention to sell off Meetup was &lt;a href=&quot;https://www.businessinsider.com/wework-wants-sell-3-businesses-managed-by-q-conductor-meetup-2019-9?r=US&amp;amp;IR=T&quot;&gt;previously&lt;/a&gt; &lt;a href=&quot;https://www.theinformation.com/articles/wework-puts-three-businesses-up-for-sale&quot;&gt;known&lt;/a&gt;. Unfortunately for the longtime social network, it was one of several &lt;a href=&quot;https://www.wired.co.uk/article/wework-meetup&quot;&gt;casualties&lt;/a&gt; arising from WeWork’s &lt;a href=&quot;https://techcrunch.com/2020/03/17/softbank-reportedly-balks-at-commitment-to-buy-3b-in-shares-from-wework-shareholders/&quot;&gt;larger&lt;/a&gt; &lt;a href=&quot;https://techcrunch.com/2019/09/30/wework-delays-ipo/&quot;&gt;troubles.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;It’s unclear, however, what the future holds for Meetup. Though the government lockdown policies may eventually end, consumers’ appetite for getting together in real-life groups with people they first met online may not be as strong as it was before. Meetup may have to shift more of its focus to supporting online-only groups — a market that’s today dominated by Facebook Groups, or niche apps catering to specific categories, like Peanut for moms or Nextdoor for neighbors, for instance.&lt;/p&gt;
&lt;p&gt;“We are confident in the enormous potential of the business and Meetup’s mission of bringing people together in substantive ways,” said &lt;a class=&quot;crunchbase-link&quot; href=&quot;https://crunchbase.com/organization/alleycorp&quot; target=&quot;_blank&quot; data-type=&quot;organization&quot; data-entity=&quot;alleycorp&quot;&gt;AlleyCorp’s&lt;/a&gt; Ryan, in a statement. “We are very excited to collectively serve and grow Meetup’s extensive and incredibly engaged user base.”&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://techcrunch.com/pages/covid-19-updates/&quot;&gt;&lt;img src=&quot;https://techcrunch.com/wp-content/uploads/2020/03/covid-19-footer.png&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Mon, 30 Mar 2020 18:22:31 +0000</pubDate>
<dc:creator>uptown</dc:creator>
<og:title>WeWork sells off social network Meetup to AlleyCorp and other investors – TechCrunch</og:title>
<og:description>Meetup, the social networking platform designed to connect people in person, is being spun out from shared office space provider WeWork, the company confirmed on Monday. The site is being sold to AlleyCorp and other private investors for an undisclosed sum, but one that’s reportedly far less …</og:description>
<og:image>https://techcrunch.com/wp-content/uploads/2020/03/meetup.jpg?w=711</og:image>
<og:url>http://social.techcrunch.com/2020/03/30/wework-sells-off-social-network-meetup-to-alleycorp-and-other-investors/</og:url>
<og:type>article</og:type>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://techcrunch.com/2020/03/30/wework-sells-off-social-network-meetup-to-alleycorp-and-other-investors/</dc:identifier>
</item>
<item>
<title>Please Fund More Science</title>
<link>https://blog.samaltman.com/please-fund-more-science</link>
<guid isPermaLink="true" >https://blog.samaltman.com/please-fund-more-science</guid>
<description>&lt;p&gt;Experts on the COVID-19 pandemic seem to think there are three ways out—that is, for life, health, and the economy to return roughly to normal. &lt;/p&gt;
&lt;p&gt;Either we get a vaccine good enough that R0 for the world goes below 1, a good enough treatment that people no longer need to be afraid, or we develop a great culture of testing, contract tracing, masks, and isolation.&lt;/p&gt;
&lt;p&gt;I wish that the federal government were doing much more—it would be great to see even a few percent of the recent stimulus bill go to funding R+D.  But they don’t seem to be funding enough science, and although I think concerns about the private sector and philanthropy doing what the government is supposed to be doing are somewhat valid, there isn’t a great alternative right now.&lt;/p&gt;
&lt;p&gt;On the positive side, I have never seen a field focused on one problem with such ferocity before.  The response of biotech companies and research labs is amazing, and the speed they are operating at seems to have increased by more than 10x.  It’s the best of the spirit of innovation, and it’s inspiring to see what these companies and research labs are doing.&lt;/p&gt;
&lt;p&gt;Scientists can get us out of this.  What they need are money and connections.&lt;/p&gt;
&lt;p&gt;Investors and donors—this is where we can help.  Please consider shifting some of your focus and capital to scientific efforts addressing the pandemic.  (And future pandemics too—I think this will be a before-and-after moment in the world, and until we can defend against new viruses quickly, things are going to be different.)&lt;/p&gt;
&lt;p&gt;The learning curve is quick, and there are a lot of experts willing to help you with diligence.  It feels good to do something that might be useful, it’s interesting to do something totally new, and it will make you more optimistic.&lt;/p&gt;
&lt;p&gt;If you make it known to your network that you want to fund efforts working on COVID-19, you’ll get flooded with opportunities.  And it’s always good to invest where the best founders are congregating.&lt;/p&gt;
</description>
<pubDate>Mon, 30 Mar 2020 17:47:43 +0000</pubDate>
<dc:creator>davnicwil</dc:creator>
<og:title>Please Fund More Science</og:title>
<og:type>article</og:type>
<og:url>https://blog.samaltman.com/please-fund-more-science</og:url>
<og:description>Experts on the COVID-19 pandemic seem to think there are three ways out—that is, for life, health, and the economy to return roughly to normal.  Either we get a vaccine good enough that R0 for the...</og:description>
<dc:format>text/html</dc:format>
<dc:identifier>https://blog.samaltman.com/please-fund-more-science</dc:identifier>
</item>
<item>
<title>Amazon, Instacart delivery workers strike for coronavirus protection and pay</title>
<link>https://www.npr.org/2020/03/30/823767492/amazon-instacart-grocery-delivery-workers-strike-for-coronavirus-protection-and-</link>
<guid isPermaLink="true" >https://www.npr.org/2020/03/30/823767492/amazon-instacart-grocery-delivery-workers-strike-for-coronavirus-protection-and-</guid>
<description>&lt;div id=&quot;res823790385&quot; class=&quot;bucketwrap image large&quot;&gt;
&lt;div class=&quot;imagewrap&quot; data-crop-type=&quot;&quot;&gt;&lt;img src=&quot;https://media.npr.org/assets/img/2020/03/30/gettyimages-1207671954-3f78366aae3ce6eab05558d9f8405f695e640733-s1100-c15.jpg&quot; data-original=&quot;https://media.npr.org/assets/img/2020/03/30/gettyimages-1207671954-3f78366aae3ce6eab05558d9f8405f695e640733-s1100.jpg&quot; class=&quot;img lazyOnLoad&quot; alt=&quot;&quot;/&gt;
&lt;/div&gt;
&lt;div class=&quot;credit-caption&quot;&gt;
&lt;div class=&quot;caption-wrap&quot; readability=&quot;8&quot;&gt;
&lt;div class=&quot;caption&quot; aria-label=&quot;Image caption&quot; readability=&quot;11&quot;&gt;
&lt;p&gt;Instacart said it would distribute supplies, including hand sanitizer, to more workers and that it would change some tipping settings. But it didn't address paid sick leave for its contractors. &lt;strong class=&quot;credit&quot; aria-label=&quot;Image credit&quot;&gt;Frederic J. Brown/AFP/Getty Images&lt;/strong&gt; &lt;strong class=&quot;hide-caption&quot;&gt;hide caption&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;strong class=&quot;toggle-caption&quot;&gt;toggle caption&lt;/strong&gt;&lt;/div&gt;
&lt;span class=&quot;credit&quot; aria-label=&quot;Image credit&quot;&gt;Frederic J. Brown/AFP/Getty Images&lt;/span&gt;&lt;/div&gt;
&lt;div class=&quot;enlarge_measure&quot;&gt;
&lt;div class=&quot;img_wrap&quot;&gt;&lt;img data-original=&quot;https://media.npr.org/assets/img/2020/03/30/gettyimages-1207671954-3f78366aae3ce6eab05558d9f8405f695e640733-s1200.jpg&quot; alt=&quot;&quot;/&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;enlarge_html&quot; readability=&quot;7.5&quot;&gt;
&lt;div class=&quot;image_data&quot; readability=&quot;10&quot;&gt;
&lt;p class=&quot;caption&quot;&gt;Instacart said it would distribute supplies, including hand sanitizer, to more workers and that it would change some tipping settings. But it didn't address paid sick leave for its contractors.&lt;/p&gt;
&lt;span class=&quot;credit&quot; aria-label=&quot;Image credit&quot;&gt;Frederic J. Brown/AFP/Getty Images&lt;/span&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Updated at 6:01 p.m. ET&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Some Amazon warehouse workers in Staten Island, N.Y., and Instacart's grocery delivery workers nationwide walked off their jobs on Monday. They are demanding stepped-up protection and pay as they continue to work while much of the country is asked to isolate as a safeguard against the coronavirus.&lt;/p&gt;
&lt;p&gt;The protests come as both Amazon and Instacart &lt;a href=&quot;https://www.npr.org/2020/03/24/820624379/from-grocery-stores-to-pizza-delivery-some-companies-are-on-a-hiring-spree&quot;&gt;have said they plan to hire&lt;/a&gt; tens of thousands of new workers. Online shopping and grocery home delivery are skyrocketing as much of the nation hunkers down and people stay at home, following orders and recommendations from the federal and local governments.&lt;/p&gt;
&lt;p&gt;This has put a spotlight on workers who shop, pack and deliver these high-demand supplies. Companies refer to the workers as &quot;heroes,&quot; but workers say their employers aren't doing enough to keep them safe.&lt;/p&gt;
&lt;p&gt;The workers are asking for a variety of changes:&lt;/p&gt;
&lt;ul class=&quot;edTag&quot;&gt;&lt;li&gt;Workers from both Amazon and Instacart want more access to paid sick time off. At this time, it's available only to those who have tested positive for the coronavirus or get placed on mandatory self-quarantine.&lt;/li&gt;
&lt;li&gt;Amazon workers want their warehouse to be closed for a longer cleaning, with guaranteed pay.&lt;/li&gt;
&lt;li&gt;Instacart's grocery delivery gig workers are asking for disinfectant wipes and hand sanitizer and better pay to offset the risk they are taking.&lt;/li&gt;
&lt;/ul&gt;&lt;aside id=&quot;ad-backstage-wrap&quot; aria-label=&quot;advertisement&quot;&gt;
&lt;/aside&gt;&lt;div id=&quot;res823798947&quot; class=&quot;bucketwrap internallink insettwocolumn inset2col&quot;&gt;
&lt;div class=&quot;bucket img&quot;&gt;&lt;a id=&quot;featuredStackSquareImage820624379&quot; href=&quot;https://www.npr.org/2020/03/24/820624379/from-grocery-stores-to-pizza-delivery-some-companies-are-on-a-hiring-spree&quot; data-metrics=&quot;{&amp;quot;category&amp;quot;:&amp;quot;Story to Story&amp;quot;,&amp;quot;action&amp;quot;:&amp;quot;Click Internal Link&amp;quot;,&amp;quot;label&amp;quot;:&amp;quot;https:\/\/www.npr.org\/2020\/03\/24\/820624379\/from-grocery-stores-to-pizza-delivery-some-companies-are-on-a-hiring-spree&amp;quot;}&quot;&gt;&lt;img src=&quot;https://media.npr.org/assets/img/2020/03/24/ap_20083778568937_sq-e2193583503e48f7acb7779e18d8ef33f78725b9-s100-c15.jpg&quot; data-original=&quot;https://media.npr.org/assets/img/2020/03/24/ap_20083778568937_sq-e2193583503e48f7acb7779e18d8ef33f78725b9-s100.jpg&quot; class=&quot;img lazyOnLoad&quot; alt=&quot;From Grocery Stores To Pizza Delivery, Some Companies Are On A Hiring Spree&quot;/&gt;&lt;/a&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Workers at Amazon's Staten Island facility have said that multiple people at the warehouse have been diagnosed with COVID-19. Some of them plan to walk off the job on Monday to pressure the company to close the warehouse for an extended deep cleaning.&lt;/p&gt;
&lt;p&gt;At Amazon, which employs some 800,000 people, workers have diagnosed positively for COVID-19 in at least 11 warehouses, forcing a prolonged closure of at least &lt;a href=&quot;https://www.npr.org/sections/coronavirus-live-updates/2020/03/26/822045229/amazon-closes-kentucky-warehouse-after-workers-test-positive&quot;&gt;one warehouse in Kentucky&lt;/a&gt;. The company says it has &quot;taken extreme measures to keep people safe,&quot; including allowing unlimited unpaid leave time for employees who feel uncomfortable working.&lt;/p&gt;
&lt;div id=&quot;res823799109&quot; class=&quot;bucketwrap internallink insettwocolumn inset2col&quot;&gt;
&lt;div class=&quot;bucket img&quot;&gt;&lt;a id=&quot;featuredStackSquareImage822045229&quot; href=&quot;https://www.npr.org/sections/coronavirus-live-updates/2020/03/26/822045229/amazon-closes-kentucky-warehouse-after-workers-test-positive&quot; data-metrics=&quot;{&amp;quot;category&amp;quot;:&amp;quot;Story to Story&amp;quot;,&amp;quot;action&amp;quot;:&amp;quot;Click Internal Link&amp;quot;,&amp;quot;label&amp;quot;:&amp;quot;https:\/\/www.npr.org\/sections\/coronavirus-live-updates\/2020\/03\/26\/822045229\/amazon-closes-kentucky-warehouse-after-workers-test-positive&amp;quot;}&quot;&gt;&lt;img src=&quot;https://media.npr.org/assets/img/2020/03/26/rts373r8_sq-e318bc35d153e8c95ec4277c2dac1eb9bbe2090c-s100-c15.jpg&quot; data-original=&quot;https://media.npr.org/assets/img/2020/03/26/rts373r8_sq-e318bc35d153e8c95ec4277c2dac1eb9bbe2090c-s100.jpg&quot; class=&quot;img lazyOnLoad&quot; alt=&quot;Amazon Closes Kentucky Warehouse After Workers Test Positive&quot;/&gt;&lt;/a&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;a href=&quot;https://www.npr.org/sections/coronavirus-live-updates/2020/03/27/822605906/amazon-official-says-company-is-taking-every-precaution-after-workers-test-posit&quot;&gt;Amazon says&lt;/a&gt; its decision on whether to close a warehouse for cleaning or for how long depends on where the sick workers were in the building, for how long, how long ago and other assessments. The company has also &lt;a href=&quot;https://www.npr.org/2020/03/16/816704442/amazon-to-hire-100-000-workers-to-meet-surge-in-demand&quot;&gt;temporarily raised&lt;/a&gt; its pay by $2 an hour through April.&lt;/p&gt;
&lt;p&gt;&quot;I touch over 2,000 different items every day I work there. I have to grab products out of the shelf and put them in the bins. ... And I'm not wearing any protection,&quot; said Terrell Worm, one of the thousands of workers at the Staten Island warehouse. &quot;Amazon says we're all a family there. If they really saw us as family, they'd care about keeping us safe and keeping us home.&quot;&lt;/p&gt;
&lt;p&gt;He says he left work last week an hour after learning of the first confirmed COVID-19 case in the facility, taking advantage of new unpaid leave. But he plans to return next week because he can't afford to remain unpaid.&lt;/p&gt;
&lt;p&gt;Instacart's army of grocery delivery workers are not employees, but independent contractors. They say the company has not provided them with proper protective items like disinfectants, hazard pay of an extra $5 per order and a higher default tip in the settings of the app.&lt;/p&gt;
&lt;div id=&quot;res823799632&quot; class=&quot;bucketwrap internallink insettwocolumn inset2col&quot;&gt;
&lt;div class=&quot;bucket img&quot;&gt;&lt;a id=&quot;featuredStackSquareImage778546287&quot; href=&quot;https://www.npr.org/2019/11/25/778546287/at-the-mercy-of-an-app-workers-feel-the-instacart-squeeze&quot; data-metrics=&quot;{&amp;quot;category&amp;quot;:&amp;quot;Story to Story&amp;quot;,&amp;quot;action&amp;quot;:&amp;quot;Click Internal Link&amp;quot;,&amp;quot;label&amp;quot;:&amp;quot;https:\/\/www.npr.org\/2019\/11\/25\/778546287\/at-the-mercy-of-an-app-workers-feel-the-instacart-squeeze&amp;quot;}&quot;&gt;&lt;img src=&quot;https://media.npr.org/assets/img/2019/11/20/0111919nprinstacart0017_sq-fc785ccde7834e6a82abd1037d89a88d033eed32-s100-c15.jpg&quot; data-original=&quot;https://media.npr.org/assets/img/2019/11/20/0111919nprinstacart0017_sq-fc785ccde7834e6a82abd1037d89a88d033eed32-s100.jpg&quot; class=&quot;img lazyOnLoad&quot; alt=&quot;At The Mercy Of An App: Workers Feel The Instacart Squeeze&quot;/&gt;&lt;/a&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Instacart on Sunday said it would distribute supplies, including hand sanitizer, to more workers and that it would change some tipping settings, but did not address paid sick leave for its contractors.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&quot;&lt;/strong&gt;Actions speak louder than words,&quot; Instacart worker Sarah Polito told NPR. &quot;You can tell us that we're these household heroes and that you appreciate us. But you're not actually, they're not showing it. They're not taking these steps to give us the precautions. They're not giving us hazard pay.&quot;&lt;/p&gt;
&lt;p&gt;It was unclear how many Instacart gig workers participated in Monday's action and refused to work. A spokeswoman for the company said it has seen &quot;absolutely no impact to Instacart's operations.&quot; She said in the last week, 250,000 new people signed up to work through the app and a fifth of them have already started picking up gigs.&lt;/p&gt;
&lt;p&gt;At Amazon, the organizers said some 50 people joined the protest outside of the warehouse. An Amazon representative said only 15 people participated.&lt;/p&gt;
&lt;p&gt;In a statement on Monday, the company said its staff was &quot;tripling down on deep cleaning, procuring safety supplies that are available ... and in Staten Island we are now temperature checking everyone entering the facility.&quot; Amazon has declined to disclose how many workers at the warehouse have tested positive for COVID-19.&lt;/p&gt;
</description>
<pubDate>Mon, 30 Mar 2020 17:04:54 +0000</pubDate>
<dc:creator>onewhonknocks</dc:creator>
<og:title>Amazon, Instacart Grocery Delivery Workers Demand Coronavirus Protection And Pay</og:title>
<og:url>https://www.npr.org/2020/03/30/823767492/amazon-instacart-grocery-delivery-workers-strike-for-coronavirus-protection-and-</og:url>
<og:type>article</og:type>
<og:description>Some Amazon workers in New York and Instacart workers nationwide walked off their jobs Monday. They want more access to paid sick leave as well as protective gear and other safety measures.</og:description>
<og:image>https://media.npr.org/assets/img/2020/03/30/gettyimages-1207671954_wide-382214f906801fcf4e74013b637d082f0d3b6871.jpg?s=1400</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.npr.org/2020/03/30/823767492/amazon-instacart-grocery-delivery-workers-strike-for-coronavirus-protection-and-</dc:identifier>
</item>
<item>
<title>Dutch museum says van Gogh painting stolen in overnight raid</title>
<link>https://news.artnet.com/art-world/thieves-stolen-van-gogh-masterpiece-dutch-museum-1819743</link>
<guid isPermaLink="true" >https://news.artnet.com/art-world/thieves-stolen-van-gogh-masterpiece-dutch-museum-1819743</guid>
<description>&lt;p&gt;&lt;span&gt;Thieves have taken advantage of the distraction provided by the public health situation to steal a prize Vincent van Gogh painting from a museum in the Netherlands. Under cover of darkness, the bandits targeted the Singer Laren museum in Laren, east of Amsterdam, and made off with the Dutch master’s&lt;/span&gt; &lt;em&gt;&lt;span&gt;The Parsonage Garden at Nuenen in Spring &lt;/span&gt;&lt;/em&gt;&lt;span&gt;(1884) while the institution was closed to the public.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;“I am extremely pissed off that this happened,” the museum’s director Jan Rudolph de Lorm &lt;a href=&quot;https://www.youtube.com/watch?v=ssguVU1hw6M&amp;amp;feature=youtu.be&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;said at a press conference&lt;/a&gt; on Monday&lt;/span&gt;&lt;span&gt;. “This is a huge blow. This is extremely difficult, especially in these times.”&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;The break-in at the museum happened in the early hours of Monday morning, at around 3:15 a.m. The thieves smashed a large glass door at the front of the museum to access the building. Police reached the scene after the museum’s alarm was triggered, but the perpetrators had vanished by the time they arrived, according to a statement from the local authorities.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;To add insult to injury, the painting does not even belong to the museum—it was on loan from the Groninger Museum in&lt;/span&gt; &lt;span&gt;Groningen&lt;/span&gt;&lt;span&gt;, the Netherlands, according to the police.&lt;/span&gt; &lt;span&gt;The 1884 work was the only painting by Van Gogh in the Groninger Museum’s collection. It was painted when Van Gogh was living in Neunen, where his father was a pastor, between 1883 and 1885, and depicts the ruins of the village church, which the artist could see from his father’s house. (The date of the theft also happens to be the artist’s birthday: he was born on March 30, 1853.) &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;“The Groninger Museum is shocked by the news,” the museum said in a statement. A spokesperson declined to comment further, citing the police investigation.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Police have launched a criminal investigation and are reviewing security footage and questioning local residents. They have also launched a broader appeal for information and are requesting any security footage captured by other cameras in the neighborhood. Laren is one of the most affluent towns in the Netherlands.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;It is unclear whether anything else was stolen from the Singer Laren’s 3,000-piece collection. The museum was established in 1954 by Anna Singer, the widow of the American painter William Singer, to showcase their collection. It includes works by Dutch artists Jan Toorop, Chris Beekman, and Herman Kruyder, among others. Most Dutch museums shuttered on March 14 in an effort to preserve public health; the Singer Laren museum is closed until June 1. &lt;/span&gt;&lt;/p&gt;
&lt;br/&gt;&lt;em&gt;Follow &lt;a href=&quot;https://www.facebook.com/artnet&quot; target=&quot;_blank&quot;&gt;artnet News&lt;/a&gt; on Facebook:&lt;/em&gt;&lt;br/&gt;&lt;em&gt;&lt;a href=&quot;http://link.artnet.com/join/522/newscta&amp;amp;hash=8e9534fb495110baf97a368037111816&quot; target=&quot;_blank&quot;&gt;Want to stay ahead of the art world? Subscribe to our newsletter to get the breaking news, eye-opening interviews, and incisive critical takes that drive the conversation forward.&lt;/a&gt;&lt;/em&gt;</description>
<pubDate>Mon, 30 Mar 2020 16:30:03 +0000</pubDate>
<dc:creator>danso</dc:creator>
<og:type>article</og:type>
<og:title>Opportunistic Thieves Just Stole a Prized Van Gogh Landscape From a Locked-Down Dutch Museum Under Cover of Night</og:title>
<og:description>A Van Gogh painting was stolen from the Singer Laren museum in the Netherlands in the early hours of Monday morning.</og:description>
<og:url>https://news.artnet.com/art-world/thieves-stolen-van-gogh-masterpiece-dutch-museum-1819743</og:url>
<og:image>https://news.artnet.com/app/news-upload/2020/03/PersPersfotos-los_1200xAUTO_fit_center-center_95_noneVincent-van-Gogh_Lentetuin-de-pastorietuin-te-Nuenen-in-het-voorjaar_Groninger-Museum_HR.png</og:image>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://news.artnet.com/art-world/thieves-stolen-van-gogh-masterpiece-dutch-museum-1819743</dc:identifier>
</item>
<item>
<title>Bosses panic-buy spy software to keep tabs on remote workers</title>
<link>https://www.bloomberg.com/news/features/2020-03-27/bosses-panic-buy-spy-software-to-keep-tabs-on-remote-workers</link>
<guid isPermaLink="true" >https://www.bloomberg.com/news/features/2020-03-27/bosses-panic-buy-spy-software-to-keep-tabs-on-remote-workers</guid>
<description>[unable to retrieve full-text content]
&lt;p&gt;Article URL: &lt;a href=&quot;https://www.bloomberg.com/news/features/2020-03-27/bosses-panic-buy-spy-software-to-keep-tabs-on-remote-workers&quot;&gt;https://www.bloomberg.com/news/features/2020-03-27/bosses-panic-buy-spy-software-to-keep-tabs-on-remote-workers&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Comments URL: &lt;a href=&quot;https://news.ycombinator.com/item?id=22728971&quot;&gt;https://news.ycombinator.com/item?id=22728971&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Points: 428&lt;/p&gt;
&lt;p&gt;# Comments: 319&lt;/p&gt;
</description>
<pubDate>Mon, 30 Mar 2020 15:54:11 +0000</pubDate>
<dc:creator>chatmasta</dc:creator>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.bloomberg.com/tosv2.html?vid=&amp;uuid=27366a20-72eb-11ea-84a6-e5d423ec0cdb&amp;url=L25ld3MvZmVhdHVyZXMvMjAyMC0wMy0yNy9ib3NzZXMtcGFuaWMtYnV5LXNweS1zb2Z0d2FyZS10by1rZWVwLXRhYnMtb24tcmVtb3RlLXdvcmtlcnM=</dc:identifier>
</item>
<item>
<title>Problems with Japan&amp;#039;s Covid-19 reports</title>
<link>https://stdio.sangwhan.com/wtf-japan-covid-19-report/</link>
<guid isPermaLink="true" >https://stdio.sangwhan.com/wtf-japan-covid-19-report/</guid>
<description>&lt;p&gt;These are some thoughts on the daily reports issued by the Japanese Ministry of Health, Labor, and Welfare. I'll be using data from the &lt;a href=&quot;https://www.mhlw.go.jp/stf/newpage_10521.html&quot;&gt;March 27 COVID-19 status report&lt;/a&gt; and the &lt;a href=&quot;https://www.mhlw.go.jp/stf/seisakunitsuite/bunya/newpage_00032.html&quot;&gt;English Version&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Setting aside that these reports seem to be manually written in HTML by a human being (unlike other places that offer a dashboard, e.g. &lt;a href=&quot;http://ncov.mohw.go.kr&quot;&gt;South Korea&lt;/a&gt;) there are some serious issues with this report format. I am writing this on March 29, but I will explain why am I using a report from March 27 at the end.&lt;/p&gt;
&lt;h2 id=&quot;sumswherewearegoingwedontneedsumstowork&quot;&gt;Sums? Where we are going, we don't need sums to work.&lt;/h2&gt;
&lt;p&gt;First, this is the breakdown table at the top of the report. I'm using the version from the English page, for legibility reasons. Here is an illustration of the legibility problem, using a grain of sesame:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://stdio.sangwhan.com/content/images/2020/03/sesame1.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Compare this with a Wikipedia page, with the same sesame grain.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://stdio.sangwhan.com/content/images/2020/03/sesame2.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://stdio.sangwhan.com/content/images/2020/03/000614495.png&quot; alt=&quot;COVID-19 numbers in Japan, March 27 2020&quot;/&gt;&lt;/p&gt;
&lt;p&gt;First problem here is that none of the really important tables here are actually text based tables - &lt;strong&gt;they are images&lt;/strong&gt;. Images with no alt text, hence will give you dead silence if you try to &lt;strong&gt;access the information with a screen reader&lt;/strong&gt;. I won't go into the details why this is bad as that's enough material for a whole new post, but you can read more on this &lt;a href=&quot;https://www.w3.org/WAI/tutorials/images/tips/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;On the other hand, it's extremely detailed, which is nice - but how do these numbers break down? The answer is, not in a very straightforward way.&lt;/p&gt;
&lt;p&gt;So this table, confusingly enough is a quasi-hierarchy. It has these levels:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;Level 1: PCR tested positive, PCR tested&lt;/li&gt;
&lt;li&gt;Level 2: With no symptoms, With symptoms, Under confirmation of the symptom, Death (this is special, see below)&lt;/li&gt;
&lt;li&gt;Level 3: w/Symptoms - Already discharged, w/Symptoms - Need in-patient treatment, w/o Symptoms - Already discharged, w/o Symptoms - Need in-patient treatment&lt;/li&gt;
&lt;li&gt;And so forth.&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;Tested negative is implicit. It's presumably &lt;code&gt;pcr_tested - pcr_tested_positive&lt;/code&gt;. Ideally, &lt;code&gt;pcr_positive&lt;/code&gt; and &lt;code&gt;pcr_negative&lt;/code&gt; would have been level 1, with level 0 being &lt;code&gt;pcr_tested&lt;/code&gt;.&lt;br/&gt;Now confusingly enough, here is how you integrate to get PCR tested positive, which is level 2:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;pcr_tested_positive = with_no_symptoms + with_symptoms + under_confirmation&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Remember to &lt;strong&gt;not&lt;/strong&gt; include death, because this is a quasi-hierarchy. The table tempts you to, but it's excluded. (The quasi-nature is because it is under the PCR tested positive umbrella on level 2.) So what about integrating level 3?&lt;/p&gt;
&lt;p&gt;That's simple. You &lt;strong&gt;don't&lt;/strong&gt;. Because no matter how hard you try, the numbers won't add up. (e.g. Give it a try - you'll end up with 129 != 131 and 1147 != 1191. We'll need &lt;strong&gt;one of these numbers later&lt;/strong&gt;.) Level 4 adds up though, so the plot thickens.&lt;/p&gt;
&lt;p&gt;So, up next - do the rows integrate nicely? Fortunately - yes. Does the breakdown matter to the average joe? Not really. Unless you are a healthcare official, the details really don't matter - the average population only needs to know the summed numbers to be able to compare how bad the situation is with other countries, and how careful they should be when leaving their homes.&lt;/p&gt;
&lt;p&gt;Here is a simplified version I made that shows only what matters to the &lt;strong&gt;average person&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://stdio.sangwhan.com/content/images/2020/03/Screen-Shot-2020-03-29-at-12.33.20-PM.png&quot; alt=&quot;Simplified Japanese COVID-19 Statistics&quot;/&gt;&lt;/p&gt;
&lt;p&gt;According to this data, the positive case mortality rate is around 3.21%.&lt;/p&gt;
&lt;h2 id=&quot;thestatisticallydisappearingghostshippassengers&quot;&gt;The statistically disappearing ghost ship passengers&lt;/h2&gt;
&lt;p&gt;Moving on to the next chart, we can see some interesting patterns here.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://stdio.sangwhan.com/content/images/2020/03/yesterday.png&quot; alt=&quot;Hospitilization and Discharge, dated March 26&quot;/&gt;&lt;/p&gt;
&lt;p&gt;First, there is a new number that was not disclosed in the previous table - 2059, and 672 respectively. So what are these? 2059 is a sum including the cruise ship passengers. Even worse, in the Japanese version even this table is missing - and only provides a separate table with the cruise ship numbers, and &lt;strong&gt;completely omits the summed count&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://stdio.sangwhan.com/content/images/2020/03/cruise.png&quot; alt=&quot;Cruise ship numbers in Japanese page, dated March 26&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Why? Nobody knows. The problem here is that these people are no longer on the ship; and have actually landed on Japanese soil. So the real number of positive cases on Japanese soil is &lt;strong&gt;actually 2059, and not 1387&lt;/strong&gt; as the previous table suggests. It is also worth noting that 603 of the 672 people have been discharged, and &lt;strong&gt;nobody has a slight idea where these people are&lt;/strong&gt; as of today.&lt;/p&gt;
&lt;p&gt;On top of that, &quot;cured&quot; cases reported by the government in press releases (but not this report, so the numbers aren't off by 600 people) &lt;strong&gt;include patients from the cruise ship&lt;/strong&gt;, so if you calculate the ratio of cured to infected, &lt;strong&gt;it's on a different magnitude&lt;/strong&gt;. Number magic! Deaths on the other hand have not been summed, so if you are a Japanese citizen who happened to die of COVID-19 complications after getting off of the Diamond Princess, you have not contributed to the mortality rate. Yay for statistics!&lt;/p&gt;
&lt;p&gt;Moving on to the next nit, there is a bubble that says &quot;from severe to moderate/mild symptoms&quot; with a value next to it, but crossing two cells. What does this mean? Nobody knows, and there is no explanation why it crosses two cells on the page either.&lt;/p&gt;
&lt;p&gt;The previous table, which is dated &quot;12:00, Mar. 27&quot;, this table is dated &quot;18:00 Mar. 26&quot;. That is a 18 hour difference between two adjacent tables - yet the total cases are exactly the same. So either all the hospitals are clocking out exactly at 18:00 and halting all testing, or something is very wrong.&lt;/p&gt;
&lt;h2 id=&quot;lookwoodyinfectedpeopleeverywhereeverywhere&quot;&gt;Look Woody, infected people everywhere. EVERYWHERE.&lt;/h2&gt;
&lt;p&gt;Now, after roughly two screens worth of a information summarized about the local situation, they move on to a &lt;strong&gt;static table&lt;/strong&gt; breakdown of the global situation with &lt;strong&gt;no visualization&lt;/strong&gt;. This section allocates a 53.47% of the vertical pixel real estate of the entire report. Sure, it's useful information - but not in a table which doesn't allow sorting with no plot. Here is the real-estate breakdown visualized:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://stdio.sangwhan.com/content/images/2020/03/Screen-Shot-2020-03-29-at-5.09.19-PM.png&quot; alt=&quot;What the fuck Japan.&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Here is the thing - there are a &lt;a href=&quot;https://www.worldometers.info/coronavirus/&quot;&gt;dozens&lt;/a&gt; &lt;a href=&quot;https://ourworldindata.org/coronavirus&quot;&gt;of&lt;/a&gt; &lt;a href=&quot;https://www.who.int/emergencies/diseases/novel-coronavirus-2019/situation-reports/&quot;&gt;places&lt;/a&gt; &lt;a href=&quot;https://ncov2019.live&quot;&gt;that&lt;/a&gt; &lt;a href=&quot;https://gisanddata.maps.arcgis.com/apps/opsdashboard/index.html#/bda7594740fd40299423467b48e9ecf6&quot;&gt;do&lt;/a&gt; &lt;a href=&quot;https://covid19dashboards.com&quot;&gt;this&lt;/a&gt; &lt;a href=&quot;https://www.kff.org/global-health-policy/fact-sheet/coronavirus-tracker/&quot;&gt;better&lt;/a&gt; than this page, so the citizens here can look them up there. Even if English literacy is not a thing in Japan, I'm sure Ctrl+F and typing a country name in English for specific cases is not rocket science for anyone who has finished mandatory public education. Why they allocate so much space to information very few will read is a mystery - if they really want to, this should probably be a separate post.&lt;/p&gt;
&lt;p&gt;I'm not sure what the intent of this is. Is it to show how terrible the rest of the world is and how great Japan is managing the situation? I don't know.&lt;/p&gt;
&lt;h2 id=&quot;inormallydontsumthingsbutwhenidotheydontaddup&quot;&gt;I normally don't sum things, but when I do - they don't add up.&lt;/h2&gt;
&lt;p&gt;Now, we finally move on to the meat of the report. Local regional breakdowns. Why this is &lt;strong&gt;after the global numbers is beyond me&lt;/strong&gt;, but at this point it seems like anything goes.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://stdio.sangwhan.com/content/images/2020/03/Screen-Shot-2020-03-29-at-1.22.45-PM.png&quot; alt=&quot;Japan regional breakdown, no date disclosed&quot;/&gt;&lt;/p&gt;
&lt;p&gt;The table columns are in the order of municipality, patients, currently in-hospital, discharged, and dead.&lt;/p&gt;
&lt;p&gt;Now to add more consistency to the report, we have yet another unsortable static table. You can also see here that unlike the previous table, it has been sorted by the second column, which is well, consistent with &lt;strong&gt;none&lt;/strong&gt; of the tables we have seen so far - but at this point, who cares.&lt;/p&gt;
&lt;p&gt;This time, the sum of patients &lt;strong&gt;include&lt;/strong&gt; the dead. Try it yourself.&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;227 = 194 + 28 + 5&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;There is no rhyme or reason behind the inconsistencies between the first summary table and the regional breakdown. (Not to mention that none of the tables have matching columns for baseline comparison, because that seemed like a good idea at the time to someone at Kasumigaseki.) There isn't much more to write about here, common sense seems to be a scarce resource to those who have been involved in the report.&lt;/p&gt;
&lt;p&gt;Moving on, here is the grand total.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://stdio.sangwhan.com/content/images/2020/03/Screen-Shot-2020-03-29-at-1.24.49-PM.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Wait, &lt;strong&gt;what&lt;/strong&gt;? Where did &lt;strong&gt;1191&lt;/strong&gt; come from? When is this table from? Well, nobody knows - it's not written anywhere. Let's add those up, like we did on the first row of the same table.&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;828 + 319 + 46 = 1193&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;What?&lt;/p&gt;
&lt;p&gt;What we do know is that this is yet another set of new numbers which don't match up to anything we have seen so far. Or does it? Remember they noted &lt;strong&gt;無症状病原体保有者を除く&lt;/strong&gt; (excluding those who are asymptomatic) above? Well, let's try that - here are some assumptions we will make based on what the government probably was thinking.&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;Awaiting is considered asymptomatic, because that lowers the count. No symptoms, right?&lt;/li&gt;
&lt;li&gt;Asymptomatic is obviously asymptomatic.&lt;/li&gt;
&lt;li&gt;The dead has no symptoms, obviously.&lt;/li&gt;
&lt;li&gt;Remember we pretend the ghost ship passengers don't exist? They don't. They don't exist. Shhh.&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;Ah, but there is 1191, which is the &quot;with symptoms&quot; column sum in the first table, right? But what about awaiting and dead and all of that? Maybe there is another way to compute this.&lt;/p&gt;
&lt;p&gt;After trying a bunch of combinations from the table above, the conclusion is that this number might also come from this function.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://stdio.sangwhan.com/content/images/2020/03/magic.png&quot; alt=&quot;Coefficients used by magic function&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;sum_local = pcr_positive - with_no_symptoms - awaiting_symptoms&lt;/li&gt;
&lt;li&gt;1191 = 1349 - 131 - 27&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;It turns out - this magic function works for all rows. That means the hierarchy is represented in yet another confusing form, but let's not go too deep into that.&lt;/p&gt;
&lt;p&gt;I have no idea what they did about the dead, but the dead do not seem to be part of the equation. Why they chose this particular subset is beyond me.&lt;/p&gt;
&lt;h2 id=&quot;incompetencethatsourscrapeshield&quot;&gt;Incompetence? That's our Scrapeshield.&lt;/h2&gt;
&lt;p&gt;To add insult to injury, if you want to use these reports as a foundation for analysis, you are in for a surprise. (at least I was.)&lt;/p&gt;
&lt;p&gt;Here are some issues that I encountered:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;The report formats constantly seem to change&lt;/li&gt;
&lt;li&gt;Images, as noted above&lt;/li&gt;
&lt;li&gt;No semantics or meaningful selectors in the markup&lt;/li&gt;
&lt;li&gt;Multiple report types&lt;/li&gt;
&lt;li&gt;No URL patterns&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;The reason why I used a two day old report on March 29 is simple, there was no full report yesterday nor today. I'm guessing the Tokyo lockdown means that nobody can get to work, and PCs are too expensive to buy for home use so the people at the Ministry of Health can enjoy a nice weekend with hoarded pasta.&lt;/p&gt;
&lt;p&gt;(4) in particular is interesting - the government releases multiple types of reports, depending on the week of day. Here are the different types: (you can see the full list &lt;a href=&quot;https://www.mhlw.go.jp/stf/houdou/houdou_list_202003.html&quot;&gt;here&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;新型コロナウイルス感染症の現在の状況と厚生労働省の対応について&lt;/strong&gt;: Full report. Only released on weekdays. Summary table, cruise ship table, international table, followed by regional breakdown table.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;新型コロナウイルス感染症の現在の状況について&lt;/strong&gt;: Weekend/public holiday edition. Summary table, cruise ship table, and international table. No local regional breakdown.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;新型コロナウイルスに関連した患者等の発生について&lt;/strong&gt;: Released daily. Least useful, easiest to parse. Contains only a delta of new confirmed cases (no status, like the regional breakdown in the fully report) broke down by region.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;There is still no delta report for today as of now (March 29, 16:16) and as the report release time is not noted on the posts, I'm not sure when to expect it.&lt;/p&gt;
&lt;p&gt;(UPDATE: I see it now, as of 19:30. I'm suspecting the 18:00 timestamp from earlier is probably related to this. Just a guess.)&lt;/p&gt;
&lt;h2 id=&quot;suggestions&quot;&gt;Suggestions&lt;/h2&gt;
&lt;p&gt;So, so far I've been complaining about this report type with no actionable feedback - which is bad. I doubt the Japanese government will read this post and actually take any sensible action, but here are some suggestions.&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;Make two reports. A summary (not more than two pages) report for citizens, and another detailed one for health professionals and formal use.&lt;/li&gt;
&lt;li&gt;Remove the international table. It's not useful to 99% of the audience out there. We have WHO data for that - that's what hyperlinks are for. If you want to do your own international edition (which I believe you should not, considering the quality of your existing reports) please do it as a separate report.&lt;/li&gt;
&lt;li&gt;Accompany reports with the raw data used. Even better, provide a public data feed for people to take away and throw into a tool of their choice - you might get a nice dashboard or trend report for free from someone who is bored enough.&lt;/li&gt;
&lt;li&gt;If you can't do (3), at least add some selectors to your HTML reports that can be used to pull the data out.&lt;/li&gt;
&lt;li&gt;Make the data field availability as consistent as possible. Don't suddenly add and remove fields.&lt;/li&gt;
&lt;li&gt;Make the format of the report and data points available consistent every day.&lt;/li&gt;
&lt;li&gt;Don't invent magic equations. People notice when the numbers don't match up. If you invent an equation, disclose how you ended up with that number.&lt;/li&gt;
&lt;li&gt;Release reports and data regularly, and communicate when this will be and if you cannot communicate that too.&lt;/li&gt;
&lt;li&gt;Make the report URLs predictable, so people can scrape if needed.&lt;/li&gt;
&lt;li&gt;Please consider accessibility when making these reports available. Sure - OCR technology has advanced, but that is not a valid excuse.&lt;/li&gt;
&lt;li&gt;Enough with the bloody PDFs. Tabular data in the worst case can be released as CSV or XLS and nobody will complain. Maybe that grumpy guy who still uses his 25 year old PC-98 might, but f$#k him.&lt;/li&gt;
&lt;/ol&gt;</description>
<pubDate>Mon, 30 Mar 2020 15:17:25 +0000</pubDate>
<dc:creator>hardmaru</dc:creator>
<og:type>article</og:type>
<og:title>Japan's COVID-19 Reports - 140KBs of Unadulterated Incompetence</og:title>
<og:description></og:description>
<og:url>http://stdio.sangwhan.com/wtf-japan-covid-19-report/</og:url>
<og:image>http://stdio.sangwhan.com/content/images/2020/03/Screen-Shot-2020-03-29-at-4.30.49-PM-1.png</og:image>
<dc:format>text/html</dc:format>
<dc:identifier>https://stdio.sangwhan.com/wtf-japan-covid-19-report/</dc:identifier>
</item>
<item>
<title>Open access to ACM Digital Library during coronavirus pandemic</title>
<link>https://www.acm.org/articles/bulletins/2020/march/dl-access-during-covid-19</link>
<guid isPermaLink="true" >https://www.acm.org/articles/bulletins/2020/march/dl-access-during-covid-19</guid>
<description>&lt;h2&gt;March 30, 2020&lt;/h2&gt;
&lt;p&gt;Dear ACM Members:&lt;/p&gt;
&lt;p&gt;As the coronavirus/COVID-19 pandemic continues, we at ACM would like to do what we can to help support the computing community. Many computing researchers and practitioners are now working remotely. In addition, teaching and learning have also moved online as more and more campuses close.&lt;/p&gt;
&lt;p&gt;We believe that ACM can help support research, discovery and learning during this time of crisis by opening the &lt;a href=&quot;https://dl.acm.org&quot; target=&quot;_blank&quot;&gt;ACM Digital Library&lt;/a&gt; to all. For the next three months, there will be no fees assessed for accessing or downloading work published by ACM. We hope this will help researchers, practitioners and students maintain access to our publications as well as increasing visibility and awareness of ACM’s journals, proceedings and magazines. Please be sure to inform your colleagues that the ACM DL is now open, and will continue that way through June 30, 2020.&lt;/p&gt;
&lt;p&gt;This global health crisis is a unique challenge that has impacted many ACM members. We would like to express our concern and support for all who are affected by this outbreak.&lt;/p&gt;
&lt;p&gt;Stay well!&lt;/p&gt;
&lt;p&gt;Cherri Pancake&lt;br/&gt;ACM President&lt;/p&gt;
</description>
<pubDate>Mon, 30 Mar 2020 14:10:47 +0000</pubDate>
<dc:creator>scott_s</dc:creator>
<og:title>Message from ACM Regarding Open Access to ACM Digital Library during Coronavirus</og:title>
<og:description>There will be no fees assessed for accessing or downloading work published by ACM through June 30, 2020.</og:description>
<og:type>website</og:type>
<og:url>https://www.acm.org/articles/bulletins/2020/march/dl-access-during-covid-19</og:url>
<og:image>https://www.acm.org/binaries/content/gallery/acm/ctas/publications/dl-circuit-logo.jpg</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.acm.org/articles/bulletins/2020/march/dl-access-during-covid-19</dc:identifier>
</item>
<item>
<title>For people with an abusive partner, lockdown means captivity</title>
<link>https://www.theguardian.com/commentisfree/2020/mar/30/abusive-partner-lockdown-domestic-abuse-charities-women-home</link>
<guid isPermaLink="true" >https://www.theguardian.com/commentisfree/2020/mar/30/abusive-partner-lockdown-domestic-abuse-charities-women-home</guid>
<description>&lt;p&gt;Alison* is glad the sun came out at the same time the coronavirus lockdown arrived. “I’m spending all day on the balcony to keep away,” she explains. “I’m lucky I have one.”&lt;/p&gt;
&lt;p&gt;Alison’s balcony offers her a small degree of distance from her partner, whose behaviour has become increasingly erratic since the coronavirus crisis began. For the estimated &lt;a href=&quot;https://www.ons.gov.uk/peoplepopulationandcommunity/crimeandjustice/articles/domesticabusevictimcharacteristicsenglandandwales/yearendingmarch2019&quot; data-link-name=&quot;in body link&quot; class=&quot;u-underline&quot;&gt;1.6 million women&lt;/a&gt; who experienced domestic abuse in England and Wales last year, home isn’t a place of safety. Rather than a chance to catch up on a boxset or long delayed DIY project, self isolation for women in coercive or violent relationships means being trapped indoors with your abuser.&lt;/p&gt;
&lt;aside class=&quot;element element-pullquote element--supporting&quot;&gt;&lt;blockquote&gt;
&lt;p class=&quot;pullquote-paragraph&quot;&gt;WomensAid has guidance for staying safe during the outbreak – including a 'silent solution' system for calling 999&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/aside&gt;&lt;p&gt;Alison assures me her partner won’t hurt her. “He’s had these episodes before,” she tells me over a messaging app, referring to bouts of heavy drinking that have intensified since the government introduced social distancing measures. “But he’s the worst I’ve known him for a long time.” She connects her partner’s moods with the pandemic. He “gets angry with me for being super careful about wiping things down and insisting he washes his hands,” she explains. “He thinks I’m being over the top. He’s angry with me for acting like a ‘mad person’, and calls me paranoid. But he’s putting my health at risk, too.”&lt;/p&gt;
&lt;p&gt;Since the outbreak, the charity &lt;a href=&quot;https://www.womankindbristol.org.uk/&quot; data-link-name=&quot;in body link&quot; class=&quot;u-underline&quot;&gt;WomanKind&lt;/a&gt; in Bristol has had a number of new callers. Some have directly referred to the strain of being isolated with their partners for an extended period. The counselling charity Relate has recorded an uptick in enquiries related to the pandemic; 30% of its calls in the week leading up 18 March mentioned coronavirus. Though some of these calls will have been about cancelled appointments rather than relationship issues, charities are concerned the lockdown has left many vulnerable women trapped indoors.&lt;/p&gt;
&lt;p&gt;“In unhappy relationships all the methods people might have incorporated to relieve their distress are not available to them any more,” says Ammanda Major, head of service quality and clinical practice at Relate. “Some people will be connecting with friends online, but that doesn’t take you away physically from the problems in the relationship.”&lt;/p&gt;
&lt;p&gt;There’s nowhere to go when you’re in lockdown. Major is concerned that coercive and violent partners will see this as an opportunity to “up the ante … because they essentially have a captive”.&lt;/p&gt;
&lt;p&gt;The adverse effects of the pandemic is felt most acutely among the vulnerable – the old, the sick, the financially insecure. People trapped in abusive and unhappy relationships also fall into this vulnerable category. Police forces are already reporting domestic abuse cases directly linked to the lockdown. In Avon and Somerset, the police force has reported at &lt;a href=&quot;https://www.theguardian.com/society/2020/mar/26/warning-over-rise-in-uk-domestic-abuse-cases-linked-to-coronavirus?CMP=share_btn_tw&quot; data-link-name=&quot;in body link&quot; class=&quot;u-underline&quot;&gt;20.9% increase&lt;/a&gt; in domestic violence incidents over the last two weeks.&lt;/p&gt;
&lt;p&gt;During normal conditions, victims of domestic abuse can seek help outside the home or at work. Staying with friends might have been an option when things got too difficult. Now, many are stuck in the same space as their abuser. The window for seeking help has narrowed.&lt;/p&gt;
&lt;p&gt;The home secretary, Priti Patel, has &lt;a href=&quot;https://www.independent.co.uk/news/uk/home-news/coronavirus-domestic-abuse-lockdown-priti-patel-a9432646.html&quot; data-link-name=&quot;in body link&quot; class=&quot;u-underline&quot;&gt;confirmed that women can leave&lt;/a&gt; violent households to go to a refuge during the lockdown. The trouble is, after a decade of cuts, many refuges have closed; &lt;a href=&quot;https://labourlist.org/2017/03/jon-trickett-one-in-six-refuges-have-closed-since-2010-the-tories-must-do-more-to-protect-vulnerable-women/&quot; data-link-name=&quot;in body link&quot; class=&quot;u-underline&quot;&gt;one in six&lt;/a&gt; has shut its doors since 2010. A coalition of charitable groups has &lt;a href=&quot;https://www.change.org/p/uk-parliament-domestic-violence-covid-19-the-uk-government-must-act-now-to-save-lives?recruiter=1058198831&amp;amp;recruited_by_id=3b35f4d0-6b7c-11ea-94d6-0551a092b897&amp;amp;utm_source=share_petition&amp;amp;utm_medium=copylink&amp;amp;utm_campaign=petition_dashboard&quot; data-link-name=&quot;in body link&quot; class=&quot;u-underline&quot;&gt;called for an immediate cash injection&lt;/a&gt; to support refuges and domestic violence services during the coronavirus crisis.&lt;/p&gt;
&lt;p&gt;And many services are facing a difficult dilemma: should they close their doors to new arrivals in order to prevent the spread of the virus, or remain open for victims? Some refuge services will have to lock down and stop taking referrals due to the virus . Other domestic violence charities have begun offering &lt;a href=&quot;https://www.independent.co.uk/news/uk/home-news/coronavirus-isolation-domestic-abuse-help-charities-a9407716.html&quot; data-link-name=&quot;in body link&quot; class=&quot;u-underline&quot;&gt;online support&lt;/a&gt; . But for people with controlling partners who monitor internet activity, even seeking help online can be a risk.&lt;/p&gt;
&lt;aside class=&quot;element element-rich-link element--thumbnail element-rich-link--not-upgraded&quot; data-component=&quot;rich-link&quot; data-link-name=&quot;rich-link-1 | 1&quot;&gt;&lt;div class=&quot;rich-link&quot;&gt;
&lt;div class=&quot;rich-link__container&quot;&gt;
&lt;div class=&quot;rich-link__header&quot;&gt;
&lt;h2 class=&quot;rich-link__title&quot;&gt;Lockdowns around the world bring rise in domestic violence&lt;/h2&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/aside&gt;&lt;p&gt;Help is still out there for women enduring domestic abuse. The charity WomensAid has &lt;a href=&quot;https://www.womensaid.org.uk/covid-19-coronavirus-safety-advice-for-survivors/&quot; data-link-name=&quot;in body link&quot; class=&quot;u-underline&quot;&gt;published guidance&lt;/a&gt; for staying safe during the outbreak – including a “silent solution” system for victims who may be afraid of further harm if they’re overheard calling 999. There are things friends and family can do, too, even while social distancing. “If you know you have a friend who is at risk from a partner,” Major says, “see if there is a way you can contact them digitally to check out how they are.”&lt;/p&gt;
&lt;p&gt;“You shouldn’t refer to the fact you think their partner is controlling, because that might put them at risk”, she adds. “But checking in, being there for somebody, it can help that person.”&lt;/p&gt;
&lt;p&gt;Back on her balcony, the strain of managing her partner’s moods has led to Alison “suffering from dreadful anxiety”. Even talking to loved ones feels out of reach – she doesn’t want to worry them at an already anxious time.&lt;/p&gt;
&lt;p&gt;“I really need emotional support,” she says. “It’s breaking my heart.”&lt;/p&gt;
&lt;p&gt;*Names have been changed&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;span class=&quot;bullet&quot;&gt;•&lt;/span&gt; In the UK, the domestic violence helpline is 0808 2000 247. In Australia, the national family violence counselling service is on 1800 737 732. In the US, the domestic violence hotline is 1-800-799-SAFE (7233). Other international helplines can be found at &lt;a href=&quot;https://www.google.com/url?q=http://www.befrienders.org&amp;amp;sa=D&amp;amp;source=hangouts&amp;amp;ust=1526036685643000&amp;amp;usg=AFQjCNFyqd-ltapoSCVoQifKdEVEdHlq-w&quot; data-link-name=&quot;in body link&quot; class=&quot;u-underline&quot;&gt;www.befrienders.org&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;bullet&quot;&gt;•&lt;/span&gt; Sian Norris is a writer and feminist activist&lt;/p&gt;


</description>
<pubDate>Mon, 30 Mar 2020 14:07:47 +0000</pubDate>
<dc:creator>jrwan</dc:creator>
<og:url>http://www.theguardian.com/commentisfree/2020/mar/30/abusive-partner-lockdown-domestic-abuse-charities-women-home</og:url>
<og:description>Social isolation from coronavirus is fuelling a rise in domestic abuse cases - and leading charities to shift their support online, says the writer and activist Sian Norris</og:description>
<og:image>https://i.guim.co.uk/img/media/5b383b41c75562dda9d9fba68f1376c4e0e99dd8/0_136_4080_2448/master/4080.jpg?width=1200&amp;height=630&amp;quality=85&amp;auto=format&amp;fit=crop&amp;overlay-align=bottom%2Cleft&amp;overlay-width=100p&amp;overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctb3BpbmlvbnMucG5n&amp;enable=upscale&amp;s=d64de0c83bafd6ca159e58f8cb841bf4</og:image>
<og:type>article</og:type>
<og:title>For people with an abusive partner, lockdown means captivity | Sian Norris</og:title>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.theguardian.com/commentisfree/2020/mar/30/abusive-partner-lockdown-domestic-abuse-charities-women-home</dc:identifier>
</item>
<item>
<title>Writing an OS in Rust: Async/Await</title>
<link>https://os.phil-opp.com/async-await/</link>
<guid isPermaLink="true" >https://os.phil-opp.com/async-await/</guid>
<description>&lt;aside id=&quot;toc-aside&quot;&gt;&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;https://os.phil-opp.com/async-await/#multitasking&quot;&gt;Multitasking&lt;/a&gt;
&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;https://os.phil-opp.com/async-await/#preemptive-multitasking&quot;&gt;Preemptive Multitasking&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://os.phil-opp.com/async-await/#cooperative-multitasking&quot;&gt;Cooperative Multitasking&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://os.phil-opp.com/async-await/#async-await-in-rust&quot;&gt;Async/Await in Rust&lt;/a&gt;
&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;https://os.phil-opp.com/async-await/#futures&quot;&gt;Futures&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://os.phil-opp.com/async-await/#working-with-futures&quot;&gt;Working with Futures&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://os.phil-opp.com/async-await/#the-async-await-pattern&quot;&gt;The Async/Await Pattern&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://os.phil-opp.com/async-await/#pinning&quot;&gt;Pinning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://os.phil-opp.com/async-await/#executors-and-wakers&quot;&gt;Executors and Wakers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://os.phil-opp.com/async-await/#cooperative-multitasking-1&quot;&gt;Cooperative Multitasking?&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://os.phil-opp.com/async-await/#implementation&quot;&gt;Implementation&lt;/a&gt;
&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;https://os.phil-opp.com/async-await/#task&quot;&gt;Task&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://os.phil-opp.com/async-await/#simple-executor&quot;&gt;Simple Executor&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://os.phil-opp.com/async-await/#async-keyboard-input&quot;&gt;Async Keyboard Input&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://os.phil-opp.com/async-await/#executor-with-waker-support&quot;&gt;Executor with Waker Support&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://os.phil-opp.com/async-await/#summary&quot;&gt;Summary&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://os.phil-opp.com/async-await/#what-s-next&quot;&gt;What's Next?&lt;/a&gt;&lt;/li&gt;

&lt;/ol&gt;&lt;/aside&gt;
&lt;time datetime=&quot;2020-03-27&quot; class=&quot;post-date&quot;&gt;Mar 27, 2020&lt;/time&gt;&lt;p&gt;In this post we explore &lt;em&gt;cooperative multitasking&lt;/em&gt; and the &lt;em&gt;async/await&lt;/em&gt; feature of Rust. We take a detailed look how async/await works in Rust, including the design of the &lt;code&gt;Future&lt;/code&gt; trait, the state machine transformation, and &lt;em&gt;pinning&lt;/em&gt;. We then add basic support for async/await to our kernel by creating an asynchronous keyboard task and a basic executor.&lt;/p&gt;
&lt;span id=&quot;continue-reading&quot;/&gt;
&lt;p&gt;This blog is openly developed on &lt;a href=&quot;https://github.com/phil-opp/blog_os&quot;&gt;GitHub&lt;/a&gt;. If you have any problems or questions, please open an issue there. You can also leave comments &lt;a href=&quot;https://os.phil-opp.com/async-await/#comments&quot;&gt;at the bottom&lt;/a&gt;. The complete source code for this post can be found in the &lt;a href=&quot;https://github.com/phil-opp/blog_os/tree/post-12&quot;&gt;&lt;code&gt;post-12&lt;/code&gt;&lt;/a&gt; branch.&lt;/p&gt;
&lt;div class=&quot;note&quot; readability=&quot;10.556390977444&quot;&gt;
&lt;p&gt;As a personal side note, I'm currently looking for a job in Karlsruhe (Germany) or remote. I would love to do systems programming using Rust, but I'm also open to other opportuni­ties. For more information, see my &lt;a href=&quot;https://www.linkedin.com/in/phil-opp/&quot;&gt;&lt;em&gt;LinkedIn&lt;/em&gt; profile&lt;/a&gt; or contact me at &lt;a href=&quot;mailto:job@phil-opp.com&quot;&gt;job@phil-opp.com&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;details id=&quot;toc-inline&quot;&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;
&lt;/details&gt;&lt;h2 id=&quot;multitasking&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#multitasking&quot; aria-label=&quot;Anchor link for: multitasking&quot;&gt;🔗&lt;/a&gt;Multitasking&lt;/h2&gt;
&lt;p&gt;One of the fundamental features of most operating systems is &lt;a href=&quot;https://en.wikipedia.org/wiki/Computer_multitasking&quot;&gt;&lt;em&gt;multitasking&lt;/em&gt;&lt;/a&gt;, which is the ability to execute multiple tasks concurrently. For example, you probably have other programs open while looking at this post, such as a text editor or a terminal window. Even if you have only a single browser window open, there are probably various background tasks for managing your desktop windows, checking for updates, or indexing files.&lt;/p&gt;
&lt;p&gt;While it seems like all tasks run in parallel, only a single task can be executed on a CPU core at a time. To create the illusion that the tasks run in parallel, the operating system rapidly switches between active tasks so that each one can make a bit of progress. Since computers are fast, we don't notice these switches most of the time.&lt;/p&gt;
&lt;p&gt;While single-core CPUs can only execute a single task at a time, multi-core CPUs can run multiple tasks in a truly parallel way. For example, a CPU with 8 cores can run 8 tasks at the same time. We will explain how to setup multi-core CPUs in a future post. For this post, we will focus on single-core CPUs for simplicity. (It's worth noting that all multi-core CPUs start with only a single active core, so we can treat them as single-core CPUs for now.)&lt;/p&gt;
&lt;p&gt;There are two forms of multitasking: &lt;em&gt;Cooperative&lt;/em&gt; multitasking requires tasks to regularly give up control of the CPU so that other tasks can make progress. &lt;em&gt;Preemptive&lt;/em&gt; multitasking uses operating system functionality to switch threads at arbitrary points in time by forcibly pausing them. In the following we will explore the two forms of multitasking in more detail and discuss their respective advantages and drawbacks.&lt;/p&gt;
&lt;h3 id=&quot;preemptive-multitasking&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#preemptive-multitasking&quot; aria-label=&quot;Anchor link for: preemptive-multitasking&quot;&gt;🔗&lt;/a&gt;Preemptive Multitasking&lt;/h3&gt;
&lt;p&gt;The idea behind preemptive multitasking is that the operating system controls when to switch tasks. For that, it utilizes the fact that it regains control of the CPU on each interrupt. This makes it possible to switch tasks whenever new input is available to the system. For example, it would be possible to switch tasks when the mouse is moved or a network packet arrives. The operating system can also determine the exact time that a task is allowed to run by configuring a hardware timer to send an interrupt after that time.&lt;/p&gt;
&lt;p&gt;The following graphic illustrates the task switching process on a hardware interrupt:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://os.phil-opp.com/async-await/regain-control-on-interrupt.svg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;In the first row, the CPU is executing task &lt;code&gt;A1&lt;/code&gt; of program &lt;code&gt;A&lt;/code&gt;. All other tasks are paused. In the second row, a hardware interrupt arrives at the CPU. As described in the &lt;a href=&quot;https://os.phil-opp.com/hardware-interrupts/&quot;&gt;&lt;em&gt;Hardware Interrupts&lt;/em&gt;&lt;/a&gt; post, the CPU immediately stops the execution of task &lt;code&gt;A1&lt;/code&gt; and jumps to the interrupt handler defined in the interrupt descriptor table (IDT). Through this interrupt handler, the operating system now has control of the CPU again, which allows it to switch to task &lt;code&gt;B1&lt;/code&gt; instead of continuing task &lt;code&gt;A1&lt;/code&gt;.&lt;/p&gt;
&lt;h4 id=&quot;saving-state&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#saving-state&quot; aria-label=&quot;Anchor link for: saving-state&quot;&gt;🔗&lt;/a&gt;Saving State&lt;/h4&gt;
&lt;p&gt;Since tasks are interrupted at arbitrary points in time, they might be in the middle of some calculations. In order to be able to resume them later, the operating system must backup the whole state of the task, including its &lt;a href=&quot;https://en.wikipedia.org/wiki/Call_stack&quot;&gt;call stack&lt;/a&gt; and the values of all CPU registers. This process is called a &lt;a href=&quot;https://en.wikipedia.org/wiki/Context_switch&quot;&gt;&lt;em&gt;context switch&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;As the call stack can be very large, the operating system typically sets up a separate call stack for each task instead of backing up the call stack content on each task switch. Such a task with a separate stack is called a &lt;a href=&quot;https://en.wikipedia.org/wiki/Thread_(computing)&quot;&gt;&lt;em&gt;thread of execution&lt;/em&gt;&lt;/a&gt; or &lt;em&gt;thread&lt;/em&gt; for short. By using a separate stack for each task, only the register contents need to be saved on a context switch (including the program counter and stack pointer). This approach minimizes the performance overhead of a context switch, which is very important since context switches often occur up to 100 times per second.&lt;/p&gt;
&lt;h4 id=&quot;discussion&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#discussion&quot; aria-label=&quot;Anchor link for: discussion&quot;&gt;🔗&lt;/a&gt;Discussion&lt;/h4&gt;
&lt;p&gt;The main advantage of preemptive multitasking is that the operating system can fully control the allowed execution time of a task. This way, it can guarantee that each task gets a fair share of the CPU time, without the need to trust the tasks to cooperate. This is especially important when running third-party tasks or when multiple users share a system.&lt;/p&gt;
&lt;p&gt;The disadvantage of preemption is that each task requires its own stack. Compared to a shared stack, this results in a higher memory usage per task and often limits the number of tasks in the system. Another disadvantage is that the operating system always has to save the complete CPU register state on each task switch, even if the task only used a small subset of the registers.&lt;/p&gt;
&lt;p&gt;Preemptive multitasking and threads are fundamental components of an operating system because they make it possible to run untrusted userspace programs. We will discuss these concepts in full detail in future posts. For this post, however, we will focus on cooperative multitasking, which also provides useful capabilities for our kernel.&lt;/p&gt;
&lt;h3 id=&quot;cooperative-multitasking&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#cooperative-multitasking&quot; aria-label=&quot;Anchor link for: cooperative-multitasking&quot;&gt;🔗&lt;/a&gt;Cooperative Multitasking&lt;/h3&gt;
&lt;p&gt;Instead of forcibly pausing running tasks at arbitrary points in time, cooperative multitasking lets each task run until it voluntarily gives up control of the CPU. This allows tasks to pause themselves at convenient points in time, for example when it needs to wait for an I/O operation anyway.&lt;/p&gt;
&lt;p&gt;Cooperative multitasking is often used at the language level, for example in form of &lt;a href=&quot;https://en.wikipedia.org/wiki/Coroutine&quot;&gt;coroutines&lt;/a&gt; or &lt;a href=&quot;https://rust-lang.github.io/async-book/01_getting_started/04_async_await_primer.html&quot;&gt;async/await&lt;/a&gt;. The idea is that either the programmer or the compiler inserts &lt;a href=&quot;https://en.wikipedia.org/wiki/Yield_(multithreading)&quot;&gt;&lt;em&gt;yield&lt;/em&gt;&lt;/a&gt; operations into the program, which give up control of the CPU and allow other tasks to run. For example, a yield could be inserted after each iteration of a complex loop.&lt;/p&gt;
&lt;p&gt;It is common to combine cooperative multitasking with &lt;a href=&quot;https://en.wikipedia.org/wiki/Asynchronous_I/O&quot;&gt;asynchronous operations&lt;/a&gt;. Instead of waiting until an operation is finished and preventing other tasks to run in this time, asynchronous operations return a &quot;not ready&quot; status if the operation is not finished yet. In this case, the waiting task can execute a yield operation to let other tasks run.&lt;/p&gt;
&lt;h4 id=&quot;saving-state-1&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#saving-state-1&quot; aria-label=&quot;Anchor link for: saving-state-1&quot;&gt;🔗&lt;/a&gt;Saving State&lt;/h4&gt;
&lt;p&gt;Since tasks define their pause points themselves, they don't need the operating system to save their state. Instead, they can save exactly the state they need for continuation before they pause themselves, which often results in better performance. For example, a task that just finished a complex computation might only need to backup the final result of the computation since it does not need the intermediate results anymore.&lt;/p&gt;
&lt;p&gt;Language-supported implementations of cooperative tasks are often even able to backup up the required parts of the call stack before pausing. As an example, Rust's async/await implementation stores all local variables that are still needed in an automatically generated struct (see below). By backing up the relevant parts of the call stack before pausing, all tasks can share a single call stack, which results in a much smaller memory consumption per task. This makes it possible to create an almost arbitrary number of cooperative tasks without running out of memory.&lt;/p&gt;
&lt;h4 id=&quot;discussion-1&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#discussion-1&quot; aria-label=&quot;Anchor link for: discussion-1&quot;&gt;🔗&lt;/a&gt;Discussion&lt;/h4&gt;
&lt;p&gt;The drawback of cooperative multitasking is that an uncooperative task can potentially run for an unlimited amount of time. Thus, a malicious or buggy task can prevent other tasks from running and slow down or even block the whole system. For this reason, cooperative multitasking should only be used when all tasks are known to cooperate. As a counterexample, it's not a good idea to make the operating system rely on the cooperation of arbitrary userlevel programs.&lt;/p&gt;
&lt;p&gt;However, the strong performance and memory benefits of cooperative multitasking make it a good approach for usage &lt;em&gt;within&lt;/em&gt; a program, especially in combination with asynchronous operations. Since an operating system kernel is a performance-critical program that interacts with asynchronous hardware, cooperative multitasking seems like a good approach for implementing concurrency.&lt;/p&gt;
&lt;h2 id=&quot;async-await-in-rust&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#async-await-in-rust&quot; aria-label=&quot;Anchor link for: async-await-in-rust&quot;&gt;🔗&lt;/a&gt;Async/Await in Rust&lt;/h2&gt;
&lt;p&gt;The Rust language provides first-class support for cooperative multitasking in form of async/await. Before we can explore what async/await is and how it works, we need to understand how &lt;em&gt;futures&lt;/em&gt; and asynchronous programming work in Rust.&lt;/p&gt;
&lt;h3 id=&quot;futures&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#futures&quot; aria-label=&quot;Anchor link for: futures&quot;&gt;🔗&lt;/a&gt;Futures&lt;/h3&gt;
&lt;p&gt;A &lt;em&gt;future&lt;/em&gt; represents a value that might not be available yet. This could be for example an integer that is computed by another task or a file that is downloaded from the network. Instead of waiting until the value is available, futures make it possible to continue execution until the value is needed.&lt;/p&gt;
&lt;h4 id=&quot;example&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#example&quot; aria-label=&quot;Anchor link for: example&quot;&gt;🔗&lt;/a&gt;Example&lt;/h4&gt;
&lt;p&gt;The concept of futures is best illustrated with a small example:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://os.phil-opp.com/async-await/async-example.svg&quot; alt=&quot;Sequence diagram: main calls read_file and is blocked until it returns; then it calls foo() and is also blocked until it returns. The same process is repeated, but this time async_read_file is called, which directly returns a future; then foo() is called again, which now runs concurrently to the file load. The file is available before foo() returns.&quot;/&gt;&lt;/p&gt;
&lt;p&gt;This sequence diagram shows a &lt;code&gt;main&lt;/code&gt; function that reads a file from the file system and then calls a function &lt;code&gt;foo&lt;/code&gt;. This process is repeated two times: Once with a synchronous &lt;code&gt;read_file&lt;/code&gt; call and once with an asynchronous &lt;code&gt;async_read_file&lt;/code&gt; call.&lt;/p&gt;
&lt;p&gt;With the synchronous call, the &lt;code&gt;main&lt;/code&gt; function needs to wait until the file is loaded from the file system. Only then it can call the &lt;code&gt;foo&lt;/code&gt; function, which requires it to again wait for the result.&lt;/p&gt;
&lt;p&gt;With the asynchronous &lt;code&gt;async_read_file&lt;/code&gt; call, the file system directly returns a future and loads the file asynchronously in the background. This allows the &lt;code&gt;main&lt;/code&gt; function to call &lt;code&gt;foo&lt;/code&gt; much earlier, which then runs in parallel with the file load. In this example, the file load even finishes before &lt;code&gt;foo&lt;/code&gt; returns, so &lt;code&gt;main&lt;/code&gt; can directly work with the file without further waiting after &lt;code&gt;foo&lt;/code&gt; returns.&lt;/p&gt;
&lt;h4 id=&quot;futures-in-rust&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#futures-in-rust&quot; aria-label=&quot;Anchor link for: futures-in-rust&quot;&gt;🔗&lt;/a&gt;Futures in Rust&lt;/h4&gt;
&lt;p&gt;In Rust, futures are represented by the &lt;a href=&quot;https://doc.rust-lang.org/nightly/core/future/trait.Future.html&quot;&gt;&lt;code&gt;Future&lt;/code&gt;&lt;/a&gt; trait, which looks like this:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;pub trait &lt;/span&gt;&lt;span&gt;Future {
    &lt;/span&gt;&lt;span&gt;type &lt;/span&gt;&lt;span&gt;Output&lt;/span&gt;&lt;span&gt;;
    &lt;/span&gt;&lt;span&gt;fn &lt;/span&gt;&lt;span&gt;poll(self: Pin&amp;lt;&lt;/span&gt;&lt;span&gt;&amp;amp;mut Self&lt;/span&gt;&lt;span&gt;&amp;gt;, cx: &lt;/span&gt;&lt;span&gt;&amp;amp;mut&lt;/span&gt;&lt;span&gt; Context) -&amp;gt; Poll&amp;lt;&lt;/span&gt;&lt;span&gt;Self::&lt;/span&gt;&lt;span&gt;Output&amp;gt;;
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;The &lt;a href=&quot;https://doc.rust-lang.org/book/ch19-03-advanced-traits.html#specifying-placeholder-types-in-trait-definitions-with-associated-types&quot;&gt;associated type&lt;/a&gt; &lt;code&gt;Output&lt;/code&gt; specifies the type of the asynchronous value. For example, the &lt;code&gt;async_read_file&lt;/code&gt; function in the diagram above would return a &lt;code&gt;Future&lt;/code&gt; instance with &lt;code&gt;Output&lt;/code&gt; set to &lt;code&gt;File&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The &lt;a href=&quot;https://doc.rust-lang.org/nightly/core/future/trait.Future.html#tymethod.poll&quot;&gt;&lt;code&gt;poll&lt;/code&gt;&lt;/a&gt; method allows to check if the value is already available. It returns a &lt;a href=&quot;https://doc.rust-lang.org/nightly/core/future/trait.Future.html#tymethod.poll&quot;&gt;&lt;code&gt;Poll&lt;/code&gt;&lt;/a&gt; enum, which looks like this:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;pub enum &lt;/span&gt;&lt;span&gt;Poll&amp;lt;T&amp;gt; {
    Ready(T),
    Pending,
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;When the value is already available (e.g. the file was fully read from disk), it is returned wrapped in the &lt;code&gt;Ready&lt;/code&gt; variant. Otherwise, the &lt;code&gt;Pending&lt;/code&gt; variant is returned, which signals the caller that the value is not yet available.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;poll&lt;/code&gt; method takes two arguments: &lt;code&gt;self: Pin&amp;lt;&amp;amp;mut Self&amp;gt;&lt;/code&gt; and &lt;code&gt;cx: &amp;amp;mut Context&lt;/code&gt;. The former behaves like a normal &lt;code&gt;&amp;amp;mut self&lt;/code&gt; reference, with the difference that the &lt;code&gt;Self&lt;/code&gt; value is &lt;a href=&quot;https://doc.rust-lang.org/nightly/core/pin/index.html&quot;&gt;&lt;em&gt;pinned&lt;/em&gt;&lt;/a&gt; to its memory location. Understanding &lt;code&gt;Pin&lt;/code&gt; and why it is needed is difficult without understanding how async/await works first. We will therefore explain it later in this post.&lt;/p&gt;
&lt;p&gt;The purpose of the &lt;code&gt;cx: &amp;amp;mut Context&lt;/code&gt; parameter is to pass a &lt;a href=&quot;https://doc.rust-lang.org/nightly/core/task/struct.Waker.html&quot;&gt;&lt;code&gt;Waker&lt;/code&gt;&lt;/a&gt; instance to the asynchronous task, e.g. the file system load. This &lt;code&gt;Waker&lt;/code&gt; allows the asynchronous task to signal that it (or a part of it) is finished, e.g. that the file was loaded from disk. Since the main task knows that it will be notified when the &lt;code&gt;Future&lt;/code&gt; is ready, it does not need to call &lt;code&gt;poll&lt;/code&gt; over and over again. We will explain this process in more detail later in this post when we implement our own waker type.&lt;/p&gt;
&lt;h3 id=&quot;working-with-futures&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#working-with-futures&quot; aria-label=&quot;Anchor link for: working-with-futures&quot;&gt;🔗&lt;/a&gt;Working with Futures&lt;/h3&gt;
&lt;p&gt;We now know how futures are defined and understand the basic idea behind the &lt;code&gt;poll&lt;/code&gt; method. However, we still don't know how to effectively work with futures. The problem is that futures represent results of asynchronous tasks, which might be not available yet. In practice, however, we often need these values directly for further calculations. So the question is: How can we efficiently retrieve the value of a future when we need it?&lt;/p&gt;
&lt;h4 id=&quot;waiting-on-futures&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#waiting-on-futures&quot; aria-label=&quot;Anchor link for: waiting-on-futures&quot;&gt;🔗&lt;/a&gt;Waiting on Futures&lt;/h4&gt;
&lt;p&gt;One possible answer is to wait until a future becomes ready. This could look something like this:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;let&lt;/span&gt;&lt;span&gt; future &lt;/span&gt;&lt;span&gt;= &lt;/span&gt;&lt;span&gt;async_read_file(&lt;/span&gt;&lt;span&gt;&quot;foo.txt&quot;&lt;/span&gt;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;let&lt;/span&gt;&lt;span&gt; file_content &lt;/span&gt;&lt;span&gt;= loop &lt;/span&gt;&lt;span&gt;{
    &lt;/span&gt;&lt;span&gt;match&lt;/span&gt;&lt;span&gt; future.poll(…) {
        Poll::Ready(value) &lt;/span&gt;&lt;span&gt;=&amp;gt; break&lt;/span&gt;&lt;span&gt; value,
        Poll::Pending &lt;/span&gt;&lt;span&gt;=&amp;gt; &lt;/span&gt;&lt;span&gt;{}, &lt;/span&gt;&lt;span&gt;// do nothing
    &lt;/span&gt;&lt;span&gt;}
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;Here we &lt;em&gt;actively&lt;/em&gt; wait for the future by calling &lt;code&gt;poll&lt;/code&gt; over and over again in a loop. The arguments to &lt;code&gt;poll&lt;/code&gt; don't matter here, so we omitted them. While this solution works, it is very inefficient because we keep the CPU busy until the value becomes available.&lt;/p&gt;
&lt;p&gt;A more efficient approach could be to &lt;em&gt;block&lt;/em&gt; the current thread until the future becomes available. This is of course only possible if you have threads, so this solution does not work for our kernel, at least not yet. Even on systems where blocking is supported, it is often not desired because it turns an asynchronous task into a synchronous task again, thereby inhibiting the potential performance benefits of parallel tasks.&lt;/p&gt;
&lt;h4 id=&quot;future-combinators&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#future-combinators&quot; aria-label=&quot;Anchor link for: future-combinators&quot;&gt;🔗&lt;/a&gt;Future Combinators&lt;/h4&gt;
&lt;p&gt;An alternative to waiting is to use future combinators. Future combinators are methods like &lt;code&gt;map&lt;/code&gt; that allow chaining and combining futures together, similar to the methods on &lt;a href=&quot;https://doc.rust-lang.org/stable/core/iter/trait.Iterator.html&quot;&gt;&lt;code&gt;Iterator&lt;/code&gt;&lt;/a&gt;. Instead of waiting on the future, these combinators return a future themselves, which applies the mapping operation on &lt;code&gt;poll&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;As an example, a simple &lt;code&gt;string_len&lt;/code&gt; combinator for converting a &lt;code&gt;Future&amp;lt;Output = String&amp;gt;&lt;/code&gt; to a &lt;code&gt;Future&amp;lt;Output = usize&amp;gt;&lt;/code&gt; could look like this:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;struct &lt;/span&gt;&lt;span&gt;StringLen&amp;lt;F&amp;gt; {
    inner_future: F,
}

&lt;/span&gt;&lt;span&gt;impl&lt;/span&gt;&lt;span&gt;&amp;lt;F&amp;gt; Future &lt;/span&gt;&lt;span&gt;for &lt;/span&gt;&lt;span&gt;StringLen&amp;lt;F&amp;gt; &lt;/span&gt;&lt;span&gt;where&lt;/span&gt;&lt;span&gt; F: Future&amp;lt;Output = String&amp;gt; {
    &lt;/span&gt;&lt;span&gt;type &lt;/span&gt;&lt;span&gt;Output &lt;/span&gt;&lt;span&gt;= usize&lt;/span&gt;&lt;span&gt;;

    &lt;/span&gt;&lt;span&gt;fn &lt;/span&gt;&lt;span&gt;poll(&lt;/span&gt;&lt;span&gt;mut &lt;/span&gt;&lt;span&gt;self: Pin&amp;lt;&lt;/span&gt;&lt;span&gt;&amp;amp;mut Self&lt;/span&gt;&lt;span&gt;&amp;gt;, cx: &lt;/span&gt;&lt;span&gt;&amp;amp;mut &lt;/span&gt;&lt;span&gt;Context&amp;lt;'&lt;/span&gt;&lt;span&gt;_&lt;/span&gt;&lt;span&gt;&amp;gt;) -&amp;gt; Poll&amp;lt;T&amp;gt; {
        &lt;/span&gt;&lt;span&gt;match &lt;/span&gt;&lt;span&gt;self.inner_future.poll(cx) {
            Poll::Ready(s) &lt;/span&gt;&lt;span&gt;=&amp;gt; &lt;/span&gt;&lt;span&gt;Poll::Ready(s.len()),
            Poll::Pending &lt;/span&gt;&lt;span&gt;=&amp;gt; &lt;/span&gt;&lt;span&gt;Poll::Pending,
        }
    }
}

&lt;/span&gt;&lt;span&gt;fn &lt;/span&gt;&lt;span&gt;string_len(string: impl Future&amp;lt;Output = String&amp;gt;)
    -&amp;gt; impl Future&amp;lt;Output = &lt;/span&gt;&lt;span&gt;usize&lt;/span&gt;&lt;span&gt;&amp;gt;
{
    StringLen {
        inner_future: string,
    }
}

&lt;/span&gt;&lt;span&gt;// Usage
&lt;/span&gt;&lt;span&gt;fn &lt;/span&gt;&lt;span&gt;file_len() -&amp;gt; impl Future&amp;lt;Output = &lt;/span&gt;&lt;span&gt;usize&lt;/span&gt;&lt;span&gt;&amp;gt; {
    &lt;/span&gt;&lt;span&gt;let&lt;/span&gt;&lt;span&gt; file_content_future &lt;/span&gt;&lt;span&gt;= &lt;/span&gt;&lt;span&gt;async_read_file(&lt;/span&gt;&lt;span&gt;&quot;foo.txt&quot;&lt;/span&gt;&lt;span&gt;);
    string_len(file_content_future)
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;This code does not quite work because it does not handle &lt;a href=&quot;https://doc.rust-lang.org/stable/core/pin/index.html&quot;&gt;&lt;em&gt;pinning&lt;/em&gt;&lt;/a&gt;, but it suffices as an example. The basic idea is that the &lt;code&gt;string_len&lt;/code&gt; function wraps a given &lt;code&gt;Future&lt;/code&gt; instance into a new &lt;code&gt;StringLen&lt;/code&gt; struct, which also implements &lt;code&gt;Future&lt;/code&gt;. When the wrapped future is polled, it polls the inner future. If the value is not ready yet, &lt;code&gt;Poll::Pending&lt;/code&gt; is returned from the wrapped future too. If the value is ready, the string is extracted from the &lt;code&gt;Poll::Ready&lt;/code&gt; variant and its length is calculated. Afterwards, it is wrapped in &lt;code&gt;Poll::Ready&lt;/code&gt; again and returned.&lt;/p&gt;
&lt;p&gt;With this &lt;code&gt;string_len&lt;/code&gt; function, we can calculate the length of an asynchronous string without waiting for it. Since the function returns a &lt;code&gt;Future&lt;/code&gt; again, the caller can't work directly on the returned value, but needs to use combinator functions again. This way, the whole call graph becomes asynchronous and we can efficiently wait for multiple futures at once at some point, e.g. in the main function.&lt;/p&gt;
&lt;p&gt;Manually writing combinator functions is difficult, therefore they are often provided by libraries. While the Rust standard library itself provides no combinator methods yet, the semi-official (and &lt;code&gt;no_std&lt;/code&gt; compatible) &lt;a href=&quot;https://docs.rs/futures/0.3.4/futures/&quot;&gt;&lt;code&gt;futures&lt;/code&gt;&lt;/a&gt; crate does. Its &lt;a href=&quot;https://docs.rs/futures/0.3.4/futures/future/trait.FutureExt.html&quot;&gt;&lt;code&gt;FutureExt&lt;/code&gt;&lt;/a&gt; trait provides high-level combinator methods such as &lt;a href=&quot;https://docs.rs/futures/0.3.4/futures/future/trait.FutureExt.html#method.map&quot;&gt;&lt;code&gt;map&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;https://docs.rs/futures/0.3.4/futures/future/trait.FutureExt.html#method.then&quot;&gt;&lt;code&gt;then&lt;/code&gt;&lt;/a&gt;, which can be used to manipulate the result with arbitrary closures.&lt;/p&gt;
&lt;h5 id=&quot;advantages&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#advantages&quot; aria-label=&quot;Anchor link for: advantages&quot;&gt;🔗&lt;/a&gt;Advantages&lt;/h5&gt;
&lt;p&gt;The big advantage of future combinators is that they keep the operations asynchronous. In combination with asynchronous I/O interfaces, this approach can lead to very high performance. The fact that future combinators are implemented as normal structs with trait implementations allows the compiler to excessively optimize them. For more details, see the &lt;a href=&quot;https://aturon.github.io/blog/2016/08/11/futures/&quot;&gt;&lt;em&gt;Zero-cost futures in Rust&lt;/em&gt;&lt;/a&gt; post, which announced the addition of futures to the Rust ecosystem.&lt;/p&gt;
&lt;h5 id=&quot;drawbacks&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#drawbacks&quot; aria-label=&quot;Anchor link for: drawbacks&quot;&gt;🔗&lt;/a&gt;Drawbacks&lt;/h5&gt;
&lt;p&gt;While future combinators make it possible to write very efficient code, they can be difficult to use in some situations because of the type system and the closure based interface. For example, consider code like this:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;fn &lt;/span&gt;&lt;span&gt;example(min_len: &lt;/span&gt;&lt;span&gt;usize&lt;/span&gt;&lt;span&gt;) -&amp;gt; impl Future&amp;lt;Output = String&amp;gt; {
    async_read_file(&lt;/span&gt;&lt;span&gt;&quot;foo.txt&quot;&lt;/span&gt;&lt;span&gt;).then(&lt;/span&gt;&lt;span&gt;move |&lt;/span&gt;&lt;span&gt;content&lt;/span&gt;&lt;span&gt;| &lt;/span&gt;&lt;span&gt;{
        &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;&lt;span&gt; content.len() &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt; min_len {
            Either::Left(async_read_file(&lt;/span&gt;&lt;span&gt;&quot;bar.txt&quot;&lt;/span&gt;&lt;span&gt;).map(|s| content &lt;/span&gt;&lt;span&gt;+ &amp;amp;&lt;/span&gt;&lt;span&gt;s))
        } &lt;/span&gt;&lt;span&gt;else &lt;/span&gt;&lt;span&gt;{
            Either::Right(future::ready(content))
        }
    })
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;(&lt;a href=&quot;https://play.rust-lang.org/?version=stable&amp;amp;mode=debug&amp;amp;edition=2018&amp;amp;gist=91fc09024eecb2448a85a7ef6a97b8d8&quot;&gt;Try it on the playground&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Here we read the file &lt;code&gt;foo.txt&lt;/code&gt; and then use the &lt;a href=&quot;https://docs.rs/futures/0.3.4/futures/future/trait.FutureExt.html#method.then&quot;&gt;&lt;code&gt;then&lt;/code&gt;&lt;/a&gt; combinator to chain a second future based on the file content. If the content length is smaller than the given &lt;code&gt;min_len&lt;/code&gt;, we read a different &lt;code&gt;bar.txt&lt;/code&gt; file and append it to &lt;code&gt;content&lt;/code&gt; using the &lt;a href=&quot;https://docs.rs/futures/0.3.4/futures/future/trait.FutureExt.html#method.map&quot;&gt;&lt;code&gt;map&lt;/code&gt;&lt;/a&gt; combinator. Otherwise we return only the content of &lt;code&gt;foo.txt&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;We need to use the &lt;a href=&quot;https://doc.rust-lang.org/std/keyword.move.html&quot;&gt;&lt;code&gt;move&lt;/code&gt; keyword&lt;/a&gt; for the closure passed to &lt;code&gt;then&lt;/code&gt; because otherwise there would be a lifetime error for &lt;code&gt;min_len&lt;/code&gt;. The reason for the &lt;a href=&quot;https://docs.rs/futures/0.3.4/futures/future/enum.Either.html&quot;&gt;&lt;code&gt;Either&lt;/code&gt;&lt;/a&gt; wrapper is that if and else blocks must always have the same type. Since we return different future types in the blocks, we must use the wrapper type to unify them into a single type. The &lt;a href=&quot;https://docs.rs/futures/0.3.4/futures/future/fn.ready.html&quot;&gt;&lt;code&gt;ready&lt;/code&gt;&lt;/a&gt; function wraps a value into a future, which is immediately ready. The function is required here because the &lt;code&gt;Either&lt;/code&gt; wrapper expects that the wrapped value implements &lt;code&gt;Future&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;As you can imagine, this can quickly lead to very complex code for larger projects. It gets especially complicated if borrowing and different lifetimes are involved. For this reason, a lot of work was invested to add support for async/await to Rust, with the goal of making asynchronous code radically simpler to write.&lt;/p&gt;
&lt;h3 id=&quot;the-async-await-pattern&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#the-async-await-pattern&quot; aria-label=&quot;Anchor link for: the-async-await-pattern&quot;&gt;🔗&lt;/a&gt;The Async/Await Pattern&lt;/h3&gt;
&lt;p&gt;The idea behind async/await is to let the programmer write code that &lt;em&gt;looks&lt;/em&gt; like normal synchronous code, but is turned into asynchronous code by the compiler. It works based on the two keywords &lt;code&gt;async&lt;/code&gt; and &lt;code&gt;await&lt;/code&gt;. The &lt;code&gt;async&lt;/code&gt; keyword can be used in a function signature to turn a synchronous function into an asynchronous function that returns a future:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;async &lt;/span&gt;&lt;span&gt;fn &lt;/span&gt;&lt;span&gt;foo() -&amp;gt; &lt;/span&gt;&lt;span&gt;u32 &lt;/span&gt;&lt;span&gt;{
    &lt;/span&gt;&lt;span&gt;0
&lt;/span&gt;&lt;span&gt;}

&lt;/span&gt;&lt;span&gt;// the above is roughly translated by the compiler to:
&lt;/span&gt;&lt;span&gt;fn &lt;/span&gt;&lt;span&gt;foo() -&amp;gt; impl Future&amp;lt;Output = &lt;/span&gt;&lt;span&gt;u32&lt;/span&gt;&lt;span&gt;&amp;gt; {
    future::ready(&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;)
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;This keyword alone wouldn't be that useful. However, inside &lt;code&gt;async&lt;/code&gt; functions, the &lt;code&gt;await&lt;/code&gt; keyword can be used to retrieve the asynchronous value of a future:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;async &lt;/span&gt;&lt;span&gt;fn &lt;/span&gt;&lt;span&gt;example(min_len: &lt;/span&gt;&lt;span&gt;usize&lt;/span&gt;&lt;span&gt;) -&amp;gt; String {
    &lt;/span&gt;&lt;span&gt;let&lt;/span&gt;&lt;span&gt; content &lt;/span&gt;&lt;span&gt;= &lt;/span&gt;&lt;span&gt;async_read_file(&lt;/span&gt;&lt;span&gt;&quot;foo.txt&quot;&lt;/span&gt;&lt;span&gt;).await;
    &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;&lt;span&gt; content.len() &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt; min_len {
        content &lt;/span&gt;&lt;span&gt;+ &amp;amp;&lt;/span&gt;&lt;span&gt;async_read_file(&lt;/span&gt;&lt;span&gt;&quot;bar.txt&quot;&lt;/span&gt;&lt;span&gt;).await
    } &lt;/span&gt;&lt;span&gt;else &lt;/span&gt;&lt;span&gt;{
        content
    }
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;(&lt;a href=&quot;https://play.rust-lang.org/?version=stable&amp;amp;mode=debug&amp;amp;edition=2018&amp;amp;gist=d93c28509a1c67661f31ff820281d434&quot;&gt;Try it on the playground&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;This function is a direct translation of the &lt;code&gt;example&lt;/code&gt; function that used combinator functions from &lt;a href=&quot;https://os.phil-opp.com/async-await/#drawbacks&quot;&gt;above&lt;/a&gt;. Using the &lt;code&gt;.await&lt;/code&gt; operator, we can retrieve the value of a future without needing any closures or &lt;code&gt;Either&lt;/code&gt; types. As a result, we can write our code like we write normal synchronous code, with the difference that &lt;em&gt;this is still asynchronous code&lt;/em&gt;.&lt;/p&gt;
&lt;h4 id=&quot;state-machine-transformation&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#state-machine-transformation&quot; aria-label=&quot;Anchor link for: state-machine-transformation&quot;&gt;🔗&lt;/a&gt;State Machine Transformation&lt;/h4&gt;
&lt;p&gt;What the compiler does behind this scenes is to transform the body of the &lt;code&gt;async&lt;/code&gt; function into a &lt;a href=&quot;https://en.wikipedia.org/wiki/Finite-state_machine&quot;&gt;&lt;em&gt;state machine&lt;/em&gt;&lt;/a&gt;, with each &lt;code&gt;.await&lt;/code&gt; call representing a different state. For the above &lt;code&gt;example&lt;/code&gt; function, the compiler creates a state machine with the following four states:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://os.phil-opp.com/async-await/async-state-machine-states.svg&quot; alt=&quot;Four states: start, waiting on foo.txt, waiting on bar.txt, end&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Each state represents a different pause point of the function. The &lt;em&gt;&quot;Start&quot;&lt;/em&gt; and &lt;em&gt;&quot;End&quot;&lt;/em&gt; states represent the function at the beginning and end of its execution. The &lt;em&gt;&quot;Waiting on foo.txt&quot;&lt;/em&gt; state represents that the function is currently waiting for the first &lt;code&gt;async_read_file&lt;/code&gt; result. Similarly, the &lt;em&gt;&quot;Waiting on bar.txt&quot;&lt;/em&gt; state represents the pause point where the function is waiting on the second &lt;code&gt;async_read_file&lt;/code&gt; result.&lt;/p&gt;
&lt;p&gt;The state machine implements the &lt;code&gt;Future&lt;/code&gt; trait by making each &lt;code&gt;poll&lt;/code&gt; call a possible state transition:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://os.phil-opp.com/async-await/async-state-machine-basic.svg&quot; alt=&quot;Four states: start, waiting on foo.txt, waiting on bar.txt, end&quot;/&gt;&lt;/p&gt;
&lt;p&gt;The diagram uses arrows to represent state switches and diamond shapes to represent alternative ways. For example, if the &lt;code&gt;foo.txt&lt;/code&gt; file is not ready, the path marked with &lt;em&gt;&quot;no&quot;&lt;/em&gt; is taken and the &lt;em&gt;&quot;Waiting on foo.txt&quot;&lt;/em&gt; state is reached. Otherwise, the &lt;em&gt;&quot;yes&quot;&lt;/em&gt; path is taken. The small red diamond without caption represents the &lt;code&gt;if content.len() &amp;lt; 100&lt;/code&gt; branch of the &lt;code&gt;example&lt;/code&gt; function.&lt;/p&gt;
&lt;p&gt;We see that the first &lt;code&gt;poll&lt;/code&gt; call starts the function and lets it run until it reaches a future that is not ready yet. If all futures on the path are ready, the function can run till the &lt;em&gt;&quot;End&quot;&lt;/em&gt; state, where it returns its result wrapped in &lt;code&gt;Poll::Ready&lt;/code&gt;. Otherwise, the state machine enters a waiting state and returns &lt;code&gt;Poll::Pending&lt;/code&gt;. On the next &lt;code&gt;poll&lt;/code&gt; call, the state machine then starts from the last waiting state and retries the last operation.&lt;/p&gt;
&lt;h4 id=&quot;saving-state-2&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#saving-state-2&quot; aria-label=&quot;Anchor link for: saving-state-2&quot;&gt;🔗&lt;/a&gt;Saving State&lt;/h4&gt;
&lt;p&gt;In order to be able to continue from the last waiting state, the state machine must keep track of the current state internally. In addition, it must save all the variables that it needs to continue execution on the next &lt;code&gt;poll&lt;/code&gt; call. This is where the compiler can really shine: Since it knows which variables are used when, it can automatically generate structs with exactly the variables that are needed.&lt;/p&gt;
&lt;p&gt;As an example, the compiler generates structs like the following for the above &lt;code&gt;example&lt;/code&gt; function:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;// The `example` function again so that you don't have to scroll up
&lt;/span&gt;&lt;span&gt;async &lt;/span&gt;&lt;span&gt;fn &lt;/span&gt;&lt;span&gt;example(min_len: &lt;/span&gt;&lt;span&gt;usize&lt;/span&gt;&lt;span&gt;) -&amp;gt; String {
    &lt;/span&gt;&lt;span&gt;let&lt;/span&gt;&lt;span&gt; content &lt;/span&gt;&lt;span&gt;= &lt;/span&gt;&lt;span&gt;async_read_file(&lt;/span&gt;&lt;span&gt;&quot;foo.txt&quot;&lt;/span&gt;&lt;span&gt;).await;
    &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;&lt;span&gt; content.len() &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt; min_len {
        content &lt;/span&gt;&lt;span&gt;+ &amp;amp;&lt;/span&gt;&lt;span&gt;async_read_file(&lt;/span&gt;&lt;span&gt;&quot;bar.txt&quot;&lt;/span&gt;&lt;span&gt;).await
    } &lt;/span&gt;&lt;span&gt;else &lt;/span&gt;&lt;span&gt;{
        content
    }
}

&lt;/span&gt;&lt;span&gt;// The compiler-generated state structs:

&lt;/span&gt;&lt;span&gt;struct &lt;/span&gt;&lt;span&gt;StartState {
    min_len: &lt;/span&gt;&lt;span&gt;usize&lt;/span&gt;&lt;span&gt;,
}

&lt;/span&gt;&lt;span&gt;struct &lt;/span&gt;&lt;span&gt;WaitingOnFooTxtState {
    min_len: &lt;/span&gt;&lt;span&gt;usize&lt;/span&gt;&lt;span&gt;,
    foo_txt_future: impl Future&amp;lt;Output = String&amp;gt;,
}

&lt;/span&gt;&lt;span&gt;struct &lt;/span&gt;&lt;span&gt;WaitingOnBarTxtState {
    content: String,
    bar_txt_future: impl Future&amp;lt;Output = String&amp;gt;,
}

&lt;/span&gt;&lt;span&gt;struct &lt;/span&gt;&lt;span&gt;EndState {}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;In the &quot;start&quot; and &lt;em&gt;&quot;Waiting on foo.txt&quot;&lt;/em&gt; states, the &lt;code&gt;min_len&lt;/code&gt; parameter needs to be stored because it is required for the comparison with &lt;code&gt;content.len()&lt;/code&gt; later. The &lt;em&gt;&quot;Waiting on foo.txt&quot;&lt;/em&gt; state additionally stores a &lt;code&gt;foo_txt_future&lt;/code&gt;, which represents the future returned by the &lt;code&gt;async_read_file&lt;/code&gt; call. This future needs to be polled again when the state machine continues, so it needs to be saved.&lt;/p&gt;
&lt;p&gt;The &lt;em&gt;&quot;Waiting on bar.txt&quot;&lt;/em&gt; state contains the &lt;code&gt;content&lt;/code&gt; variable because it is needed for the string concatenation after &lt;code&gt;bar.txt&lt;/code&gt; is ready. It also stores a &lt;code&gt;bar_txt_future&lt;/code&gt; that represents the in-progress load of &lt;code&gt;bar.txt&lt;/code&gt;. The struct does not contain the &lt;code&gt;min_len&lt;/code&gt; variable because it is no longer needed after the &lt;code&gt;content.len()&lt;/code&gt; comparison. In the &lt;em&gt;&quot;end&quot;&lt;/em&gt; state, no variables are stored because the function did already run to completion.&lt;/p&gt;
&lt;p&gt;Keep in mind that this is only an example for the code that the compiler could generate. The struct names and the field layout are an implementation detail and might be different.&lt;/p&gt;
&lt;h4 id=&quot;the-full-state-machine-type&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#the-full-state-machine-type&quot; aria-label=&quot;Anchor link for: the-full-state-machine-type&quot;&gt;🔗&lt;/a&gt;The Full State Machine Type&lt;/h4&gt;
&lt;p&gt;While the exact compiler-generated code is an implementation detail, it helps in understanding to imagine how the generated state machine &lt;em&gt;could&lt;/em&gt; look for the &lt;code&gt;example&lt;/code&gt; function. We already defined the structs representing the different states and containing the required variables. To create a state machine on top of them, we can combine them into an &lt;a href=&quot;https://doc.rust-lang.org/book/ch06-01-defining-an-enum.html&quot;&gt;&lt;code&gt;enum&lt;/code&gt;&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;enum &lt;/span&gt;&lt;span&gt;ExampleStateMachine {
    Start(StartState),
    WaitingOnFooTxt(WaitingOnFooTxtState),
    WaitingOnBarTxt(WaitingOnBarTxtState),
    End(EndState),
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;We define a separate enum variant for each state and add the corresponding state struct to each variant as a field. To implement the state transitions, the compiler generates an implementation of the &lt;code&gt;Future&lt;/code&gt; trait based on the &lt;code&gt;example&lt;/code&gt; function:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;impl &lt;/span&gt;&lt;span&gt;Future &lt;/span&gt;&lt;span&gt;for &lt;/span&gt;&lt;span&gt;ExampleStateMachine {
    &lt;/span&gt;&lt;span&gt;type &lt;/span&gt;&lt;span&gt;Output &lt;/span&gt;&lt;span&gt;= &lt;/span&gt;&lt;span&gt;String; &lt;/span&gt;&lt;span&gt;// return type of `example`

    &lt;/span&gt;&lt;span&gt;fn &lt;/span&gt;&lt;span&gt;poll(self: Pin&amp;lt;&lt;/span&gt;&lt;span&gt;&amp;amp;mut Self&lt;/span&gt;&lt;span&gt;&amp;gt;, cx: &lt;/span&gt;&lt;span&gt;&amp;amp;mut&lt;/span&gt;&lt;span&gt; Context) -&amp;gt; Poll&amp;lt;&lt;/span&gt;&lt;span&gt;Self::&lt;/span&gt;&lt;span&gt;Output&amp;gt; {
        &lt;/span&gt;&lt;span&gt;loop &lt;/span&gt;&lt;span&gt;{
            &lt;/span&gt;&lt;span&gt;match &lt;/span&gt;&lt;span&gt;self { &lt;/span&gt;&lt;span&gt;// TODO: handle pinning
                &lt;/span&gt;&lt;span&gt;ExampleStateMachine::Start(state) &lt;/span&gt;&lt;span&gt;=&amp;gt; &lt;/span&gt;&lt;span&gt;{…}
                ExampleStateMachine::WaitingOnFooTxt(state) &lt;/span&gt;&lt;span&gt;=&amp;gt; &lt;/span&gt;&lt;span&gt;{…}
                ExampleStateMachine::WaitingOnBarTxt(state) &lt;/span&gt;&lt;span&gt;=&amp;gt; &lt;/span&gt;&lt;span&gt;{…}
                ExampleStateMachine::End(state) &lt;/span&gt;&lt;span&gt;=&amp;gt; &lt;/span&gt;&lt;span&gt;{…}
            }
        }
    }
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;Output&lt;/code&gt; type of the future is &lt;code&gt;String&lt;/code&gt; because it's the return type of the &lt;code&gt;example&lt;/code&gt; function. To implement the &lt;code&gt;poll&lt;/code&gt; function, we use a match statement on the current state inside a &lt;code&gt;loop&lt;/code&gt;. The idea is that we switch to the next state as long as possible and use an explicit &lt;code&gt;return Poll::Pending&lt;/code&gt; when we can't continue.&lt;/p&gt;
&lt;p&gt;For simplicity, we only show simplified code and don't handle &lt;a href=&quot;https://doc.rust-lang.org/stable/core/pin/index.html&quot;&gt;pinning&lt;/a&gt;, ownership, lifetimes, etc. So this and the following code should be treated as pseudo-code and not used directly. Of course, the real compiler-generated code handles everything correctly, albeit possibly in a different way.&lt;/p&gt;
&lt;p&gt;To keep the code excerpts small, we present the code for each match arm separately. Let's begin with the &lt;code&gt;Start&lt;/code&gt; state:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;ExampleStateMachine::Start(state) &lt;/span&gt;&lt;span&gt;=&amp;gt; &lt;/span&gt;&lt;span&gt;{
    &lt;/span&gt;&lt;span&gt;// from body of `example`
    &lt;/span&gt;&lt;span&gt;let&lt;/span&gt;&lt;span&gt; foo_txt_future &lt;/span&gt;&lt;span&gt;= &lt;/span&gt;&lt;span&gt;async_read_file(&lt;/span&gt;&lt;span&gt;&quot;foo.txt&quot;&lt;/span&gt;&lt;span&gt;);
    &lt;/span&gt;&lt;span&gt;// `.await` operation
    &lt;/span&gt;&lt;span&gt;let&lt;/span&gt;&lt;span&gt; state &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; WaitingOnFooTxtState {
        min_len: state.min_len,
        foo_txt_future,
    };
    &lt;/span&gt;&lt;span&gt;*&lt;/span&gt;&lt;span&gt;self &lt;/span&gt;&lt;span&gt;= &lt;/span&gt;&lt;span&gt;ExampleStateMachine::WaitingOnFooTxt(state);
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;The state machine is in the &lt;code&gt;Start&lt;/code&gt; state when it is right at the beginning of the function. In this case, we execute all the code from the body of the &lt;code&gt;example&lt;/code&gt; function until the first &lt;code&gt;.await&lt;/code&gt;. To handle the &lt;code&gt;.await&lt;/code&gt; operation, we change the state of the &lt;code&gt;self&lt;/code&gt; state machine to &lt;code&gt;WaitingOnFooTxt&lt;/code&gt;, which includes the construction of the &lt;code&gt;WaitingOnFooTxtState&lt;/code&gt; struct.&lt;/p&gt;
&lt;p&gt;Since the &lt;code&gt;match self {…}&lt;/code&gt; statement is executed in a loop, the execution jumps to the &lt;code&gt;WaitingOnFooTxt&lt;/code&gt; arm next:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;ExampleStateMachine::WaitingOnFooTxt(state) &lt;/span&gt;&lt;span&gt;=&amp;gt; &lt;/span&gt;&lt;span&gt;{
    &lt;/span&gt;&lt;span&gt;match&lt;/span&gt;&lt;span&gt; state.foo_txt_future.poll(cx) {
        Poll::Pending &lt;/span&gt;&lt;span&gt;=&amp;gt; return &lt;/span&gt;&lt;span&gt;Poll::Pending,
        Poll::Ready(content) &lt;/span&gt;&lt;span&gt;=&amp;gt; &lt;/span&gt;&lt;span&gt;{
            &lt;/span&gt;&lt;span&gt;// from body of `example`
            &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;&lt;span&gt; content.len() &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt; state.min_len {
                &lt;/span&gt;&lt;span&gt;let&lt;/span&gt;&lt;span&gt; bar_txt_future &lt;/span&gt;&lt;span&gt;= &lt;/span&gt;&lt;span&gt;async_read_file(&lt;/span&gt;&lt;span&gt;&quot;bar.txt&quot;&lt;/span&gt;&lt;span&gt;);
                &lt;/span&gt;&lt;span&gt;// `.await` operation
                &lt;/span&gt;&lt;span&gt;let&lt;/span&gt;&lt;span&gt; state &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; WaitingOnBarTxtState {
                    content,
                    bar_txt_future,
                };
                &lt;/span&gt;&lt;span&gt;*&lt;/span&gt;&lt;span&gt;self &lt;/span&gt;&lt;span&gt;= &lt;/span&gt;&lt;span&gt;ExampleStateMachine::WaitingOnBarTxt(state);
            } &lt;/span&gt;&lt;span&gt;else &lt;/span&gt;&lt;span&gt;{
                &lt;/span&gt;&lt;span&gt;*&lt;/span&gt;&lt;span&gt;self &lt;/span&gt;&lt;span&gt;= &lt;/span&gt;&lt;span&gt;ExampleStateMachine::End(EndState));
                &lt;/span&gt;&lt;span&gt;return &lt;/span&gt;&lt;span&gt;Poll::Ready(content);
            }
        }
    }
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;In this match arm we first call the &lt;code&gt;poll&lt;/code&gt; function of the &lt;code&gt;foo_txt_future&lt;/code&gt;. If it is not ready, we exit the loop and return &lt;code&gt;Poll::Pending&lt;/code&gt;. Since &lt;code&gt;self&lt;/code&gt; stays in the &lt;code&gt;WaitingOnFooTxt&lt;/code&gt; state in this case, the next &lt;code&gt;poll&lt;/code&gt; call on the state machine will enter the same match arm and retry polling the &lt;code&gt;foo_txt_future&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;When the &lt;code&gt;foo_txt_future&lt;/code&gt; is ready, we assign the result to the &lt;code&gt;content&lt;/code&gt; variable and continue to execute the code of the &lt;code&gt;example&lt;/code&gt; function: If &lt;code&gt;content.len()&lt;/code&gt; is smaller than the &lt;code&gt;min_len&lt;/code&gt; saved in the state struct, the &lt;code&gt;bar.txt&lt;/code&gt; file is read asynchronously. We again translate the &lt;code&gt;.await&lt;/code&gt; operation into a state change, this time into the &lt;code&gt;WaitingOnBarTxt&lt;/code&gt; state. Since we're executing the &lt;code&gt;match&lt;/code&gt; inside a loop, the execution directly jumps to the match arm for the new state afterwards, where the &lt;code&gt;bar_txt_future&lt;/code&gt; is polled.&lt;/p&gt;
&lt;p&gt;In case we enter the &lt;code&gt;else&lt;/code&gt; branch, no further &lt;code&gt;.await&lt;/code&gt; operation occurs. We reach the end of the function and return &lt;code&gt;content&lt;/code&gt; wrapped in &lt;code&gt;Poll::Ready&lt;/code&gt;. We also change the current state to the &lt;code&gt;End&lt;/code&gt; state.&lt;/p&gt;
&lt;p&gt;The code for the &lt;code&gt;WaitingOnBarTxt&lt;/code&gt; state looks like this:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;ExampleStateMachine::WaitingOnBarTxt(state) &lt;/span&gt;&lt;span&gt;=&amp;gt; &lt;/span&gt;&lt;span&gt;{
    &lt;/span&gt;&lt;span&gt;match&lt;/span&gt;&lt;span&gt; state.bar_txt_future.poll(cx) {
        Poll::Pending &lt;/span&gt;&lt;span&gt;=&amp;gt; return &lt;/span&gt;&lt;span&gt;Poll::Pending,
        Poll::Ready(bar_txt) &lt;/span&gt;&lt;span&gt;=&amp;gt; &lt;/span&gt;&lt;span&gt;{
            &lt;/span&gt;&lt;span&gt;*&lt;/span&gt;&lt;span&gt;self &lt;/span&gt;&lt;span&gt;= &lt;/span&gt;&lt;span&gt;ExampleStateMachine::End(EndState));
            &lt;/span&gt;&lt;span&gt;// from body of `example`
            &lt;/span&gt;&lt;span&gt;return &lt;/span&gt;&lt;span&gt;Poll::Ready(state.content &lt;/span&gt;&lt;span&gt;+ &amp;amp;&lt;/span&gt;&lt;span&gt;bar_txt);
        }
    }
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;Similar to the &lt;code&gt;WaitingOnFooTxt&lt;/code&gt; state, we start by polling the &lt;code&gt;bar_txt_future&lt;/code&gt;. If it is still pending, we exit the loop and return &lt;code&gt;Poll::Pending&lt;/code&gt;. Otherwise, we can perform the last operation of the &lt;code&gt;example&lt;/code&gt; function: Concatenating the &lt;code&gt;content&lt;/code&gt; variable with the result from the future. We update the state machine to the &lt;code&gt;End&lt;/code&gt; state and then return the result wrapped in &lt;code&gt;Poll::Ready&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Finally, the code for the &lt;code&gt;End&lt;/code&gt; state looks like this:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;ExampleStateMachine::End(&lt;/span&gt;&lt;span&gt;_&lt;/span&gt;&lt;span&gt;) &lt;/span&gt;&lt;span&gt;=&amp;gt; &lt;/span&gt;&lt;span&gt;{
    panic!(&lt;/span&gt;&lt;span&gt;&quot;poll called after Poll::Ready was returned&quot;&lt;/span&gt;&lt;span&gt;);
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;Futures should not be polled again after they returned &lt;code&gt;Poll::Ready&lt;/code&gt;, therefore we panic if &lt;code&gt;poll&lt;/code&gt; is called when we are already in the &lt;code&gt;End&lt;/code&gt; state.&lt;/p&gt;
&lt;p&gt;We now know how the compiler-generated state machine and its implementation of the &lt;code&gt;Future&lt;/code&gt; trait &lt;em&gt;could&lt;/em&gt; look like. In practice, the compiler generates code in different way. (In case you're interested, the implementation is currently based on &lt;a href=&quot;https://doc.rust-lang.org/nightly/unstable-book/language-features/generators.html&quot;&gt;&lt;em&gt;generators&lt;/em&gt;&lt;/a&gt;, but this is only an implementation detail.)&lt;/p&gt;
&lt;p&gt;The last piece of the puzzle is the generated code for the &lt;code&gt;example&lt;/code&gt; function itself. Remember, the function header was defined like this:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;async &lt;/span&gt;&lt;span&gt;fn &lt;/span&gt;&lt;span&gt;example(min_len: &lt;/span&gt;&lt;span&gt;usize&lt;/span&gt;&lt;span&gt;) -&amp;gt; String
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;Since the complete function body is now implemented by the state machine, the only thing that the function needs to do is to initialize the state machine and return it. The generated code for this could look like this:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;fn &lt;/span&gt;&lt;span&gt;example(min_len: &lt;/span&gt;&lt;span&gt;usize&lt;/span&gt;&lt;span&gt;) -&amp;gt; ExampleStateMachine {
    ExampleStateMachine::Start(StartState {
        min_len,
    })
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;The function no longer has an &lt;code&gt;async&lt;/code&gt; modifier since it now explicitly returns a &lt;code&gt;ExampleStateMachine&lt;/code&gt; type, which implements the &lt;code&gt;Future&lt;/code&gt; trait. As expected, the state machine is constructed in the &lt;code&gt;Start&lt;/code&gt; state and the corresponding state struct is initialized with the &lt;code&gt;min_len&lt;/code&gt; parameter.&lt;/p&gt;
&lt;p&gt;Note that this function does not start the execution of the state machine. This is a fundamental design decision of futures in Rust: They do nothing until they are polled for the first time.&lt;/p&gt;
&lt;h3 id=&quot;pinning&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#pinning&quot; aria-label=&quot;Anchor link for: pinning&quot;&gt;🔗&lt;/a&gt;Pinning&lt;/h3&gt;
&lt;p&gt;We already stumbled across &lt;em&gt;pinning&lt;/em&gt; multiple times in this post. Now is finally the time to explore what pinning is and why it is needed.&lt;/p&gt;
&lt;h4 id=&quot;self-referential-structs&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#self-referential-structs&quot; aria-label=&quot;Anchor link for: self-referential-structs&quot;&gt;🔗&lt;/a&gt;Self-Referential Structs&lt;/h4&gt;
&lt;p&gt;As explained above, the state machine transformation stores the local variables of each pause point in a struct. For small examples like our &lt;code&gt;example&lt;/code&gt; function, this was straightforward and did not lead to any problems. However, things become more difficult when variables reference each other. For example, consider this function:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;async &lt;/span&gt;&lt;span&gt;fn &lt;/span&gt;&lt;span&gt;pin_example() -&amp;gt; &lt;/span&gt;&lt;span&gt;i32 &lt;/span&gt;&lt;span&gt;{
    &lt;/span&gt;&lt;span&gt;let&lt;/span&gt;&lt;span&gt; array &lt;/span&gt;&lt;span&gt;= &lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;, &lt;/span&gt;&lt;span&gt;2&lt;/span&gt;&lt;span&gt;, &lt;/span&gt;&lt;span&gt;3&lt;/span&gt;&lt;span&gt;];
    &lt;/span&gt;&lt;span&gt;let&lt;/span&gt;&lt;span&gt; element &lt;/span&gt;&lt;span&gt;= &amp;amp;&lt;/span&gt;&lt;span&gt;array[&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;&lt;span&gt;];
    async_write_file(&lt;/span&gt;&lt;span&gt;&quot;foo.txt&quot;&lt;/span&gt;&lt;span&gt;, element.to_string()).await;
    &lt;/span&gt;&lt;span&gt;*&lt;/span&gt;&lt;span&gt;element
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;This function creates a small &lt;code&gt;array&lt;/code&gt; with the contents &lt;code&gt;1&lt;/code&gt;, &lt;code&gt;2&lt;/code&gt;, and &lt;code&gt;3&lt;/code&gt;. It then creates a reference to the last array element and stores it in an &lt;code&gt;element&lt;/code&gt; variable. Next, it asynchronously writes the number converted to a string to a &lt;code&gt;foo.txt&lt;/code&gt; file. Finally, it returns the number referenced by &lt;code&gt;element&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Since the function uses a single &lt;code&gt;await&lt;/code&gt; operation, the resulting state machine has three states: start, end, and &quot;waiting on write&quot;. The function takes no arguments, so the struct for the start state is empty. Like before, the struct for the end state is empty too because the function is finished at this point. The struct for the &quot;waiting on write&quot; state is more interesting:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;struct &lt;/span&gt;&lt;span&gt;WaitingOnWriteState {
    array: [1, 2, 3],
    element: 0x1001a, &lt;/span&gt;&lt;span&gt;// address of the last array element
&lt;/span&gt;&lt;span&gt;}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;We need to store both the &lt;code&gt;array&lt;/code&gt; and &lt;code&gt;element&lt;/code&gt; variables because &lt;code&gt;element&lt;/code&gt; is required for the return value and &lt;code&gt;array&lt;/code&gt; is referenced by &lt;code&gt;element&lt;/code&gt;. Since &lt;code&gt;element&lt;/code&gt; is a reference, it stores a &lt;em&gt;pointer&lt;/em&gt; (i.e. a memory address) to the referenced element. We used &lt;code&gt;0x1001a&lt;/code&gt; as an example memory address here. In reality it needs to be the address of the last element of the &lt;code&gt;array&lt;/code&gt; field, so it depends on where the struct lives in memory. Structs with such internal pointers are called &lt;em&gt;self-referential&lt;/em&gt; structs because they reference themselves from one of their fields.&lt;/p&gt;
&lt;h4 id=&quot;the-problem-with-self-referential-structs&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#the-problem-with-self-referential-structs&quot; aria-label=&quot;Anchor link for: the-problem-with-self-referential-structs&quot;&gt;🔗&lt;/a&gt;The Problem with Self-Referential Structs&lt;/h4&gt;
&lt;p&gt;The internal pointer of our self-referential struct leads to a fundamental problem, which becomes apparent when we look at its memory layout:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://os.phil-opp.com/async-await/self-referential-struct.svg&quot; alt=&quot;array at 0x10014 with fields 1, 2, and 3; element at address 0x10020, pointing to the last array element at 0x1001a&quot;/&gt;&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;array&lt;/code&gt; field starts at address 0x10014 and the &lt;code&gt;element&lt;/code&gt; field at address 0x10020. It points to address 0x1001a because the last array element lives at this address. At this point, everything is still fine. However, an issue occurs when we move this struct to a different memory address:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://os.phil-opp.com/async-await/self-referential-struct-moved.svg&quot; alt=&quot;array at 0x10024 with fields 1, 2, and 3; element at address 0x10030, still pointing to 0x1001a, even though the last array element now lives at 0x1002a&quot;/&gt;&lt;/p&gt;
&lt;p&gt;We moved the struct a bit so that it starts at address &lt;code&gt;0x10024&lt;/code&gt; now. This could for example happen when we pass the struct as a function argument or assign it to a different stack variable. The problem is that the &lt;code&gt;element&lt;/code&gt; field still points to address &lt;code&gt;0x1001a&lt;/code&gt; even though the last &lt;code&gt;array&lt;/code&gt; element now lives at address &lt;code&gt;0x1002a&lt;/code&gt;. Thus, the pointer is dangling with the result that undefined behavior occurs on the next &lt;code&gt;poll&lt;/code&gt; call.&lt;/p&gt;
&lt;h4 id=&quot;possible-solutions&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#possible-solutions&quot; aria-label=&quot;Anchor link for: possible-solutions&quot;&gt;🔗&lt;/a&gt;Possible Solutions&lt;/h4&gt;
&lt;p&gt;There are three fundamental approaches to solve the dangling pointer problem:&lt;/p&gt;
&lt;ul readability=&quot;11.5&quot;&gt;&lt;li readability=&quot;3&quot;&gt;
&lt;p&gt;&lt;strong&gt;Update the pointer on move:&lt;/strong&gt; The idea is to update the internal pointer whenever the struct is moved in memory so that it is still valid after the move. Unfortunately, this approach would require extensive changes to Rust that would result in potentially huge performance losses. The reason is that some kind of runtime would need to keep track of the type of all struct fields and check on every move operation whether a pointer update is required.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;13&quot;&gt;
&lt;p&gt;&lt;strong&gt;Store an offset instead of self-references:&lt;/strong&gt;: To avoid the requirement for updating pointers, the compiler could try to store self-references as offsets from the struct's beginning instead. For example, the &lt;code&gt;element&lt;/code&gt; field of the above &lt;code&gt;WaitingOnWriteState&lt;/code&gt; struct could be stored in form of an &lt;code&gt;element_offset&lt;/code&gt; field with value 8 because the array element that the reference points to starts 8 bytes after the struct's beginning. Since the offset stays the same when the struct is moved, no field updates are required.&lt;/p&gt;
&lt;p&gt;The problem of this approach is that it requires the compiler to detect all self-references. This is not possible at compile-time because the value of a reference might depend on user input, so we would need a runtime system again to analyze references and correctly create the state structs. This would not only result in runtime costs, but also prevent certain compiler optimizations, so that it would cause large performance losses again.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;4&quot;&gt;
&lt;p&gt;&lt;strong&gt;Forbid moving the struct:&lt;/strong&gt; As we saw above, the dangling pointer only occurs when we move the struct in memory. By completely forbidding move operations on self-referential structs, the problem can be also avoided. The big advantage of this approach is that it can be implemented at the type system level without additional runtime costs. The drawback is that it puts the burden of dealing with move operations on possibly self-referential structs on the programmer.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Because its principle to provide &lt;em&gt;zero cost abstractions&lt;/em&gt;, which means that abstractions should not impose additional runtime costs, Rust decided for the third solution. For this, the &lt;a href=&quot;https://doc.rust-lang.org/stable/core/pin/index.html&quot;&gt;&lt;em&gt;pinning&lt;/em&gt;&lt;/a&gt; API was proposed in &lt;a href=&quot;https://github.com/rust-lang/rfcs/blob/master/text/2349-pin.md&quot;&gt;RFC 2349&lt;/a&gt;. In the following, we will give a short overview of this API and explain how it works with async/await and futures.&lt;/p&gt;
&lt;h4 id=&quot;heap-values&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#heap-values&quot; aria-label=&quot;Anchor link for: heap-values&quot;&gt;🔗&lt;/a&gt;Heap Values&lt;/h4&gt;
&lt;p&gt;The first observation is that &lt;a href=&quot;https://os.phil-opp.com/heap-allocation/&quot;&gt;heap allocated&lt;/a&gt; values already have a fixed memory address most of the time. They are created using a call to &lt;code&gt;allocate&lt;/code&gt; and then referenced by a pointer type such as &lt;code&gt;Box&amp;lt;T&amp;gt;&lt;/code&gt;. While moving the pointer type is possible, the heap value that the pointer points to stays at the same memory address until it is freed through a &lt;code&gt;deallocate&lt;/code&gt; call again.&lt;/p&gt;
&lt;p&gt;Using heap allocation, we can try to create a self-referential struct:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;fn &lt;/span&gt;&lt;span&gt;main() {
    &lt;/span&gt;&lt;span&gt;let mut&lt;/span&gt;&lt;span&gt; heap_value &lt;/span&gt;&lt;span&gt;= &lt;/span&gt;&lt;span&gt;Box::new(SelfReferential {
        self_ptr: &lt;/span&gt;&lt;span&gt;0 &lt;/span&gt;&lt;span&gt;as *const _&lt;/span&gt;&lt;span&gt;,
    });
    &lt;/span&gt;&lt;span&gt;let&lt;/span&gt;&lt;span&gt; ptr &lt;/span&gt;&lt;span&gt;= &amp;amp;*&lt;/span&gt;&lt;span&gt;heap_value &lt;/span&gt;&lt;span&gt;as *const&lt;/span&gt;&lt;span&gt; SelfReferential;
    heap_value.self_ptr &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; ptr;
    println!(&lt;/span&gt;&lt;span&gt;&quot;heap value at: &lt;/span&gt;&lt;span&gt;{:p}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, heap_value);
    println!(&lt;/span&gt;&lt;span&gt;&quot;internal reference: &lt;/span&gt;&lt;span&gt;{:p}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, heap_value.self_ptr);
}

&lt;/span&gt;&lt;span&gt;struct &lt;/span&gt;&lt;span&gt;SelfReferential {
    self_ptr: &lt;/span&gt;&lt;span&gt;*const Self&lt;/span&gt;&lt;span&gt;,
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;(&lt;a href=&quot;https://play.rust-lang.org/?version=stable&amp;amp;mode=debug&amp;amp;edition=2018&amp;amp;gist=ce1aff3a37fcc1c8188eeaf0f39c97e8&quot;&gt;Try it on the playground&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;We create a simple struct named &lt;code&gt;SelfReferential&lt;/code&gt; that contains a single pointer field. First, we initialize this struct with a null pointer and then allocate it on the heap using &lt;code&gt;Box::new&lt;/code&gt;. We then determine the memory address of the heap allocated struct and store it in a &lt;code&gt;ptr&lt;/code&gt; variable. Finally, we make the struct self-referential by assigning the &lt;code&gt;ptr&lt;/code&gt; variable to the &lt;code&gt;self_ptr&lt;/code&gt; field.&lt;/p&gt;
&lt;p&gt;When we execute this code &lt;a href=&quot;https://play.rust-lang.org/?version=stable&amp;amp;mode=debug&amp;amp;edition=2018&amp;amp;gist=ce1aff3a37fcc1c8188eeaf0f39c97e8&quot;&gt;on the playground&lt;/a&gt;, we see that the address of heap value and its internal pointer are equal, which means that the &lt;code&gt;self_ptr&lt;/code&gt; field is a valid self-reference. Since the &lt;code&gt;heap_value&lt;/code&gt; variable is only a pointer, moving it (e.g. by passing it to a function) does not change the address of the struct itself, so the &lt;code&gt;self_ptr&lt;/code&gt; stays valid even if the pointer is moved.&lt;/p&gt;
&lt;p&gt;However, there is still a way to break this example: We can move out of a &lt;code&gt;Box&amp;lt;T&amp;gt;&lt;/code&gt; or replace its content:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;let&lt;/span&gt;&lt;span&gt; stack_value &lt;/span&gt;&lt;span&gt;= &lt;/span&gt;&lt;span&gt;mem::replace(&lt;/span&gt;&lt;span&gt;&amp;amp;mut *&lt;/span&gt;&lt;span&gt;heap_value, SelfReferential {
    self_ptr: &lt;/span&gt;&lt;span&gt;0 &lt;/span&gt;&lt;span&gt;as *const _&lt;/span&gt;&lt;span&gt;,
});
println!(&lt;/span&gt;&lt;span&gt;&quot;value at: &lt;/span&gt;&lt;span&gt;{:p}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, &lt;/span&gt;&lt;span&gt;&amp;amp;&lt;/span&gt;&lt;span&gt;stack_value);
println!(&lt;/span&gt;&lt;span&gt;&quot;internal reference: &lt;/span&gt;&lt;span&gt;{:p}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, stack_value.self_ptr);
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;(&lt;a href=&quot;https://play.rust-lang.org/?version=stable&amp;amp;mode=debug&amp;amp;edition=2018&amp;amp;gist=e160ee8a64cba4cebc1c0473dcecb7c8&quot;&gt;Try it on the playground&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Here we use the &lt;a href=&quot;https://doc.rust-lang.org/nightly/core/mem/fn.replace.html&quot;&gt;&lt;code&gt;mem::replace&lt;/code&gt;&lt;/a&gt; function to replace the heap allocated value with a new struct instance. This allows us to move the original &lt;code&gt;heap_value&lt;/code&gt; to the stack, while the &lt;code&gt;self_ptr&lt;/code&gt; field of the struct is now a dangling pointer that still points to the old heap address. When you try to run the example on the playground, you see that the printed &lt;em&gt;&quot;value at:&quot;&lt;/em&gt; and &lt;em&gt;&quot;internal reference:&quot;&lt;/em&gt; lines show indeed different pointers. So heap allocating a value is not enough to make self-references safe.&lt;/p&gt;
&lt;p&gt;The fundamental problem that allowed the above breakage is that &lt;code&gt;Box&amp;lt;T&amp;gt;&lt;/code&gt; allows us to get a &lt;code&gt;&amp;amp;mut T&lt;/code&gt; reference to the heap allocated value. This &lt;code&gt;&amp;amp;mut&lt;/code&gt; reference makes it possible to use methods like &lt;a href=&quot;https://doc.rust-lang.org/nightly/core/mem/fn.replace.html&quot;&gt;&lt;code&gt;mem::replace&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;https://doc.rust-lang.org/nightly/core/mem/fn.swap.html&quot;&gt;&lt;code&gt;mem::swap&lt;/code&gt;&lt;/a&gt; to invalidate the heap allocated value. To resolve this problem, we must prevent that &lt;code&gt;&amp;amp;mut&lt;/code&gt; references to self-referential structs can be created.&lt;/p&gt;
&lt;h4 id=&quot;pin-box-t-and-unpin&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#pin-box-t-and-unpin&quot; aria-label=&quot;Anchor link for: pin-box-t-and-unpin&quot;&gt;🔗&lt;/a&gt;&lt;code&gt;Pin&amp;lt;Box&amp;lt;T&amp;gt;&amp;gt;&lt;/code&gt; and &lt;code&gt;Unpin&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;The pinning API provides a solution to the &lt;code&gt;&amp;amp;mut T&lt;/code&gt; problem in form of the &lt;a href=&quot;https://doc.rust-lang.org/stable/core/pin/struct.Pin.html&quot;&gt;&lt;code&gt;Pin&lt;/code&gt;&lt;/a&gt; wrapper type and the &lt;a href=&quot;https://doc.rust-lang.org/nightly/std/marker/trait.Unpin.html&quot;&gt;&lt;code&gt;Unpin&lt;/code&gt;&lt;/a&gt; marker trait. The idea behind these types is to gate all methods of &lt;code&gt;Pin&lt;/code&gt; that can be used to get &lt;code&gt;&amp;amp;mut&lt;/code&gt; references to the wrapped value (e.g. &lt;a href=&quot;https://doc.rust-lang.org/nightly/core/pin/struct.Pin.html#method.get_mut&quot;&gt;&lt;code&gt;get_mut&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;https://doc.rust-lang.org/nightly/core/pin/struct.Pin.html#impl-DerefMut&quot;&gt;&lt;code&gt;deref_mut&lt;/code&gt;&lt;/a&gt;) on the &lt;code&gt;Unpin&lt;/code&gt; trait. The &lt;code&gt;Unpin&lt;/code&gt; trait is an &lt;a href=&quot;https://doc.rust-lang.org/reference/special-types-and-traits.html#auto-traits&quot;&gt;&lt;em&gt;auto trait&lt;/em&gt;&lt;/a&gt;, which is automatically implemented for all types except types that explicitly opt-out. By making self-referential structs opt-out of &lt;code&gt;Unpin&lt;/code&gt;, there is no (safe) way to get a &lt;code&gt;&amp;amp;mut T&lt;/code&gt; from a &lt;code&gt;Pin&amp;lt;Box&amp;lt;T&amp;gt;&amp;gt;&lt;/code&gt; type for them. As a result, their internal self-references are guaranteed to stay valid.&lt;/p&gt;
&lt;p&gt;As an example, let's update the &lt;code&gt;SelfReferential&lt;/code&gt; type from above to opt-out of &lt;code&gt;Unpin&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;use &lt;/span&gt;&lt;span&gt;core::marker::PhantomPinned;

&lt;/span&gt;&lt;span&gt;struct &lt;/span&gt;&lt;span&gt;SelfReferential {
    self_ptr: &lt;/span&gt;&lt;span&gt;*const Self&lt;/span&gt;&lt;span&gt;,
    _pin: PhantomPinned,
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;We opt-out by adding a second &lt;code&gt;_pin&lt;/code&gt; field of type &lt;a href=&quot;https://doc.rust-lang.org/nightly/core/marker/struct.PhantomPinned.html&quot;&gt;&lt;code&gt;PhantomPinned&lt;/code&gt;&lt;/a&gt;. This type is a zero-sized marker type whose only purpose is to &lt;em&gt;not&lt;/em&gt; implement the &lt;code&gt;Unpin&lt;/code&gt; trait. Because of the way &lt;a href=&quot;https://doc.rust-lang.org/reference/special-types-and-traits.html#auto-traits&quot;&gt;auto traits&lt;/a&gt; work, a single field that is not &lt;code&gt;Unpin&lt;/code&gt; suffices to make the complete struct opt-out of &lt;code&gt;Unpin&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The second step is to change the &lt;code&gt;Box&amp;lt;SelfReferential&amp;gt;&lt;/code&gt; type in the example to a &lt;code&gt;Pin&amp;lt;Box&amp;lt;SelfReferential&amp;gt;&amp;gt;&lt;/code&gt; type. The easiest way to do this is to use the &lt;a href=&quot;https://doc.rust-lang.org/nightly/alloc/boxed/struct.Box.html#method.pin&quot;&gt;&lt;code&gt;Box::pin&lt;/code&gt;&lt;/a&gt; function instead of &lt;a href=&quot;https://doc.rust-lang.org/nightly/alloc/boxed/struct.Box.html#method.new&quot;&gt;&lt;code&gt;Box::new&lt;/code&gt;&lt;/a&gt; for creating the heap allocated value:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;let mut&lt;/span&gt;&lt;span&gt; heap_value &lt;/span&gt;&lt;span&gt;= &lt;/span&gt;&lt;span&gt;Box::pin(SelfReferential {
    self_ptr: &lt;/span&gt;&lt;span&gt;0 &lt;/span&gt;&lt;span&gt;as *const _&lt;/span&gt;&lt;span&gt;,
    _pin: PhantomPinned,
});
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;In addition to changing &lt;code&gt;Box::new&lt;/code&gt; to &lt;code&gt;Box::pin&lt;/code&gt;, we also need to add the new &lt;code&gt;_pin&lt;/code&gt; field in the struct initializer. Since &lt;code&gt;PhantomPinned&lt;/code&gt; is a zero sized type, we only need its type name to initialize it.&lt;/p&gt;
&lt;p&gt;When we &lt;a href=&quot;https://play.rust-lang.org/?version=stable&amp;amp;mode=debug&amp;amp;edition=2018&amp;amp;gist=961b0db194bbe851ff4d0ed08d3bd98a&quot;&gt;try to run our adjusted example&lt;/a&gt; now, we see that it no longer works:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;error[E0594]: cannot assign to data in a dereference of `std::pin::Pin&amp;lt;std::boxed::Box&amp;lt;SelfReferential&amp;gt;&amp;gt;`
  --&amp;gt; src/main.rs:10:5
   |
10 |     heap_value.self_ptr = ptr;
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^ cannot assign
   |
   = help: trait `DerefMut` is required to modify through a dereference, but it is not implemented for `std::pin::Pin&amp;lt;std::boxed::Box&amp;lt;SelfReferential&amp;gt;&amp;gt;`

error[E0596]: cannot borrow data in a dereference of `std::pin::Pin&amp;lt;std::boxed::Box&amp;lt;SelfReferential&amp;gt;&amp;gt;` as mutable
  --&amp;gt; src/main.rs:16:36
   |
16 |     let stack_value = mem::replace(&amp;amp;mut *heap_value, SelfReferential {
   |                                    ^^^^^^^^^^^^^^^^ cannot borrow as mutable
   |
   = help: trait `DerefMut` is required to modify through a dereference, but it is not implemented for `std::pin::Pin&amp;lt;std::boxed::Box&amp;lt;SelfReferential&amp;gt;&amp;gt;`
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;Both errors occur because the &lt;code&gt;Pin&amp;lt;Box&amp;lt;SelfReferential&amp;gt;&amp;gt;&lt;/code&gt; type no longer implements the &lt;code&gt;DerefMut&lt;/code&gt; trait. This exactly what we wanted because the &lt;code&gt;DerefMut&lt;/code&gt; trait would return a &lt;code&gt;&amp;amp;mut&lt;/code&gt; reference, which we want to prevent. This only happens because we both opted-out of &lt;code&gt;Unpin&lt;/code&gt; and changed &lt;code&gt;Box::new&lt;/code&gt; to &lt;code&gt;Box::pin&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The problem now is that the compiler does not only prevent moving the type in line 16, but also forbids to initialize the &lt;code&gt;self_ptr&lt;/code&gt; field in line 10. This happens because the compiler can't differentiate between valid and invalid uses of &lt;code&gt;&amp;amp;mut&lt;/code&gt; references. To get the initialization working again, we have to use the unsafe &lt;a href=&quot;https://doc.rust-lang.org/nightly/core/pin/struct.Pin.html#method.get_unchecked_mut&quot;&gt;&lt;code&gt;get_unchecked_mut&lt;/code&gt;&lt;/a&gt; method:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;// safe because modifying a field doesn't move the whole struct
&lt;/span&gt;&lt;span&gt;unsafe &lt;/span&gt;&lt;span&gt;{
    &lt;/span&gt;&lt;span&gt;let&lt;/span&gt;&lt;span&gt; mut_ref &lt;/span&gt;&lt;span&gt;= &lt;/span&gt;&lt;span&gt;Pin::as_mut(&lt;/span&gt;&lt;span&gt;&amp;amp;mut&lt;/span&gt;&lt;span&gt; heap_value);
    Pin::get_unchecked_mut(mut_ref).self_ptr &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; ptr;
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;(&lt;a href=&quot;https://play.rust-lang.org/?version=stable&amp;amp;mode=debug&amp;amp;edition=2018&amp;amp;gist=b9ebbb11429d9d79b3f9fffe819e2018&quot;&gt;Try it on the playground&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;The &lt;a href=&quot;https://doc.rust-lang.org/nightly/core/pin/struct.Pin.html#method.get_unchecked_mut&quot;&gt;&lt;code&gt;get_unchecked_mut&lt;/code&gt;&lt;/a&gt; function works on a &lt;code&gt;Pin&amp;lt;&amp;amp;mut T&amp;gt;&lt;/code&gt; instead of a &lt;code&gt;Pin&amp;lt;Box&amp;lt;T&amp;gt;&amp;gt;&lt;/code&gt;, so we have to use the &lt;a href=&quot;https://doc.rust-lang.org/nightly/core/pin/struct.Pin.html#method.as_mut&quot;&gt;&lt;code&gt;Pin::as_mut&lt;/code&gt;&lt;/a&gt; for converting the value before. Then we can set the &lt;code&gt;self_ptr&lt;/code&gt; field using the &lt;code&gt;&amp;amp;mut&lt;/code&gt; reference returned by &lt;code&gt;get_unchecked_mut&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Now the only error left is the desired error on &lt;code&gt;mem::replace&lt;/code&gt;. Remember, this operation tries to move the heap allocated value to stack, which would break the self-reference stored in the &lt;code&gt;self_ptr&lt;/code&gt; field. By opting out of &lt;code&gt;Unpin&lt;/code&gt; and using &lt;code&gt;Pin&amp;lt;Box&amp;lt;T&amp;gt;&amp;gt;&lt;/code&gt;, we can prevent this operation at compile time and thus safely work with self-referential structs. As we saw, the compiler is not able to prove that the creation of the self-reference is safe (yet), so we need to use an unsafe block and verify the correctness ourselves.&lt;/p&gt;
&lt;h4 id=&quot;stack-pinning-and-pin-mut-t&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#stack-pinning-and-pin-mut-t&quot; aria-label=&quot;Anchor link for: stack-pinning-and-pin-mut-t&quot;&gt;🔗&lt;/a&gt;Stack Pinning and &lt;code&gt;Pin&amp;lt;&amp;amp;mut T&amp;gt;&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;In the previous section we learned how to use &lt;code&gt;Pin&amp;lt;Box&amp;lt;T&amp;gt;&amp;gt;&lt;/code&gt; to safely create a heap allocated self-referential value. While this approach works fine and is relatively safe (apart from the unsafe construction), the required heap allocation comes with a performance cost. Since Rust always wants to provide &lt;em&gt;zero-cost abstractions&lt;/em&gt; when possible, the pinning API also allows to create &lt;code&gt;Pin&amp;lt;&amp;amp;mut T&amp;gt;&lt;/code&gt; instances that point to stack allocated values.&lt;/p&gt;
&lt;p&gt;Unlike &lt;code&gt;Pin&amp;lt;Box&amp;lt;T&amp;gt;&amp;gt;&lt;/code&gt; instances, which have &lt;em&gt;ownership&lt;/em&gt; of the wrapped value, &lt;code&gt;Pin&amp;lt;&amp;amp;mut T&amp;gt;&lt;/code&gt; instances only temporarily borrow the wrapped value. This makes things more complicated, as it requires the programmer to ensure additional guarantees themself. Most importantly, a &lt;code&gt;Pin&amp;lt;&amp;amp;mut T&amp;gt;&lt;/code&gt; must stay pinned for the whole lifetime of the referenced &lt;code&gt;T&lt;/code&gt;, which can be difficult to verify for stack based variables. To help with this, crates like &lt;a href=&quot;https://docs.rs/pin-utils/0.1.0-alpha.4/pin_utils/&quot;&gt;&lt;code&gt;pin-utils&lt;/code&gt;&lt;/a&gt; exist, but I still wouldn't recommend pinning to the stack unless you really know what you're doing.&lt;/p&gt;
&lt;p&gt;For further reading, check out the documentation of the &lt;a href=&quot;https://doc.rust-lang.org/nightly/core/pin/index.html&quot;&gt;&lt;code&gt;pin&lt;/code&gt; module&lt;/a&gt; and the &lt;a href=&quot;https://doc.rust-lang.org/nightly/core/pin/struct.Pin.html#method.new_unchecked&quot;&gt;&lt;code&gt;Pin::new_unchecked&lt;/code&gt;&lt;/a&gt; method.&lt;/p&gt;
&lt;h4 id=&quot;pinning-and-futures&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#pinning-and-futures&quot; aria-label=&quot;Anchor link for: pinning-and-futures&quot;&gt;🔗&lt;/a&gt;Pinning and Futures&lt;/h4&gt;
&lt;p&gt;As we already saw in this post, the &lt;a href=&quot;https://doc.rust-lang.org/nightly/core/future/trait.Future.html#tymethod.poll&quot;&gt;&lt;code&gt;Future::poll&lt;/code&gt;&lt;/a&gt; method uses pinning in form of a &lt;code&gt;Pin&amp;lt;&amp;amp;mut Self&amp;gt;&lt;/code&gt; parameter:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;fn &lt;/span&gt;&lt;span&gt;poll(self: Pin&amp;lt;&lt;/span&gt;&lt;span&gt;&amp;amp;mut Self&lt;/span&gt;&lt;span&gt;&amp;gt;, cx: &lt;/span&gt;&lt;span&gt;&amp;amp;mut&lt;/span&gt;&lt;span&gt; Context) -&amp;gt; Poll&amp;lt;&lt;/span&gt;&lt;span&gt;Self::&lt;/span&gt;&lt;span&gt;Output&amp;gt;
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;The reason that this method takes &lt;code&gt;self: Pin&amp;lt;&amp;amp;mut Self&amp;gt;&lt;/code&gt; instead of the normal &lt;code&gt;&amp;amp;mut self&lt;/code&gt; is that future instances created from async/await are often self-referential, as we saw &lt;a href=&quot;https://os.phil-opp.com/async-await/#self-referential-structs&quot;&gt;above&lt;/a&gt;. By wrapping &lt;code&gt;Self&lt;/code&gt; into &lt;code&gt;Pin&lt;/code&gt; and letting the compiler opt-out of &lt;code&gt;Unpin&lt;/code&gt; for self-referentual futures generated from async/await, it is guaranteed that the futures are not moved in memory between &lt;code&gt;poll&lt;/code&gt; calls. This ensures that all internal references are still valid.&lt;/p&gt;
&lt;p&gt;It is worth noting that moving futures before the first &lt;code&gt;poll&lt;/code&gt; call is fine. This is a result of the fact that futures are lazy and do nothing until they're polled for the first time. The &lt;code&gt;start&lt;/code&gt; state of the generated state machines therefore only contains the function arguments, but no internal references. In order to call &lt;code&gt;poll&lt;/code&gt;, the caller must wrap the future into &lt;code&gt;Pin&lt;/code&gt; first, which ensures that the future cannot be moved in memory anymore. Since stack pinning is more difficult to get right, I recommend to always use &lt;a href=&quot;https://doc.rust-lang.org/nightly/alloc/boxed/struct.Box.html#method.pin&quot;&gt;&lt;code&gt;Box::pin&lt;/code&gt;&lt;/a&gt; combined with &lt;a href=&quot;https://doc.rust-lang.org/nightly/core/pin/struct.Pin.html#method.as_mut&quot;&gt;&lt;code&gt;Pin::as_mut&lt;/code&gt;&lt;/a&gt; for this.&lt;/p&gt;
&lt;p&gt;In case you're interested in understanding how to safely implement a future combinator function using stack pinning yourself, take a look at the relatively short &lt;a href=&quot;https://docs.rs/futures-util/0.3.4/src/futures_util/future/future/map.rs.html&quot;&gt;source of the &lt;code&gt;map&lt;/code&gt; combinator method&lt;/a&gt; of the &lt;code&gt;futures&lt;/code&gt; crate and the section about &lt;a href=&quot;https://doc.rust-lang.org/stable/std/pin/index.html#projections-and-structural-pinning&quot;&gt;projections and structural pinning&lt;/a&gt; of the pin documentation.&lt;/p&gt;
&lt;h3 id=&quot;executors-and-wakers&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#executors-and-wakers&quot; aria-label=&quot;Anchor link for: executors-and-wakers&quot;&gt;🔗&lt;/a&gt;Executors and Wakers&lt;/h3&gt;
&lt;p&gt;Using async/await, it is possible to ergonomically work with futures in a completely asynchronous way. However, as we learned above, futures do nothing until they are polled. This means we have to have to call &lt;code&gt;poll&lt;/code&gt; on them at some point, otherwise the asynchronous code is never executed.&lt;/p&gt;
&lt;p&gt;With a single future, we can always wait for each future manually using a loop &lt;a href=&quot;https://os.phil-opp.com/async-await/#waiting-on-futures&quot;&gt;as described above&lt;/a&gt;. However, this approach is very inefficient and not practical for programs that create a large number of futures. The most common solution for this problem is to define a global &lt;em&gt;executor&lt;/em&gt; that is responsible for polling all futures in the system until they are finished.&lt;/p&gt;
&lt;h4 id=&quot;executors&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#executors&quot; aria-label=&quot;Anchor link for: executors&quot;&gt;🔗&lt;/a&gt;Executors&lt;/h4&gt;
&lt;p&gt;The purpose of an executor is to allow spawning futures as independent tasks, typically through some sort of &lt;code&gt;spawn&lt;/code&gt; method. The executor is then responsible for polling all futures until they are completed. The big advantage of managing all futures in a central place is that the executor can switch to a different future whenever a future returns &lt;code&gt;Poll::Pending&lt;/code&gt;. Thus, asynchronous operations are run in parallel and the CPU is kept busy.&lt;/p&gt;
&lt;p&gt;Many executor implementations can also take advantage of systems with multiple CPU cores. They create a &lt;a href=&quot;https://en.wikipedia.org/wiki/Thread_pool&quot;&gt;thread pool&lt;/a&gt; that is able to utilize all cores if there is enough work available and use techniques such as &lt;a href=&quot;https://en.wikipedia.org/wiki/Work_stealing&quot;&gt;work stealing&lt;/a&gt; to balance the load between cores. There are also special executor implementations for embedded systems that optimize for low latency and memory overhead.&lt;/p&gt;
&lt;p&gt;To avoid the overhead of polling futures over and over again, executors typically also take advantage of the &lt;em&gt;waker&lt;/em&gt; API supported by Rust's futures.&lt;/p&gt;
&lt;h4 id=&quot;wakers&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#wakers&quot; aria-label=&quot;Anchor link for: wakers&quot;&gt;🔗&lt;/a&gt;Wakers&lt;/h4&gt;
&lt;p&gt;The idea behind the waker API is that a special &lt;a href=&quot;https://doc.rust-lang.org/nightly/core/task/struct.Waker.html&quot;&gt;&lt;code&gt;Waker&lt;/code&gt;&lt;/a&gt; type is passed to each invocation of &lt;code&gt;poll&lt;/code&gt;, wrapped in the &lt;a href=&quot;https://doc.rust-lang.org/nightly/core/task/struct.Context.html&quot;&gt;&lt;code&gt;Context&lt;/code&gt;&lt;/a&gt; type. This &lt;code&gt;Waker&lt;/code&gt; type is created by the executor and can be used by the asynchronous task to signal its (partial) completion. As a result, the executor does not need to call &lt;code&gt;poll&lt;/code&gt; on a future that previously returned &lt;code&gt;Poll::Pending&lt;/code&gt; until it is notified by the corresponding waker.&lt;/p&gt;
&lt;p&gt;This is best illustrated by a small example:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;async &lt;/span&gt;&lt;span&gt;fn &lt;/span&gt;&lt;span&gt;write_file() {
    async_write_file(&lt;/span&gt;&lt;span&gt;&quot;foo.txt&quot;&lt;/span&gt;&lt;span&gt;, &lt;/span&gt;&lt;span&gt;&quot;Hello&quot;&lt;/span&gt;&lt;span&gt;).await;
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;This function asynchronously writes the string &quot;Hello&quot; to a &lt;code&gt;foo.txt&lt;/code&gt; file. Since hard disk writes take some time, the first &lt;code&gt;poll&lt;/code&gt; call on this future will likely return &lt;code&gt;Poll::Pending&lt;/code&gt;. However, the hard disk driver will internally store the &lt;code&gt;Waker&lt;/code&gt; passed to the &lt;code&gt;poll&lt;/code&gt; call and use it to notify the executor when the file was written to disk. This way, the executor does not need to waste any time trying to &lt;code&gt;poll&lt;/code&gt; the future again before it receives the waker notification.&lt;/p&gt;
&lt;p&gt;We will see how the &lt;code&gt;Waker&lt;/code&gt; type works in detail when we create our own executor with waker support in the implementation section of this post.&lt;/p&gt;
&lt;h3 id=&quot;cooperative-multitasking-1&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#cooperative-multitasking-1&quot; aria-label=&quot;Anchor link for: cooperative-multitasking-1&quot;&gt;🔗&lt;/a&gt;Cooperative Multitasking?&lt;/h3&gt;
&lt;p&gt;At the beginning of this post we talked about preemptive and cooperative multitasking. While preemptive multitasking relies on the operating system to forcibly switch between running tasks, cooperative multitasking requires that the tasks voluntarily give up control of the CPU through a &lt;em&gt;yield&lt;/em&gt; operation on a regular basis. The big advantage of the cooperative approach is that tasks can save their state themselves, which results in more efficient context switches and makes it possible to share the same call stack between tasks.&lt;/p&gt;
&lt;p&gt;It might not be immediately apparent, but futures and async/await are an implementation of the cooperative multitasking pattern:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Each future that is added to the executor is basically an cooperative task.&lt;/li&gt;
&lt;li&gt;Instead of using an explicit yield operation, futures give up control of the CPU core by returning &lt;code&gt;Poll::Pending&lt;/code&gt; (or &lt;code&gt;Poll::Ready&lt;/code&gt; at the end).
&lt;ul&gt;&lt;li&gt;There is nothing that forces futures to give up the CPU. If they want, they can never return from &lt;code&gt;poll&lt;/code&gt;, e.g. by spinning endlessly in a loop.&lt;/li&gt;
&lt;li&gt;Since each future can block the execution of the other futures in the executor, we need to trust them to be not malicious.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Futures internally store all the state they need to continue execution on the next &lt;code&gt;poll&lt;/code&gt; call. With async/await, the compiler automatically detects all variables that are needed and stores them inside the generated state machine.
&lt;ul&gt;&lt;li&gt;Only the minimum state required for continuation is saved.&lt;/li&gt;
&lt;li&gt;Since the &lt;code&gt;poll&lt;/code&gt; method gives up the call stack when it returns, the same stack can be used for polling other futures.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;We see that futures and async/await fit the cooperative multitasking pattern perfectly, they just use some different terminology. In the following, we will therefore use the terms &quot;task&quot; and &quot;future&quot; interchangeably.&lt;/p&gt;
&lt;h2 id=&quot;implementation&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#implementation&quot; aria-label=&quot;Anchor link for: implementation&quot;&gt;🔗&lt;/a&gt;Implementation&lt;/h2&gt;
&lt;p&gt;Now that we understand how cooperative multitasking based on futures and async/await works in Rust, it's time to add support for it to our kernel. Since the &lt;a href=&quot;https://doc.rust-lang.org/nightly/core/future/trait.Future.html&quot;&gt;&lt;code&gt;Future&lt;/code&gt;&lt;/a&gt; trait is part of the &lt;code&gt;core&lt;/code&gt; library and async/await is a feature of the language itself, there is nothing special we need to do to use it in our &lt;code&gt;#![no_std]&lt;/code&gt; kernel. The only requirement is that we use at least nightly &lt;code&gt;2020-03-25&lt;/code&gt; of Rust because async/await was not &lt;code&gt;no_std&lt;/code&gt; compatible before. &lt;span class=&quot;gray&quot;&gt;(There is no nightly with the rustfmt and clippy components since then, so you might have to pass the &lt;code&gt;--force&lt;/code&gt; flag to &lt;code&gt;rustup update&lt;/code&gt;, which performs the update even if it removes some installed components.)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;With a recent-enough nightly, we can start using async/await in our &lt;code&gt;main.rs&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;// in src/main.rs
&lt;/span&gt;&lt;span&gt;
async &lt;/span&gt;&lt;span&gt;fn &lt;/span&gt;&lt;span&gt;async_number() -&amp;gt; &lt;/span&gt;&lt;span&gt;u32 &lt;/span&gt;&lt;span&gt;{
    &lt;/span&gt;&lt;span&gt;42
&lt;/span&gt;&lt;span&gt;}

async &lt;/span&gt;&lt;span&gt;fn &lt;/span&gt;&lt;span&gt;example_task() {
    &lt;/span&gt;&lt;span&gt;let&lt;/span&gt;&lt;span&gt; number &lt;/span&gt;&lt;span&gt;= &lt;/span&gt;&lt;span&gt;async_number().await;
    println!(&lt;/span&gt;&lt;span&gt;&quot;async number: &lt;/span&gt;&lt;span&gt;{}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, number);
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;async_number&lt;/code&gt; function is an &lt;code&gt;async fn&lt;/code&gt;, so the compiler transforms it into a state machine that implements &lt;code&gt;Future&lt;/code&gt;. Since the function only returns &lt;code&gt;42&lt;/code&gt;, the resulting future will directly return &lt;code&gt;Poll::Ready(42)&lt;/code&gt; on the first &lt;code&gt;poll&lt;/code&gt; call. Like &lt;code&gt;async_number&lt;/code&gt;, the &lt;code&gt;example_task&lt;/code&gt; function is also an &lt;code&gt;async fn&lt;/code&gt;. It awaits the number returned by &lt;code&gt;async_number&lt;/code&gt; and then prints it using the &lt;code&gt;println&lt;/code&gt; macro.&lt;/p&gt;
&lt;p&gt;To run the future returned by &lt;code&gt;example_task&lt;/code&gt;, we need to call &lt;code&gt;poll&lt;/code&gt; on it until it signals its completion by returning &lt;code&gt;Poll::Ready&lt;/code&gt;. To do this, we need to create a simple executor type.&lt;/p&gt;
&lt;h3 id=&quot;task&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#task&quot; aria-label=&quot;Anchor link for: task&quot;&gt;🔗&lt;/a&gt;Task&lt;/h3&gt;
&lt;p&gt;Before we start the executor implementation, we create a new &lt;code&gt;task&lt;/code&gt; module with a &lt;code&gt;Task&lt;/code&gt; type:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;// in src/lib.rs

&lt;/span&gt;&lt;span&gt;pub mod &lt;/span&gt;&lt;span&gt;task;
&lt;/span&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;span&gt;// in src/task/mod.rs

&lt;/span&gt;&lt;span&gt;use &lt;/span&gt;&lt;span&gt;core::{future::Future, pin::Pin};
&lt;/span&gt;&lt;span&gt;use &lt;/span&gt;&lt;span&gt;alloc::boxed::Box;

&lt;/span&gt;&lt;span&gt;pub struct &lt;/span&gt;&lt;span&gt;Task {
    future: Pin&amp;lt;Box&amp;lt;dyn Future&amp;lt;Output = ()&amp;gt;&amp;gt;&amp;gt;,
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;Task&lt;/code&gt; struct is a newtype wrapper around a pinned, heap allocated, and dynamically dispatched future with the empty type &lt;code&gt;()&lt;/code&gt; as output. Let's go through it in detail:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;We require that the future associated with a task returns &lt;code&gt;()&lt;/code&gt;. This means that tasks don't return any result, they are just executed for its side effects. For example, the &lt;code&gt;example_task&lt;/code&gt; function we defined above has no return value, but it prints something to the screen as a side effect.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;dyn&lt;/code&gt; keyword indicates that we store a &lt;a href=&quot;https://doc.rust-lang.org/book/ch17-02-trait-objects.html&quot;&gt;&lt;em&gt;trait object&lt;/em&gt;&lt;/a&gt; in the &lt;code&gt;Box&lt;/code&gt;. This means that the methods on the future are &lt;a href=&quot;https://doc.rust-lang.org/book/ch17-02-trait-objects.html#trait-objects-perform-dynamic-dispatch&quot;&gt;&lt;em&gt;dynamically dispatched&lt;/em&gt;&lt;/a&gt;, which makes it possible to store different types of futures in the &lt;code&gt;Task&lt;/code&gt; type. This is important because each &lt;code&gt;async fn&lt;/code&gt; has its own type and we want to be able to create multiple different tasks.&lt;/li&gt;
&lt;li&gt;As we learned in the &lt;a href=&quot;https://os.phil-opp.com/async-await/#pinning&quot;&gt;section about pinning&lt;/a&gt;, the &lt;code&gt;Pin&amp;lt;Box&amp;gt;&lt;/code&gt; type ensures that a value cannot be moved in memory by placing it on the heap and preventing the creation of &lt;code&gt;&amp;amp;mut&lt;/code&gt; references to it. This is important because futures generated by async/await might be self-referential, i.e. contain pointers to itself that would be invalidated when the future is moved.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;To allow the creation of new &lt;code&gt;Task&lt;/code&gt; structs from futures, we create a &lt;code&gt;new&lt;/code&gt; function:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;// in src/task/mod.rs

&lt;/span&gt;&lt;span&gt;impl &lt;/span&gt;&lt;span&gt;Task {
    &lt;/span&gt;&lt;span&gt;pub fn &lt;/span&gt;&lt;span&gt;new(future: impl Future&amp;lt;Output = ()&amp;gt; + &lt;/span&gt;&lt;span&gt;'static&lt;/span&gt;&lt;span&gt;) -&amp;gt; Task {
        Task {
            future: Box::pin(future),
        }
    }
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;The function takes an arbitrary future with output type &lt;code&gt;()&lt;/code&gt; and pins it in memory through the &lt;a href=&quot;https://doc.rust-lang.org/nightly/alloc/boxed/struct.Box.html#method.pin&quot;&gt;&lt;code&gt;Box::pin&lt;/code&gt;&lt;/a&gt; function. Then it wraps the boxed future in the &lt;code&gt;Task&lt;/code&gt; struct and returns it. The &lt;code&gt;'static&lt;/code&gt; lifetime is required here because the returned &lt;code&gt;Task&lt;/code&gt; can live for an arbitrary time, so the future needs to be valid for that time too.&lt;/p&gt;
&lt;p&gt;We also add a &lt;code&gt;poll&lt;/code&gt; method to allow the executor to poll the stored future:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;// in src/task/mod.rs

&lt;/span&gt;&lt;span&gt;use &lt;/span&gt;&lt;span&gt;core::task::{Context, Poll};

&lt;/span&gt;&lt;span&gt;impl &lt;/span&gt;&lt;span&gt;Task {
    &lt;/span&gt;&lt;span&gt;fn &lt;/span&gt;&lt;span&gt;poll(&lt;/span&gt;&lt;span&gt;&amp;amp;mut &lt;/span&gt;&lt;span&gt;self, context: &lt;/span&gt;&lt;span&gt;&amp;amp;mut&lt;/span&gt;&lt;span&gt; Context) -&amp;gt; Poll&amp;lt;()&amp;gt; {
        self.future.as_mut().poll(context)
    }
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;Since the &lt;a href=&quot;https://doc.rust-lang.org/nightly/core/future/trait.Future.html#tymethod.poll&quot;&gt;&lt;code&gt;poll&lt;/code&gt;&lt;/a&gt; method of the &lt;code&gt;Future&lt;/code&gt; trait expects to be called on a &lt;code&gt;Pin&amp;lt;&amp;amp;mut T&amp;gt;&lt;/code&gt; type, we use the &lt;a href=&quot;https://doc.rust-lang.org/nightly/core/pin/struct.Pin.html#method.as_mut&quot;&gt;&lt;code&gt;Pin::as_mut&lt;/code&gt;&lt;/a&gt; method to convert the &lt;code&gt;self.future&lt;/code&gt; field of type &lt;code&gt;Pin&amp;lt;Box&amp;lt;T&amp;gt;&amp;gt;&lt;/code&gt; first. Then we call &lt;code&gt;poll&lt;/code&gt; on the converted &lt;code&gt;self.future&lt;/code&gt; field and return the result. Since the &lt;code&gt;Task::poll&lt;/code&gt; method should be only called by the executor that we create in a moment, we keep the function private to the &lt;code&gt;task&lt;/code&gt; module.&lt;/p&gt;
&lt;h3 id=&quot;simple-executor&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#simple-executor&quot; aria-label=&quot;Anchor link for: simple-executor&quot;&gt;🔗&lt;/a&gt;Simple Executor&lt;/h3&gt;
&lt;p&gt;Since executors can be quite complex, we deliberately start with creating a very basic executor before we implement a more featureful executor later. For this, we first create a new &lt;code&gt;task::simple_executor&lt;/code&gt; submodule:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;// in src/task/mod.rs

&lt;/span&gt;&lt;span&gt;pub mod &lt;/span&gt;&lt;span&gt;simple_executor;
&lt;/span&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;span&gt;// in src/task/simple_executor.rs

&lt;/span&gt;&lt;span&gt;use super&lt;/span&gt;&lt;span&gt;::Task;
&lt;/span&gt;&lt;span&gt;use &lt;/span&gt;&lt;span&gt;alloc::collections::VecDeque;

&lt;/span&gt;&lt;span&gt;pub struct &lt;/span&gt;&lt;span&gt;SimpleExecutor {
    task_queue: VecDeque&amp;lt;Task&amp;gt;,
}

&lt;/span&gt;&lt;span&gt;impl &lt;/span&gt;&lt;span&gt;SimpleExecutor {
    &lt;/span&gt;&lt;span&gt;pub fn &lt;/span&gt;&lt;span&gt;new() -&amp;gt; SimpleExecutor {
        SimpleExecutor {
            task_queue: VecDeque::new(),
        }
    }

    &lt;/span&gt;&lt;span&gt;pub fn &lt;/span&gt;&lt;span&gt;spawn(&lt;/span&gt;&lt;span&gt;&amp;amp;mut &lt;/span&gt;&lt;span&gt;self, task: Task) {
        self.task_queue.push_back(task)
    }
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;The struct contains a single &lt;code&gt;task_queue&lt;/code&gt; field of type &lt;a href=&quot;https://doc.rust-lang.org/stable/alloc/collections/vec_deque/struct.VecDeque.html&quot;&gt;&lt;code&gt;VecDeque&lt;/code&gt;&lt;/a&gt;, which is basically a vector that allows to push and pop operations on both ends. The idea behind using this type is that we insert new tasks through the &lt;code&gt;spawn&lt;/code&gt; method at the end and pop the next task for execution from the front. This way, we get a simple &lt;a href=&quot;https://en.wikipedia.org/wiki/FIFO_(computing_and_electronics)&quot;&gt;FIFO queue&lt;/a&gt; (&lt;em&gt;&quot;first in, first out&quot;&lt;/em&gt;).&lt;/p&gt;
&lt;h4 id=&quot;dummy-waker&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#dummy-waker&quot; aria-label=&quot;Anchor link for: dummy-waker&quot;&gt;🔗&lt;/a&gt;Dummy Waker&lt;/h4&gt;
&lt;p&gt;In order to call the &lt;code&gt;poll&lt;/code&gt; method, we need to create a &lt;a href=&quot;https://doc.rust-lang.org/nightly/core/task/struct.Context.html&quot;&gt;&lt;code&gt;Context&lt;/code&gt;&lt;/a&gt; type, which wraps a &lt;a href=&quot;https://doc.rust-lang.org/nightly/core/task/struct.Waker.html&quot;&gt;&lt;code&gt;Waker&lt;/code&gt;&lt;/a&gt; type. To start simple, we will first create a dummy waker that does nothing. For this, we create a &lt;a href=&quot;https://doc.rust-lang.org/stable/core/task/struct.RawWaker.html&quot;&gt;&lt;code&gt;RawWaker&lt;/code&gt;&lt;/a&gt; instance, which defines the implementation of the different &lt;code&gt;Waker&lt;/code&gt; methods, and then use the &lt;a href=&quot;https://doc.rust-lang.org/stable/core/task/struct.Waker.html#method.from_raw&quot;&gt;&lt;code&gt;Waker::from_raw&lt;/code&gt;&lt;/a&gt; function to turn it into a &lt;code&gt;Waker&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;// in src/task/simple_executor.rs

&lt;/span&gt;&lt;span&gt;use &lt;/span&gt;&lt;span&gt;core::task::{Waker, RawWaker};

&lt;/span&gt;&lt;span&gt;fn &lt;/span&gt;&lt;span&gt;dummy_raw_waker() -&amp;gt; RawWaker {
    todo!();
}

&lt;/span&gt;&lt;span&gt;fn &lt;/span&gt;&lt;span&gt;dummy_waker() -&amp;gt; Waker {
    &lt;/span&gt;&lt;span&gt;unsafe &lt;/span&gt;&lt;span&gt;{ Waker::from_raw(dummy_raw_waker()) }
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;from_raw&lt;/code&gt; function is unsafe because undefined behavior can occur if the programmer does not uphold the documented requirements of &lt;code&gt;RawWaker&lt;/code&gt;. Before we look at the implementation of the &lt;code&gt;dummy_raw_waker&lt;/code&gt; function, we first try to understand how the &lt;code&gt;RawWaker&lt;/code&gt; type works.&lt;/p&gt;
&lt;h5 id=&quot;rawwaker&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#rawwaker&quot; aria-label=&quot;Anchor link for: rawwaker&quot;&gt;🔗&lt;/a&gt;&lt;code&gt;RawWaker&lt;/code&gt;&lt;/h5&gt;
&lt;p&gt;The &lt;a href=&quot;https://doc.rust-lang.org/stable/core/task/struct.RawWaker.html&quot;&gt;&lt;code&gt;RawWaker&lt;/code&gt;&lt;/a&gt; type requires the programmer to explicitly define a &lt;a href=&quot;https://en.wikipedia.org/wiki/Virtual_method_table&quot;&gt;&lt;em&gt;virtual method table&lt;/em&gt;&lt;/a&gt; (&lt;em&gt;vtable&lt;/em&gt;) that specifies the functions that should be called when the &lt;code&gt;RawWaker&lt;/code&gt; is cloned, woken, or dropped. The layout of this vtable is defined by the &lt;a href=&quot;https://doc.rust-lang.org/stable/core/task/struct.RawWakerVTable.html&quot;&gt;&lt;code&gt;RawWakerVTable&lt;/code&gt;&lt;/a&gt; type. Each function receives a &lt;code&gt;*const ()&lt;/code&gt; argument that is basically a &lt;em&gt;type-erased&lt;/em&gt; &lt;code&gt;&amp;amp;self&lt;/code&gt; pointer to some struct, e.g. allocated on the heap. The reason for using a &lt;code&gt;*const ()&lt;/code&gt; pointer instead of a proper reference is that the &lt;code&gt;RawWaker&lt;/code&gt; type should be non-generic but still support arbitrary types. The pointer value that is passed to the functions is the &lt;code&gt;data&lt;/code&gt; pointer given to &lt;a href=&quot;https://doc.rust-lang.org/stable/core/task/struct.RawWaker.html#method.new&quot;&gt;&lt;code&gt;RawWaker::new&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Typically, the &lt;code&gt;RawWaker&lt;/code&gt; is created for some heap allocated struct that is wrapped into the &lt;a href=&quot;https://doc.rust-lang.org/stable/alloc/boxed/struct.Box.html&quot;&gt;&lt;code&gt;Box&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;https://doc.rust-lang.org/stable/alloc/sync/struct.Arc.html&quot;&gt;&lt;code&gt;Arc&lt;/code&gt;&lt;/a&gt; type. For such types, methods like &lt;a href=&quot;https://doc.rust-lang.org/stable/alloc/boxed/struct.Box.html#method.into_raw&quot;&gt;&lt;code&gt;Box::into_raw&lt;/code&gt;&lt;/a&gt; can be used to convert the &lt;code&gt;Box&amp;lt;T&amp;gt;&lt;/code&gt; to a &lt;code&gt;*const T&lt;/code&gt; pointer. This pointer can then be casted to an anonymous &lt;code&gt;*const ()&lt;/code&gt; pointer and passed to &lt;code&gt;RawWaker::new&lt;/code&gt;. Since each vtable function receives the same &lt;code&gt;*const ()&lt;/code&gt; as argument, the functions can safely cast the pointer back to a &lt;code&gt;Box&amp;lt;T&amp;gt;&lt;/code&gt; or a &lt;code&gt;&amp;amp;T&lt;/code&gt; to operate on it. As you can imagine, this process is highly dangerous and can easily lead to undefined behavior on mistakes. For this reason, manually creating a &lt;code&gt;RawWaker&lt;/code&gt; is not recommended unless necessary.&lt;/p&gt;
&lt;h5 id=&quot;a-dummy-rawwaker&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#a-dummy-rawwaker&quot; aria-label=&quot;Anchor link for: a-dummy-rawwaker&quot;&gt;🔗&lt;/a&gt;A Dummy &lt;code&gt;RawWaker&lt;/code&gt;&lt;/h5&gt;
&lt;p&gt;While manually creating a &lt;code&gt;RawWaker&lt;/code&gt; is not recommended, there is currently no other way to create a dummy &lt;code&gt;Waker&lt;/code&gt; that does nothing. Fortunately, the fact that we want to do nothing makes it relatively safe to implement the &lt;code&gt;dummy_raw_waker&lt;/code&gt; function:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;// in src/task/simple_executor.rs

&lt;/span&gt;&lt;span&gt;use &lt;/span&gt;&lt;span&gt;core::task::RawWakerVTable;

&lt;/span&gt;&lt;span&gt;fn &lt;/span&gt;&lt;span&gt;dummy_raw_waker() -&amp;gt; RawWaker {
    &lt;/span&gt;&lt;span&gt;fn &lt;/span&gt;&lt;span&gt;no_op(&lt;/span&gt;&lt;span&gt;_&lt;/span&gt;&lt;span&gt;: &lt;/span&gt;&lt;span&gt;*const &lt;/span&gt;&lt;span&gt;()) {}
    &lt;/span&gt;&lt;span&gt;fn &lt;/span&gt;&lt;span&gt;clone(&lt;/span&gt;&lt;span&gt;_&lt;/span&gt;&lt;span&gt;: &lt;/span&gt;&lt;span&gt;*const &lt;/span&gt;&lt;span&gt;()) -&amp;gt; RawWaker {
        dummy_raw_waker()
    }

    &lt;/span&gt;&lt;span&gt;let&lt;/span&gt;&lt;span&gt; vtable &lt;/span&gt;&lt;span&gt;= &amp;amp;&lt;/span&gt;&lt;span&gt;RawWakerVTable::new(clone, no_op, no_op, no_op);
    RawWaker::new(&lt;/span&gt;&lt;span&gt;0 &lt;/span&gt;&lt;span&gt;as *const &lt;/span&gt;&lt;span&gt;(), vtable)
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;First, we define two inner functions named &lt;code&gt;no_op&lt;/code&gt; and &lt;code&gt;clone&lt;/code&gt;. The &lt;code&gt;no_op&lt;/code&gt; function takes a &lt;code&gt;*const ()&lt;/code&gt; pointer and does nothing. The &lt;code&gt;clone&lt;/code&gt; function also takes a &lt;code&gt;*const ()&lt;/code&gt; pointer and returns a new &lt;code&gt;RawWaker&lt;/code&gt; by calling &lt;code&gt;dummy_raw_waker&lt;/code&gt; again. We use these two functions to create a minimal &lt;code&gt;RawWakerVTable&lt;/code&gt;: The &lt;code&gt;clone&lt;/code&gt; function is used for the cloning operations and the &lt;code&gt;no_op&lt;/code&gt; function is used for all other operations. Since the &lt;code&gt;RawWaker&lt;/code&gt; does nothing, it does not matter that we return a new &lt;code&gt;RawWaker&lt;/code&gt; from &lt;code&gt;clone&lt;/code&gt; instead of cloning it.&lt;/p&gt;
&lt;p&gt;After creating the &lt;code&gt;vtable&lt;/code&gt;, we use the &lt;a href=&quot;https://doc.rust-lang.org/stable/core/task/struct.RawWaker.html#method.new&quot;&gt;&lt;code&gt;RawWaker::new&lt;/code&gt;&lt;/a&gt; function to create the &lt;code&gt;RawWaker&lt;/code&gt;. The passed &lt;code&gt;*const ()&lt;/code&gt; does not matter since none of the vtable function uses it. For this reason, we simply pass a null pointer.&lt;/p&gt;
&lt;h4 id=&quot;a-run-method&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#a-run-method&quot; aria-label=&quot;Anchor link for: a-run-method&quot;&gt;🔗&lt;/a&gt;A &lt;code&gt;run&lt;/code&gt; Method&lt;/h4&gt;
&lt;p&gt;Now we have a way to create a &lt;code&gt;Waker&lt;/code&gt; instance, we can use it to implement a &lt;code&gt;run&lt;/code&gt; method on our executor. The most simple &lt;code&gt;run&lt;/code&gt; method is to repeatedly poll all queued tasks in a loop until all are done. This is not very efficient since it does not utilize the notifications of the &lt;code&gt;Waker&lt;/code&gt; type, but it is an easy way to get things running:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;// in src/task/simple_executor.rs

&lt;/span&gt;&lt;span&gt;use &lt;/span&gt;&lt;span&gt;core::task::{Context, Poll};

&lt;/span&gt;&lt;span&gt;impl &lt;/span&gt;&lt;span&gt;SimpleExecutor {
    &lt;/span&gt;&lt;span&gt;pub fn &lt;/span&gt;&lt;span&gt;run(&lt;/span&gt;&lt;span&gt;&amp;amp;mut &lt;/span&gt;&lt;span&gt;self) {
        &lt;/span&gt;&lt;span&gt;while let &lt;/span&gt;&lt;span&gt;Some(&lt;/span&gt;&lt;span&gt;mut&lt;/span&gt;&lt;span&gt; task) &lt;/span&gt;&lt;span&gt;= &lt;/span&gt;&lt;span&gt;self.task_queue.pop_front() {
            &lt;/span&gt;&lt;span&gt;let&lt;/span&gt;&lt;span&gt; waker &lt;/span&gt;&lt;span&gt;= &lt;/span&gt;&lt;span&gt;dummy_waker();
            &lt;/span&gt;&lt;span&gt;let mut&lt;/span&gt;&lt;span&gt; context &lt;/span&gt;&lt;span&gt;= &lt;/span&gt;&lt;span&gt;Context::from_waker(&lt;/span&gt;&lt;span&gt;&amp;amp;&lt;/span&gt;&lt;span&gt;waker);
            &lt;/span&gt;&lt;span&gt;match&lt;/span&gt;&lt;span&gt; task.poll(&lt;/span&gt;&lt;span&gt;&amp;amp;mut&lt;/span&gt;&lt;span&gt; context) {
                Poll::Ready(()) &lt;/span&gt;&lt;span&gt;=&amp;gt; &lt;/span&gt;&lt;span&gt;{} &lt;/span&gt;&lt;span&gt;// task done
                &lt;/span&gt;&lt;span&gt;Poll::Pending &lt;/span&gt;&lt;span&gt;=&amp;gt; &lt;/span&gt;&lt;span&gt;self.task_queue.push_back(task),
            }
        }
    }
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;The function uses a &lt;code&gt;while let&lt;/code&gt; loop to handle all tasks in the &lt;code&gt;task_queue&lt;/code&gt;. For each task, it first creates a &lt;code&gt;Context&lt;/code&gt; type by wrapping a &lt;code&gt;Waker&lt;/code&gt; instance returned by our &lt;code&gt;dummy_waker&lt;/code&gt; function. Then it invokes the &lt;code&gt;Task::poll&lt;/code&gt; method with this &lt;code&gt;context&lt;/code&gt;. If the &lt;code&gt;poll&lt;/code&gt; method returns &lt;code&gt;Poll::Ready&lt;/code&gt;, the task is finished and we can continue with the next task. If the task is still &lt;code&gt;Poll::Pending&lt;/code&gt;, we add it to the back of the queue again so that it will be polled again in a subsequent loop iteration.&lt;/p&gt;
&lt;h4 id=&quot;trying-it&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#trying-it&quot; aria-label=&quot;Anchor link for: trying-it&quot;&gt;🔗&lt;/a&gt;Trying It&lt;/h4&gt;
&lt;p&gt;With our &lt;code&gt;SimpleExecutor&lt;/code&gt; type, we can now try running the task returned by the &lt;code&gt;example_task&lt;/code&gt; function in our &lt;code&gt;main.rs&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;// in src/main.rs

&lt;/span&gt;&lt;span&gt;use &lt;/span&gt;&lt;span&gt;blog_os::task::{Task, simple_executor::SimpleExecutor};

&lt;/span&gt;&lt;span&gt;fn &lt;/span&gt;&lt;span&gt;kernel_main(boot_info: &lt;/span&gt;&lt;span&gt;&amp;amp;'static&lt;/span&gt;&lt;span&gt; BootInfo) -&amp;gt; &lt;/span&gt;&lt;span&gt;! &lt;/span&gt;&lt;span&gt;{
    &lt;/span&gt;&lt;span&gt;// […] initialization routines, including `init_heap`

    &lt;/span&gt;&lt;span&gt;let mut&lt;/span&gt;&lt;span&gt; executor &lt;/span&gt;&lt;span&gt;= &lt;/span&gt;&lt;span&gt;SimpleExecutor::new();
    executor.spawn(Task::new(example_task()));
    executor.run();

    &lt;/span&gt;&lt;span&gt;// […] test_main, &quot;it did not crash&quot; message, hlt_loop
&lt;/span&gt;&lt;span&gt;}


&lt;/span&gt;&lt;span&gt;// Below is the example_task function again so that you don't have to scroll up
&lt;/span&gt;&lt;span&gt;
async &lt;/span&gt;&lt;span&gt;fn &lt;/span&gt;&lt;span&gt;async_number() -&amp;gt; &lt;/span&gt;&lt;span&gt;u32 &lt;/span&gt;&lt;span&gt;{
    &lt;/span&gt;&lt;span&gt;42
&lt;/span&gt;&lt;span&gt;}

async &lt;/span&gt;&lt;span&gt;fn &lt;/span&gt;&lt;span&gt;example_task() {
    &lt;/span&gt;&lt;span&gt;let&lt;/span&gt;&lt;span&gt; number &lt;/span&gt;&lt;span&gt;= &lt;/span&gt;&lt;span&gt;async_number().await;
    println!(&lt;/span&gt;&lt;span&gt;&quot;async number: &lt;/span&gt;&lt;span&gt;{}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, number);
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;When we run it, we see that the expected &lt;em&gt;&quot;async number: 42&quot;&lt;/em&gt; message is printed to the screen:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://os.phil-opp.com/async-await/qemu-simple-executor.png&quot; alt=&quot;QEMU printing &amp;quot;Hello World&amp;quot;, &amp;quot;async number: 42&amp;quot;, and &amp;quot;It did not crash!&amp;quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Let's summarize the various steps that happen for this example:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;First, a new instance of our &lt;code&gt;SimpleExecutor&lt;/code&gt; type is created with an empty &lt;code&gt;task_queue&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Next, we call the asynchronous &lt;code&gt;example_task&lt;/code&gt; function, which returns a future. We wrap this future in the &lt;code&gt;Task&lt;/code&gt; type, which moves it to the heap and pins it, and then add the task to the &lt;code&gt;task_queue&lt;/code&gt; of the executor through the &lt;code&gt;spawn&lt;/code&gt; method.&lt;/li&gt;
&lt;li&gt;We then call the &lt;code&gt;run&lt;/code&gt; method to start the execution of the single task in the queue. This involves:
&lt;ul&gt;&lt;li&gt;Popping the task from the front of the &lt;code&gt;task_queue&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Creating a &lt;code&gt;RawWaker&lt;/code&gt; for the task, converting it to a &lt;a href=&quot;https://doc.rust-lang.org/nightly/core/task/struct.Waker.html&quot;&gt;&lt;code&gt;Waker&lt;/code&gt;&lt;/a&gt; instance, and then creating a &lt;a href=&quot;https://doc.rust-lang.org/nightly/core/task/struct.Context.html&quot;&gt;&lt;code&gt;Context&lt;/code&gt;&lt;/a&gt; instance from it.&lt;/li&gt;
&lt;li&gt;Calling the &lt;a href=&quot;https://doc.rust-lang.org/nightly/core/future/trait.Future.html#tymethod.poll&quot;&gt;&lt;code&gt;poll&lt;/code&gt;&lt;/a&gt; method on the future of the task, using the &lt;code&gt;Context&lt;/code&gt; we just created.&lt;/li&gt;
&lt;li&gt;Since the &lt;code&gt;example_task&lt;/code&gt; does not wait for anything, it can directly run til its end on the first &lt;code&gt;poll&lt;/code&gt; call. This is where the &lt;em&gt;&quot;async number: 42&quot;&lt;/em&gt; line is printed.&lt;/li&gt;
&lt;li&gt;Since the &lt;code&gt;example_task&lt;/code&gt; directly returns &lt;code&gt;Poll::Ready&lt;/code&gt;, it is not added back to the task queue.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;run&lt;/code&gt; method returns after the &lt;code&gt;task_queue&lt;/code&gt; becomes empty. The execution of our &lt;code&gt;kernel_main&lt;/code&gt; function continues and the &lt;em&gt;&quot;It did not crash!&quot;&lt;/em&gt; message is printed.&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;async-keyboard-input&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#async-keyboard-input&quot; aria-label=&quot;Anchor link for: async-keyboard-input&quot;&gt;🔗&lt;/a&gt;Async Keyboard Input&lt;/h3&gt;
&lt;p&gt;Our simple executor does not utilize the &lt;code&gt;Waker&lt;/code&gt; notifications and simply loops over all tasks until they are done. This wasn't a problem for our example since our &lt;code&gt;example_task&lt;/code&gt; can directly run to finish on the first &lt;code&gt;poll&lt;/code&gt; call. To see the performance advantages of a proper &lt;code&gt;Waker&lt;/code&gt; implementation, we first need to create a task that is truly asynchronous, i.e. a task that will probably return &lt;code&gt;Poll::Pending&lt;/code&gt; on the first &lt;code&gt;poll&lt;/code&gt; call.&lt;/p&gt;
&lt;p&gt;We already have some kind of asynchronicity in our system that we can use for this: hardware interrupts. As we learned in the &lt;a href=&quot;https://os.phil-opp.com/hardware-interrupts/&quot;&gt;&lt;em&gt;Interrupts&lt;/em&gt;&lt;/a&gt; post, hardware interrupts can occur at arbitrary points in time, determined by some external device. For example, a hardware timer sends an interrupt to the CPU after some predefined time elapsed. When the CPU receives an interrupt, it immediately transfers control to the corresponding handler function defined in the interrupt descriptor table (IDT).&lt;/p&gt;
&lt;p&gt;In the following, we will create an asynchronous task based on the keyboard interrupt. The keyboard interrupt is a good candidate for this because it is both non-deterministic and latency-critical. Non-deteministic means that there is no way to predict when the next key press will occur because it is entirely dependent on the user. Latency-critical means that we want to handle the keyboard input in a timely manner, otherwise the user will feel a lag. To support such a task in an efficient way, it will be essential that the executor has proper support for &lt;code&gt;Waker&lt;/code&gt; notifications.&lt;/p&gt;
&lt;h4 id=&quot;scancode-queue&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#scancode-queue&quot; aria-label=&quot;Anchor link for: scancode-queue&quot;&gt;🔗&lt;/a&gt;Scancode Queue&lt;/h4&gt;
&lt;p&gt;Currently, we handle the keyboard input directly in the interrupt handler. This is not a good idea for the long term because interrupt handlers should stay as short as possible as they might interrupt important work. Instead, interrupt handlers should only perform the minimal amount of work necessary (e.g. reading the keyboard scancode) and leave the rest of the work (e.g. interpreting the scancode) to a background task.&lt;/p&gt;
&lt;p&gt;A common pattern for delegating work to a background task is to create some sort of queue. The interrupt handler pushes work units of work to the queue and the background task handles the work in the queue. Applied to our keyboard interrupt, this means that the interrupt handler only reads the scancode from the keyboard, pushes it to the queue, and then returns. The keyboard task sits on the other end of the queue and interprets and handles each scancode that is pushed to it:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://os.phil-opp.com/async-await/scancode-queue.svg&quot; alt=&quot;Scancode queue with 8 slots on the top. Keyboard interrupt handler on the bottom left with a &amp;quot;push scancode&amp;quot; arrow to the left of the queue. Keyboard task on the bottom right with a &amp;quot;pop scancode&amp;quot; queue coming from the right side of the queue.&quot;/&gt;&lt;/p&gt;
&lt;p&gt;A simple implementation of that queue could be a mutex-protected &lt;a href=&quot;https://doc.rust-lang.org/stable/alloc/collections/vec_deque/struct.VecDeque.html&quot;&gt;&lt;code&gt;VecDeque&lt;/code&gt;&lt;/a&gt;. However, using mutexes in interrupt handlers is not a good idea since it can easily lead to deadlocks. For example, when the user presses a key while the keyboard task has locked the queue, the interrupt handler tries to acquire the lock again and hangs indefinitely. Another problem with this approach is that &lt;code&gt;VecDeque&lt;/code&gt; automatically increases its capacity by performing a new heap allocation when it becomes full. This can lead to deadlocks again because our allocator also uses a mutex internally. Further problems are that heap allocations can fail or take a considerable amount of time when the heap is fragmented.&lt;/p&gt;
&lt;p&gt;To prevent these problems, we need a queue implementation that does not require mutexes or allocations for its &lt;code&gt;push&lt;/code&gt; operation. Such queues can be implemented by using lock-free &lt;a href=&quot;https://doc.rust-lang.org/core/sync/atomic/index.html&quot;&gt;atomic operations&lt;/a&gt; for pushing and popping elements. This way, it is possible to create &lt;code&gt;push&lt;/code&gt; and &lt;code&gt;pop&lt;/code&gt; operations that only require a &lt;code&gt;&amp;amp;self&lt;/code&gt; reference and are thus usable without a mutex. To avoid allocations on &lt;code&gt;push&lt;/code&gt;, the queue can be backed by a pre-allocated fixed-size buffer. While this makes the queue &lt;em&gt;bounded&lt;/em&gt; (i.e. it has a maximum length), it is often possible to define reasonable upper bounds for the queue length in practice so that this isn't a big problem.&lt;/p&gt;
&lt;h5 id=&quot;the-crossbeam-crate&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#the-crossbeam-crate&quot; aria-label=&quot;Anchor link for: the-crossbeam-crate&quot;&gt;🔗&lt;/a&gt;The &lt;code&gt;crossbeam&lt;/code&gt; Crate&lt;/h5&gt;
&lt;p&gt;Implementing such a queue in a correct and efficient way is very difficult, so I recommend to stick to existing, well-tested implementations. One popular Rust project that implements various mutex-free types for concurrent programming is &lt;a href=&quot;https://github.com/crossbeam-rs/crossbeam&quot;&gt;&lt;code&gt;crossbeam&lt;/code&gt;&lt;/a&gt;. It provides a type named &lt;a href=&quot;https://docs.rs/crossbeam/0.7.3/crossbeam/queue/struct.ArrayQueue.html&quot;&gt;&lt;code&gt;ArrayQueue&lt;/code&gt;&lt;/a&gt; that is exactly what we need in this case. And we're lucky: The type is fully compatible to &lt;code&gt;no_std&lt;/code&gt; crates with allocation support.&lt;/p&gt;
&lt;p&gt;To use the type, we need to add a dependency on the &lt;code&gt;crossbeam-queue&lt;/code&gt; crate:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;# in Cargo.toml

&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;dependencies.crossbeam-queue&lt;/span&gt;&lt;span&gt;]
&lt;/span&gt;&lt;span&gt;version &lt;/span&gt;&lt;span&gt;= &lt;/span&gt;&lt;span&gt;&quot;0.2.1&quot;
&lt;/span&gt;&lt;span&gt;default-features &lt;/span&gt;&lt;span&gt;= &lt;/span&gt;&lt;span&gt;false
features &lt;/span&gt;&lt;span&gt;= [&lt;/span&gt;&lt;span&gt;&quot;alloc&quot;&lt;/span&gt;&lt;span&gt;]
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;By default, the crate depends on the standard library. To make it &lt;code&gt;no_std&lt;/code&gt; compatible, we need to disable its default features and instead enable the &lt;code&gt;alloc&lt;/code&gt; feature. &lt;span class=&quot;gray&quot;&gt;(Note that depending on the main &lt;code&gt;crossbeam&lt;/code&gt; crate does not work here because it is missing an export of the &lt;code&gt;queue&lt;/code&gt; module for &lt;code&gt;no_std&lt;/code&gt;. I filed a &lt;a href=&quot;https://github.com/crossbeam-rs/crossbeam/pull/480&quot;&gt;pull request&lt;/a&gt; to fix this, but it wasn't released on crates.io yet.)&lt;/span&gt;&lt;/p&gt;
&lt;h5 id=&quot;queue-implementation&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#queue-implementation&quot; aria-label=&quot;Anchor link for: queue-implementation&quot;&gt;🔗&lt;/a&gt;Queue Implementation&lt;/h5&gt;
&lt;p&gt;Using the &lt;code&gt;ArrayQueue&lt;/code&gt; type, we can now create a global scancode queue in a new &lt;code&gt;task::keyboard&lt;/code&gt; module:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;// in src/task/mod.rs

&lt;/span&gt;&lt;span&gt;pub mod &lt;/span&gt;&lt;span&gt;keyboard;
&lt;/span&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;span&gt;// in src/task/keyboard.rs

&lt;/span&gt;&lt;span&gt;use &lt;/span&gt;&lt;span&gt;conquer_once::spin::OnceCell;
&lt;/span&gt;&lt;span&gt;use &lt;/span&gt;&lt;span&gt;crossbeam_queue::ArrayQueue;

&lt;/span&gt;&lt;span&gt;static &lt;/span&gt;&lt;span&gt;SCANCODE_QUEUE&lt;/span&gt;&lt;span&gt;: OnceCell&amp;lt;ArrayQueue&amp;lt;&lt;/span&gt;&lt;span&gt;u8&lt;/span&gt;&lt;span&gt;&amp;gt;&amp;gt; &lt;/span&gt;&lt;span&gt;= &lt;/span&gt;&lt;span&gt;OnceCell::uninit();
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;Since the &lt;a href=&quot;https://docs.rs/crossbeam/0.7.3/crossbeam/queue/struct.ArrayQueue.html#method.new&quot;&gt;&lt;code&gt;ArrayQueue::new&lt;/code&gt;&lt;/a&gt; performs a heap allocation, which are not possible at compile time (&lt;a href=&quot;https://github.com/rust-lang/const-eval/issues/20&quot;&gt;yet&lt;/a&gt;), we can't initialize the static variable directly. Instead, we use the &lt;a href=&quot;https://docs.rs/conquer-once/0.2.0/conquer_once/raw/struct.OnceCell.html&quot;&gt;&lt;code&gt;OnceCell&lt;/code&gt;&lt;/a&gt; type of the &lt;a href=&quot;https://docs.rs/conquer-once/0.2.0/conquer_once/index.html&quot;&gt;&lt;code&gt;conquer_once&lt;/code&gt;&lt;/a&gt; crate, which makes it possible to perform safe one-time initialization of static values. To include the crate, we need to add it as a dependency in our &lt;code&gt;Cargo.toml&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;# in Cargo.toml

&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;dependencies.conquer-once&lt;/span&gt;&lt;span&gt;]
&lt;/span&gt;&lt;span&gt;version &lt;/span&gt;&lt;span&gt;= &lt;/span&gt;&lt;span&gt;&quot;0.2.0&quot;
&lt;/span&gt;&lt;span&gt;default-features &lt;/span&gt;&lt;span&gt;= &lt;/span&gt;&lt;span&gt;false
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;Instead of the &lt;a href=&quot;https://docs.rs/conquer-once/0.2.0/conquer_once/raw/struct.OnceCell.html&quot;&gt;&lt;code&gt;OnceCell&lt;/code&gt;&lt;/a&gt; primitive, we could also use the &lt;a href=&quot;https://docs.rs/lazy_static/1.4.0/lazy_static/index.html&quot;&gt;&lt;code&gt;lazy_static&lt;/code&gt;&lt;/a&gt; macro here. However, the &lt;code&gt;OnceCell&lt;/code&gt; type has the advantage that we can ensure that the initialization does not happen in the interrupt handler, thus preventing that the interrupt handler performs a heap allocation.&lt;/p&gt;
&lt;h4 id=&quot;filling-the-queue&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#filling-the-queue&quot; aria-label=&quot;Anchor link for: filling-the-queue&quot;&gt;🔗&lt;/a&gt;Filling the Queue&lt;/h4&gt;
&lt;p&gt;To fill the scancode queue, we create a new &lt;code&gt;add_scancode&lt;/code&gt; function that we will call from the interrupt handler:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;// in src/task/keyboard.rs

&lt;/span&gt;&lt;span&gt;use crate&lt;/span&gt;&lt;span&gt;::println;

&lt;/span&gt;&lt;span&gt;/// Called by the keyboard interrupt handler
///
/// Must not block or allocate.
&lt;/span&gt;&lt;span&gt;pub&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;crate&lt;/span&gt;&lt;span&gt;) &lt;/span&gt;&lt;span&gt;fn &lt;/span&gt;&lt;span&gt;add_scancode(scancode: &lt;/span&gt;&lt;span&gt;u8&lt;/span&gt;&lt;span&gt;) {
    &lt;/span&gt;&lt;span&gt;if let &lt;/span&gt;&lt;span&gt;Ok(queue) &lt;/span&gt;&lt;span&gt;= &lt;/span&gt;&lt;span&gt;SCANCODE_QUEUE&lt;/span&gt;&lt;span&gt;.try_get() {
        &lt;/span&gt;&lt;span&gt;if let &lt;/span&gt;&lt;span&gt;Err(&lt;/span&gt;&lt;span&gt;_&lt;/span&gt;&lt;span&gt;) &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; queue.push(scancode) {
            println!(&lt;/span&gt;&lt;span&gt;&quot;WARNING: scancode queue full; dropping keyboard input&quot;&lt;/span&gt;&lt;span&gt;);
        }
    } &lt;/span&gt;&lt;span&gt;else &lt;/span&gt;&lt;span&gt;{
        println!(&lt;/span&gt;&lt;span&gt;&quot;WARNING: scancode queue uninitialized&quot;&lt;/span&gt;&lt;span&gt;);
    }
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;We use the &lt;a href=&quot;https://docs.rs/conquer-once/0.2.0/conquer_once/raw/struct.OnceCell.html#method.try_get&quot;&gt;&lt;code&gt;OnceCell::try_get&lt;/code&gt;&lt;/a&gt; to get a reference to the initialized queue. If the queue is not initialized yet, we ignore the keyboard scancode and print a warning. It's important that we don't try to initialize the queue in this function because it will be called by the interrupt handler, which should not perform heap allocations. Since this function should not be callable from our &lt;code&gt;main.rs&lt;/code&gt;, we use the &lt;code&gt;pub(crate)&lt;/code&gt; visibility to make it only available to our &lt;code&gt;lib.rs&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The fact that the &lt;a href=&quot;https://docs.rs/crossbeam/0.7.3/crossbeam/queue/struct.ArrayQueue.html#method.push&quot;&gt;&lt;code&gt;ArrayQueue::push&lt;/code&gt;&lt;/a&gt; method requires only a &lt;code&gt;&amp;amp;self&lt;/code&gt; reference makes it very simple to call the method on the static queue. The &lt;code&gt;ArrayQueue&lt;/code&gt; type performs all necessary synchronization itself, so we don't need a mutex wrapper here. In case the queue is full, we print a warning too.&lt;/p&gt;
&lt;p&gt;To call the &lt;code&gt;add_scancode&lt;/code&gt; function on keyboard interrupts, we update our &lt;code&gt;keyboard_interrupt_handler&lt;/code&gt; function in the &lt;code&gt;interrupts&lt;/code&gt; module:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;// in src/interrupts.rs

&lt;/span&gt;&lt;span&gt;extern &lt;/span&gt;&lt;span&gt;&quot;x86-interrupt&quot; &lt;/span&gt;&lt;span&gt;fn &lt;/span&gt;&lt;span&gt;keyboard_interrupt_handler(
    _stack_frame: &lt;/span&gt;&lt;span&gt;&amp;amp;mut&lt;/span&gt;&lt;span&gt; InterruptStackFrame
) {
    &lt;/span&gt;&lt;span&gt;use &lt;/span&gt;&lt;span&gt;x86_64::instructions::port::Port;

    &lt;/span&gt;&lt;span&gt;let mut&lt;/span&gt;&lt;span&gt; port &lt;/span&gt;&lt;span&gt;= &lt;/span&gt;&lt;span&gt;Port::new(&lt;/span&gt;&lt;span&gt;0x60&lt;/span&gt;&lt;span&gt;);
    &lt;/span&gt;&lt;span&gt;let&lt;/span&gt;&lt;span&gt; scancode: &lt;/span&gt;&lt;span&gt;u8 = unsafe &lt;/span&gt;&lt;span&gt;{ port.read() };
    &lt;/span&gt;&lt;span&gt;crate&lt;/span&gt;&lt;span&gt;::task::keyboard::add_scancode(scancode); &lt;/span&gt;&lt;span&gt;// new

    &lt;/span&gt;&lt;span&gt;unsafe &lt;/span&gt;&lt;span&gt;{
        &lt;/span&gt;&lt;span&gt;PICS&lt;/span&gt;&lt;span&gt;.lock()
            .notify_end_of_interrupt(InterruptIndex::Keyboard.as_u8());
    }
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;We removed all the keyboard handling code from this function and instead added a call to the &lt;code&gt;add_scancode&lt;/code&gt; function. The rest of the function stays the same as before.&lt;/p&gt;
&lt;p&gt;As expected, keypresses are no longer printed to the screen when we run our project using &lt;code&gt;cargo xrun&lt;/code&gt; now. Instead, we see the warning that the scancode queue is uninitialized for every keystroke.&lt;/p&gt;
&lt;h4 id=&quot;scancode-stream&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#scancode-stream&quot; aria-label=&quot;Anchor link for: scancode-stream&quot;&gt;🔗&lt;/a&gt;Scancode Stream&lt;/h4&gt;
&lt;p&gt;To initialize the &lt;code&gt;SCANCODE_QUEUE&lt;/code&gt; and read the scancodes from the queue in an asynchronous way, we create a new &lt;code&gt;ScancodeStream&lt;/code&gt; type:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;// in src/task/keyboard.rs

&lt;/span&gt;&lt;span&gt;pub struct &lt;/span&gt;&lt;span&gt;ScancodeStream {
    _private: (),
}

&lt;/span&gt;&lt;span&gt;impl &lt;/span&gt;&lt;span&gt;ScancodeStream {
    &lt;/span&gt;&lt;span&gt;pub fn &lt;/span&gt;&lt;span&gt;new() -&amp;gt; &lt;/span&gt;&lt;span&gt;Self &lt;/span&gt;&lt;span&gt;{
        &lt;/span&gt;&lt;span&gt;SCANCODE_QUEUE&lt;/span&gt;&lt;span&gt;.try_init_once(|| ArrayQueue::new(&lt;/span&gt;&lt;span&gt;100&lt;/span&gt;&lt;span&gt;))
            .expect(&lt;/span&gt;&lt;span&gt;&quot;ScancodeStream::new should only be called once&quot;&lt;/span&gt;&lt;span&gt;);
        ScancodeStream { _private: () }
    }
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;The purpose of the &lt;code&gt;_private&lt;/code&gt; field is to prevent construction of the struct from outside of the module. This makes the &lt;code&gt;new&lt;/code&gt; function the only way to construct the type. In the function, we first try to initialize the &lt;code&gt;SCANCODE_QUEUE&lt;/code&gt; static. We panic if it is already initialized to ensure that only a single &lt;code&gt;ScancodeStream&lt;/code&gt; instance can be created.&lt;/p&gt;
&lt;p&gt;To make the scancodes available to asynchronous tasks, the next step is to implement &lt;code&gt;poll&lt;/code&gt;-like method that tries to pop the next scancode off the queue. While this sounds like we should implement &lt;a href=&quot;https://doc.rust-lang.org/nightly/core/future/trait.Future.html&quot;&gt;&lt;code&gt;Future&lt;/code&gt;&lt;/a&gt; trait for our type, this does not quite fit here. The problem is that the &lt;code&gt;Future&lt;/code&gt; trait only abstracts over a single asynchronous value and expects that the &lt;code&gt;poll&lt;/code&gt; method is not called again after it returns &lt;code&gt;Poll::Ready&lt;/code&gt;. Our scancode queue, however, contains multiple asynchronous values so that it is ok to keep polling it.&lt;/p&gt;
&lt;h5 id=&quot;the-stream-trait&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#the-stream-trait&quot; aria-label=&quot;Anchor link for: the-stream-trait&quot;&gt;🔗&lt;/a&gt;The &lt;code&gt;Stream&lt;/code&gt; Trait&lt;/h5&gt;
&lt;p&gt;Since types that yield multiple asynchronous values are common, the &lt;a href=&quot;https://docs.rs/futures/0.3.4/futures/&quot;&gt;&lt;code&gt;futures&lt;/code&gt;&lt;/a&gt; crate provides a useful abstraction for such types: the &lt;a href=&quot;https://rust-lang.github.io/async-book/05_streams/01_chapter.html&quot;&gt;&lt;code&gt;Stream&lt;/code&gt;&lt;/a&gt; trait. The trait is defined like this:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;pub trait &lt;/span&gt;&lt;span&gt;Stream {
    &lt;/span&gt;&lt;span&gt;type &lt;/span&gt;&lt;span&gt;Item&lt;/span&gt;&lt;span&gt;;

    &lt;/span&gt;&lt;span&gt;fn &lt;/span&gt;&lt;span&gt;poll_next(self: Pin&amp;lt;&lt;/span&gt;&lt;span&gt;&amp;amp;mut Self&lt;/span&gt;&lt;span&gt;&amp;gt;, cx: &lt;/span&gt;&lt;span&gt;&amp;amp;mut&lt;/span&gt;&lt;span&gt; Context)
        -&amp;gt; Poll&amp;lt;Option&amp;lt;&lt;/span&gt;&lt;span&gt;Self::&lt;/span&gt;&lt;span&gt;Item&amp;gt;&amp;gt;;
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;This definition is quite similar to the &lt;a href=&quot;https://doc.rust-lang.org/nightly/core/future/trait.Future.html&quot;&gt;&lt;code&gt;Future&lt;/code&gt;&lt;/a&gt; trait, with the following differences:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;The associated type is named &lt;code&gt;Item&lt;/code&gt; instead of &lt;code&gt;Output&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Instead of a &lt;code&gt;poll&lt;/code&gt; method that returns &lt;code&gt;Poll&amp;lt;Self::Item&amp;gt;&lt;/code&gt;, the &lt;code&gt;Stream&lt;/code&gt; trait defines a &lt;code&gt;poll_next&lt;/code&gt; method that returns a &lt;code&gt;Poll&amp;lt;Option&amp;lt;Self::Item&amp;gt;&amp;gt;&lt;/code&gt; (note the additional &lt;code&gt;Option&lt;/code&gt;).&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;There is also a semantic difference: The &lt;code&gt;poll_next&lt;/code&gt; can be called repeatedly, until it returns &lt;code&gt;Poll::Ready(None)&lt;/code&gt; to signal that the stream is finished. In this regard, the method is similar to the &lt;a href=&quot;https://doc.rust-lang.org/stable/core/iter/trait.Iterator.html#tymethod.next&quot;&gt;&lt;code&gt;Iterator::next&lt;/code&gt;&lt;/a&gt; method, which also returns &lt;code&gt;None&lt;/code&gt; after the last value.&lt;/p&gt;
&lt;h5 id=&quot;implementing-stream&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#implementing-stream&quot; aria-label=&quot;Anchor link for: implementing-stream&quot;&gt;🔗&lt;/a&gt;Implementing &lt;code&gt;Stream&lt;/code&gt;&lt;/h5&gt;
&lt;p&gt;Let's implement the &lt;code&gt;Stream&lt;/code&gt; trait for our &lt;code&gt;ScancodeStream&lt;/code&gt; to provide the values of the &lt;code&gt;SCANCODE_QUEUE&lt;/code&gt; in an asynchronous way. For this, we first need to add a dependency on the &lt;code&gt;futures-util&lt;/code&gt; crate, which contains the &lt;code&gt;Stream&lt;/code&gt; type:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;# in Cargo.toml

&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;dependencies.futures-util&lt;/span&gt;&lt;span&gt;]
&lt;/span&gt;&lt;span&gt;version &lt;/span&gt;&lt;span&gt;= &lt;/span&gt;&lt;span&gt;&quot;0.3.4&quot;
&lt;/span&gt;&lt;span&gt;default-features &lt;/span&gt;&lt;span&gt;= &lt;/span&gt;&lt;span&gt;false
features &lt;/span&gt;&lt;span&gt;= [&lt;/span&gt;&lt;span&gt;&quot;alloc&quot;&lt;/span&gt;&lt;span&gt;]
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;We disable the default features to make the crate &lt;code&gt;no_std&lt;/code&gt; compatible and enable the &lt;code&gt;alloc&lt;/code&gt; feature to make its allocation-based types available (we will need this later). &lt;span class=&quot;gray&quot;&gt;(Note that we could also add a dependency on the main &lt;code&gt;futures&lt;/code&gt; crate, which re-exports the &lt;code&gt;futures-util&lt;/code&gt; crate, but this would result in a larger number of dependencies and longer compile times.)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Now we can import and implement the &lt;code&gt;Stream&lt;/code&gt; trait:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;// in src/task/keyboard.rs

&lt;/span&gt;&lt;span&gt;use &lt;/span&gt;&lt;span&gt;core::{pin::Pin, task::{Poll, Context}};
&lt;/span&gt;&lt;span&gt;use &lt;/span&gt;&lt;span&gt;futures_util::stream::Stream;

&lt;/span&gt;&lt;span&gt;impl &lt;/span&gt;&lt;span&gt;Stream &lt;/span&gt;&lt;span&gt;for &lt;/span&gt;&lt;span&gt;ScancodeStream {
    &lt;/span&gt;&lt;span&gt;type &lt;/span&gt;&lt;span&gt;Item &lt;/span&gt;&lt;span&gt;= u8&lt;/span&gt;&lt;span&gt;;

    &lt;/span&gt;&lt;span&gt;fn &lt;/span&gt;&lt;span&gt;poll_next(self: Pin&amp;lt;&lt;/span&gt;&lt;span&gt;&amp;amp;mut Self&lt;/span&gt;&lt;span&gt;&amp;gt;, cx: &lt;/span&gt;&lt;span&gt;&amp;amp;mut&lt;/span&gt;&lt;span&gt; Context) -&amp;gt; Poll&amp;lt;Option&amp;lt;&lt;/span&gt;&lt;span&gt;u8&lt;/span&gt;&lt;span&gt;&amp;gt;&amp;gt; {
        &lt;/span&gt;&lt;span&gt;let&lt;/span&gt;&lt;span&gt; queue &lt;/span&gt;&lt;span&gt;= &lt;/span&gt;&lt;span&gt;SCANCODE_QUEUE&lt;/span&gt;&lt;span&gt;.try_get().expect(&lt;/span&gt;&lt;span&gt;&quot;not initialized&quot;&lt;/span&gt;&lt;span&gt;);
        &lt;/span&gt;&lt;span&gt;match&lt;/span&gt;&lt;span&gt; queue.pop() {
            Ok(scancode) &lt;/span&gt;&lt;span&gt;=&amp;gt; &lt;/span&gt;&lt;span&gt;Poll::Ready(Some(scancode)),
            Err(crossbeam_queue::PopError) &lt;/span&gt;&lt;span&gt;=&amp;gt; &lt;/span&gt;&lt;span&gt;Poll::Pending,
        }
    }
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;We first use the &lt;a href=&quot;https://docs.rs/conquer-once/0.2.0/conquer_once/raw/struct.OnceCell.html#method.try_get&quot;&gt;&lt;code&gt;OnceCell::try_get&lt;/code&gt;&lt;/a&gt; method to get a reference to the initialized scancode queue. This should never fail since we initialize the queue in the &lt;code&gt;new&lt;/code&gt; function, so we can safely use the &lt;code&gt;expect&lt;/code&gt; method to panic if it's not initialized. Next, we use the &lt;a href=&quot;https://docs.rs/crossbeam/0.7.3/crossbeam/queue/struct.ArrayQueue.html#method.pop&quot;&gt;&lt;code&gt;ArrayQueue::pop&lt;/code&gt;&lt;/a&gt; method to try to get the next element from the queue. If it succeeds we return the scancode wrapped in &lt;code&gt;Poll::Ready(Some(…))&lt;/code&gt;. If it fails, it means that the queue is empty. In that case, we return &lt;code&gt;Poll::Pending&lt;/code&gt;.&lt;/p&gt;
&lt;h4 id=&quot;waker-support&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#waker-support&quot; aria-label=&quot;Anchor link for: waker-support&quot;&gt;🔗&lt;/a&gt;Waker Support&lt;/h4&gt;
&lt;p&gt;Like the &lt;code&gt;Futures::poll&lt;/code&gt; method, the &lt;code&gt;Stream::poll_next&lt;/code&gt; method requires that the asynchronous task notifies the executor when it becomes ready after &lt;code&gt;Poll::Pending&lt;/code&gt; is returned. This way, the executor does not need to poll the same task again until it is notified, which greatly reduces the performance overhead of waiting tasks.&lt;/p&gt;
&lt;p&gt;To send this notification, the task should extract the &lt;a href=&quot;https://doc.rust-lang.org/nightly/core/task/struct.Waker.html&quot;&gt;&lt;code&gt;Waker&lt;/code&gt;&lt;/a&gt; from the passed &lt;a href=&quot;https://doc.rust-lang.org/nightly/core/task/struct.Context.html&quot;&gt;&lt;code&gt;Context&lt;/code&gt;&lt;/a&gt; reference and store it somewhere. When the task becomes ready, it should invoke the &lt;a href=&quot;https://doc.rust-lang.org/stable/core/task/struct.Waker.html#method.wake&quot;&gt;&lt;code&gt;wake&lt;/code&gt;&lt;/a&gt; method on the stored &lt;code&gt;Waker&lt;/code&gt; to notify the executor that the task should be polled again.&lt;/p&gt;
&lt;h5 id=&quot;atomicwaker&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#atomicwaker&quot; aria-label=&quot;Anchor link for: atomicwaker&quot;&gt;🔗&lt;/a&gt;AtomicWaker&lt;/h5&gt;
&lt;p&gt;To implement the &lt;code&gt;Waker&lt;/code&gt; notification for our &lt;code&gt;ScancodeStream&lt;/code&gt;, we need a place where we can store the &lt;code&gt;Waker&lt;/code&gt; between poll calls. We can't store it as a field in the &lt;code&gt;ScancodeStream&lt;/code&gt; itself because it needs to be accessible from the &lt;code&gt;add_scancode&lt;/code&gt; function. The solution for this is to use a static variable of the &lt;a href=&quot;https://docs.rs/futures-util/0.3.4/futures_util/task/struct.AtomicWaker.html&quot;&gt;&lt;code&gt;AtomicWaker&lt;/code&gt;&lt;/a&gt; type provided by the &lt;code&gt;futures-util&lt;/code&gt; crate. Like the &lt;code&gt;ArrayQueue&lt;/code&gt; type, this type is based on atomic instructions and can be safely stored in a static and modified concurrently.&lt;/p&gt;
&lt;p&gt;Let's use the &lt;a href=&quot;https://docs.rs/futures-util/0.3.4/futures_util/task/struct.AtomicWaker.html&quot;&gt;&lt;code&gt;AtomicWaker&lt;/code&gt;&lt;/a&gt; type to define a static &lt;code&gt;WAKER&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;// in src/task/keyboard.rs

&lt;/span&gt;&lt;span&gt;use &lt;/span&gt;&lt;span&gt;futures_util::task::AtomicWaker;

&lt;/span&gt;&lt;span&gt;static &lt;/span&gt;&lt;span&gt;WAKER&lt;/span&gt;&lt;span&gt;: AtomicWaker &lt;/span&gt;&lt;span&gt;= &lt;/span&gt;&lt;span&gt;AtomicWaker::new();
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;The idea is that the &lt;code&gt;poll_next&lt;/code&gt; implementation stores the current waker in this static and the &lt;code&gt;add_scancode&lt;/code&gt; function calls the &lt;code&gt;wake&lt;/code&gt; function on it when a new scancode is added to the queue.&lt;/p&gt;
&lt;h5 id=&quot;storing-a-waker&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#storing-a-waker&quot; aria-label=&quot;Anchor link for: storing-a-waker&quot;&gt;🔗&lt;/a&gt;Storing a Waker&lt;/h5&gt;
&lt;p&gt;The contract defined by &lt;code&gt;poll&lt;/code&gt;/&lt;code&gt;poll_next&lt;/code&gt; requires that the task registers a wakeup for the passed &lt;code&gt;Waker&lt;/code&gt; when it returns &lt;code&gt;Poll::Pending&lt;/code&gt;. Let's modify our &lt;code&gt;poll_next&lt;/code&gt; implementation to satisfy these requirement:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;// in src/task/keyboard.rs

&lt;/span&gt;&lt;span&gt;impl &lt;/span&gt;&lt;span&gt;Stream &lt;/span&gt;&lt;span&gt;for &lt;/span&gt;&lt;span&gt;ScancodeStream {
    &lt;/span&gt;&lt;span&gt;type &lt;/span&gt;&lt;span&gt;Item &lt;/span&gt;&lt;span&gt;= u8&lt;/span&gt;&lt;span&gt;;

    &lt;/span&gt;&lt;span&gt;fn &lt;/span&gt;&lt;span&gt;poll_next(self: Pin&amp;lt;&lt;/span&gt;&lt;span&gt;&amp;amp;mut Self&lt;/span&gt;&lt;span&gt;&amp;gt;, cx: &lt;/span&gt;&lt;span&gt;&amp;amp;mut&lt;/span&gt;&lt;span&gt; Context) -&amp;gt; Poll&amp;lt;Option&amp;lt;&lt;/span&gt;&lt;span&gt;u8&lt;/span&gt;&lt;span&gt;&amp;gt;&amp;gt; {
        &lt;/span&gt;&lt;span&gt;let&lt;/span&gt;&lt;span&gt; queue &lt;/span&gt;&lt;span&gt;= &lt;/span&gt;&lt;span&gt;SCANCODE_QUEUE
            &lt;/span&gt;&lt;span&gt;.try_get()
            .expect(&lt;/span&gt;&lt;span&gt;&quot;scancode queue not initialized&quot;&lt;/span&gt;&lt;span&gt;);

        &lt;/span&gt;&lt;span&gt;// fast path
        &lt;/span&gt;&lt;span&gt;if let &lt;/span&gt;&lt;span&gt;Ok(scancode) &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; queue.pop() {
            &lt;/span&gt;&lt;span&gt;return &lt;/span&gt;&lt;span&gt;Poll::Ready(Some(scancode));
        }

        &lt;/span&gt;&lt;span&gt;WAKER&lt;/span&gt;&lt;span&gt;.register(&lt;/span&gt;&lt;span&gt;&amp;amp;&lt;/span&gt;&lt;span&gt;cx.waker());
        &lt;/span&gt;&lt;span&gt;match&lt;/span&gt;&lt;span&gt; queue.pop() {
            Ok(scancode) &lt;/span&gt;&lt;span&gt;=&amp;gt; &lt;/span&gt;&lt;span&gt;{
                &lt;/span&gt;&lt;span&gt;WAKER&lt;/span&gt;&lt;span&gt;.take();
                Poll::Ready(Some(scancode))
            }
            Err(crossbeam_queue::PopError) &lt;/span&gt;&lt;span&gt;=&amp;gt; &lt;/span&gt;&lt;span&gt;Poll::Pending,
        }
    }
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;Like before, we first use the &lt;a href=&quot;https://docs.rs/conquer-once/0.2.0/conquer_once/raw/struct.OnceCell.html#method.try_get&quot;&gt;&lt;code&gt;OnceCell::try_get&lt;/code&gt;&lt;/a&gt; function to get a reference to the initialized scancode queue. We then optimistically try to &lt;code&gt;pop&lt;/code&gt; from the queue and return &lt;code&gt;Poll::Ready&lt;/code&gt; when it succeeds. This way, we can avoid the performance overhead of registering a waker when the queue is not empty.&lt;/p&gt;
&lt;p&gt;If the first call to &lt;code&gt;queue.pop()&lt;/code&gt; does not succeed, the queue is potentially empty. Only potentially because the interrupt handler might have filled the queue asynchronously immediately after the check. Since this race condition can occur again for the next check, we need to register the &lt;code&gt;Waker&lt;/code&gt; in the &lt;code&gt;WAKER&lt;/code&gt; static before the second check. This way, a wakeup might happen before we return &lt;code&gt;Poll::Pending&lt;/code&gt;, but it is guaranteed that we get a wakeup for any scancodes pushed after the check.&lt;/p&gt;
&lt;p&gt;After registering the &lt;code&gt;Waker&lt;/code&gt; contained in the passed &lt;a href=&quot;https://doc.rust-lang.org/nightly/core/task/struct.Context.html&quot;&gt;&lt;code&gt;Context&lt;/code&gt;&lt;/a&gt; through the &lt;a href=&quot;https://docs.rs/futures-util/0.3.4/futures_util/task/struct.AtomicWaker.html#method.register&quot;&gt;&lt;code&gt;AtomicWaker::register&lt;/code&gt;&lt;/a&gt; function, we try popping from the queue a second time. If it now succeeds, we return &lt;code&gt;Poll::Ready&lt;/code&gt;. We also remove the registered waker again using &lt;a href=&quot;https://docs.rs/futures/0.3.4/futures/task/struct.AtomicWaker.html#method.take&quot;&gt;&lt;code&gt;AtomicWaker::take&lt;/code&gt;&lt;/a&gt; because a waker notification is no longer needed. In case &lt;code&gt;queue.pop()&lt;/code&gt; fails for a second time, we return &lt;code&gt;Poll::Pending&lt;/code&gt; like before, but this time with a registered wakeup.&lt;/p&gt;
&lt;p&gt;Note that there are two ways that a wakeup can happen for a task that did not return &lt;code&gt;Poll::Pending&lt;/code&gt; (yet). One way is the mentioned race condition when the wakeup happens immediately before returning &lt;code&gt;Poll::Pending&lt;/code&gt;. The other way is when the queue is no longer empty after registering the waker so that &lt;code&gt;Poll::Ready&lt;/code&gt; is returned. Since these spurious wakeups are not preventable, the executor needs to be able to handle them correctly.&lt;/p&gt;
&lt;h5 id=&quot;waking-the-stored-waker&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#waking-the-stored-waker&quot; aria-label=&quot;Anchor link for: waking-the-stored-waker&quot;&gt;🔗&lt;/a&gt;Waking the Stored Waker&lt;/h5&gt;
&lt;p&gt;To wake the stored &lt;code&gt;Waker&lt;/code&gt;, we add a call to &lt;code&gt;WAKER.wake()&lt;/code&gt; in the &lt;code&gt;add_scancode&lt;/code&gt; function:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;// in src/task/keyboard.rs

&lt;/span&gt;&lt;span&gt;pub&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;crate&lt;/span&gt;&lt;span&gt;) add_scancode(scancode: &lt;/span&gt;&lt;span&gt;u8&lt;/span&gt;&lt;span&gt;) {
    &lt;/span&gt;&lt;span&gt;if let &lt;/span&gt;&lt;span&gt;Ok(queue) &lt;/span&gt;&lt;span&gt;= &lt;/span&gt;&lt;span&gt;SCANCODE_QUEUE&lt;/span&gt;&lt;span&gt;.try_get() {
        &lt;/span&gt;&lt;span&gt;if let &lt;/span&gt;&lt;span&gt;Err(&lt;/span&gt;&lt;span&gt;_&lt;/span&gt;&lt;span&gt;) &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; scancode_queue.push(scancode) {
            println!(&lt;/span&gt;&lt;span&gt;&quot;WARNING: scancode queue full; dropping keyboard input&quot;&lt;/span&gt;&lt;span&gt;);
        } &lt;/span&gt;&lt;span&gt;else &lt;/span&gt;&lt;span&gt;{
            &lt;/span&gt;&lt;span&gt;WAKER&lt;/span&gt;&lt;span&gt;.wake(); &lt;/span&gt;&lt;span&gt;// new
        &lt;/span&gt;&lt;span&gt;}
    } &lt;/span&gt;&lt;span&gt;else &lt;/span&gt;&lt;span&gt;{
        println!(&lt;/span&gt;&lt;span&gt;&quot;WARNING: scancode queue uninitialized&quot;&lt;/span&gt;&lt;span&gt;);
    }
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;The only change that we performed is to add a call to &lt;code&gt;WAKER.wake()&lt;/code&gt; if the push to the scancode queue succeeds. If a waker is registered in the &lt;code&gt;WAKER&lt;/code&gt; static, this method will call the equally-named &lt;a href=&quot;https://doc.rust-lang.org/stable/core/task/struct.Waker.html#method.wake&quot;&gt;&lt;code&gt;wake&lt;/code&gt;&lt;/a&gt; method on it, which notifies the executor. Otherwise, the operation is a no-op, i.e. nothing happens.&lt;/p&gt;
&lt;p&gt;It is important that we call &lt;code&gt;wake&lt;/code&gt; only after pushing to the queue because otherwise the task might be woken too early when the queue is still empty. This can for example happen when using a multi-threaded executor that starts the woken task concurrently on a different CPU core. While we don't have thread support yet, we will add it soon and we don't want things to break then.&lt;/p&gt;
&lt;h4 id=&quot;keyboard-task&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#keyboard-task&quot; aria-label=&quot;Anchor link for: keyboard-task&quot;&gt;🔗&lt;/a&gt;Keyboard Task&lt;/h4&gt;
&lt;p&gt;Now that we implemented the &lt;code&gt;Stream&lt;/code&gt; trait for our &lt;code&gt;ScancodeStream&lt;/code&gt;, we can use it to create an asynchronous keyboard task:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;// in src/task/keyboard.rs

&lt;/span&gt;&lt;span&gt;use &lt;/span&gt;&lt;span&gt;futures_util::stream::StreamExt;
&lt;/span&gt;&lt;span&gt;use &lt;/span&gt;&lt;span&gt;pc_keyboard::{layouts, DecodedKey, HandleControl, Keyboard, ScancodeSet1};
&lt;/span&gt;&lt;span&gt;use crate&lt;/span&gt;&lt;span&gt;::print;

&lt;/span&gt;&lt;span&gt;pub&lt;/span&gt;&lt;span&gt; async &lt;/span&gt;&lt;span&gt;fn &lt;/span&gt;&lt;span&gt;print_keypresses() {
    &lt;/span&gt;&lt;span&gt;let mut&lt;/span&gt;&lt;span&gt; scancodes &lt;/span&gt;&lt;span&gt;= &lt;/span&gt;&lt;span&gt;ScancodeStream::new();
    &lt;/span&gt;&lt;span&gt;let mut&lt;/span&gt;&lt;span&gt; keyboard &lt;/span&gt;&lt;span&gt;= &lt;/span&gt;&lt;span&gt;Keyboard::new(layouts::Us104Key, ScancodeSet1,
        HandleControl::Ignore);

    &lt;/span&gt;&lt;span&gt;while let &lt;/span&gt;&lt;span&gt;Some(scancode) &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; scancodes.next().await {
        &lt;/span&gt;&lt;span&gt;if let &lt;/span&gt;&lt;span&gt;Ok(Some(key_event)) &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; keyboard.add_byte(scancode) {
            &lt;/span&gt;&lt;span&gt;if let &lt;/span&gt;&lt;span&gt;Some(key) &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; keyboard.process_keyevent(key_event) {
                &lt;/span&gt;&lt;span&gt;match&lt;/span&gt;&lt;span&gt; key {
                    DecodedKey::Unicode(character) &lt;/span&gt;&lt;span&gt;=&amp;gt; &lt;/span&gt;&lt;span&gt;print!(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;{}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, character),
                    DecodedKey::RawKey(key) &lt;/span&gt;&lt;span&gt;=&amp;gt; &lt;/span&gt;&lt;span&gt;print!(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;{:?}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, key),
                }
            }
        }
    }
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;The code is very similar to the code we had in our &lt;a href=&quot;https://os.phil-opp.com/hardware-interrupts/#interpreting-the-scancodes&quot;&gt;keyboard interrupt handler&lt;/a&gt; before we modified it in this post. The only difference is that, instead of reading the scancode from an I/O port, we take it from the &lt;code&gt;ScancodeStream&lt;/code&gt;. For this, we first create a new &lt;code&gt;Scancode&lt;/code&gt; stream and then repeatedly use the &lt;a href=&quot;https://docs.rs/futures-util/0.3.4/futures_util/stream/trait.StreamExt.html#method.next&quot;&gt;&lt;code&gt;next&lt;/code&gt;&lt;/a&gt; method provided by the &lt;a href=&quot;https://docs.rs/futures-util/0.3.4/futures_util/stream/trait.StreamExt.html&quot;&gt;&lt;code&gt;StreamExt&lt;/code&gt;&lt;/a&gt; trait to get a &lt;code&gt;Future&lt;/code&gt; that resolves to the next element in the stream. By using the &lt;code&gt;await&lt;/code&gt; operator on it, we asynchronously wait for the result of the future.&lt;/p&gt;
&lt;p&gt;We use &lt;code&gt;while let&lt;/code&gt; to loop until the stream returns &lt;code&gt;None&lt;/code&gt; to signal its end. Since our &lt;code&gt;poll_next&lt;/code&gt; method never returns &lt;code&gt;None&lt;/code&gt;, this is effectively an endless loop, so the &lt;code&gt;print_keypresses&lt;/code&gt; task never finishes.&lt;/p&gt;
&lt;p&gt;Let's add the &lt;code&gt;print_keypresses&lt;/code&gt; task to our executor in our &lt;code&gt;main.rs&lt;/code&gt; to get working keyboard input again:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;// in src/main.rs

&lt;/span&gt;&lt;span&gt;use &lt;/span&gt;&lt;span&gt;blog_os::task::keyboard; &lt;/span&gt;&lt;span&gt;// new

&lt;/span&gt;&lt;span&gt;fn &lt;/span&gt;&lt;span&gt;kernel_main(boot_info: &lt;/span&gt;&lt;span&gt;&amp;amp;'static&lt;/span&gt;&lt;span&gt; BootInfo) -&amp;gt; &lt;/span&gt;&lt;span&gt;! &lt;/span&gt;&lt;span&gt;{

    &lt;/span&gt;&lt;span&gt;// […] initialization routines, including init_heap, test_main

    &lt;/span&gt;&lt;span&gt;let mut&lt;/span&gt;&lt;span&gt; executor &lt;/span&gt;&lt;span&gt;= &lt;/span&gt;&lt;span&gt;SimpleExecutor::new();
    executor.spawn(Task::new(example_task()));
    executor.spawn(Task::new(keyboard::print_keypresses())); &lt;/span&gt;&lt;span&gt;// new
&lt;/span&gt;&lt;span&gt;    executor.run();

    &lt;/span&gt;&lt;span&gt;// […] &quot;it did not crash&quot; message, hlt_loop
&lt;/span&gt;&lt;span&gt;}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;When we execute &lt;code&gt;cargo xrun&lt;/code&gt; now, we see that keyboard input works again:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://os.phil-opp.com/async-await/qemu-keyboard-output.gif&quot; alt=&quot;QEMU printing &amp;quot;.....H...e...l...l..o..... ...W..o..r....l...d...!&amp;quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;If you keep an eye on the CPU utilization of your computer, you will see that the &lt;code&gt;QEMU&lt;/code&gt; process now continuously keeps the CPU busy. This happens because our &lt;code&gt;SimpleExecutor&lt;/code&gt; polls tasks over and over again in a loop. So even if we don't press any keys on the keyboard, the executor repeatedly calls &lt;code&gt;poll&lt;/code&gt; on our &lt;code&gt;print_keypresses&lt;/code&gt; task, even though the task cannot make any progress and will return &lt;code&gt;Poll::Pending&lt;/code&gt; each time.&lt;/p&gt;
&lt;h3 id=&quot;executor-with-waker-support&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#executor-with-waker-support&quot; aria-label=&quot;Anchor link for: executor-with-waker-support&quot;&gt;🔗&lt;/a&gt;Executor with Waker Support&lt;/h3&gt;
&lt;p&gt;To fix the performance problem, we need to create an executor that properly utilizes the &lt;code&gt;Waker&lt;/code&gt; notifications. This way, the executor is notified when the next keyboard interrupt occurs, so it does not need to keep polling the &lt;code&gt;print_keypresses&lt;/code&gt; task over and over again.&lt;/p&gt;
&lt;h4 id=&quot;task-id&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#task-id&quot; aria-label=&quot;Anchor link for: task-id&quot;&gt;🔗&lt;/a&gt;Task Id&lt;/h4&gt;
&lt;p&gt;The first step in creating an executor with proper support for waker notifications is to give each task an unique ID. This is required because we need a way to specify which task should be woken. We start by creating a new &lt;code&gt;TaskId&lt;/code&gt; wrapper type:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;// in src/task/mod.rs

&lt;/span&gt;&lt;span&gt;#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord)]
&lt;/span&gt;&lt;span&gt;struct &lt;/span&gt;&lt;span&gt;TaskId(&lt;/span&gt;&lt;span&gt;usize&lt;/span&gt;&lt;span&gt;);
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;TaskId&lt;/code&gt; struct is a simple wrapper type around &lt;code&gt;usize&lt;/code&gt;. We derive a number of traits for it to make it printable, copyable, comparable, and sortable. The latter is important because we want to use &lt;code&gt;TaskId&lt;/code&gt; as the key type of a &lt;a href=&quot;https://doc.rust-lang.org/alloc/collections/btree_map/struct.BTreeMap.html&quot;&gt;&lt;code&gt;BTreeMap&lt;/code&gt;&lt;/a&gt; in a moment.&lt;/p&gt;
&lt;p&gt;To assign each task an unique ID, we utilize the fact that each task stores a pinned, heap-allocated future:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;pub struct &lt;/span&gt;&lt;span&gt;Task {
    future: Pin&amp;lt;Box&amp;lt;dyn Future&amp;lt;Output = ()&amp;gt;&amp;gt;&amp;gt;,
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;The idea is to use the memory address of this future as an ID. This address is unique because no two futures are stored at the same address. The &lt;code&gt;Pin&lt;/code&gt; type ensures that they can't move in memory, so we also know that the address stays the same as long as the task exists. These properties make the address a good candidate for an ID.&lt;/p&gt;
&lt;p&gt;The implementation looks like this:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;// in src/task/mod.rs

&lt;/span&gt;&lt;span&gt;impl &lt;/span&gt;&lt;span&gt;Task {
    &lt;/span&gt;&lt;span&gt;fn &lt;/span&gt;&lt;span&gt;id(&lt;/span&gt;&lt;span&gt;&amp;amp;&lt;/span&gt;&lt;span&gt;self) -&amp;gt; TaskId {
        &lt;/span&gt;&lt;span&gt;use &lt;/span&gt;&lt;span&gt;core::ops::Deref;

        &lt;/span&gt;&lt;span&gt;let&lt;/span&gt;&lt;span&gt; addr &lt;/span&gt;&lt;span&gt;= &lt;/span&gt;&lt;span&gt;Pin::deref(&lt;/span&gt;&lt;span&gt;&amp;amp;&lt;/span&gt;&lt;span&gt;self.future) &lt;/span&gt;&lt;span&gt;as *const _ as *const &lt;/span&gt;&lt;span&gt;() &lt;/span&gt;&lt;span&gt;as usize&lt;/span&gt;&lt;span&gt;;
        TaskId(addr)
    }
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;We use the &lt;code&gt;deref&lt;/code&gt; method of the &lt;a href=&quot;https://doc.rust-lang.org/core/ops/trait.Deref.html&quot;&gt;&lt;code&gt;Deref&lt;/code&gt;&lt;/a&gt; trait to get a reference to the heap allocated future. To get the corresponding memory address, we convert this reference to a raw pointer and then to an &lt;code&gt;usize&lt;/code&gt;. Finally, we return the address wrapped in the &lt;code&gt;TaskId&lt;/code&gt; struct.&lt;/p&gt;
&lt;h4 id=&quot;the-executor-type&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#the-executor-type&quot; aria-label=&quot;Anchor link for: the-executor-type&quot;&gt;🔗&lt;/a&gt;The &lt;code&gt;Executor&lt;/code&gt; Type&lt;/h4&gt;
&lt;p&gt;We create our new &lt;code&gt;Executor&lt;/code&gt; type in a &lt;code&gt;task::executor&lt;/code&gt; module:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;// in src/task/mod.rs

&lt;/span&gt;&lt;span&gt;pub mod &lt;/span&gt;&lt;span&gt;executor;
&lt;/span&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;span&gt;// in src/task/executor.rs

&lt;/span&gt;&lt;span&gt;use super&lt;/span&gt;&lt;span&gt;::{Task, TaskId};
&lt;/span&gt;&lt;span&gt;use &lt;/span&gt;&lt;span&gt;alloc::{collections::{BTreeMap, VecDeque}, sync::Arc};
&lt;/span&gt;&lt;span&gt;use &lt;/span&gt;&lt;span&gt;core::task::Waker;
&lt;/span&gt;&lt;span&gt;use &lt;/span&gt;&lt;span&gt;crossbeam_queue::ArrayQueue;

&lt;/span&gt;&lt;span&gt;pub struct &lt;/span&gt;&lt;span&gt;Executor {
    task_queue: VecDeque&amp;lt;Task&amp;gt;,
    waiting_tasks: BTreeMap&amp;lt;TaskId, Task&amp;gt;,
    wake_queue: Arc&amp;lt;ArrayQueue&amp;lt;TaskId&amp;gt;&amp;gt;,
    waker_cache: BTreeMap&amp;lt;TaskId, Waker&amp;gt;,
}

&lt;/span&gt;&lt;span&gt;impl &lt;/span&gt;&lt;span&gt;Executor {
    &lt;/span&gt;&lt;span&gt;pub fn &lt;/span&gt;&lt;span&gt;new() -&amp;gt; &lt;/span&gt;&lt;span&gt;Self &lt;/span&gt;&lt;span&gt;{
        Executor {
            task_queue: VecDeque::new(),
            waiting_tasks: BTreeMap::new(),
            wake_queue: Arc::new(ArrayQueue::new(&lt;/span&gt;&lt;span&gt;100&lt;/span&gt;&lt;span&gt;)),
            waker_cache: BTreeMap::new(),
        }
    }
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;In addition to a &lt;code&gt;task_queue&lt;/code&gt;, which stores the tasks that are ready to execute, the type has a &lt;code&gt;waiting_tasks&lt;/code&gt; map, a &lt;code&gt;wake_queue&lt;/code&gt; and a &lt;code&gt;waker_cache&lt;/code&gt;. These fields have the following purpose:&lt;/p&gt;
&lt;ul readability=&quot;7.8526912181303&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;The &lt;code&gt;waiting_tasks&lt;/code&gt; map stores tasks that returned &lt;code&gt;Poll::Pending&lt;/code&gt;. The map is indexed by the &lt;code&gt;TaskId&lt;/code&gt; to allow efficient continuation of a specific task.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;8.7815028901734&quot;&gt;
&lt;p&gt;The &lt;code&gt;wake_queue&lt;/code&gt; is &lt;a href=&quot;https://docs.rs/crossbeam/0.7.3/crossbeam/queue/struct.ArrayQueue.html&quot;&gt;&lt;code&gt;ArrayQueue&lt;/code&gt;&lt;/a&gt; of task IDs, wrapped into the &lt;a href=&quot;https://doc.rust-lang.org/stable/alloc/sync/struct.Arc.html&quot;&gt;&lt;code&gt;Arc&lt;/code&gt;&lt;/a&gt; type that implements &lt;em&gt;reference counting&lt;/em&gt;. Reference counting makes it possible to share ownership of the value between multiple owners. It works by allocating the value on the heap and counting the number of active references to it. When the number of active references reaches zero, the value is no longer needed and can be deallocated.&lt;/p&gt;
&lt;p&gt;We use the &lt;code&gt;Arc&lt;/code&gt; wrapper for the &lt;code&gt;wake_queue&lt;/code&gt; because it will be shared between the executor and wakers. The idea is that the wakers push the ID of the woken task to the queue. The executor sits on the receiving end of the queue and moves all woken tasks from the &lt;code&gt;waiting_tasks&lt;/code&gt; map back to the &lt;code&gt;task_queue&lt;/code&gt;. The reason for using a fixed-size queue instead of an unbounded queue such as &lt;a href=&quot;https://docs.rs/crossbeam-queue/0.2.1/crossbeam_queue/struct.SegQueue.html&quot;&gt;&lt;code&gt;SegQueue&lt;/code&gt;&lt;/a&gt; is that interrupt handlers that should not allocate will push to this queue.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;3.9496221662469&quot;&gt;
&lt;p&gt;The &lt;code&gt;waker_cache&lt;/code&gt; map caches the &lt;a href=&quot;https://doc.rust-lang.org/nightly/core/task/struct.Waker.html&quot;&gt;&lt;code&gt;Waker&lt;/code&gt;&lt;/a&gt; of a task after its creation. This has two reasons: First, it improves performance by reusing the same waker for multiple wake-ups of the same task instead of creating a new waker each time. Second, it ensures that reference-counted wakers are not deallocated inside interrupt handlers because it could lead to deadlocks (there are more details on this below).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;To create an &lt;code&gt;Executor&lt;/code&gt;, we provide a simple &lt;code&gt;new&lt;/code&gt; function. We choose a capacity of 100 for the &lt;code&gt;wake_queue&lt;/code&gt;, which should be more than enough for the foreseeable future. In case our system will have more than 100 concurrent tasks at some point, we can easily increase this size.&lt;/p&gt;
&lt;h4 id=&quot;spawning-tasks&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#spawning-tasks&quot; aria-label=&quot;Anchor link for: spawning-tasks&quot;&gt;🔗&lt;/a&gt;Spawning Tasks&lt;/h4&gt;
&lt;p&gt;As for the &lt;code&gt;SimpleExecutor&lt;/code&gt;, we provide a &lt;code&gt;spawn&lt;/code&gt; method on our &lt;code&gt;Executor&lt;/code&gt; type that adds a given task to the &lt;code&gt;task_queue&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;// in src/task/executor.rs

&lt;/span&gt;&lt;span&gt;impl &lt;/span&gt;&lt;span&gt;Executor {
    &lt;/span&gt;&lt;span&gt;pub fn &lt;/span&gt;&lt;span&gt;spawn(&lt;/span&gt;&lt;span&gt;&amp;amp;mut &lt;/span&gt;&lt;span&gt;self, task: Task) {
        self.task_queue.push_back(task)
    }
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;While this method requires a &lt;code&gt;&amp;amp;mut&lt;/code&gt; reference to the executor it is not callable after the executor has been started. If it should be possible to let tasks themselves spawn additional tasks at some point, we could change the type of the task queue to a concurrent queue such as &lt;a href=&quot;https://docs.rs/crossbeam-queue/0.2.1/crossbeam_queue/struct.SegQueue.html&quot;&gt;&lt;code&gt;SegQueue&lt;/code&gt;&lt;/a&gt; and share a reference to this queue with tasks.&lt;/p&gt;
&lt;h4 id=&quot;running-tasks&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#running-tasks&quot; aria-label=&quot;Anchor link for: running-tasks&quot;&gt;🔗&lt;/a&gt;Running Tasks&lt;/h4&gt;
&lt;p&gt;To execute all tasks in the &lt;code&gt;task_queue&lt;/code&gt;, we create a private &lt;code&gt;run_ready_tasks&lt;/code&gt; method:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;// in src/task/executor.rs

&lt;/span&gt;&lt;span&gt;use &lt;/span&gt;&lt;span&gt;core::task::{Context, Poll};

&lt;/span&gt;&lt;span&gt;impl &lt;/span&gt;&lt;span&gt;Executor {
    &lt;/span&gt;&lt;span&gt;fn &lt;/span&gt;&lt;span&gt;run_ready_tasks(&lt;/span&gt;&lt;span&gt;&amp;amp;mut &lt;/span&gt;&lt;span&gt;self) {
        &lt;/span&gt;&lt;span&gt;while let &lt;/span&gt;&lt;span&gt;Some(&lt;/span&gt;&lt;span&gt;mut&lt;/span&gt;&lt;span&gt; task) &lt;/span&gt;&lt;span&gt;= &lt;/span&gt;&lt;span&gt;self.task_queue.pop_front() {
            &lt;/span&gt;&lt;span&gt;let&lt;/span&gt;&lt;span&gt; task_id &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; task.id();
            &lt;/span&gt;&lt;span&gt;if !&lt;/span&gt;&lt;span&gt;self.waker_cache.contains_key(&lt;/span&gt;&lt;span&gt;&amp;amp;&lt;/span&gt;&lt;span&gt;task_id) {
                self.waker_cache.insert(task_id, self.create_waker(task_id));
            }
            &lt;/span&gt;&lt;span&gt;let&lt;/span&gt;&lt;span&gt; waker &lt;/span&gt;&lt;span&gt;= &lt;/span&gt;&lt;span&gt;self.waker_cache.get(&lt;/span&gt;&lt;span&gt;&amp;amp;&lt;/span&gt;&lt;span&gt;task_id).expect(&lt;/span&gt;&lt;span&gt;&quot;should exist&quot;&lt;/span&gt;&lt;span&gt;);
            &lt;/span&gt;&lt;span&gt;let mut&lt;/span&gt;&lt;span&gt; context &lt;/span&gt;&lt;span&gt;= &lt;/span&gt;&lt;span&gt;Context::from_waker(waker);
            &lt;/span&gt;&lt;span&gt;match&lt;/span&gt;&lt;span&gt; task.poll(&lt;/span&gt;&lt;span&gt;&amp;amp;mut&lt;/span&gt;&lt;span&gt; context) {
                Poll::Ready(()) &lt;/span&gt;&lt;span&gt;=&amp;gt; &lt;/span&gt;&lt;span&gt;{
                    &lt;/span&gt;&lt;span&gt;// task done -&amp;gt; remove cached waker
                    &lt;/span&gt;&lt;span&gt;self.waker_cache.remove(&lt;/span&gt;&lt;span&gt;&amp;amp;&lt;/span&gt;&lt;span&gt;task_id);
                }
                Poll::Pending &lt;/span&gt;&lt;span&gt;=&amp;gt; &lt;/span&gt;&lt;span&gt;{
                    &lt;/span&gt;&lt;span&gt;if &lt;/span&gt;&lt;span&gt;self.waiting_tasks.insert(task_id, task).is_some() {
                        panic!(&lt;/span&gt;&lt;span&gt;&quot;task with same ID already in waiting_tasks&quot;&lt;/span&gt;&lt;span&gt;);
                    }
                },
            }
        }
    }
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;The basic idea of this function is similar to our &lt;code&gt;SimpleExecutor&lt;/code&gt;: Loop over all tasks in the &lt;code&gt;task_queue&lt;/code&gt;, create a waker for each task, and then poll it. However, instead of adding pending tasks back to the end of the &lt;code&gt;task_queue&lt;/code&gt;, we store them in the &lt;code&gt;waiting_tasks&lt;/code&gt; map until they are woken again. The waker creation is done by a method named &lt;code&gt;create_waker&lt;/code&gt;, whose implemenation will be shown in a moment.&lt;/p&gt;
&lt;p&gt;To avoid the performance overhead of creating a waker on each poll, we use the &lt;code&gt;waker_cache&lt;/code&gt; map to store the waker for each task after it has been created. For this, we first use the &lt;a href=&quot;https://doc.rust-lang.org/alloc/collections/btree_map/struct.BTreeMap.html#method.contains_key&quot;&gt;&lt;code&gt;BTreeMap::contains_key&lt;/code&gt;&lt;/a&gt; method to check whether a cached waker exists for the task. If not, we use the &lt;a href=&quot;https://doc.rust-lang.org/alloc/collections/btree_map/struct.BTreeMap.html#method.insert&quot;&gt;&lt;code&gt;BTreeMap::insert&lt;/code&gt;&lt;/a&gt; method to create it. Afterwards, we can be sure that the waker exists, so we use the &lt;a href=&quot;https://doc.rust-lang.org/alloc/collections/btree_map/struct.BTreeMap.html#method.get&quot;&gt;&lt;code&gt;BTreeMap::get&lt;/code&gt;&lt;/a&gt; method in combination with an &lt;a href=&quot;https://doc.rust-lang.org/core/option/enum.Option.html#method.expect&quot;&gt;&lt;code&gt;expect&lt;/code&gt;&lt;/a&gt; call to get a reference to it.&lt;/p&gt;
&lt;p&gt;Note that reusing wakers like this is not possible for all waker implementations, but our implemenation will allow it. To clean up the &lt;code&gt;waker_cache&lt;/code&gt; when a task is finished, we use use the &lt;a href=&quot;https://doc.rust-lang.org/alloc/collections/btree_map/struct.BTreeMap.html#method.remove&quot;&gt;&lt;code&gt;BTreeMap::remove&lt;/code&gt;&lt;/a&gt; method to remove any cached waker for that task from the map.&lt;/p&gt;
&lt;h4 id=&quot;waker-design&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#waker-design&quot; aria-label=&quot;Anchor link for: waker-design&quot;&gt;🔗&lt;/a&gt;Waker Design&lt;/h4&gt;
&lt;p&gt;The job of the waker is to push the ID of the woken task to the &lt;code&gt;wake_queue&lt;/code&gt; of the executor. We implement this by creating a new &lt;code&gt;TaskWaker&lt;/code&gt; struct that stores the task ID and a reference to the &lt;code&gt;wake_queue&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;// in src/task/executor.rs

&lt;/span&gt;&lt;span&gt;struct &lt;/span&gt;&lt;span&gt;TaskWaker {
    task_id: TaskId,
    wake_queue: Arc&amp;lt;ArrayQueue&amp;lt;TaskId&amp;gt;&amp;gt;,
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;Since the ownership of the &lt;code&gt;wake_queue&lt;/code&gt; is shared between the executor and wakers, we use the &lt;a href=&quot;https://doc.rust-lang.org/stable/alloc/sync/struct.Arc.html&quot;&gt;&lt;code&gt;Arc&lt;/code&gt;&lt;/a&gt; wrapper type to implement shared reference-counted ownership.&lt;/p&gt;
&lt;p&gt;The implementation of the wake operation is quite simple:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;// in src/task/executor.rs

&lt;/span&gt;&lt;span&gt;impl &lt;/span&gt;&lt;span&gt;TaskWaker {
    &lt;/span&gt;&lt;span&gt;fn &lt;/span&gt;&lt;span&gt;wake_task(&lt;/span&gt;&lt;span&gt;&amp;amp;&lt;/span&gt;&lt;span&gt;self) {
        self.wake_queue.push(self.task_id).expect(&lt;/span&gt;&lt;span&gt;&quot;wake_queue full&quot;&lt;/span&gt;&lt;span&gt;);
    }
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;We push the &lt;code&gt;task_id&lt;/code&gt; to the referenced &lt;code&gt;wake_queue&lt;/code&gt;. Since modifications of the &lt;a href=&quot;https://docs.rs/crossbeam/0.7.3/crossbeam/queue/struct.ArrayQueue.html&quot;&gt;&lt;code&gt;ArrayQueue&lt;/code&gt;&lt;/a&gt; type only require a shared reference, we can implement this method on &lt;code&gt;&amp;amp;self&lt;/code&gt; instead of &lt;code&gt;&amp;amp;mut self&lt;/code&gt;.&lt;/p&gt;
&lt;h5 id=&quot;the-wake-trait&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#the-wake-trait&quot; aria-label=&quot;Anchor link for: the-wake-trait&quot;&gt;🔗&lt;/a&gt;The &lt;code&gt;Wake&lt;/code&gt; Trait&lt;/h5&gt;
&lt;p&gt;In order to use our &lt;code&gt;TaskWaker&lt;/code&gt; type for polling futures, we need to convert it to a &lt;a href=&quot;https://doc.rust-lang.org/nightly/core/task/struct.Waker.html&quot;&gt;&lt;code&gt;Waker&lt;/code&gt;&lt;/a&gt; instance first. This is required because the &lt;a href=&quot;https://doc.rust-lang.org/nightly/core/future/trait.Future.html#tymethod.poll&quot;&gt;&lt;code&gt;Future::poll&lt;/code&gt;&lt;/a&gt; method takes a &lt;a href=&quot;https://doc.rust-lang.org/nightly/core/task/struct.Context.html&quot;&gt;&lt;code&gt;Context&lt;/code&gt;&lt;/a&gt; instance as argument, which can only be constructed from the &lt;code&gt;Waker&lt;/code&gt; type. While we could do this by providing an implementation of the &lt;a href=&quot;https://doc.rust-lang.org/stable/core/task/struct.RawWaker.html&quot;&gt;&lt;code&gt;RawWaker&lt;/code&gt;&lt;/a&gt; type, it's both simpler and safer to instead implement the &lt;code&gt;Arc&lt;/code&gt;-based &lt;a href=&quot;https://doc.rust-lang.org/nightly/alloc/task/trait.Wake.html&quot;&gt;&lt;code&gt;Wake&lt;/code&gt;&lt;/a&gt; trait and then using the &lt;a href=&quot;https://doc.rust-lang.org/nightly/core/convert/trait.From.html&quot;&gt;&lt;code&gt;From&lt;/code&gt;&lt;/a&gt; implementations provided by the standard library to construct the &lt;code&gt;Waker&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The trait implementation looks like this:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;// in src/task/simple_executor.rs

&lt;/span&gt;&lt;span&gt;use &lt;/span&gt;&lt;span&gt;alloc::task::Wake;

&lt;/span&gt;&lt;span&gt;impl &lt;/span&gt;&lt;span&gt;Wake &lt;/span&gt;&lt;span&gt;for &lt;/span&gt;&lt;span&gt;TaskWaker {
    &lt;/span&gt;&lt;span&gt;fn &lt;/span&gt;&lt;span&gt;wake(self: Arc&amp;lt;&lt;/span&gt;&lt;span&gt;Self&lt;/span&gt;&lt;span&gt;&amp;gt;) {
        self.wake_task();
    }

    &lt;/span&gt;&lt;span&gt;fn &lt;/span&gt;&lt;span&gt;wake_by_ref(self: &lt;/span&gt;&lt;span&gt;&amp;amp;&lt;/span&gt;&lt;span&gt;Arc&amp;lt;&lt;/span&gt;&lt;span&gt;Self&lt;/span&gt;&lt;span&gt;&amp;gt;) {
        self.wake_task();
    }
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;The trait is still unstable, so we have to add &lt;strong&gt;&lt;code&gt;#![feature(wake_trait)]&lt;/code&gt;&lt;/strong&gt; to the top of our &lt;code&gt;lib.rs&lt;/code&gt; to use it. Since wakers are commonly shared between the executor and the asynchronous tasks, the trait methods require that the &lt;code&gt;Self&lt;/code&gt; instance is wrapped in the &lt;a href=&quot;https://doc.rust-lang.org/stable/alloc/sync/struct.Arc.html&quot;&gt;&lt;code&gt;Arc&lt;/code&gt;&lt;/a&gt; type, which implements reference-counted ownership. This means that we have to move our &lt;code&gt;TaskWaker&lt;/code&gt; to an &lt;code&gt;Arc&lt;/code&gt; to in order to call them.&lt;/p&gt;
&lt;p&gt;The difference between the &lt;code&gt;wake&lt;/code&gt; and &lt;code&gt;wake_by_ref&lt;/code&gt; methods is that the latter only requires a reference the &lt;code&gt;Arc&lt;/code&gt;, while the former takes ownership of the &lt;code&gt;Arc&lt;/code&gt; and thus often requires an increase of the reference count. Not all types support waking by reference, so implementing the &lt;code&gt;wake_by_ref&lt;/code&gt; method is optional, however it can lead to better performance because it avoids unnecessary reference count modifications. In our case, we can simply forward both trait methods to our &lt;code&gt;wake_task&lt;/code&gt; function, which requires only a shared &lt;code&gt;&amp;amp;self&lt;/code&gt; reference.&lt;/p&gt;
&lt;h5 id=&quot;creating-wakers&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#creating-wakers&quot; aria-label=&quot;Anchor link for: creating-wakers&quot;&gt;🔗&lt;/a&gt;Creating Wakers&lt;/h5&gt;
&lt;p&gt;Since the &lt;code&gt;Waker&lt;/code&gt; type supports &lt;a href=&quot;https://doc.rust-lang.org/nightly/core/convert/trait.From.html&quot;&gt;&lt;code&gt;From&lt;/code&gt;&lt;/a&gt; conversions for all &lt;code&gt;Arc&lt;/code&gt;-wrapped values that implement the &lt;code&gt;Wake&lt;/code&gt; trait, we can now implement the &lt;code&gt;Executor::create_waker&lt;/code&gt; method using our &lt;code&gt;TaskWaker&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;// in src/task/executor.rs

&lt;/span&gt;&lt;span&gt;impl &lt;/span&gt;&lt;span&gt;Executor {
    &lt;/span&gt;&lt;span&gt;fn &lt;/span&gt;&lt;span&gt;create_waker(&lt;/span&gt;&lt;span&gt;&amp;amp;&lt;/span&gt;&lt;span&gt;self, task_id: TaskId) -&amp;gt; Waker {
        Waker::from(Arc::new(TaskWaker {
            task_id,
            wake_queue: self.wake_queue.clone(),
        }))
    }
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;We create the &lt;code&gt;TaskWaker&lt;/code&gt; using the passed &lt;code&gt;task_id&lt;/code&gt; and a clone of the &lt;code&gt;wake_queue&lt;/code&gt;. Since the &lt;code&gt;wake_queue&lt;/code&gt; is wrapped into &lt;code&gt;Arc&lt;/code&gt;, the &lt;code&gt;clone&lt;/code&gt; only increases the reference count of the value, but still points to the same heap allocated queue. We store the &lt;code&gt;TaskWaker&lt;/code&gt; in an &lt;code&gt;Arc&lt;/code&gt; too because the &lt;code&gt;Waker::from&lt;/code&gt; implementation requires it. This function then takes care of constructing a &lt;a href=&quot;https://doc.rust-lang.org/stable/core/task/struct.RawWakerVTable.html&quot;&gt;&lt;code&gt;RawWakerVTable&lt;/code&gt;&lt;/a&gt; and a &lt;a href=&quot;https://doc.rust-lang.org/stable/core/task/struct.RawWaker.html&quot;&gt;&lt;code&gt;RawWaker&lt;/code&gt;&lt;/a&gt; instance for our &lt;code&gt;TaskWaker&lt;/code&gt; type. In case you're interested in how it works in detail, check out the &lt;a href=&quot;https://github.com/rust-lang/rust/blob/cdb50c6f2507319f29104a25765bfb79ad53395c/src/liballoc/task.rs#L58-L87&quot;&gt;implementation in the &lt;code&gt;alloc&lt;/code&gt; crate&lt;/a&gt;.&lt;/p&gt;
&lt;h5 id=&quot;handling-wake-ups&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#handling-wake-ups&quot; aria-label=&quot;Anchor link for: handling-wake-ups&quot;&gt;🔗&lt;/a&gt;Handling Wake-Ups&lt;/h5&gt;
&lt;p&gt;To handle wake-ups in our executor, we add a &lt;code&gt;wake_tasks&lt;/code&gt; method:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;// in src/task/executor.rs

&lt;/span&gt;&lt;span&gt;impl &lt;/span&gt;&lt;span&gt;Executor {
    &lt;/span&gt;&lt;span&gt;fn &lt;/span&gt;&lt;span&gt;wake_tasks(&lt;/span&gt;&lt;span&gt;&amp;amp;mut &lt;/span&gt;&lt;span&gt;self) {
        &lt;/span&gt;&lt;span&gt;while let &lt;/span&gt;&lt;span&gt;Ok(task_id) &lt;/span&gt;&lt;span&gt;= &lt;/span&gt;&lt;span&gt;self.wake_queue.pop() {
            &lt;/span&gt;&lt;span&gt;if let &lt;/span&gt;&lt;span&gt;Some(task) &lt;/span&gt;&lt;span&gt;= &lt;/span&gt;&lt;span&gt;self.waiting_tasks.remove(&lt;/span&gt;&lt;span&gt;&amp;amp;&lt;/span&gt;&lt;span&gt;task_id) {
                self.task_queue.push_back(task);
            }
        }
    }
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;We use a &lt;code&gt;while let&lt;/code&gt; loop to pop all items from the &lt;code&gt;wake_queue&lt;/code&gt;. For each popped task ID, we remove the corresponding task from the &lt;code&gt;waiting_tasks&lt;/code&gt; map and add it to the back of the &lt;code&gt;task_queue&lt;/code&gt;. Since we register wakers before checking whether a task needs to be put to sleep, it might happen that a wake-up occurs for tasks even though they are not in the &lt;code&gt;waiting_tasks&lt;/code&gt; map. In this case, we simply ignore the wake-up.&lt;/p&gt;
&lt;h4 id=&quot;a-run-method-1&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#a-run-method-1&quot; aria-label=&quot;Anchor link for: a-run-method-1&quot;&gt;🔗&lt;/a&gt;A &lt;code&gt;run&lt;/code&gt; Method&lt;/h4&gt;
&lt;p&gt;With our waker implementation in place, we can finally construct a &lt;code&gt;run&lt;/code&gt; method for our executor:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;// in src/task/executor.rs

&lt;/span&gt;&lt;span&gt;impl &lt;/span&gt;&lt;span&gt;Executor {
    &lt;/span&gt;&lt;span&gt;pub fn &lt;/span&gt;&lt;span&gt;run(&lt;/span&gt;&lt;span&gt;&amp;amp;mut &lt;/span&gt;&lt;span&gt;self) -&amp;gt; &lt;/span&gt;&lt;span&gt;! &lt;/span&gt;&lt;span&gt;{
        &lt;/span&gt;&lt;span&gt;loop &lt;/span&gt;&lt;span&gt;{
            self.wake_tasks();
            self.run_ready_tasks();
        }
    }
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;This method just calls the &lt;code&gt;wake_tasks&lt;/code&gt; and &lt;code&gt;run_ready_tasks&lt;/code&gt; functions in a loop. While we could theoretically return from the function when both the &lt;code&gt;task_queue&lt;/code&gt; and the &lt;code&gt;waiting_tasks&lt;/code&gt; map become empty, this would never happen since our &lt;code&gt;keyboard_task&lt;/code&gt; never finishes, so a simply &lt;code&gt;loop&lt;/code&gt; should suffice. Since the function never returns, we use the &lt;code&gt;!&lt;/code&gt; return type to mark the function as &lt;a href=&quot;https://doc.rust-lang.org/stable/rust-by-example/fn/diverging.html&quot;&gt;diverging&lt;/a&gt; to the compiler.&lt;/p&gt;
&lt;p&gt;We can now change our &lt;code&gt;kernel_main&lt;/code&gt; to use our new &lt;code&gt;Executor&lt;/code&gt; instead of the &lt;code&gt;SimpleExecutor&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;// in src/main.rs

&lt;/span&gt;&lt;span&gt;use &lt;/span&gt;&lt;span&gt;blog_os::task::executor::Executor; &lt;/span&gt;&lt;span&gt;// new

&lt;/span&gt;&lt;span&gt;fn &lt;/span&gt;&lt;span&gt;kernel_main(boot_info: &lt;/span&gt;&lt;span&gt;&amp;amp;'static&lt;/span&gt;&lt;span&gt; BootInfo) -&amp;gt; &lt;/span&gt;&lt;span&gt;! &lt;/span&gt;&lt;span&gt;{
    &lt;/span&gt;&lt;span&gt;// […] initialization routines, including init_heap, test_main

    &lt;/span&gt;&lt;span&gt;let mut&lt;/span&gt;&lt;span&gt; executor &lt;/span&gt;&lt;span&gt;= &lt;/span&gt;&lt;span&gt;Executor::new(); &lt;/span&gt;&lt;span&gt;// new
&lt;/span&gt;&lt;span&gt;    executor.spawn(Task::new(example_task()));
    executor.spawn(Task::new(keyboard::print_keypresses()));
    executor.run();
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;We only need to change the import and the type name. Since our &lt;code&gt;run&lt;/code&gt; function is marked as diverging, the compiler knows that it never returns so that we no longer need a call to &lt;code&gt;hlt_loop&lt;/code&gt; at the end of our &lt;code&gt;kernel_main&lt;/code&gt; function.&lt;/p&gt;
&lt;p&gt;When we run our kernel using &lt;code&gt;cargo xrun&lt;/code&gt; now, we see that keyboard input still works:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://os.phil-opp.com/async-await/qemu-keyboard-output-again.gif&quot; alt=&quot;QEMU printing &amp;quot;.....H...e...l...l..o..... ...a..g..a....i...n...!&amp;quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;However, the CPU utilization of QEMU did not get any better. The reason for this is that we still keep the CPU busy for the whole time. We no longer poll tasks until they are woken again, but we still check the &lt;code&gt;wake_queue&lt;/code&gt; and the &lt;code&gt;task_queue&lt;/code&gt; in a busy loop. To fix this, we need to put the CPU to sleep if there is no more work to do.&lt;/p&gt;
&lt;h4 id=&quot;sleep-if-idle&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#sleep-if-idle&quot; aria-label=&quot;Anchor link for: sleep-if-idle&quot;&gt;🔗&lt;/a&gt;Sleep If Idle&lt;/h4&gt;
&lt;p&gt;The basic idea is to execute the &lt;a href=&quot;https://en.wikipedia.org/wiki/HLT_(x86_instruction)&quot;&gt;&lt;code&gt;hlt&lt;/code&gt; instruction&lt;/a&gt; when both the &lt;code&gt;task_queue&lt;/code&gt; and the &lt;code&gt;wake_queue&lt;/code&gt; are empty. This instruction puts the CPU to sleep until the next interrupt arrives. The fact that the CPU immediately becomes active again on interrupts ensures that we can still directly react when an interrupt handler pushes to the &lt;code&gt;wake_queue&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;To implement this, we create a new &lt;code&gt;sleep_if_idle&lt;/code&gt; method to our executor and call it from our &lt;code&gt;run&lt;/code&gt; method:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;// in src/task/executor.rs

&lt;/span&gt;&lt;span&gt;impl &lt;/span&gt;&lt;span&gt;Executor {
    &lt;/span&gt;&lt;span&gt;pub fn &lt;/span&gt;&lt;span&gt;run(&lt;/span&gt;&lt;span&gt;&amp;amp;mut &lt;/span&gt;&lt;span&gt;self) -&amp;gt; &lt;/span&gt;&lt;span&gt;! &lt;/span&gt;&lt;span&gt;{
        &lt;/span&gt;&lt;span&gt;loop &lt;/span&gt;&lt;span&gt;{
            self.wake_tasks();
            self.run_ready_tasks();
            self.sleep_if_idle();   &lt;/span&gt;&lt;span&gt;// new
        &lt;/span&gt;&lt;span&gt;}
    }

    &lt;/span&gt;&lt;span&gt;fn &lt;/span&gt;&lt;span&gt;sleep_if_idle(&lt;/span&gt;&lt;span&gt;&amp;amp;&lt;/span&gt;&lt;span&gt;self) {
        &lt;/span&gt;&lt;span&gt;if &lt;/span&gt;&lt;span&gt;self.wake_queue.is_empty() {
            x86_64::instructions::hlt();
        }
    }
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;Since we call &lt;code&gt;sleep_if_idle&lt;/code&gt; directly after &lt;code&gt;run_ready_tasks&lt;/code&gt;, which loops until the &lt;code&gt;task_queue&lt;/code&gt; becomes empty, we only need to check the &lt;code&gt;wake_queue&lt;/code&gt;. If it is empty too, there is no task that is ready to run, so we execute the &lt;code&gt;hlt&lt;/code&gt; instruction through the &lt;a href=&quot;https://docs.rs/x86_64/0.9.6/x86_64/instructions/fn.hlt.html&quot;&gt;&lt;code&gt;instructions::hlt&lt;/code&gt;&lt;/a&gt; wrapper function provided by the &lt;a href=&quot;https://docs.rs/x86_64/0.9.6/x86_64/index.html&quot;&gt;&lt;code&gt;x86_64&lt;/code&gt;&lt;/a&gt; crate.&lt;/p&gt;
&lt;p&gt;Unfortunately, there is a subtle race condition in this implementation. Since interrupts are asynchronous and can happen at any time, it is possible that an interrupt happens between the &lt;code&gt;is_empty&lt;/code&gt; check and the call to &lt;code&gt;hlt&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;if &lt;/span&gt;&lt;span&gt;self.wake_queue.is_empty() {
    &lt;/span&gt;&lt;span&gt;/// &amp;lt;--- interrupt can happen here
    &lt;/span&gt;&lt;span&gt;x86_64::instructions::hlt();
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;In case this interrupt pushes to the &lt;code&gt;wake_queue&lt;/code&gt;, we put the CPU to sleep even though there is now a ready task. In the worst case, this could delay the handling of a keyboard interrupt until the next keypress or the next timer interrupt. So how do we prevent it?&lt;/p&gt;
&lt;p&gt;The answer is to disable interrupts on the CPU before the check and atomically enable them again together with the &lt;code&gt;hlt&lt;/code&gt; instruction. This way, all interrupts that happen between in between are delayed after the &lt;code&gt;hlt&lt;/code&gt; instruction so that no wake-ups are missed. To implement this approach, we can use the &lt;a href=&quot;https://docs.rs/x86_64/0.9.6/x86_64/instructions/interrupts/fn.enable_interrupts_and_hlt.html&quot;&gt;&lt;code&gt;enable_interrupts_and_hlt&lt;/code&gt;&lt;/a&gt; function provided by the &lt;a href=&quot;https://docs.rs/x86_64/0.9.6/x86_64/index.html&quot;&gt;&lt;code&gt;x86_64&lt;/code&gt;&lt;/a&gt; crate. This function is only available since version 0.9.6, so you might need to update your &lt;code&gt;x86_64&lt;/code&gt; dependency to use it.&lt;/p&gt;
&lt;p&gt;The updated implementation of our &lt;code&gt;sleep_if_idle&lt;/code&gt; function looks like this:&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;// in src/task/executor.rs

&lt;/span&gt;&lt;span&gt;impl &lt;/span&gt;&lt;span&gt;Executor {
    &lt;/span&gt;&lt;span&gt;fn &lt;/span&gt;&lt;span&gt;sleep_if_idle(&lt;/span&gt;&lt;span&gt;&amp;amp;&lt;/span&gt;&lt;span&gt;self) {
        &lt;/span&gt;&lt;span&gt;use &lt;/span&gt;&lt;span&gt;x86_64::instructions::interrupts::{self, enable_interrupts_and_hlt};

        &lt;/span&gt;&lt;span&gt;// fast path
        &lt;/span&gt;&lt;span&gt;if !&lt;/span&gt;&lt;span&gt;self.wake_queue.is_empty() {
            &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt;;
        }

        interrupts::disable();
        &lt;/span&gt;&lt;span&gt;if &lt;/span&gt;&lt;span&gt;self.wake_queue.is_empty() {
            enable_interrupts_and_hlt();
        } &lt;/span&gt;&lt;span&gt;else &lt;/span&gt;&lt;span&gt;{
            interrupts::enable();
        }
    }
}
&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;To avoid unnecessarily disabling interrupts, we early return if the &lt;code&gt;wake_queue&lt;/code&gt; is not empty. Otherwise, we disable interrupts and check the &lt;code&gt;wake_queue&lt;/code&gt; again. If it is still empty, we use the &lt;a href=&quot;https://docs.rs/x86_64/0.9.6/x86_64/instructions/interrupts/fn.enable_interrupts_and_hlt.html&quot;&gt;&lt;code&gt;enable_interrupts_and_hlt&lt;/code&gt;&lt;/a&gt; function to enable interrupts and put the CPU to sleep as a single atomic operation. In case the queue is no longer empty, it means that an interrupt woke a task between the first and the second check. In that case, we enable interrupts again and directly continue execution without executing &lt;code&gt;hlt&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Now our executor properly puts the CPU to sleep when there is nothing to do. We can see that the QEMU process as a much lower CPU utilization when we run our kernel using &lt;code&gt;cargo xrun&lt;/code&gt; again.&lt;/p&gt;
&lt;h4 id=&quot;possible-extensions&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#possible-extensions&quot; aria-label=&quot;Anchor link for: possible-extensions&quot;&gt;🔗&lt;/a&gt;Possible Extensions&lt;/h4&gt;
&lt;p&gt;Our executor is now able to run tasks in an efficient way. It utilizes waker notifications to avoid polling waiting tasks and puts the CPU to sleep when there is currently no work to do. However, our executor is still quite basic and there are many possible ways to extend its functionality:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Scheduling:&lt;/strong&gt; We currently use the &lt;a href=&quot;https://doc.rust-lang.org/stable/alloc/collections/vec_deque/struct.VecDeque.html&quot;&gt;&lt;code&gt;VecDeque&lt;/code&gt;&lt;/a&gt; type to implement a &lt;em&gt;first in first out&lt;/em&gt; (FIFO) strategy for our &lt;code&gt;task_queue&lt;/code&gt;, which is often also called &lt;em&gt;round robin&lt;/em&gt; scheduling. This strategy might not be the most efficient for all workloads. For example, it might make sense to prioritize latency-critical tasks or task that do a lot of I/O. See the &lt;a href=&quot;http://pages.cs.wisc.edu/%7Eremzi/OSTEP/cpu-sched.pdf&quot;&gt;scheduling chapter&lt;/a&gt; of the &lt;a href=&quot;http://pages.cs.wisc.edu/%7Eremzi/OSTEP/&quot;&gt;&lt;em&gt;Operating Systems: Three Easy Pieces&lt;/em&gt;&lt;/a&gt; book or the &lt;a href=&quot;https://en.wikipedia.org/wiki/Scheduling_(computing)&quot;&gt;Wikipedia article on scheduling&lt;/a&gt; for more information.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Task Spawning&lt;/strong&gt;: Our &lt;code&gt;Executor::spawn&lt;/code&gt; method currently requires a &lt;code&gt;&amp;amp;mut self&lt;/code&gt; reference and is thus no longer available after starting the &lt;code&gt;run&lt;/code&gt; method. To fix this, we could create an additional &lt;code&gt;Spawner&lt;/code&gt; type that shares some kind of queue with the executor and allows task creation from within tasks themselves. The queue could be for example the &lt;code&gt;task_queue&lt;/code&gt; directly or a separate queue that the executor checks in its run loop.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Utilizing Threads&lt;/strong&gt;: We don't have support for threads yet, but we will add it in the next post. This will make it possible to launch multiple instances of the executor in different threads. The advantage of this approach is that the delay imposed by long running tasks can be reduced because other tasks can run concurrently. This approach also allows it to utilize multiple CPU cores.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Load Balancing&lt;/strong&gt;: When adding threading support, it becomes important how to distribute the tasks between the executors to ensure that all CPU cores are utilized. A common technique for this is &lt;a href=&quot;https://en.wikipedia.org/wiki/Work_stealing&quot;&gt;&lt;em&gt;work stealing&lt;/em&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We started this post by introducing &lt;strong&gt;multitasking&lt;/strong&gt; and differentiating between &lt;em&gt;preemptive&lt;/em&gt; multitasking, which forcibly interrupts running tasks regularly, and &lt;em&gt;cooperative&lt;/em&gt; multitasking, which lets tasks run until they voluntarily give up control of the CPU.&lt;/p&gt;
&lt;p&gt;We then explored how Rust's support of &lt;strong&gt;async/await&lt;/strong&gt; provides a language-level implementation of cooperative multitasking. Rust bases its implementation on top of the polling-based &lt;code&gt;Future&lt;/code&gt; trait, which abstracts asynchronous tasks. Using async/await, it is possible to work with futures almost like with normal synchronous code. The difference is that asynchronous functions return a &lt;code&gt;Future&lt;/code&gt; again, which needs to be added to an executor at some point in order to run it.&lt;/p&gt;
&lt;p&gt;Behind the scenes, the compiler transforms async/await code to &lt;em&gt;state machines&lt;/em&gt;, with each &lt;code&gt;.await&lt;/code&gt; operation corresponding to a possible pause point. By utilizing its knowledge about the program, the compiler is able to save only the minimal state for each pause point, resulting in a very small memory consumption per task. One challenge is that the generated state machines might contain &lt;em&gt;self-referential&lt;/em&gt; structs, for example when local variables of the asynchronous function reference each other. To prevent pointer invalidation, Rust uses the &lt;code&gt;Pin&lt;/code&gt; type to ensure that futures cannot be moved in memory anymore after they have been polled for the first time.&lt;/p&gt;
&lt;p&gt;For our &lt;strong&gt;implementation&lt;/strong&gt;, we first created a very basic executor that polls all spawned tasks in a busy loop without using the &lt;code&gt;Waker&lt;/code&gt; type at all. We then showed the advantage of waker notifications by implementing an asynchronous keyboard task. The task defines a static &lt;code&gt;SCANCODE_QUEUE&lt;/code&gt; using the mutex-free &lt;code&gt;ArrayQueue&lt;/code&gt; type provided by the &lt;code&gt;crossbeam&lt;/code&gt; crate. Instead of handling keypresses directly, the keyboard interrupt handler now puts all received scancodes in the queue and then wakes the registered &lt;code&gt;Waker&lt;/code&gt; to signal that new input is available. On the receiving end, we created a &lt;code&gt;ScancodeStream&lt;/code&gt; type to provide a &lt;code&gt;Future&lt;/code&gt; resolving to the next scancode in the queue. This made it possible to create an asynchronous &lt;code&gt;print_keypresses&lt;/code&gt; task that uses async/await to interpret and print the scancodes in the queue.&lt;/p&gt;
&lt;p&gt;To utilize the waker notifications of the keyboard task, we created a new &lt;code&gt;Executor&lt;/code&gt; type that differentiates between ready and waiting tasks. Using an &lt;code&gt;Arc&lt;/code&gt;-shared &lt;code&gt;wake_queue&lt;/code&gt;, we implemented a &lt;code&gt;TaskWaker&lt;/code&gt; type that sends wake-up notifications directly to the executor, which can then mark the corresponding task as ready again. To save power when no tasks are runnable, we added support for putting the CPU to sleep using the &lt;code&gt;hlt&lt;/code&gt; instruction. Finally, we discussed some potential extensions of our executor, for example for providing multi-core support.&lt;/p&gt;
&lt;h2 id=&quot;what-s-next&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;https://os.phil-opp.com/async-await/#what-s-next&quot; aria-label=&quot;Anchor link for: what-s-next&quot;&gt;🔗&lt;/a&gt;What's Next?&lt;/h2&gt;
&lt;p&gt;Using async/wait, we now have basic support for cooperative multitasking in our kernel. While cooperative multitasking is very efficient, it leads to latency problems when individual tasks keep running for too long and thus prevent other tasks to run. For this reason, it makes sense to also add support for preemptive multitasking to our kernel.&lt;/p&gt;
&lt;p&gt;In the next post, we will introduce &lt;em&gt;threads&lt;/em&gt; as the most common form of preemptive multitasking. In addition to resolving the problem of long running tasks, threads will also prepare us for utilizing multiple CPU cores and running untrusted user programs in the future.&lt;/p&gt;

&lt;hr/&gt;&lt;div class=&quot;PageNavigation&quot;&gt;&lt;a class=&quot;prev&quot; href=&quot;https://os.phil-opp.com/allocator-designs/&quot;&gt;« Allocator Designs&lt;/a&gt;&lt;/div&gt;
&lt;hr/&gt;&lt;section&gt;
&lt;/section&gt;&lt;aside class=&quot;page-aside-right&quot;/&gt;</description>
<pubDate>Mon, 30 Mar 2020 13:52:04 +0000</pubDate>
<dc:creator>phil-opp</dc:creator>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://os.phil-opp.com/async-await/</dc:identifier>
</item>
<item>
<title>WireGuard 1.0</title>
<link>https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/T/#u</link>
<guid isPermaLink="true" >https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/T/#u</guid>
<description>&lt;head&gt;&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;&lt;title&gt;[ANNOUNCE] WireGuard 1.0.0 for Linux 5.6 Released&lt;/title&gt;&lt;link rel=&quot;alternate&quot; title=&quot;Atom feed&quot; href=&quot;../../new.atom&quot; type=&quot;application/atom+xml&quot; /&gt;&lt;link type=&quot;text/css&quot; rel=&quot;stylesheet&quot; href=&quot;../../null.css?0&quot; title=&quot;default&quot; /&gt;&lt;link type=&quot;text/css&quot; rel=&quot;stylesheet&quot; href=&quot;../../216light.css?5dc3504d&quot; media=&quot;screen,(prefers-color-scheme:light)&quot; title=&quot;216light&quot; /&gt;&lt;link type=&quot;text/css&quot; rel=&quot;stylesheet&quot; href=&quot;../../216dark.css?5d0a9431&quot; media=&quot;screen,(prefers-color-scheme:dark)&quot; title=&quot;216dark&quot; /&gt;&lt;/head&gt;&lt;body id=&quot;readabilityBody&quot; readability=&quot;109.02676056338&quot;&gt;

&lt;pre&gt;
&lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/T/#ecf3795b5137b213d17b86ea1a7574eb5bd7726f4&quot; id=&quot;mcf3795b5137b213d17b86ea1a7574eb5bd7726f4&quot; name=&quot;mcf3795b5137b213d17b86ea1a7574eb5bd7726f4&quot;&gt;*&lt;/a&gt; &lt;u id=&quot;u&quot;&gt;&lt;strong&gt;[ANNOUNCE] WireGuard 1.0.0 for Linux 5.6 Released&lt;/strong&gt;&lt;/u&gt;
&lt;strong&gt;@ 2020-03-30  2:16 Jason A. Donenfeld&lt;/strong&gt;
  2020-03-30  2:20 ` &lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/T/#m1840b8fd1cda1be3e3b572f8913b4ce15924e153&quot;&gt;Eric Light&lt;/a&gt;
                   ` &lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/T/#r1840b8fd1cda1be3e3b572f8913b4ce15924e153&quot;&gt;(3 more replies)&lt;/a&gt;
  &lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/T/#rcf3795b5137b213d17b86ea1a7574eb5bd7726f4&quot;&gt;0 siblings, 4 replies; 5+ messages in thread&lt;/a&gt;
From: Jason A. Donenfeld @ 2020-03-30  2:16 UTC (&lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/&quot;&gt;permalink&lt;/a&gt; / &lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/raw&quot;&gt;raw&lt;/a&gt;)
  To: WireGuard mailing list

Hi folks,

Earlier this evening, Linus released [1] Linus 5.6, which contains our
first release of WireGuard. This is quite exciting. It means that
kernels from here on out will have WireGuard built-in by default. And
for those of you who were scared away prior by the &quot;dOnT uSe tHiS
k0de!!1!&quot; warnings everywhere, you now have something more stable to
work with.

The last several weeks of 5.6 development and stabilization have been
exciting, with our codebase undergoing a quick security audit [3], and
some real headway in terms of getting into distributions.

We'll also continue to maintain our wireguard-linux-compat [2]
backports repo for older kernels. On the backports front, WireGuard
was backported to Ubuntu 20.04 (via wireguard-linux-compat) [4] and
Debian Buster (via a real backport to 5.5.y) [5]. I'm also maintaining
real backports, not via the compat layer, to 5.4.y [6] and 5.5.y [7],
and we'll see where those wind up; 5.4.y is an LTS release.

Meanwhile, the usual up-to-date distributions like Arch, Gentoo, and
Fedora 32 will be getting WireGuard automatically by virtue of having
5.6, and I expect these to increase in number over time.

Enjoy!
Jason


[1] &lt;a href=&quot;https://lore.kernel.org/lkml/CAHk-=wi9ZT7Stg-uSpX0UWQzam6OP9Jzz6Xu1CkYu1cicpD5OA@mail.gmail.com/&quot;&gt;https://lore.kernel.org/lkml/CAHk-=wi9ZT7Stg-uSpX0UWQzam6OP9Jzz6Xu1CkYu1cicpD5OA@mail.gmail.com/&lt;/a&gt;
[2] &lt;a href=&quot;https://git.zx2c4.com/wireguard-linux-compat/&quot;&gt;https://git.zx2c4.com/wireguard-linux-compat/&lt;/a&gt;
[3] &lt;a href=&quot;https://lore.kernel.org/netdev/20200319003047.113501-1-Jason@zx2c4.com/&quot;&gt;https://lore.kernel.org/netdev/20200319003047.113501-1-Jason@zx2c4.com/&lt;/a&gt;
[4] &lt;a href=&quot;https://git.launchpad.net/~ubuntu-kernel/ubuntu/+source/linux/+git/focal/tree/debian/dkms-versions?h=master-next&quot;&gt;https://git.launchpad.net/~ubuntu-kernel/ubuntu/+source/linux/+git/focal/tree/debian/dkms-versions?h=master-next&lt;/a&gt;
[5] &lt;a href=&quot;https://salsa.debian.org/kernel-team/linux/-/tree/master/debian%2Fpatches%2Ffeatures%2Fall%2Fwireguard&quot;&gt;https://salsa.debian.org/kernel-team/linux/-/tree/master/debian%2Fpatches%2Ffeatures%2Fall%2Fwireguard&lt;/a&gt;
[6] &lt;a href=&quot;https://git.zx2c4.com/wireguard-linux/log/?h=backport-5.4.y&quot;&gt;https://git.zx2c4.com/wireguard-linux/log/?h=backport-5.4.y&lt;/a&gt;
[7] &lt;a href=&quot;https://git.zx2c4.com/wireguard-linux/log/?h=backport-5.5.y&quot;&gt;https://git.zx2c4.com/wireguard-linux/log/?h=backport-5.5.y&lt;/a&gt;

&lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/T/#mcf3795b5137b213d17b86ea1a7574eb5bd7726f4&quot; id=&quot;ecf3795b5137b213d17b86ea1a7574eb5bd7726f4&quot; name=&quot;ecf3795b5137b213d17b86ea1a7574eb5bd7726f4&quot;&gt;^&lt;/a&gt; &lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/&quot;&gt;permalink&lt;/a&gt; &lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/raw&quot;&gt;raw&lt;/a&gt; &lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/#R&quot;&gt;reply&lt;/a&gt;    [&lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/T/#u&quot;&gt;&lt;strong&gt;flat&lt;/strong&gt;&lt;/a&gt;|&lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/t/#u&quot;&gt;nested&lt;/a&gt;] &lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/T/#rcf3795b5137b213d17b86ea1a7574eb5bd7726f4&quot;&gt;5+ messages in thread&lt;/a&gt;
&lt;/pre&gt;
&lt;hr /&gt;&lt;pre&gt;
&lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/T/#e1840b8fd1cda1be3e3b572f8913b4ce15924e153&quot; id=&quot;m1840b8fd1cda1be3e3b572f8913b4ce15924e153&quot; name=&quot;m1840b8fd1cda1be3e3b572f8913b4ce15924e153&quot;&gt;*&lt;/a&gt; &lt;strong&gt;Re: [ANNOUNCE] WireGuard 1.0.0 for Linux 5.6 Released&lt;/strong&gt;
  2020-03-30  2:16 &lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/T/#mcf3795b5137b213d17b86ea1a7574eb5bd7726f4&quot;&gt;[ANNOUNCE] WireGuard 1.0.0 for Linux 5.6 Released&lt;/a&gt; Jason A. Donenfeld
&lt;strong&gt;@ 2020-03-30  2:20 ` Eric Light&lt;/strong&gt;
  2020-03-30  5:13 ` &lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/T/#mfc27de7fe78e0d168fb4f484aa3f745d1423272d&quot;&gt;Muenz, Michael&lt;/a&gt;
                   ` &lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/T/#rfc27de7fe78e0d168fb4f484aa3f745d1423272d&quot;&gt;(2 subsequent siblings)&lt;/a&gt;
  &lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/T/#r1840b8fd1cda1be3e3b572f8913b4ce15924e153&quot;&gt;3 siblings, 0 replies; 5+ messages in thread&lt;/a&gt;
From: Eric Light @ 2020-03-30  2:20 UTC (&lt;a href=&quot;https://lore.kernel.org/wireguard/7a0b9f59-0f17-4f7a-a174-272955706b2e@www.fastmail.com/&quot;&gt;permalink&lt;/a&gt; / &lt;a href=&quot;https://lore.kernel.org/wireguard/7a0b9f59-0f17-4f7a-a174-272955706b2e@www.fastmail.com/raw&quot;&gt;raw&lt;/a&gt;)
  To: wireguard

Oh, Jason, that is outstanding news!  Congratulations to you and the whole team of people who have contributed - be it developing, blog posts, or financially.  

Well done, you lot!

E

--------------------------------------------
Q: Why is this email five sentences or less?
A: &lt;a href=&quot;http://five.sentenc.es&quot;&gt;http://five.sentenc.es&lt;/a&gt;

On Mon, 30 Mar 2020, at 15:16, Jason A. Donenfeld wrote:
&lt;span class=&quot;q&quot;&gt;&amp;gt; Hi folks,
&amp;gt; 
&amp;gt; Earlier this evening, Linus released [1] Linus 5.6, which contains our
&amp;gt; first release of WireGuard. This is quite exciting. It means that
&amp;gt; kernels from here on out will have WireGuard built-in by default. And
&amp;gt; for those of you who were scared away prior by the &quot;dOnT uSe tHiS
&amp;gt; k0de!!1!&quot; warnings everywhere, you now have something more stable to
&amp;gt; work with.
&amp;gt; 
&amp;gt; The last several weeks of 5.6 development and stabilization have been
&amp;gt; exciting, with our codebase undergoing a quick security audit [3], and
&amp;gt; some real headway in terms of getting into distributions.
&amp;gt; 
&amp;gt; We'll also continue to maintain our wireguard-linux-compat [2]
&amp;gt; backports repo for older kernels. On the backports front, WireGuard
&amp;gt; was backported to Ubuntu 20.04 (via wireguard-linux-compat) [4] and
&amp;gt; Debian Buster (via a real backport to 5.5.y) [5]. I'm also maintaining
&amp;gt; real backports, not via the compat layer, to 5.4.y [6] and 5.5.y [7],
&amp;gt; and we'll see where those wind up; 5.4.y is an LTS release.
&amp;gt; 
&amp;gt; Meanwhile, the usual up-to-date distributions like Arch, Gentoo, and
&amp;gt; Fedora 32 will be getting WireGuard automatically by virtue of having
&amp;gt; 5.6, and I expect these to increase in number over time.
&amp;gt; 
&amp;gt; Enjoy!
&amp;gt; Jason
&amp;gt; 
&amp;gt; 
&amp;gt; [1] 
&amp;gt; &lt;a href=&quot;https://lore.kernel.org/lkml/CAHk-=wi9ZT7Stg-uSpX0UWQzam6OP9Jzz6Xu1CkYu1cicpD5OA@mail.gmail.com/&quot;&gt;https://lore.kernel.org/lkml/CAHk-=wi9ZT7Stg-uSpX0UWQzam6OP9Jzz6Xu1CkYu1cicpD5OA@mail.gmail.com/&lt;/a&gt;
&amp;gt; [2] &lt;a href=&quot;https://git.zx2c4.com/wireguard-linux-compat/&quot;&gt;https://git.zx2c4.com/wireguard-linux-compat/&lt;/a&gt;
&amp;gt; [3] 
&amp;gt; &lt;a href=&quot;https://lore.kernel.org/netdev/20200319003047.113501-1-Jason@zx2c4.com/&quot;&gt;https://lore.kernel.org/netdev/20200319003047.113501-1-Jason@zx2c4.com/&lt;/a&gt;
&amp;gt; [4] 
&amp;gt; &lt;a href=&quot;https://git.launchpad.net/~ubuntu-kernel/ubuntu/+source/linux/+git/focal/tree/debian/dkms-versions?h=master-next&quot;&gt;https://git.launchpad.net/~ubuntu-kernel/ubuntu/+source/linux/+git/focal/tree/debian/dkms-versions?h=master-next&lt;/a&gt;
&amp;gt; [5] 
&amp;gt; &lt;a href=&quot;https://salsa.debian.org/kernel-team/linux/-/tree/master/debian%2Fpatches%2Ffeatures%2Fall%2Fwireguard&quot;&gt;https://salsa.debian.org/kernel-team/linux/-/tree/master/debian%2Fpatches%2Ffeatures%2Fall%2Fwireguard&lt;/a&gt;
&amp;gt; [6] &lt;a href=&quot;https://git.zx2c4.com/wireguard-linux/log/?h=backport-5.4.y&quot;&gt;https://git.zx2c4.com/wireguard-linux/log/?h=backport-5.4.y&lt;/a&gt;
&amp;gt; [7] &lt;a href=&quot;https://git.zx2c4.com/wireguard-linux/log/?h=backport-5.5.y&quot;&gt;https://git.zx2c4.com/wireguard-linux/log/?h=backport-5.5.y&lt;/a&gt;
&amp;gt;
&lt;/span&gt;
&lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/T/#m1840b8fd1cda1be3e3b572f8913b4ce15924e153&quot; id=&quot;e1840b8fd1cda1be3e3b572f8913b4ce15924e153&quot; name=&quot;e1840b8fd1cda1be3e3b572f8913b4ce15924e153&quot;&gt;^&lt;/a&gt; &lt;a href=&quot;https://lore.kernel.org/wireguard/7a0b9f59-0f17-4f7a-a174-272955706b2e@www.fastmail.com/&quot;&gt;permalink&lt;/a&gt; &lt;a href=&quot;https://lore.kernel.org/wireguard/7a0b9f59-0f17-4f7a-a174-272955706b2e@www.fastmail.com/raw&quot;&gt;raw&lt;/a&gt; &lt;a href=&quot;https://lore.kernel.org/wireguard/7a0b9f59-0f17-4f7a-a174-272955706b2e@www.fastmail.com/#R&quot;&gt;reply&lt;/a&gt; [&lt;a href=&quot;https://lore.kernel.org/wireguard/7a0b9f59-0f17-4f7a-a174-272955706b2e@www.fastmail.com/T/#u&quot;&gt;&lt;strong&gt;flat&lt;/strong&gt;&lt;/a&gt;|&lt;a href=&quot;https://lore.kernel.org/wireguard/7a0b9f59-0f17-4f7a-a174-272955706b2e@www.fastmail.com/t/#u&quot;&gt;nested&lt;/a&gt;] &lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/T/#r1840b8fd1cda1be3e3b572f8913b4ce15924e153&quot;&gt;5+ messages in thread&lt;/a&gt;
&lt;/pre&gt;
&lt;hr /&gt;&lt;pre&gt;
&lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/T/#efc27de7fe78e0d168fb4f484aa3f745d1423272d&quot; id=&quot;mfc27de7fe78e0d168fb4f484aa3f745d1423272d&quot; name=&quot;mfc27de7fe78e0d168fb4f484aa3f745d1423272d&quot;&gt;*&lt;/a&gt; &lt;strong&gt;Re: [ANNOUNCE] WireGuard 1.0.0 for Linux 5.6 Released&lt;/strong&gt;
  2020-03-30  2:16 &lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/T/#mcf3795b5137b213d17b86ea1a7574eb5bd7726f4&quot;&gt;[ANNOUNCE] WireGuard 1.0.0 for Linux 5.6 Released&lt;/a&gt; Jason A. Donenfeld
  2020-03-30  2:20 ` &lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/T/#m1840b8fd1cda1be3e3b572f8913b4ce15924e153&quot;&gt;Eric Light&lt;/a&gt;
&lt;strong&gt;@ 2020-03-30  5:13 ` Muenz, Michael&lt;/strong&gt;
  2020-03-30 12:24 ` &lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/T/#m2ffdd0c1a86ff84a911d0fd51b731f73caf1b58e&quot;&gt;Fredrik Strömberg&lt;/a&gt;
  2020-03-30 13:17 ` &lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/T/#meead426ddad274c62cbe25c7b8dbb8e528d32be4&quot;&gt;Greg KH&lt;/a&gt;
  &lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/T/#rfc27de7fe78e0d168fb4f484aa3f745d1423272d&quot;&gt;3 siblings, 0 replies; 5+ messages in thread&lt;/a&gt;
From: Muenz, Michael @ 2020-03-30  5:13 UTC (&lt;a href=&quot;https://lore.kernel.org/wireguard/dc684a08-340b-5a3c-1a70-06f8a0ac6c58@spam-fetish.org/&quot;&gt;permalink&lt;/a&gt; / &lt;a href=&quot;https://lore.kernel.org/wireguard/dc684a08-340b-5a3c-1a70-06f8a0ac6c58@spam-fetish.org/raw&quot;&gt;raw&lt;/a&gt;)
  To: wireguard

Am 30.03.2020 um 04:16 schrieb Jason A. Donenfeld:
&lt;span class=&quot;q&quot;&gt;&amp;gt; Hi folks,
&amp;gt;
&amp;gt; Earlier this evening, Linus released [1] Linus 5.6, which contains our
&amp;gt; first release of WireGuard. This is quite exciting. It means that
&amp;gt; kernels from here on out will have WireGuard built-in by default. And
&amp;gt; for those of you who were scared away prior by the &quot;dOnT uSe tHiS
&amp;gt; k0de!!1!&quot; warnings everywhere, you now have something more stable to
&amp;gt; work with.
&amp;gt;
&amp;gt; The last several weeks of 5.6 development and stabilization have been
&amp;gt; exciting, with our codebase undergoing a quick security audit [3], and
&amp;gt; some real headway in terms of getting into distributions.
&amp;gt;
&amp;gt; We'll also continue to maintain our wireguard-linux-compat [2]
&amp;gt; backports repo for older kernels. On the backports front, WireGuard
&amp;gt; was backported to Ubuntu 20.04 (via wireguard-linux-compat) [4] and
&amp;gt; Debian Buster (via a real backport to 5.5.y) [5]. I'm also maintaining
&amp;gt; real backports, not via the compat layer, to 5.4.y [6] and 5.5.y [7],
&amp;gt; and we'll see where those wind up; 5.4.y is an LTS release.
&amp;gt;
&amp;gt; Meanwhile, the usual up-to-date distributions like Arch, Gentoo, and
&amp;gt; Fedora 32 will be getting WireGuard automatically by virtue of having
&amp;gt; 5.6, and I expect these to increase in number over time.
&amp;gt;
&amp;gt; Enjoy!
&amp;gt; Jason
&amp;gt;
&lt;/span&gt;Hi Jason,


Congrats to this awesom release! I never thought it would walk in that fast.

This will enormously speed up the spread of WireGuard and I'm hoping 
that nobody forgets to keep the code generic so all features will be 
available on every operating system, like FreeBSD (I maintain the plugin 
for OPNsense Firewall). Bit afraid with this hype it will be like FRR 
where most fancy features are linux-only and we (BSD users) can only use 
the basics.

Thanks and keep on rocking! :)


Michael


&lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/T/#mfc27de7fe78e0d168fb4f484aa3f745d1423272d&quot; id=&quot;efc27de7fe78e0d168fb4f484aa3f745d1423272d&quot; name=&quot;efc27de7fe78e0d168fb4f484aa3f745d1423272d&quot;&gt;^&lt;/a&gt; &lt;a href=&quot;https://lore.kernel.org/wireguard/dc684a08-340b-5a3c-1a70-06f8a0ac6c58@spam-fetish.org/&quot;&gt;permalink&lt;/a&gt; &lt;a href=&quot;https://lore.kernel.org/wireguard/dc684a08-340b-5a3c-1a70-06f8a0ac6c58@spam-fetish.org/raw&quot;&gt;raw&lt;/a&gt; &lt;a href=&quot;https://lore.kernel.org/wireguard/dc684a08-340b-5a3c-1a70-06f8a0ac6c58@spam-fetish.org/#R&quot;&gt;reply&lt;/a&gt;  [&lt;a href=&quot;https://lore.kernel.org/wireguard/dc684a08-340b-5a3c-1a70-06f8a0ac6c58@spam-fetish.org/T/#u&quot;&gt;&lt;strong&gt;flat&lt;/strong&gt;&lt;/a&gt;|&lt;a href=&quot;https://lore.kernel.org/wireguard/dc684a08-340b-5a3c-1a70-06f8a0ac6c58@spam-fetish.org/t/#u&quot;&gt;nested&lt;/a&gt;] &lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/T/#rfc27de7fe78e0d168fb4f484aa3f745d1423272d&quot;&gt;5+ messages in thread&lt;/a&gt;
&lt;/pre&gt;
&lt;hr /&gt;&lt;pre&gt;
&lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/T/#e2ffdd0c1a86ff84a911d0fd51b731f73caf1b58e&quot; id=&quot;m2ffdd0c1a86ff84a911d0fd51b731f73caf1b58e&quot; name=&quot;m2ffdd0c1a86ff84a911d0fd51b731f73caf1b58e&quot;&gt;*&lt;/a&gt; &lt;strong&gt;Re: [ANNOUNCE] WireGuard 1.0.0 for Linux 5.6 Released&lt;/strong&gt;
  2020-03-30  2:16 &lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/T/#mcf3795b5137b213d17b86ea1a7574eb5bd7726f4&quot;&gt;[ANNOUNCE] WireGuard 1.0.0 for Linux 5.6 Released&lt;/a&gt; Jason A. Donenfeld
  2020-03-30  2:20 ` &lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/T/#m1840b8fd1cda1be3e3b572f8913b4ce15924e153&quot;&gt;Eric Light&lt;/a&gt;
  2020-03-30  5:13 ` &lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/T/#mfc27de7fe78e0d168fb4f484aa3f745d1423272d&quot;&gt;Muenz, Michael&lt;/a&gt;
&lt;strong&gt;@ 2020-03-30 12:24 ` Fredrik Strömberg&lt;/strong&gt;
  2020-03-30 13:17 ` &lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/T/#meead426ddad274c62cbe25c7b8dbb8e528d32be4&quot;&gt;Greg KH&lt;/a&gt;
  &lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/T/#r2ffdd0c1a86ff84a911d0fd51b731f73caf1b58e&quot;&gt;3 siblings, 0 replies; 5+ messages in thread&lt;/a&gt;
From: Fredrik Strömberg @ 2020-03-30 12:24 UTC (&lt;a href=&quot;https://lore.kernel.org/wireguard/CANTUoechj1jeWTm0YqwPxXctA2eYDah8OiVWi=zL61p8yHhViA@mail.gmail.com/&quot;&gt;permalink&lt;/a&gt; / &lt;a href=&quot;https://lore.kernel.org/wireguard/CANTUoechj1jeWTm0YqwPxXctA2eYDah8OiVWi=zL61p8yHhViA@mail.gmail.com/raw&quot;&gt;raw&lt;/a&gt;)
  To: WireGuard mailing list

On Mon, Mar 30, 2020 at 4:33 AM Jason A. Donenfeld &amp;lt;Jason@zx2c4.com&amp;gt; wrote:
&lt;span class=&quot;q&quot;&gt;&amp;gt; Earlier this evening, Linus released [1] Linus 5.6, which contains our
&amp;gt; first release of WireGuard. This is quite exciting. It means that
&amp;gt; kernels from here on out will have WireGuard built-in by default.
&lt;/span&gt;
Yippee!

Congratulations Jason, and to everyone else who has contributed to the
development of WireGuard.

Cheers,
Fredrik Stromberg

&lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/T/#m2ffdd0c1a86ff84a911d0fd51b731f73caf1b58e&quot; id=&quot;e2ffdd0c1a86ff84a911d0fd51b731f73caf1b58e&quot; name=&quot;e2ffdd0c1a86ff84a911d0fd51b731f73caf1b58e&quot;&gt;^&lt;/a&gt; &lt;a href=&quot;https://lore.kernel.org/wireguard/CANTUoechj1jeWTm0YqwPxXctA2eYDah8OiVWi=zL61p8yHhViA@mail.gmail.com/&quot;&gt;permalink&lt;/a&gt; &lt;a href=&quot;https://lore.kernel.org/wireguard/CANTUoechj1jeWTm0YqwPxXctA2eYDah8OiVWi=zL61p8yHhViA@mail.gmail.com/raw&quot;&gt;raw&lt;/a&gt; &lt;a href=&quot;https://lore.kernel.org/wireguard/CANTUoechj1jeWTm0YqwPxXctA2eYDah8OiVWi=zL61p8yHhViA@mail.gmail.com/#R&quot;&gt;reply&lt;/a&gt;    [&lt;a href=&quot;https://lore.kernel.org/wireguard/CANTUoechj1jeWTm0YqwPxXctA2eYDah8OiVWi=zL61p8yHhViA@mail.gmail.com/T/#u&quot;&gt;&lt;strong&gt;flat&lt;/strong&gt;&lt;/a&gt;|&lt;a href=&quot;https://lore.kernel.org/wireguard/CANTUoechj1jeWTm0YqwPxXctA2eYDah8OiVWi=zL61p8yHhViA@mail.gmail.com/t/#u&quot;&gt;nested&lt;/a&gt;] &lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/T/#r2ffdd0c1a86ff84a911d0fd51b731f73caf1b58e&quot;&gt;5+ messages in thread&lt;/a&gt;
&lt;/pre&gt;
&lt;hr /&gt;&lt;pre&gt;
&lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/T/#eeead426ddad274c62cbe25c7b8dbb8e528d32be4&quot; id=&quot;meead426ddad274c62cbe25c7b8dbb8e528d32be4&quot; name=&quot;meead426ddad274c62cbe25c7b8dbb8e528d32be4&quot;&gt;*&lt;/a&gt; &lt;strong&gt;Re: [ANNOUNCE] WireGuard 1.0.0 for Linux 5.6 Released&lt;/strong&gt;
  2020-03-30  2:16 &lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/T/#mcf3795b5137b213d17b86ea1a7574eb5bd7726f4&quot;&gt;[ANNOUNCE] WireGuard 1.0.0 for Linux 5.6 Released&lt;/a&gt; Jason A. Donenfeld
                   ` &lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/T/#r2ffdd0c1a86ff84a911d0fd51b731f73caf1b58e&quot;&gt;(2 preceding siblings ...)&lt;/a&gt;
  2020-03-30 12:24 ` &lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/T/#m2ffdd0c1a86ff84a911d0fd51b731f73caf1b58e&quot;&gt;Fredrik Strömberg&lt;/a&gt;
&lt;strong&gt;@ 2020-03-30 13:17 ` Greg KH&lt;/strong&gt;
  &lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/T/#reead426ddad274c62cbe25c7b8dbb8e528d32be4&quot;&gt;3 siblings, 0 replies; 5+ messages in thread&lt;/a&gt;
From: Greg KH @ 2020-03-30 13:17 UTC (&lt;a href=&quot;https://lore.kernel.org/wireguard/20200330131701.GA243095@kroah.com/&quot;&gt;permalink&lt;/a&gt; / &lt;a href=&quot;https://lore.kernel.org/wireguard/20200330131701.GA243095@kroah.com/raw&quot;&gt;raw&lt;/a&gt;)
  To: Jason A. Donenfeld; &lt;strong&gt;+Cc:&lt;/strong&gt; WireGuard mailing list

On Sun, Mar 29, 2020 at 08:16:43PM -0600, Jason A. Donenfeld wrote:
&lt;span class=&quot;q&quot;&gt;&amp;gt; Hi folks,
&amp;gt; 
&amp;gt; Earlier this evening, Linus released [1] Linus 5.6, which contains our
&amp;gt; first release of WireGuard. This is quite exciting. It means that
&amp;gt; kernels from here on out will have WireGuard built-in by default. And
&amp;gt; for those of you who were scared away prior by the &quot;dOnT uSe tHiS
&amp;gt; k0de!!1!&quot; warnings everywhere, you now have something more stable to
&amp;gt; work with.
&amp;gt; 
&amp;gt; The last several weeks of 5.6 development and stabilization have been
&amp;gt; exciting, with our codebase undergoing a quick security audit [3], and
&amp;gt; some real headway in terms of getting into distributions.
&lt;/span&gt;
Congrats on all of this, and thanks for sticking with it.

greg k-h

&lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/T/#meead426ddad274c62cbe25c7b8dbb8e528d32be4&quot; id=&quot;eeead426ddad274c62cbe25c7b8dbb8e528d32be4&quot; name=&quot;eeead426ddad274c62cbe25c7b8dbb8e528d32be4&quot;&gt;^&lt;/a&gt; &lt;a href=&quot;https://lore.kernel.org/wireguard/20200330131701.GA243095@kroah.com/&quot;&gt;permalink&lt;/a&gt; &lt;a href=&quot;https://lore.kernel.org/wireguard/20200330131701.GA243095@kroah.com/raw&quot;&gt;raw&lt;/a&gt; &lt;a href=&quot;https://lore.kernel.org/wireguard/20200330131701.GA243095@kroah.com/#R&quot;&gt;reply&lt;/a&gt;     [&lt;a href=&quot;https://lore.kernel.org/wireguard/20200330131701.GA243095@kroah.com/T/#u&quot;&gt;&lt;strong&gt;flat&lt;/strong&gt;&lt;/a&gt;|&lt;a href=&quot;https://lore.kernel.org/wireguard/20200330131701.GA243095@kroah.com/t/#u&quot;&gt;nested&lt;/a&gt;] &lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/T/#reead426ddad274c62cbe25c7b8dbb8e528d32be4&quot;&gt;5+ messages in thread&lt;/a&gt;
&lt;/pre&gt;
&lt;hr /&gt;&lt;pre&gt;
end of thread, back to &lt;a href=&quot;https://lore.kernel.org/wireguard/&quot;&gt;index&lt;/a&gt;

&lt;strong id=&quot;t&quot;&gt;Thread overview:&lt;/strong&gt; 5+ messages (download: &lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/t.mbox.gz&quot;&gt;mbox.gz&lt;/a&gt; / follow: &lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/t.atom&quot;&gt;Atom feed&lt;/a&gt;)
-- links below jump to the message on this page --
2020-03-30  2:16 &lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/T/#mcf3795b5137b213d17b86ea1a7574eb5bd7726f4&quot; id=&quot;rcf3795b5137b213d17b86ea1a7574eb5bd7726f4&quot; name=&quot;rcf3795b5137b213d17b86ea1a7574eb5bd7726f4&quot;&gt;[ANNOUNCE] WireGuard 1.0.0 for Linux 5.6 Released&lt;/a&gt; Jason A. Donenfeld
2020-03-30  2:20 ` &lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/T/#m1840b8fd1cda1be3e3b572f8913b4ce15924e153&quot; id=&quot;r1840b8fd1cda1be3e3b572f8913b4ce15924e153&quot; name=&quot;r1840b8fd1cda1be3e3b572f8913b4ce15924e153&quot;&gt;Eric Light&lt;/a&gt;
2020-03-30  5:13 ` &lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/T/#mfc27de7fe78e0d168fb4f484aa3f745d1423272d&quot; id=&quot;rfc27de7fe78e0d168fb4f484aa3f745d1423272d&quot; name=&quot;rfc27de7fe78e0d168fb4f484aa3f745d1423272d&quot;&gt;Muenz, Michael&lt;/a&gt;
2020-03-30 12:24 ` &lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/T/#m2ffdd0c1a86ff84a911d0fd51b731f73caf1b58e&quot; id=&quot;r2ffdd0c1a86ff84a911d0fd51b731f73caf1b58e&quot; name=&quot;r2ffdd0c1a86ff84a911d0fd51b731f73caf1b58e&quot;&gt;Fredrik Strömberg&lt;/a&gt;
2020-03-30 13:17 ` &lt;a href=&quot;https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/T/#meead426ddad274c62cbe25c7b8dbb8e528d32be4&quot; id=&quot;reead426ddad274c62cbe25c7b8dbb8e528d32be4&quot; name=&quot;reead426ddad274c62cbe25c7b8dbb8e528d32be4&quot;&gt;Greg KH&lt;/a&gt;
&lt;/pre&gt;
&lt;hr /&gt;&lt;pre&gt;
WireGuard Archive on lore.kernel.org

Archives are clonable:
        git clone --mirror https://lore.kernel.org/wireguard/0 wireguard/git/0.git

        # If you have public-inbox 1.1+ installed, you may
        # initialize and index your mirror using the following commands:
        public-inbox-init -V2 wireguard wireguard/ https://lore.kernel.org/wireguard \
                wireguard@lists.zx2c4.com
        public-inbox-index wireguard

Example &lt;a href=&quot;https://lore.kernel.org/wireguard/_/text/config/raw&quot;&gt;config snippet&lt;/a&gt; for mirrors

Newsgroup available over NNTP:
        &lt;a href=&quot;nntp://nntp.lore.kernel.org/com.zx2c4.lists.wireguard&quot;&gt;nntp://nntp.lore.kernel.org/com.zx2c4.lists.wireguard&lt;/a&gt;


AGPL code for this site: git clone &lt;a href=&quot;https://public-inbox.org/public-inbox.git&quot;&gt;https://public-inbox.org/public-inbox.git&lt;/a&gt;
&lt;/pre&gt;
&lt;/body&gt;</description>
<pubDate>Mon, 30 Mar 2020 12:12:44 +0000</pubDate>
<dc:creator>iamd3vil</dc:creator>
<dc:format>text/html</dc:format>
<dc:identifier>https://lore.kernel.org/wireguard/CAHmME9qOpDeraWo5rM31EWQW574KEduRBTL-+0A2ZyqBNDeYkg@mail.gmail.com/T/</dc:identifier>
</item>
</channel>
</rss>