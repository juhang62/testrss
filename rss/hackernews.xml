<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=hnrss.org%2Fnewest%3Fpoints%3D200&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://hnrss.org/newest?points=200" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>Hacker News: Newest</title>
<link>https://news.ycombinator.com/newest</link>
<description>Hacker News RSS</description>
<item>
<title>Swift for TensorFlow Shuts Down</title>
<link>https://github.com/tensorflow/swift</link>
<guid isPermaLink="true" >https://github.com/tensorflow/swift</guid>
<description>&lt;p align=&quot;center&quot;&gt;&lt;a target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; href=&quot;https://github.com/tensorflow/swift/blob/main/images/logo.png&quot;&gt;&lt;img src=&quot;https://github.com/tensorflow/swift/raw/main/images/logo.png&quot;/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Swift for TensorFlow was an experiment in the next-generation platform for machine learning, incorporating the latest research across machine learning, compilers, differentiable programming, systems design, and beyond. It was archived in February 2021. Some significant achievements from this project include:&lt;/p&gt;
&lt;p&gt;This site will not receive further updates. The API documentation and binary downloads will continue to be accessible as well as the &lt;a href=&quot;https://docs.google.com/document/d/1Fm56p5rV1t2Euh6WLtBFKGqI43ozC3EIjReyLk-LCLU/edit&quot; rel=&quot;nofollow&quot;&gt;Open Design Review meeting recordings&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Getting started&lt;/h2&gt;
&lt;h3&gt;Using Swift for TensorFlow&lt;/h3&gt;
&lt;h3&gt;Tutorials &lt;a target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; href=&quot;https://camo.githubusercontent.com/756e8e5187b778c7b7440cce63e1ca5069313fea0abddc151a92f5b5f536f471/68747470733a2f2f7777772e74656e736f72666c6f772e6f72672f696d616765732f636f6c61625f6c6f676f5f333270782e706e67&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/756e8e5187b778c7b7440cce63e1ca5069313fea0abddc151a92f5b5f536f471/68747470733a2f2f7777772e74656e736f72666c6f772e6f72672f696d616765732f636f6c61625f6c6f676f5f333270782e706e67&quot; alt=&quot;&quot; data-canonical-src=&quot;https://www.tensorflow.org/images/colab_logo_32px.png&quot;/&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;h3&gt;Resources&lt;/h3&gt;
&lt;h3&gt;Forums&lt;/h3&gt;
&lt;p&gt;The discussions happened on the &lt;a href=&quot;https://groups.google.com/a/tensorflow.org/d/forum/swift&quot; rel=&quot;nofollow&quot;&gt;swift@tensorflow.org mailing list&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Why Swift for TensorFlow?&lt;/h2&gt;
&lt;p&gt;Swift for TensorFlow is a new way to develop machine learning models. It gives you the power of &lt;a href=&quot;https://www.tensorflow.org&quot; rel=&quot;nofollow&quot;&gt;TensorFlow&lt;/a&gt; directly integrated into the &lt;a href=&quot;https://swift.org/about&quot; rel=&quot;nofollow&quot;&gt;Swift programming language&lt;/a&gt;. We believe that machine learning paradigms are so important that they deserve &lt;strong&gt;first-class language and compiler support&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;A fundamental primitive in machine learning is gradient-based optimization: computing function derivatives to optimize parameters. With Swift for TensorFlow, you can easily differentiate functions using differential operators like &lt;a href=&quot;https://www.tensorflow.org/swift/api_docs/Functions#/s:10TensorFlow8gradient2of15CotangentVectorQzxcq_xc_tAA14DifferentiableRzSFR_AaFR_AdaFPQy_Rs_r0_lF&quot; rel=&quot;nofollow&quot;&gt;&lt;code&gt;gradient(of:)&lt;/code&gt;&lt;/a&gt;, or differentiate with respect to an entire model by calling method &lt;a href=&quot;https://www.tensorflow.org/swift/api_docs/Protocols/Differentiable#/s:10TensorFlow14DifferentiablePAAE8gradient2in15CotangentVectorQzqd__xXE_tSFRd__AaBRd__AfCQyd__Rsd__lF&quot; rel=&quot;nofollow&quot;&gt;&lt;code&gt;gradient(in:)&lt;/code&gt;&lt;/a&gt;. These differentiation APIs are not just available for &lt;code&gt;Tensor&lt;/code&gt;-related concepts‚Äîthey are generalized for all types that conform to the &lt;a href=&quot;https://www.tensorflow.org/swift/api_docs/Protocols/Differentiable&quot; rel=&quot;nofollow&quot;&gt;&lt;code&gt;Differentiable&lt;/code&gt;&lt;/a&gt; protocol, including &lt;code&gt;Float&lt;/code&gt;, &lt;code&gt;Double&lt;/code&gt;, SIMD vectors, and your own data structures.&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-swift&quot; readability=&quot;15&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;//&lt;/span&gt; Custom differentiable type.&lt;/span&gt;
&lt;span class=&quot;pl-k&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;pl-en&quot;&gt;Model&lt;/span&gt;: &lt;span class=&quot;pl-e&quot;&gt;Differentiable &lt;/span&gt;{
    &lt;span class=&quot;pl-k&quot;&gt;var&lt;/span&gt; w&lt;span class=&quot;pl-k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pl-c1&quot;&gt;Float&lt;/span&gt;
    &lt;span class=&quot;pl-k&quot;&gt;var&lt;/span&gt; b&lt;span class=&quot;pl-k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pl-c1&quot;&gt;Float&lt;/span&gt;
    &lt;span class=&quot;pl-k&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;pl-en&quot;&gt;applied&lt;/span&gt;(&lt;span class=&quot;pl-en&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;pl-smi&quot;&gt;input&lt;/span&gt;: &lt;span class=&quot;pl-c1&quot;&gt;Float&lt;/span&gt;) &lt;span class=&quot;pl-k&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;pl-c1&quot;&gt;Float&lt;/span&gt; {
        &lt;span class=&quot;pl-k&quot;&gt;return&lt;/span&gt; w &lt;span class=&quot;pl-k&quot;&gt;*&lt;/span&gt; input &lt;span class=&quot;pl-k&quot;&gt;+&lt;/span&gt; b
    }
}

&lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;//&lt;/span&gt; Differentiate using `gradient(at:_:in:)`.&lt;/span&gt;
&lt;span class=&quot;pl-k&quot;&gt;let&lt;/span&gt; model &lt;span class=&quot;pl-k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;pl-c1&quot;&gt;Model&lt;/span&gt;(&lt;span class=&quot;pl-c1&quot;&gt;w&lt;/span&gt;: &lt;span class=&quot;pl-c1&quot;&gt;4&lt;/span&gt;, &lt;span class=&quot;pl-c1&quot;&gt;b&lt;/span&gt;: &lt;span class=&quot;pl-c1&quot;&gt;3&lt;/span&gt;)
&lt;span class=&quot;pl-k&quot;&gt;let&lt;/span&gt; input&lt;span class=&quot;pl-k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pl-c1&quot;&gt;Float&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;pl-c1&quot;&gt;2&lt;/span&gt;
&lt;span class=&quot;pl-k&quot;&gt;let&lt;/span&gt; (ùõÅmodel, ùõÅinput) &lt;span class=&quot;pl-k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;pl-c1&quot;&gt;gradient&lt;/span&gt;(&lt;span class=&quot;pl-c1&quot;&gt;at&lt;/span&gt;: model, input) { model, input &lt;span class=&quot;pl-k&quot;&gt;in&lt;/span&gt;
    model.&lt;span class=&quot;pl-c1&quot;&gt;applied&lt;/span&gt;(&lt;span class=&quot;pl-c1&quot;&gt;to&lt;/span&gt;: input)
}

&lt;span class=&quot;pl-c1&quot;&gt;print&lt;/span&gt;(ùõÅmodel) &lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;//&lt;/span&gt; Model.TangentVector(w: 2.0, b: 1.0)&lt;/span&gt;
&lt;span class=&quot;pl-c1&quot;&gt;print&lt;/span&gt;(ùõÅinput) &lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;//&lt;/span&gt; 4.0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Beyond derivatives, the Swift for TensorFlow project comes with a sophisticated toolchain to make users more productive. You can run Swift interactively in a Jupyter notebook, and get helpful autocomplete suggestions to help you explore the massive API surface of a modern deep learning library. You can &lt;a href=&quot;https://colab.research.google.com/github/tensorflow/swift/blob/main/docs/site/tutorials/model_training_walkthrough.ipynb&quot; rel=&quot;nofollow&quot;&gt;get started right in your browser in seconds&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;Migrating to Swift for TensorFlow is really easy thanks to Swift's powerful Python integration. You can incrementally migrate your Python code over (or continue to use your favorite Python libraries), because you can easily call your favorite Python library with a familiar syntax:&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-swift&quot; readability=&quot;10&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;pl-k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;pl-en&quot;&gt;TensorFlow&lt;/span&gt;
&lt;span class=&quot;pl-k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;pl-en&quot;&gt;Python&lt;/span&gt;

&lt;span class=&quot;pl-k&quot;&gt;let&lt;/span&gt; np &lt;span class=&quot;pl-k&quot;&gt;=&lt;/span&gt; Python.&lt;span class=&quot;pl-c1&quot;&gt;import&lt;/span&gt;(&lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;numpy&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;)

&lt;span class=&quot;pl-k&quot;&gt;let&lt;/span&gt; array &lt;span class=&quot;pl-k&quot;&gt;=&lt;/span&gt; np.&lt;span class=&quot;pl-c1&quot;&gt;arange&lt;/span&gt;(&lt;span class=&quot;pl-c1&quot;&gt;100&lt;/span&gt;).&lt;span class=&quot;pl-c1&quot;&gt;reshape&lt;/span&gt;(&lt;span class=&quot;pl-c1&quot;&gt;10&lt;/span&gt;, &lt;span class=&quot;pl-c1&quot;&gt;10&lt;/span&gt;)  &lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;//&lt;/span&gt; Create a 10x10 numpy array.&lt;/span&gt;
&lt;span class=&quot;pl-k&quot;&gt;let&lt;/span&gt; tensor &lt;span class=&quot;pl-k&quot;&gt;=&lt;/span&gt; Tensor&lt;span class=&quot;pl-k&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;pl-c1&quot;&gt;Float&lt;/span&gt;&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;(&lt;span class=&quot;pl-c1&quot;&gt;numpy&lt;/span&gt;: array)  &lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;//&lt;/span&gt; Seamless integration!&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Documentation&lt;/h2&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;Beware: the project is moving very quickly, and thus some of these documents are slightly out of date as compared to the current state-of-the-art.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;Overview&lt;/h3&gt;
&lt;h3&gt;Technology deep dive&lt;/h3&gt;
&lt;p&gt;The Swift for TensorFlow project builds on top of powerful theoretical foundations. For insight into some of the underlying technologies, check out the following documentation.&lt;/p&gt;
&lt;h2&gt;Source code&lt;/h2&gt;
&lt;p&gt;Compiler and standard library development happens on the &lt;code&gt;main&lt;/code&gt; branch of the &lt;a href=&quot;https://github.com/apple/swift/tree/main&quot;&gt;apple/swift&lt;/a&gt; repository.&lt;/p&gt;
&lt;p&gt;Additional code repositories that make up the core of the project include:&lt;/p&gt;
&lt;blockquote readability=&quot;6.3476702508961&quot;&gt;
&lt;p&gt;Swift for TensorFlow is &lt;strong&gt;no longer&lt;/strong&gt; a fork of the official Swift language; development was previously done on the &lt;code&gt;tensorflow&lt;/code&gt; branch of the &lt;a href=&quot;https://github.com/apple/swift/tree/tensorflow&quot;&gt;apple/swift&lt;/a&gt; repository. Language additions were designed to fit with the direction of Swift and are going through the &lt;a href=&quot;https://github.com/apple/swift-evolution&quot;&gt;Swift Evolution&lt;/a&gt; process.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;Jupyter Notebook support&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;http://jupyter.org/&quot; rel=&quot;nofollow&quot;&gt;Jupyter Notebook&lt;/a&gt; support for Swift is under development at &lt;a href=&quot;https://github.com/google/swift-jupyter&quot;&gt;google/swift-jupyter&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Model garden&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/tensorflow/swift-models&quot;&gt;tensorflow/swift-models&lt;/a&gt; is a repository of machine learning models built with Swift for TensorFlow. It intended to provide examples of how to use Swift for TensorFlow, to allow for end-to-end tests of machine learning APIs, and to host model benchmarking infrastructure.&lt;/p&gt;
&lt;h3&gt;SwiftAI&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/fastai/swiftai&quot;&gt;fastai/swiftai&lt;/a&gt; is a high-level API for Swift for TensorFlow, modeled after the &lt;a href=&quot;https://github.com/fastai/fastai&quot;&gt;fastai Python library&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Community&lt;/h2&gt;
&lt;p&gt;Swift for TensorFlow discussions happen on the &lt;a href=&quot;https://groups.google.com/a/tensorflow.org/d/forum/swift&quot; rel=&quot;nofollow&quot;&gt;swift@tensorflow.org mailing list&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Bugs reports and feature requests&lt;/h3&gt;
&lt;p&gt;Before reporting an issue, please check the &lt;a href=&quot;https://github.com/tensorflow/swift/blob/main/FAQ.md&quot;&gt;Frequently Asked Questions&lt;/a&gt; to see if your question has already been addressed.&lt;/p&gt;
&lt;p&gt;For questions about general use or feature requests, please send an email to the &lt;a href=&quot;mailto:swift@tensorflow.org&quot;&gt;mailing list&lt;/a&gt; or search for relevant issues in the &lt;a href=&quot;https://bugs.swift.org/projects/TF/issues/?filter=allopenissues&quot; rel=&quot;nofollow&quot;&gt;JIRA issue tracker&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For the most part, the core team's development is also tracked in &lt;a href=&quot;https://bugs.swift.org/secure/RapidBoard.jspa?rapidView=17&amp;amp;projectKey=TF&amp;amp;view=planning&quot; rel=&quot;nofollow&quot;&gt;JIRA&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Contributing&lt;/h3&gt;
&lt;p&gt;We welcome contributions from everyone. Read the &lt;a href=&quot;https://github.com/tensorflow/swift/blob/main/Contributing.md&quot;&gt;contributing guide&lt;/a&gt; for information on how to get started.&lt;/p&gt;
&lt;h3&gt;Code of conduct&lt;/h3&gt;
&lt;p&gt;In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.&lt;/p&gt;
&lt;p&gt;The Swift for TensorFlow community is guided by our &lt;a href=&quot;https://github.com/tensorflow/swift/blob/main/CODE_OF_CONDUCT.md&quot;&gt;Code of Conduct&lt;/a&gt;, which we encourage everybody to read before participating.&lt;/p&gt;
</description>
<pubDate>Fri, 12 Feb 2021 19:21:19 +0000</pubDate>
<dc:creator>high_derivative</dc:creator>
<og:image>https://avatars.githubusercontent.com/u/15658638?s=400&amp;v=4</og:image>
<og:type>object</og:type>
<og:title>tensorflow/swift</og:title>
<og:url>https://github.com/tensorflow/swift</og:url>
<og:description>Swift for TensorFlow. Contribute to tensorflow/swift development by creating an account on GitHub.</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://github.com/tensorflow/swift</dc:identifier>
</item>
<item>
<title>Multiple Beverly Hills PD officers now weaponizing copyright against streaming</title>
<link>https://www.vice.com/en/article/bvxa7q/new-video-shows-beverly-hills-cops-playing-beatles-to-trigger-instagram-copyright-filter</link>
<guid isPermaLink="true" >https://www.vice.com/en/article/bvxa7q/new-video-shows-beverly-hills-cops-playing-beatles-to-trigger-instagram-copyright-filter</guid>
<description>&lt;p&gt;&lt;span class=&quot;abc__textblock size--article&quot; data-component=&quot;TextBlock&quot;&gt;Turns out that Beverly Hills PD isn‚Äôt just into Sublime‚Äîthey also like the Beatles.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;abc__textblock size--article&quot; data-component=&quot;TextBlock&quot;&gt;In a new video that LA area activist Sennett Devermont says was taken on January 16th, we can see Devermont trying to ask Sergeant Billy Fair‚Äînow best known for blasting Sublime at BHPD HQ‚Äîa question. But suddenly, he is interrupted by the mournful voice of Paul McCartney:&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;abc__textblock size--article&quot; data-component=&quot;TextBlock&quot;&gt;&lt;em&gt;Yesterday‚Ä¶ all my troubles seemed so far away‚Ä¶&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;adph adph--border&quot;&gt;
&lt;p&gt;&lt;span&gt;Advertisement&lt;/span&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;p&gt;&lt;span class=&quot;abc__textblock size--article&quot; data-component=&quot;TextBlock&quot;&gt;It‚Äôs the unmistakable opening of The Beatles‚Äô classic ‚ÄúYesterday,‚Äù coming from the cell phone of Officer Julian Reyes, who is standing nearby. Fair points at Reyes‚Äô phone, as if to draw Devermont‚Äôs attention to it, and walks away.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;abc__textblock size--article&quot; data-component=&quot;TextBlock&quot;&gt;Devermont, who is holding a ‚ÄúMedia/Press‚Äù identification badge, then walks up to Reyes, who is still playing music, and tries to ask him a question. But the officer doesn‚Äôt answer‚Äîhe simply stares straight ahead and holds his cell phone pointed towards Devermont, as the Beatles‚Äô ‚ÄúYesterday‚Äù moves into the second verse.&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;abc__textblock size--article&quot; data-component=&quot;TextBlock&quot;&gt;As VICE News reported Tuesday, police in Beverly Hills have &lt;a href=&quot;https://www.vice.com/en/article/bvxb94/is-this-beverly-hills-cop-playing-sublimes-santeria-to-avoid-being-livestreamed&quot;&gt;&lt;span&gt;repeatedly played copyrighted music while being filmed&lt;/span&gt;&lt;/a&gt;, seemingly in an attempt to trigger Instagram's algorithmic copyright filters, which could result in videos of police interactions with the public being taken down. Repeated infractions can result in the suspension of live streamers' accounts.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;abc__textblock size--article&quot; data-component=&quot;TextBlock&quot;&gt;This video is the third that VICE News has seen from Beverly Hills and involves a second police officer, suggesting this is a tactic that is being employed by various officers on the force and was not just an isolated incident. The video also may also shed some light on why BHPD is so adamant about preventing themselves from being filmed.¬†&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;abc__textblock size--article&quot; data-component=&quot;TextBlock&quot;&gt;After getting the silent treatment from the officer playing the music, Devermont walks back over to Fair, who immediately starts complaining.¬†&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;adph adph--border&quot;&gt;
&lt;p&gt;&lt;span&gt;Advertisement&lt;/span&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;p&gt;&lt;span class=&quot;abc__textblock size--article&quot; data-component=&quot;TextBlock&quot;&gt;‚ÄúThere‚Äôs too much pressure when you‚Äôre here,‚Äù he says.¬†&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;abc__textblock size--article&quot; data-component=&quot;TextBlock&quot;&gt;Fair expresses his worry that something he says will be taken out of context, and repeated on the news. He then changes the subject, and this time a bit more cheerfully, asks how many people are watching Devermont‚Äôs feed.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;abc__textblock size--article&quot; data-component=&quot;TextBlock&quot;&gt;Devermont turns his phone around, and allows Fair to have a look at the live stream.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;abc__textblock size--article&quot; data-component=&quot;TextBlock&quot;&gt;‚Äú364?‚Äù he says, after Devermont shows him the number of people watching on the screen. ‚ÄúThat‚Äôs kinda weak‚Äù, he says, looking at Devermont. ‚ÄúI‚Äôve seen bigger crowds for you‚Ä¶ you‚Äôve done better.‚Äù&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;abc__textblock size--article&quot; data-component=&quot;TextBlock&quot;&gt;Less than a month later, the same Fair would blast Sublime at Devermont.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;abc__textblock size--article&quot; data-component=&quot;TextBlock&quot;&gt;This strategy isn‚Äôt entirely surprising. Nick Simmons and Adam Holland, researchers at Lumen Database, which studies copyright takedowns on social media, &lt;a href=&quot;https://www.lumendatabase.org/blog_entries/background-audio-takedowns&quot;&gt;&lt;span&gt;noted last year&lt;/span&gt;&lt;/a&gt; that music in videos filmed at Black Lives Matter protests had repeatedly resulted in them being removed from social media sites on copyright grounds. They theorized that, while these removals seemed incidental, that copyright could be weaponized by police.¬†&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;abc__textblock size--article&quot; data-component=&quot;TextBlock&quot;&gt;&quot;Law enforcement, or indeed anyone of any ideological persuasion who was seeking to prevent videos of a particular event from being shared online, need only make sure that copyrighted audio is present with sufficiently recognizable clarity and volume in the background of a protest or other event,&quot; they wrote. &quot;A chilling prospect indeed.&quot;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;abc__textblock size--article&quot; data-component=&quot;TextBlock&quot;&gt;Now, we're seeing it actually happen.&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Fri, 12 Feb 2021 15:52:20 +0000</pubDate>
<dc:creator>booleanbetrayal</dc:creator>
<og:title>New Video Shows Beverly Hills Cops Playing Beatles to Trigger Instagram Copyright Filter</og:title>
<og:description>In at least three cases, Beverly Hills Cops have started playing music seemingly to prevent themselves from being filmed by an activist.</og:description>
<og:image>https://video-images.vice.com/articles/6025e5da060c7e00959e13dc/lede/1613096463621-screen-shot-2021-02-11-at-92024-pm.png?image-resize-opts=Y3JvcD0xeHc6MC42ODExeGg7MHh3LDAuMjQzNnhoJnJlc2l6ZT0xMjAwOiomcmVzaXplPTEyMDA6Kg</og:image>
<og:type>website</og:type>
<og:url>https://www.vice.com/en/article/bvxa7q/new-video-shows-beverly-hills-cops-playing-beatles-to-trigger-instagram-copyright-filter</og:url>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.vice.com/en/article/bvxa7q/new-video-shows-beverly-hills-cops-playing-beatles-to-trigger-instagram-copyright-filter</dc:identifier>
</item>
<item>
<title>Mathematician Solves Sensitivity Conjecture in Two Pages (2019)</title>
<link>https://www.quantamagazine.org/mathematician-solves-computer-science-conjecture-in-two-pages-20190725/</link>
<guid isPermaLink="true" >https://www.quantamagazine.org/mathematician-solves-computer-science-conjecture-in-two-pages-20190725/</guid>
<description>&lt;p&gt;A &lt;a href=&quot;https://arxiv.org/abs/1907.00847&quot;&gt;paper posted online&lt;/a&gt; this month has settled a nearly 30-year-old conjecture about the structure of the fundamental building blocks of computer circuits. This ‚Äúsensitivity‚Äù conjecture has stumped many of the most prominent computer scientists over the years, yet the new proof is so simple that one researcher summed it up in a &lt;a href=&quot;https://twitter.com/BooleanAnalysis/status/1145837576487612416&quot;&gt;single tweet&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;‚ÄúThis conjecture has stood as one of the most frustrating and embarrassing open problems in all of combinatorics and theoretical computer science,‚Äù wrote &lt;a href=&quot;https://www.cs.utexas.edu/directory/scott-aaronson&quot;&gt;Scott Aaronson&lt;/a&gt; of the University of Texas, Austin, in a &lt;a href=&quot;https://www.scottaaronson.com/blog/?p=4229&quot;&gt;blog post&lt;/a&gt;. ‚ÄúThe list of people who tried to solve it and failed is like a who‚Äôs who of discrete math and theoretical computer science,‚Äù he added in an email.&lt;/p&gt;
&lt;p&gt;The conjecture concerns Boolean functions, rules for transforming a string of input bits (0s and 1s) into a single output bit. One such rule is to output a 1 provided any of the input bits is 1, and a 0 otherwise; another rule is to output a 0 if the string has an even number of 1s, and a 1 otherwise. Every computer circuit is some combination of Boolean functions, making them ‚Äúthe bricks and mortar of whatever you‚Äôre doing in computer science,‚Äù said &lt;a href=&quot;http://www.cs.columbia.edu/~rocco/&quot;&gt;Rocco Servedio&lt;/a&gt; of Columbia University.&lt;/p&gt;

&lt;p&gt;Over the years, computer scientists have developed many ways to measure the complexity of a given Boolean function. Each measure captures a different aspect of how the information in the input string determines the output bit. For instance, the ‚Äúsensitivity‚Äù of a Boolean function tracks, roughly speaking, the likelihood that flipping a single input bit will alter the output bit. And ‚Äúquery complexity‚Äù calculates how many input bits you have to ask about before you can be sure of the output.&lt;/p&gt;
&lt;p&gt;Each measure provides a unique window into the structure of the Boolean function. Yet computer scientists have found that nearly all these measures fit into a unified framework, so that the value of any one of them is a rough gauge for the value of the others. Only one complexity measure didn‚Äôt seem to fit in: sensitivity.&lt;/p&gt;
&lt;p&gt;In 1992, &lt;a href=&quot;http://www.cs.huji.ac.il/~noam/&quot;&gt;Noam Nisan&lt;/a&gt; of the Hebrew University of Jerusalem and &lt;a href=&quot;https://www.cs.rutgers.edu/~szegedy/&quot;&gt;Mario Szegedy&lt;/a&gt;, now of Rutgers University, &lt;a href=&quot;https://dl.acm.org/citation.cfm?id=129757&quot;&gt;conjectured&lt;/a&gt; that sensitivity does indeed fit into this framework. But no one could prove it. ‚ÄúThis, I would say, probably was the outstanding open question in the study of Boolean functions,‚Äù Servedio said.&lt;/p&gt;
&lt;p&gt;‚ÄúPeople wrote long, complicated papers trying to make the tiniest progress,‚Äù said &lt;a href=&quot;http://www.cs.cmu.edu/~odonnell/&quot;&gt;Ryan O‚ÄôDonnell&lt;/a&gt; of Carnegie Mellon University.&lt;/p&gt;
&lt;p&gt;Now &lt;a href=&quot;http://www.math.emory.edu/people/faculty/individual.php?NUM=397&quot;&gt;Hao Huang&lt;/a&gt;, a mathematician at Emory University, has proved the sensitivity conjecture with an ingenious but elementary two-page argument about the combinatorics of points on cubes. ‚ÄúIt is just beautiful, like a precious pearl,‚Äù wrote &lt;a href=&quot;https://www.di.ens.fr/ClaireMathieu.html&quot;&gt;Claire Mathieu&lt;/a&gt;, of the French National Center for Scientific Research, during a Skype interview.&lt;/p&gt;
&lt;p&gt;Aaronson and O‚ÄôDonnell both called Huang‚Äôs paper the ‚Äúbook‚Äù proof of the sensitivity conjecture, referring to &lt;a href=&quot;https://www.quantamagazine.org/gunter-ziegler-and-martin-aigner-seek-gods-perfect-math-proofs-20180319/&quot;&gt;Paul Erd≈ës‚Äô notion&lt;/a&gt; of a celestial book in which God writes the perfect proof of every theorem. ‚ÄúI find it hard to imagine that even God knows how to prove the Sensitivity Conjecture in any simpler way than this,‚Äù Aaronson &lt;a href=&quot;https://www.scottaaronson.com/blog/?p=4229&quot;&gt;wrote&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;A Sensitive Matter&lt;/h2&gt;
&lt;p&gt;Imagine, Mathieu said, that you are filling out a series of yes/no questions on a bank loan application. When you‚Äôre done, the banker will score your results and tell you whether you qualify for a loan. This process is a Boolean function: Your answers are the input bits, and the banker‚Äôs decision is the output bit.&lt;/p&gt;
&lt;p&gt;If your application gets denied, you might wonder whether you could have changed the outcome by lying on a single question ‚Äî perhaps, by claiming that you earn more than $50,000 when you really don‚Äôt. If that lie would have flipped the outcome, computer scientists say that the Boolean function is ‚Äúsensitive‚Äù to the value of that particular bit. If, say, there are seven different lies you could have told that would have each separately flipped the outcome, then for your loan profile, the sensitivity of the Boolean function is seven.&lt;/p&gt;
&lt;p&gt;Computer scientists define the overall sensitivity of the Boolean function as the biggest sensitivity value when looking at all the different possible loan profiles. In some sense, this measure calculates how many of the questions are truly important in the most borderline cases ‚Äî the applications that could most easily have swung the other way if they‚Äôd been ever so slightly different.&lt;/p&gt;

&lt;p&gt;Sensitivity is usually one of the easiest complexity measures to compute, but it‚Äôs far from the only illuminating measure. For instance, instead of handing you a paper application, the banker could have interviewed you, starting with a single question and then using your answer to determine what question to ask next. The largest number of questions the banker would ever need to ask before reaching a decision is the Boolean function‚Äôs query complexity.&lt;/p&gt;
&lt;p&gt;This measure arises in a host of settings ‚Äî for instance, a doctor might want to send a patient for as few tests as possible before reaching a diagnosis, or a machine learning expert might want an algorithm to examine as few features of an object as possible before classifying it. ‚ÄúIn a lot of situations ‚Äî diagnostic situations or learning situations ‚Äî you‚Äôre really happy if the underlying rule ‚Ä¶ has low query complexity,‚Äù O‚ÄôDonnell said.&lt;/p&gt;
&lt;p&gt;Other measures involve looking for the simplest way to write the Boolean function as a mathematical expression, or calculating how many answers the banker would have to show a boss to prove they had made the right loan decision. There‚Äôs even a quantum physics version of query complexity in which the banker can ask a ‚Äúsuperposition‚Äù of several questions at the same time. Figuring out how this measure relates to other complexity measures has helped researchers understand the &lt;a href=&quot;https://www.quantamagazine.org/quantum-computers-struggle-against-classical-algorithms-20180201/&quot;&gt;limitations of quantum algorithms&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;With the single exception of sensitivity, computer scientists proved that all these measures are closely linked. Specifically, they have a polynomial relationship to each other ‚Äî for example, one measure might be roughly the square or cube or square root of another. Only sensitivity stubbornly refused to fit into this neat characterization. Many researchers suspected that it did indeed belong, but they couldn‚Äôt prove that there were no strange Boolean functions out there whose sensitivity had an exponential rather than polynomial relationship to the other measures, which in this setting would mean that the sensitivity measure is vastly smaller than the other measures.&lt;/p&gt;
&lt;p&gt;‚ÄúThis question was a thorn in people‚Äôs sides for 30 years,‚Äù Aaronson said.&lt;/p&gt;
&lt;h2&gt;Cornering the Solution&lt;/h2&gt;
&lt;p&gt;Huang heard about the sensitivity conjecture in late 2012, over lunch with the mathematician &lt;a href=&quot;http://sites.math.rutgers.edu/~saks/&quot;&gt;Michael Saks&lt;/a&gt; at the Institute for Advanced Study, where Huang was a postdoctoral fellow. He was immediately taken with the conjecture‚Äôs simplicity and elegance. ‚ÄúStarting from that moment, I became really obsessed with thinking about it,‚Äù he said.&lt;/p&gt;
&lt;p&gt;Huang added the sensitivity conjecture to a ‚Äúsecret list‚Äù of problems he was interested in, and whenever he learned about a new mathematical tool, he considered whether it might help. ‚ÄúEvery time after I‚Äôd publish a new paper, I would always go back to this problem,‚Äù he said. ‚ÄúOf course, I would give up after a certain amount of time and work on some more realistic problem.‚Äù&lt;/p&gt;

&lt;p&gt;Huang knew, as did the broader research community, that the sensitivity conjecture could be settled if mathematicians could prove an easily stated conjecture about collections of points on cubes of different dimensions. There‚Äôs a natural way to go from a string of &lt;em&gt;n&lt;/em&gt; 0s and 1s to a point on an &lt;em&gt;n&lt;/em&gt;-dimensional cube: Simply use the &lt;em&gt;n&lt;/em&gt; bits as the coordinates of the point.&lt;/p&gt;
&lt;p&gt;For instance, the four two-bit strings ‚Äî 00, 01, 10 and 11 ‚Äî correspond to the four corners of a square in the two-dimensional plane: (0,0), (0,1), (1,0) and (1,1).¬† Likewise, the eight three-bit strings correspond to the eight corners of a three-dimensional cube, and so on in higher dimensions. A Boolean function, in turn, can be thought of as a rule for coloring these corners with two different colors (say, red for 0 and blue for 1).&lt;/p&gt;
&lt;p&gt;In 1992, &lt;a href=&quot;http://www.cs.technion.ac.il/~gotsman/&quot;&gt;Craig Gotsman&lt;/a&gt;, now of the New Jersey Institute of Technology, and &lt;a href=&quot;http://www.cs.huji.ac.il/~nati/&quot;&gt;Nati Linial&lt;/a&gt; of Hebrew University &lt;a href=&quot;https://dl.acm.org/citation.cfm?id=158788&quot;&gt;figured out&lt;/a&gt; that proving the sensitivity conjecture can be reduced to answering a simple question about cubes of different dimensions: If you choose any collection of more than half the corners of a cube and color them red, is there always some red point that is connected to many other red points? (Here, by ‚Äúconnected,‚Äù we mean that the two points share one of the outer edges of the cube, as opposed to being across a diagonal.)&lt;/p&gt;

&lt;p&gt;If your collection contains exactly half the corners of the cube, it‚Äôs possible that none of them will be connected. For example, among the eight corners of the three-dimensional cube, the four points (0,0,0), (1,1,0), (1,0,1) and (0,1,1) all sit across diagonals from one another. But as soon as more than half the points in a cube of any dimension are colored red, some connections between red points must pop up. The question is: How are these connections distributed? Will there be at least one highly connected point?&lt;/p&gt;
&lt;p&gt;In 2013, Huang started thinking that the best route to understanding this question might be through the standard method of representing a network with a matrix that tracks which points are connected and then examining a set of numbers called the matrix‚Äôs eigenvalues. For five years he kept revisiting this idea, without success. ‚ÄúBut at least thinking about it [helped] me quickly fall asleep many nights,‚Äù he &lt;a href=&quot;https://www.scottaaronson.com/blog/?p=4229#comment-1813116&quot;&gt;commented&lt;/a&gt; on Aaronson‚Äôs blog post.&lt;/p&gt;
&lt;p&gt;Then in 2018, it occurred to Huang to use a 200-year-old piece of mathematics called the Cauchy interlace theorem, which relates a matrix‚Äôs eigenvalues to those of a submatrix, making it potentially the perfect tool to study the relationship between a cube and a subset of its corners. Huang decided to request a grant from the National Science Foundation to explore this idea further.&lt;/p&gt;
&lt;p&gt;Then last month, as he sat in a Madrid hotel writing his grant proposal, he suddenly realized that he could push this approach all the way to fruition simply by switching the signs of some of the numbers in his matrix. In this way, he was able to prove that in any collection of more than half the points in an &lt;em&gt;n&lt;/em&gt;-dimensional cube, there will be some point that is connected to at least $latex \sqrt{n}$ of the other points ‚Äî and the sensitivity conjecture instantly followed from this result.&lt;/p&gt;
&lt;p&gt;When Huang‚Äôs paper landed in Mathieu‚Äôs inbox, her first reaction was ‚Äúuh-oh,‚Äù she said. ‚ÄúWhen a problem has been around 30 years and everybody has heard about it, probably the proof is either very long and tedious and complicated, or it‚Äôs very deep.‚Äù She opened the paper expecting to understand nothing.&lt;/p&gt;

&lt;p&gt;But the proof was simple enough for Mathieu and many other researchers to digest in one sitting. ‚ÄúI expect that this fall it will be taught ‚Äî in a single lecture ‚Äî in every master‚Äôs-level combinatorics course,‚Äù she messaged over Skype.&lt;/p&gt;
&lt;p&gt;Huang‚Äôs result is even stronger than necessary to prove the sensitivity conjecture, and this power should yield new insights about complexity measures. ‚ÄúIt adds to our toolkit for maybe trying to answer other questions in the analysis of Boolean functions,‚Äù Servedio said.&lt;/p&gt;
&lt;p&gt;Most importantly, though, Huang‚Äôs result lays to rest nagging worries about whether sensitivity might be some strange outlier in the world of complexity measures, Servedio said. ‚ÄúI think a lot of people slept easier that night, after hearing about this.‚Äù&lt;/p&gt;
&lt;p class=&quot;p1&quot;&gt;&lt;span class=&quot;s1&quot;&gt;&lt;em&gt;This article was reprinted on¬†&lt;/em&gt;&lt;a href=&quot;https://www.wired.com/story/a-decades-old-computer-science-puzzle-was-solved-in-two-pages/&quot;&gt;&lt;em&gt;Wired.com&lt;/em&gt;&lt;/a&gt;&lt;em&gt;.&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Fri, 12 Feb 2021 15:45:00 +0000</pubDate>
<dc:creator>kjhughes</dc:creator>
<og:type>article</og:type>
<og:title>Decades-Old Computer Science Conjecture Solved in Two Pages</og:title>
<og:description>The &quot;sensitivity&quot; conjecture stumped many top computer scientists, yet the new proof is so simple that one researcher summed it up in a single tweet.</og:description>
<og:url>https://www.quantamagazine.org/mathematician-solves-computer-science-conjecture-in-two-pages-20190725/</og:url>
<og:image>https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/07/Boolean-Sensitivity_1200_social.jpg</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.quantamagazine.org/mathematician-solves-computer-science-conjecture-in-two-pages-20190725/</dc:identifier>
</item>
<item>
<title>‚ÄúI saw that you spun up an Ubuntu image in Azure‚Äù</title>
<link>https://twitter.com/LucaBongiorni/status/1359560585990537216</link>
<guid isPermaLink="true" >https://twitter.com/LucaBongiorni/status/1359560585990537216</guid>
<description>[unable to retrieve full-text content]
&lt;p&gt;Article URL: &lt;a href=&quot;https://twitter.com/LucaBongiorni/status/1359560585990537216&quot;&gt;https://twitter.com/LucaBongiorni/status/1359560585990537216&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Comments URL: &lt;a href=&quot;https://news.ycombinator.com/item?id=26114194&quot;&gt;https://news.ycombinator.com/item?id=26114194&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Points: 957&lt;/p&gt;
&lt;p&gt;# Comments: 387&lt;/p&gt;
</description>
<pubDate>Fri, 12 Feb 2021 14:51:09 +0000</pubDate>
<dc:creator>fireball_blaze</dc:creator>
<og:type>article</og:type>
<og:title>Decades-Old Computer Science Conjecture Solved in Two Pages</og:title>
<og:description>The &quot;sensitivity&quot; conjecture stumped many top computer scientists, yet the new proof is so simple that one researcher summed it up in a single tweet.</og:description>
<og:url>https://www.quantamagazine.org/mathematician-solves-computer-science-conjecture-in-two-pages-20190725/</og:url>
<og:image>https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/07/Boolean-Sensitivity_1200_social.jpg</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.quantamagazine.org/mathematician-solves-computer-science-conjecture-in-two-pages-20190725/</dc:identifier>
</item>
<item>
<title>Self-organising textures from cellular automata</title>
<link>https://distill.pub/selforg/2021/textures/</link>
<guid isPermaLink="true" >https://distill.pub/selforg/2021/textures/</guid>
<description>&lt;head&gt;&lt;meta charset=&quot;utf-8&quot;/&gt;&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1&quot;/&gt;&lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=Edge,chrome=1&quot;/&gt;&lt;link rel=&quot;stylesheet&quot; href=&quot;https://distill.pub/third-party/katex/katex.min.css&quot; crossorigin=&quot;anonymous&quot; type=&quot;text/css&quot;/&gt;&lt;link rel=&quot;icon&quot; type=&quot;image/png&quot; href=&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAYAAACqaXHeAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA99JREFUeNrsG4t1ozDMzQSM4A2ODUonKBucN2hugtIJ6E1AboLcBiQTkJsANiAb9OCd/OpzMWBJBl5TvaeXPiiyJetry0J8wW3D3QpjRh3GjneXDq+fSQA9s2mH9x3KDhN4foJfCb8N/Jrv+2fnDn8vLRQOplWHVYdvHZYdZsBcZP1vBmh/n8DzEmhUQDPaOuP9pFuY+JwJHwHnCLQE2tnWBGEyXozY9xCUgHMhhjE2I4heVWtgIkZ83wL6Qgxj1obfWBxymPwe+b00BCCRNPbwfb60yleAkkBHGT5AEehIYz7eJrFDMF9CvH4wwhcGHiHMneFvLDQwlwvMLQq58trRcYBWfYn0A0OgHWQUSu25mE+BnoYKnnEJoeIWAifzOv7vLWd2ZKRfWAIme3tOiUaQ3UnLkb0xj1FxRIeEGKaGIHOs9nEgLaaA9i0JRYo1Ic67wJW86KSKE/ZAM8KuVMk8ITVhmxUxJ3Cl2xlm9Vtkeju1+mpCQNxaEGNCY8bs9X2YqwNoQeGjBWut/ma0QAWy/TqAsHx9wSya3I5IRxOfTC+leG+kA/4vSeEcGBtNUN6byhu3+keEZCQJUNh8MAO7HL6H8pQLnsW/Hd4T4lv93TPjfM7A46iEEqbB5EDOvwYNW6tGNZzT/o+CZ6sqZ6wUtR/wf7mi/VL8iNciT6rHih48Y55b4nKCHJCCzb4y0nwFmin3ZEMIoLfZF8F7nncFmvnWBaBj7CGAYA/WGJsUwHdYqVDwAmNsUgAx4CGgAA7GOOxADYOFWOaIKifuVYzmOpREqA21Mo7aPsgiY1PhOMAmxtR+AUbYH3Id2wc0SAFIQTsn9IUGWR8k9jx3vtXSiAacFxTAGakBk9UudkNECd6jLe+6HrshshvIuC6IlLMRy7er+JpcKma24SlE4cFZSZJDGVVrsNvitQhQrDhW0jfiOLfFd47C42eHT56D/BK0To+58Ahj+cAT8HT1UWlfLZCCd/uKawzU0Rh2EyIX/Icqth3niG8ybNroezwe6khdCNxRN+l4XGdOLVLlOOt2hTRJlr1ETIuMAltVTMz70mJrkdGAaZLSmnBEqmAE32JCMmuTlCnRgsBENtOUpHhvvsYIL0ibnBkaC6QvKcR7738GKp0AKnim7xgUSNv1bpS8QwhBt8r+EP47v/oyRK/S34yJ9nT+AN0Tkm4OdB9E4BsmXM3SnMlRFUrtp6IDpV2eKzdYvF3etm3KhQksbOLChGkSmcBdmcEwvqkrMy5BzL00NZeu3qPYJOOuCc+5NjcWKXQxFvTa3NoXJ4d8in7fiAUuTt781dkvuHX4K8AA2Usy7yNKLy0AAAAASUVORK5CYII=&quot;/&gt;&lt;link href=&quot;/rss.xml&quot; rel=&quot;alternate&quot; type=&quot;application/rss+xml&quot; title=&quot;Articles from Distill&quot;/&gt;&lt;title&gt;Self-Organising Textures&lt;/title&gt;&lt;link rel=&quot;canonical&quot; href=&quot;https://distill.pub/selforg/2021/textures&quot;/&gt;&lt;meta property=&quot;description&quot; itemprop=&quot;description&quot; content=&quot;Neural Cellular Automata learn to generate textures, exhibiting surprising properties.&quot;/&gt;&lt;meta property=&quot;article:published&quot; itemprop=&quot;datePublished&quot; content=&quot;2021-02-11&quot;/&gt;&lt;meta property=&quot;article:created&quot; itemprop=&quot;dateCreated&quot; content=&quot;2021-02-11&quot;/&gt;&lt;meta property=&quot;article:modified&quot; itemprop=&quot;dateModified&quot; content=&quot;2021-02-11T20:55:01.000Z&quot;/&gt;&lt;meta property=&quot;article:author&quot; content=&quot;Eyvind Niklasson&quot;/&gt;&lt;meta property=&quot;article:author&quot; content=&quot;Alexander Mordvintsev&quot;/&gt;&lt;meta property=&quot;article:author&quot; content=&quot;Ettore Randazzo&quot;/&gt;&lt;meta property=&quot;article:author&quot; content=&quot;Michael Levin&quot;/&gt;&lt;meta property=&quot;og:type&quot; content=&quot;article&quot;/&gt;&lt;meta property=&quot;og:title&quot; content=&quot;Self-Organising Textures&quot;/&gt;&lt;meta property=&quot;og:description&quot; content=&quot;Neural Cellular Automata learn to generate textures, exhibiting surprising properties.&quot;/&gt;&lt;meta property=&quot;og:url&quot; content=&quot;https://distill.pub/selforg/2021/textures&quot;/&gt;&lt;meta property=&quot;og:image&quot; content=&quot;https://distill.pub/selforg/2021/textures/thumbnail.jpg&quot;/&gt;&lt;meta property=&quot;og:locale&quot; content=&quot;en_US&quot;/&gt;&lt;meta property=&quot;og:site_name&quot; content=&quot;Distill&quot;/&gt;&lt;meta name=&quot;twitter:card&quot; content=&quot;summary_large_image&quot;/&gt;&lt;meta name=&quot;twitter:title&quot; content=&quot;Self-Organising Textures&quot;/&gt;&lt;meta name=&quot;twitter:description&quot; content=&quot;Neural Cellular Automata learn to generate textures, exhibiting surprising properties.&quot;/&gt;&lt;meta name=&quot;twitter:url&quot; content=&quot;https://distill.pub/selforg/2021/textures&quot;/&gt;&lt;meta name=&quot;twitter:image&quot; content=&quot;https://distill.pub/selforg/2021/textures/thumbnail.jpg&quot;/&gt;&lt;meta name=&quot;twitter:image:width&quot; content=&quot;560&quot;/&gt;&lt;meta name=&quot;twitter:image:height&quot; content=&quot;295&quot;/&gt;&lt;meta name=&quot;citation_title&quot; content=&quot;Self-Organising Textures&quot;/&gt;&lt;meta name=&quot;citation_fulltext_html_url&quot; content=&quot;https://distill.pub/selforg/2021/textures&quot;/&gt;&lt;meta name=&quot;citation_volume&quot; content=&quot;6&quot;/&gt;&lt;meta name=&quot;citation_issue&quot; content=&quot;2&quot;/&gt;&lt;meta name=&quot;citation_firstpage&quot; content=&quot;e00027.003&quot;/&gt;&lt;meta name=&quot;citation_doi&quot; content=&quot;10.23915/distill.00027.003&quot;/&gt;&lt;meta name=&quot;citation_journal_title&quot; content=&quot;Distill&quot;/&gt;&lt;meta name=&quot;citation_journal_abbrev&quot; content=&quot;Distill&quot;/&gt;&lt;meta name=&quot;citation_issn&quot; content=&quot;2476-0757&quot;/&gt;&lt;meta name=&quot;citation_fulltext_world_readable&quot; content=&quot;&quot;/&gt;&lt;meta name=&quot;citation_online_date&quot; content=&quot;2021/02/11&quot;/&gt;&lt;meta name=&quot;citation_publication_date&quot; content=&quot;2021/02/11&quot;/&gt;&lt;meta name=&quot;citation_author&quot; content=&quot;Niklasson, Eyvind&quot;/&gt;&lt;meta name=&quot;citation_author_institution&quot; content=&quot;Google&quot;/&gt;&lt;meta name=&quot;citation_author&quot; content=&quot;Mordvintsev, Alexander&quot;/&gt;&lt;meta name=&quot;citation_author_institution&quot; content=&quot;Google&quot;/&gt;&lt;meta name=&quot;citation_author&quot; content=&quot;Randazzo, Ettore&quot;/&gt;&lt;meta name=&quot;citation_author_institution&quot; content=&quot;Google&quot;/&gt;&lt;meta name=&quot;citation_author&quot; content=&quot;Levin, Michael&quot;/&gt;&lt;meta name=&quot;citation_author_institution&quot; content=&quot;Tufts&quot;/&gt;&lt;meta name=&quot;citation_reference&quot; content=&quot;citation_title=Growing Neural Cellular Automata;citation_author=Alexander Mordvintsev;citation_author=Ettore Randazzo;citation_author=Eyvind Niklasson;citation_author=Michael Levin;citation_publication_date=2020;citation_journal_title=Distill;citation_volume=5;citation_number=2;&quot;/&gt;&lt;meta name=&quot;citation_reference&quot; content=&quot;citation_title=Image segmentation via Cellular Automata;citation_author=Mark Sandler;citation_author=Andrey Zhmoginov;citation_author=Liangcheng Luo;citation_author=Alexander Mordvintsev;citation_author=Ettore Randazzo;citation_author=Blaise Ag√∫era y. Arcas;citation_publication_date=2020;citation_arxiv_id=2008.04965;&quot;/&gt;&lt;meta name=&quot;citation_reference&quot; content=&quot;citation_title=Self-classifying MNIST Digits;citation_author=Ettore Randazzo;citation_author=Alexander Mordvintsev;citation_author=Eyvind Niklasson;citation_author=Michael Levin;citation_author=Sam Greydanus;citation_publication_date=2020;citation_journal_title=Distill;citation_volume=5;citation_number=8;&quot;/&gt;&lt;meta name=&quot;citation_reference&quot; content=&quot;citation_title=Differentiable Image Parameterizations;citation_author=Alexander Mordvintsev;citation_author=Nicola Pezzotti;citation_author=Ludwig Schubert;citation_author=Chris Olah;citation_publication_date=2018;citation_journal_title=Distill;citation_volume=3;citation_number=7;&quot;/&gt;&lt;meta name=&quot;citation_reference&quot; content=&quot;citation_title=The chemical basis of morphogenesis;citation_author=Alan Mathison Turing;citation_publication_date=1952;citation_journal_title=Philosophical transactions of the Royal Society of London. Series B, Biological sciences;citation_volume=237;citation_number=641;&quot;/&gt;&lt;meta name=&quot;citation_reference&quot; content=&quot;citation_title=Turing patterns in development: what about the horse part?;citation_author=Luciano Marcon;citation_author=James Sharpe;citation_publication_date=2012;citation_journal_title=Current opinion in genetics &amp;amp;amp; development;citation_volume=22;citation_number=6;&quot;/&gt;&lt;meta name=&quot;citation_reference&quot; content=&quot;citation_title=A unified design space of synthetic stripe-forming networks;citation_author=Yolanda Schaerli;citation_author=Andreea Munteanu;citation_author=Mag√ºi Gili;citation_author=James Cotterell;citation_author=James Sharpe;citation_author=Mark Isalan;citation_publication_date=2014;citation_journal_title=Nature communications;citation_volume=5;&quot;/&gt;&lt;meta name=&quot;citation_reference&quot; content=&quot;citation_title=On the Formation of Digits and Joints during Limb Development;citation_author=Tom W. Hiscock;citation_author=Patrick Tschopp;citation_author=Clifford J. Tabin;citation_publication_date=2017;citation_journal_title=Developmental cell;citation_volume=41;citation_number=5;&quot;/&gt;&lt;meta name=&quot;citation_reference&quot; content=&quot;citation_title=Modeling digits. Digit patterning is controlled by a Bmp-Sox9-Wnt Turing network modulated by morphogen gradients;citation_author=J. Raspopovic;citation_author=L. Marcon;citation_author=L. Russo;citation_author=J. Sharpe;citation_publication_date=2014;citation_journal_title=Science;citation_volume=345;citation_number=6196;&quot;/&gt;&lt;meta name=&quot;citation_reference&quot; content=&quot;citation_title=Pattern formation mechanisms of self-organizing reaction-diffusion systems;citation_author=Amit N. Landge;citation_author=Benjamin M. Jordan;citation_author=Xavier Diego;citation_author=Patrick M√ºller;citation_publication_date=2020;citation_journal_title=Developmental biology;citation_volume=460;citation_number=1;&quot;/&gt;&lt;meta name=&quot;citation_reference&quot; content=&quot;citation_title=Bioelectric gene and reaction networks: computational modelling of genetic, biochemical and bioelectrical dynamics in pattern regulation;citation_author=Alexis Pietak;citation_author=Michael Levin;citation_publication_date=2017;citation_journal_title=Journal of the Royal Society, Interface / the Royal Society;citation_volume=14;citation_number=134;&quot;/&gt;&lt;meta name=&quot;citation_reference&quot; content=&quot;citation_title=Turing-like patterns can arise from purely bioelectric mechanisms;citation_author=Micah Brodsky;citation_journal_title=Draft;&quot;/&gt;&lt;meta name=&quot;citation_reference&quot; content=&quot;citation_title=Dissipative structures in biological systems: bistability, oscillations, spatial patterns and waves;citation_author=Albert Goldbeter;citation_publication_date=2018;citation_journal_title=Philosophical transactions. Series A, Mathematical, physical, and engineering sciences;citation_volume=376;citation_number=2124;&quot;/&gt;&lt;meta name=&quot;citation_reference&quot; content=&quot;citation_title=Gene networks and liar paradoxes;citation_author=Mark Isalan;citation_publication_date=2009;citation_journal_title=BioEssays: news and reviews in molecular, cellular and developmental biology;citation_volume=31;citation_number=10;&quot;/&gt;&lt;meta name=&quot;citation_reference&quot; content=&quot;citation_title=Texture Synthesis Using Convolutional Neural Networks;citation_author=Leon A. Gatys;citation_author=Alexander S. Ecker;citation_author=Matthias Bethge;citation_publication_date=2015;citation_arxiv_id=1505.07376;&quot;/&gt;&lt;meta name=&quot;citation_reference&quot; content=&quot;citation_title=The chemical basis of morphogenesis. 1953;citation_author=A. M. Turing;citation_publication_date=1990;citation_journal_title=Bulletin of mathematical biology;citation_volume=52;citation_number=1-2;&quot;/&gt;&lt;meta name=&quot;citation_reference&quot; content=&quot;citation_title=Pattern formation by interacting chemical fronts;citation_author=K. J. Lee;citation_author=W. D. McCormick;citation_author=Q. Ouyang;citation_author=H. L. Swinney;citation_publication_date=1993;citation_journal_title=Science;citation_volume=261;citation_number=5118;&quot;/&gt;&lt;meta name=&quot;citation_reference&quot; content=&quot;citation_title=Complex patterns in a simple system;citation_author=J. E. Pearson;citation_publication_date=1993;citation_journal_title=Science;citation_volume=261;citation_number=5118;&quot;/&gt;&lt;meta name=&quot;citation_reference&quot; content=&quot;citation_title=Very Deep Convolutional Networks for Large-Scale Image Recognition;citation_author=Karen Simonyan;citation_author=Andrew Zisserman;citation_publication_date=2014;citation_arxiv_id=1409.1556;&quot;/&gt;&lt;meta name=&quot;citation_reference&quot; content=&quot;citation_title=Adam: A Method for Stochastic Optimization;citation_author=Diederik P. Kingma;citation_author=Jimmy Ba;citation_publication_date=2014;citation_arxiv_id=1412.6980;&quot;/&gt;&lt;meta name=&quot;citation_reference&quot; content=&quot;citation_title=Describing Textures in the Wild;citation_author=Mircea Cimpoi;citation_author=Subhransu Maji;citation_author=Iasonas Kokkinos;citation_author=Sammy Mohamed;citation_author=Andrea Vedaldi;citation_publication_date=2013;citation_arxiv_id=1311.3618;&quot;/&gt;&lt;meta name=&quot;citation_reference&quot; content=&quot;citation_title=The texture lexicon: Understanding the categorization of visual texture terms and their relationship to texture images;citation_author=Nalini Bhushan;citation_author=A. Ravishankar Rao;citation_author=Gerald L. Lohse;citation_publication_date=1997;citation_journal_title=Cognitive science;citation_volume=21;citation_number=2;&quot;/&gt;&lt;meta name=&quot;citation_reference&quot; content=&quot;citation_title=Re-membering the body: applications of computational neuroscience to the top-down control of regeneration of limbs and other complex organs;citation_author=G. Pezzulo;citation_author=M. Levin;citation_publication_date=2015;citation_journal_title=Integrative biology: quantitative biosciences from nano to macro;citation_volume=7;citation_number=12;&quot;/&gt;&lt;meta name=&quot;citation_reference&quot; content=&quot;citation_title=Embryonic Development and Induction;citation_author=Hans Speman;citation_publication_date=1938;citation_journal_title=The American Journal of the Medical Sciences;citation_volume=196;citation_number=5;&quot;/&gt;&lt;meta name=&quot;citation_reference&quot; content=&quot;citation_title=Communication, Memory, and Development;citation_author=Stephen Grossberg;citation_publication_date=1978;&quot;/&gt;&lt;meta name=&quot;citation_reference&quot; content=&quot;citation_title=WaveFunctionCollapse;citation_author=Maxim Gumin;&quot;/&gt;&lt;meta name=&quot;citation_reference&quot; content=&quot;citation_title=Texture Networks: Feed-forward Synthesis of Textures and Stylized Images;citation_author=Dmitry Ulyanov;citation_author=Vadim Lebedev;citation_author=Andrea Vedaldi;citation_author=Victor Lempitsky;citation_publication_date=2016;citation_arxiv_id=1603.03417;&quot;/&gt;&lt;meta name=&quot;citation_reference&quot; content=&quot;citation_title=TextureGAN: Controlling deep image synthesis with texture patches;citation_author=Wenqi Xian;citation_author=Patsorn Sangkloy;citation_author=Varun Agrawal;citation_author=Amit Raj;citation_author=Jingwan Lu;citation_author=Chen Fang;citation_author=Fisher Yu;citation_author=James Hays;citation_publication_date=2018;&quot;/&gt;&lt;meta name=&quot;citation_reference&quot; content=&quot;citation_title=Interactive evolution of camouflage;citation_author=Craig Reynolds;citation_publication_date=2011;citation_journal_title=Artificial life;citation_volume=17;citation_number=2;&quot;/&gt;&lt;meta name=&quot;citation_reference&quot; content=&quot;citation_title=A parametric texture model based on joint statistics of complex wavelet coefficients;citation_author=Javier Portilla;citation_author=Eero P. Simoncelli;citation_publication_date=2000;&quot;/&gt;&lt;meta name=&quot;citation_reference&quot; content=&quot;citation_title=Trainable Nonlinear Reaction Diffusion: A Flexible Framework for Fast and Effective Image Restoration;citation_author=Yunjin Chen;citation_author=Thomas Pock;citation_publication_date=2017;citation_journal_title=IEEE transactions on pattern analysis and machine intelligence;citation_volume=39;citation_number=6;&quot;/&gt;&lt;meta name=&quot;citation_reference&quot; content=&quot;citation_title=The evolutionary significance of butterfly eyespots;citation_author=Ullasa Kodandaramaiah;citation_publication_date=2011;citation_journal_title=Behavioral ecology: official journal of the International Society for Behavioral Ecology;citation_volume=22;citation_number=6;&quot;/&gt;&lt;meta name=&quot;citation_reference&quot; content=&quot;citation_title=Live Cell Imaging of Butterfly Pupal and Larval Wings In Vivo;citation_author=Yoshikazu Ohno;citation_author=Joji M. Otaki;citation_publication_date=2015;citation_journal_title=PloS one;citation_volume=10;citation_number=6;&quot;/&gt;&lt;meta name=&quot;citation_reference&quot; content=&quot;citation_title=Focusing on butterfly eyespot focus: uncoupling of white spots from eyespot bodies in nymphalid butterflies;citation_author=Masaki Iwata;citation_author=Joji M. Otaki;citation_publication_date=2016;citation_journal_title=SpringerPlus;citation_volume=5;citation_number=1;&quot;/&gt;&lt;meta name=&quot;citation_reference&quot; content=&quot;citation_title=OpenAI Microscope;citation_author=Ludwig Schubert;citation_author=Michael Petrov;citation_author=Shan Carter;citation_author=Nick Cammarata;citation_author=Gabriel Goh;citation_author=Chris Olah;citation_publication_date=2020;&quot;/&gt;&lt;meta name=&quot;citation_reference&quot; content=&quot;citation_title=The neural origins of shell structure and pattern in aquatic mollusks;citation_author=Alistair Boettiger;citation_author=Bard Ermentrout;citation_author=George Oster;citation_publication_date=2009;citation_journal_title=Proceedings of the National Academy of Sciences of the United States of America;citation_volume=106;citation_number=16;&quot;/&gt;&lt;meta name=&quot;citation_reference&quot; content=&quot;citation_title=Emergent complexity in simple neural systems;citation_author=Alistair N. Boettiger;citation_author=George Oster;citation_publication_date=2009;citation_journal_title=Communicative &amp;amp;amp; integrative biology;citation_volume=2;citation_number=6;&quot;/&gt;&lt;meta name=&quot;citation_reference&quot; content=&quot;citation_title=Going deeper with convolutions;citation_author=Christian Szegedy;citation_author=Wei Liu;citation_author=Yangqing Jia;citation_author=Pierre Sermanet;citation_author=Scott Reed;citation_author=Dragomir Anguelov;citation_author=Dumitru Erhan;citation_author=Vincent Vanhoucke;citation_author=Andrew Rabinovich;citation_publication_date=2015;citation_arxiv_id=1409.4842;&quot;/&gt;&lt;meta name=&quot;citation_reference&quot; content=&quot;citation_title=Stable and Controllable Neural Texture Synthesis and Style Transfer Using Histogram Losses;citation_author=Eric Risser;citation_author=Pierre Wilmot;citation_author=Connelly Barnes;citation_publication_date=2017;citation_arxiv_id=1701.08893;&quot;/&gt;&lt;meta name=&quot;citation_reference&quot; content=&quot;citation_title=Stem cell migration and mechanotransduction on linear stiffness gradient hydrogels;citation_author=William J. Hadden;citation_author=Jennifer L. Young;citation_author=Andrew W. Holle;citation_author=Meg L. McFetridge;citation_author=Du Yong Kim;citation_author=Philip Wijesinghe;citation_author=Hermes Taylor-Weiner;citation_author=Jessica H. Wen;citation_author=Andrew R. Lee;citation_author=Karen Bieback;citation_author=et al.;citation_publication_date=2017;citation_journal_title=Proceedings of the National Academy of Sciences of the United States of America;citation_volume=114;citation_number=22;&quot;/&gt;&lt;/head&gt;&lt;body distill-prerendered=&quot;&quot; id=&quot;readabilityBody&quot; readability=&quot;725.40238562585&quot;&gt;


&lt;p&gt;Neural Cellular Automata Model of Pattern Formation&lt;/p&gt;
&lt;div class=&quot;l-body-outset grid&quot; id=&quot;demo&quot;&gt;

&lt;div id=&quot;pattern-controls&quot;&gt;
&lt;p&gt;&lt;span&gt;Textures&lt;/span&gt;&lt;/p&gt;



&lt;p&gt;&lt;span&gt;Inception&lt;/span&gt;&lt;/p&gt;





&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;byline grid&quot; readability=&quot;2.5263157894737&quot;&gt;

&lt;div&gt;
&lt;h3&gt;Published&lt;/h3&gt;
&lt;p&gt;Feb. 11, 2021&lt;/p&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;nav class=&quot;l-text toc figcaption&quot;&gt;&lt;h3&gt;Contents&lt;/h3&gt;




&lt;/nav&gt;&lt;section id=&quot;thread-nav&quot; class=&quot;thread-info&quot; readability=&quot;4.4846416382253&quot;&gt;&lt;img class=&quot;thread-icon&quot; src=&quot;https://distill.pub/selforg/2021/textures/images/multiple-pages.svg&quot; width=&quot;43px&quot; height=&quot;50px&quot;/&gt;&lt;p class=&quot;explanation&quot;&gt;This article is part of the &lt;a href=&quot;https://distill.pub/2020/selforg/&quot;&gt;Differentiable Self-organizing Systems Thread&lt;/a&gt;, an experimental format collecting invited short articles delving into differentiable self-organizing systems, interspersed with critical commentary from several experts in adjacent fields.&lt;/p&gt;
&lt;a class=&quot;prev&quot; href=&quot;https://distill.pub/2020/selforg/mnist/&quot;&gt;Self-classifying MNIST Digits&lt;/a&gt;&lt;/section&gt;&lt;p&gt;Neural Cellular Automata (NCA We use NCA to refer to both &lt;em&gt;Neural Cellular Automata&lt;/em&gt; and &lt;em&gt;Neural Cellular Automaton&lt;/em&gt;.) are capable of learning a diverse set of behaviours: from generating stable, regenerating, static images , to segmenting images , to learning to ‚Äúself-classify‚Äù shapes . The inductive bias imposed by using cellular automata is powerful. A system of individual agents running the same learned local rule can solve surprisingly complex tasks. Moreover, individual agents, or cells, can learn to coordinate their behavior even when separated by large distances. By construction, they solve these tasks in a massively parallel and inherently degenerate Degenerate in this case refers to the &lt;a href=&quot;https://en.wikipedia.org/wiki/Degeneracy_(biology)&quot;&gt;biological concept of degeneracy&lt;/a&gt;. way. Each cell must be able to take on the role of any other cell - as a result they tend to generalize well to unseen situations.&lt;/p&gt;
&lt;p&gt;In this work, we apply NCA to the task of texture synthesis. This task involves reproducing the general appearance of a texture template, as opposed to making pixel-perfect copies. We are going to focus on texture losses that allow for a degree of ambiguity. After training NCA models to reproduce textures, we subsequently investigate their learned behaviors and observe a few surprising effects. Starting from these investigations, we make the case that the cells learn distributed, local, algorithms.&lt;/p&gt;
&lt;p&gt;To do this, we apply an old trick: we employ neural cellular automata as a differentiable image parameterization .&lt;/p&gt;
&lt;h2 id=&quot;patterns-textures-and-physical-processes&quot;&gt;Patterns, textures and physical processes&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://distill.pub/selforg/2021/textures/images/zebra.jpg&quot;/&gt; A pair of Zebra. Zebra are said to have unique stripes.&lt;/p&gt;
&lt;p&gt;Zebra stripes are an iconic texture. Ask almost anyone to identify zebra stripes in a set of images, and they will have no trouble doing so. Ask them to describe what zebra stripes look like, and they will gladly tell you that they are parallel stripes of slightly varying width, alternating in black and white. And yet, they may also tell you that no two zebra have the same set of stripes Perhaps an apocryphal claim, but at the very lowest level every zebra will be unique. Ourp point is - ‚Äúzebra stripes‚Äù as a concept in human understanding refers to the general structure of a black and white striped pattern and not to a specific mapping from location to colour.. This is because evolution has programmed the cells responsible for creating the zebra pattern to generate a pattern of a certain quality, with certain characteristics, as opposed to programming them with the blueprints for an exact bitmap of the edges and locations of stripes to be moulded to the surface of the zebra‚Äôs body.&lt;/p&gt;
&lt;p&gt;Put another way, patterns and textures are ill-defined concepts. The Cambridge English Dictionary defines a pattern as ‚Äúany regularly repeated arrangement, especially a design made from repeated lines, shapes, or colours on a surface‚Äù. This definition falls apart rather quickly when looking at patterns and textures that impart a feeling or quality, rather than a specific repeating property. A coloured fuzzy rug, for instance, can be considered a pattern or a texture, but is composed of strands pointing in random directions with small random variations in size and color, and there is no discernable regularity to the pattern. Penrose tilings do not repeat (they are not translationally invariant), but show them to anyone and they‚Äôll describe them as a pattern or a texture. Most patterns in nature are outputs of locally interacting processes that may or may not be stochastic in nature, but are often based on fairly simple rules. There is a large body of work on models which give rise to such patterns in nature; most of it is inspired by Turing‚Äôs seminal paper on morphogenesis.&lt;/p&gt;
&lt;p&gt;Such patterns are very common in developmental biology . In addition to coat colors and skin pigmentation, invariant large-scale patterns, arising in spite of stochastic low-level dynamics, are a key feature of peripheral nerve networks, vascular networks, somites (blocks of tissue demarcated in embryogenesis that give rise to many organs), and segments of anatomical and genetic-level features, including whole body plans (e.g., snakes and centipedes) and appendages (such as demarcation of digit fields within the vertebrate limb). These kinds of patterns are generated by reaction-diffusion processes, bioelectric signaling, planar polarity, and other cell-to-cell communication mechanisms. Patterns in biology are not only structural, but also physiological, as in the waves of electrical activity in the brain and the dynamics of gene regulatory networks. These gene regulatory networks, for example, can support computation sufficiently sophisticated as to be subject to Liar paradoxes See &lt;a href=&quot;https://en.wikipedia.org/wiki/Liar_paradox&quot;&gt;liar paradox&lt;/a&gt;. In principle, gene regulatory networks can express paradoxical behaviour, such as that expression of factor A represses the expression of factor A. One result of such a paradox can be that a certain factor will oscillate with time. . Studying the emergence and control of such patterns can help us to understand not only their evolutionary origins, but also how they are recognized (either in the visual system of a second observer or in adjacent cells during regeneration) and how they can be modulated for the purposes of regenerative medicine.&lt;/p&gt;
&lt;p&gt;As a result, when having any model learn to produce textures or patterns, we want it to learn a generative process for the pattern. We can think of such a process as a means of sampling from the distribution governing this pattern. The first hurdle is to choose an appropriate loss function, or qualitative measure of the pattern. To do so, we employ ideas from Gatys et. al . NCA become the parametrization for an image which we ‚Äústylize‚Äù in the style of the target pattern. In this case, instead of restyling an existing image, we begin with a fully unconstrained setting: the output of an untrained, randomly initialized, NCA. The NCA serve as the ‚Äúrenderer‚Äù or ‚Äúgenerator‚Äù, and a pre-trained differentiable model serves as a distinguisher of the patterns, providing the gradient necessary for the renderer to learn to produce a pattern of a certain style.&lt;/p&gt;
&lt;h3 id=&quot;from-turing-to-cellular-automata-to-neural-networks&quot;&gt;From Turing, to Cellular Automata, to Neural Networks&lt;/h3&gt;
&lt;p&gt;NCA are well suited for generating textures. To understand why, we‚Äôll demonstrate parallels between texture generation in nature and NCA. Given these parallels, we argue that NCA are a good model class for texture generation.&lt;/p&gt;
&lt;h4 id=&quot;pdes&quot;&gt;PDEs&lt;/h4&gt;
&lt;p&gt;In ‚ÄúThe Chemical Basis of Morphogenesis‚Äù , Alan Turing suggested that simple physical processes of reaction and diffusion, modelled by partial differential equations, lie behind pattern formation in nature, such as the aforementioned zebra stripes. Extensive work has since been done to identify PDEs modeling reaction-diffusion and evaluating their behaviour. One of the more celebrated examples is the Gray-Scott model of reaction diffusion (,). This process has a veritable zoo of interesting behaviour, explorable by simply tuning the two parameters. We strongly encourage readers to visit this &lt;a href=&quot;http://mrob.com/pub/comp/xmorphia/&quot;&gt;interactive atlas&lt;/a&gt; of the different regions of the Gray-Scott reaction diffusion model to get a sense for the extreme variety of behaviour hidden behind two simple knobs. The more adventurous can even &lt;a href=&quot;https://groups.csail.mit.edu/mac/projects/amorphous/jsim/sim/GrayScott.html&quot;&gt;play with a simulation locally&lt;/a&gt; or &lt;a href=&quot;https://mrob.com/pub/comp/xmorphia/ogl/index.html&quot;&gt;in the browser&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To tackle the problem of reproducing our textures, we propose a more general version of the above systems, described by a simple Partial Differential Equation (PDE) over the state space of an image.&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;‚àÇs‚àÇt=f(s,‚àáxs,‚àáx2s)\frac{\partial \mathbf{s} }{\partial t } = f(\textbf{s}, \nabla_\mathbf{x} \textbf{s}, \nabla_\mathbf{x}^{2}\textbf{s})&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mfrac&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathrm mtight&quot;&gt;‚àÇ&lt;/span&gt;&lt;span class=&quot;mord mathit mtight&quot;&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathrm mtight&quot;&gt;‚àÇ&lt;/span&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathbf mtight&quot;&gt;s&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;‚Äã&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mord mathit&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord text&quot;&gt;&lt;span class=&quot;mord mathbf&quot;&gt;s&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mpunct&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathrm&quot;&gt;‚àá&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathbf mtight&quot;&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;‚Äã&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord text&quot;&gt;&lt;span class=&quot;mord mathbf&quot;&gt;s&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mpunct&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathrm&quot;&gt;‚àá&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathbf mtight&quot;&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathrm mtight&quot;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;‚Äã&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord text&quot;&gt;&lt;span class=&quot;mord mathbf&quot;&gt;s&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Here, &lt;span&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;ff&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord mathit&quot;&gt;f&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is a function that depends on the gradient (&lt;span&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;‚àáxs\nabla_\mathbf{x} \textbf{s}&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathrm&quot;&gt;‚àá&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathbf mtight&quot;&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;‚Äã&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord text&quot;&gt;&lt;span class=&quot;mord mathbf&quot;&gt;s&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;) and Laplacian (&lt;span&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;‚àáx2s\nabla_\mathbf{x}^{2}\textbf{s}&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathrm&quot;&gt;‚àá&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathbf mtight&quot;&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathrm mtight&quot;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;‚Äã&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord text&quot;&gt;&lt;span class=&quot;mord mathbf&quot;&gt;s&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;) of the state space and determines the time evolution of this state space. &lt;span&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;ss&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord mathit&quot;&gt;s&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; represents a k dimensional vector, whose first three components correspond to the visible RGB color channels.&lt;/p&gt;
&lt;p&gt;Intuitively, we have defined a system where every point of the image changes with time, in a way that depends on how the image currently changes across space, with respect to its immediate neighbourhood. Readers may start to recognize the resemblance between this and another system based on immediately local interactions.&lt;/p&gt;
&lt;h4 id=&quot;to-cas&quot;&gt;To CAs&lt;/h4&gt;
&lt;p&gt;Differential equations governing natural phenomena are usually evaluated using numerical differential equation solvers. Indeed, this is sometimes the &lt;strong&gt;only&lt;/strong&gt; way to solve them, as many PDEs and ODEs of interest do not have closed form solutions. This is even the case for some deceptively simple ones, such as the &lt;a href=&quot;https://en.wikipedia.org/wiki/Three-body_problem&quot;&gt;three-body problem&lt;/a&gt;. Numerically solving PDEs and ODEs is a vast and well-established field. One of the biggest hammers in the metaphorical toolkit for numerically evaluating differential equations is discretization: the process of converting the variables of the system from continuous space to a discrete space, where numerical integration is tractable. When using some ODEs to model a change in a phenomena over time, for example, it makes sense to advance through time in discrete steps, possibly of variable size.&lt;/p&gt;
&lt;p&gt;We now show that numerically integrating the aforementioned PDE is equivalent to reframing the problem as a Neural Cellular Automata, with &lt;span&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;ff&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord mathit&quot;&gt;f&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; assuming the role of the NCA rule.&lt;/p&gt;
&lt;p&gt;The logical approach to discretizing the space the PDE operates on is to discretize the continuous 2D image space into a 2D raster grid. Boundary conditions are of concern but we can address them by moving to a toroidal world where each dimension wraps around on itself.&lt;/p&gt;
&lt;p&gt;Similarly to space, we choose to treat time in a discretized fashion and evaluate our NCA at fixed-sized time steps. This is equivalent to explicit Euler integration. However, here we make an important deviation from traditional PDE numerical integration methods for two reasons. First, if all cells are updated synchronously, initial conditions &lt;span&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;s0s_0&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathit&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathrm mtight&quot;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;‚Äã&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; must vary from cell-to-cell in order to break the symmetry. Second, the physical implementation of the synchronous model would require the existence of a global clock, shared by all cells. One way to work around the former is by initializing the grid with random noise, but in the spirit of self organisation we instead choose to decouple the cell updates by asynchronously evaluating the CA. We sample a subset of all cells at each time-step to update. This introduces both asynchronicity in time (cells will sometimes operate on information from their neighbours that is several timesteps old), and asymmetry in space, solving both aforementioned issues.&lt;/p&gt;
&lt;p&gt;Our next step towards representing a PDE with cellular automata is to discretize the gradient and Laplacian operators. For this we use the &lt;a href=&quot;https://en.wikipedia.org/wiki/Sobel_operator&quot;&gt;sobel operator&lt;/a&gt; and the &lt;a href=&quot;https://en.wikipedia.org/wiki/Discrete_Laplace_operator&quot;&gt;9-point variant&lt;/a&gt; of the discrete Laplace operator, as below.&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;[‚àí101‚àí202‚àí101][‚àí1‚àí2‚àí1000121][1212‚àí122121]SobelxSobelyLaplacian \begin{array}{ c c c } \begin{bmatrix} -1 &amp;amp; 0 &amp;amp; 1\\-2 &amp;amp; 0 &amp;amp; 2 \\-1 &amp;amp; 0 &amp;amp; 1 \end{bmatrix} &amp;amp; \begin{bmatrix} -1 &amp;amp; -2 &amp;amp; -1\\ 0 &amp;amp; 0 &amp;amp; 0 \\1 &amp;amp; 2 &amp;amp; 1 \end{bmatrix} &amp;amp; \begin{bmatrix} 1 &amp;amp; 2 &amp;amp; 1\\2 &amp;amp; -12 &amp;amp; 2 \\1 &amp;amp; 2 &amp;amp; 1 \end{bmatrix} \\ Sobel_x &amp;amp; Sobel_y &amp;amp; Laplacian \end{array}&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mtable&quot;&gt;&lt;span class=&quot;col-align-c&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;minner&quot;&gt;&lt;span class=&quot;mopen&quot;&gt;&lt;span class=&quot;delimsizing mult&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;delimsizinginner delim-size4&quot;&gt;&lt;span&gt;‚é£&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;delimsizinginner delim-size4&quot;&gt;&lt;span&gt;‚é°&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;‚Äã&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mtable&quot;&gt;&lt;span class=&quot;col-align-c&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord&quot;&gt;‚àí&lt;/span&gt;&lt;span class=&quot;mord mathrm&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord&quot;&gt;‚àí&lt;/span&gt;&lt;span class=&quot;mord mathrm&quot;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord&quot;&gt;‚àí&lt;/span&gt;&lt;span class=&quot;mord mathrm&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;‚Äã&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;col-align-c&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathrm&quot;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathrm&quot;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathrm&quot;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;‚Äã&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;col-align-c&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathrm&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathrm&quot;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathrm&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;‚Äã&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;&lt;span class=&quot;delimsizing mult&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;delimsizinginner delim-size4&quot;&gt;&lt;span&gt;‚é¶&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;delimsizinginner delim-size4&quot;&gt;&lt;span&gt;‚é§&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;‚Äã&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathit&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;mord mathit&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;mord mathit&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;mord mathit&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathit&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathit mtight&quot;&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;‚Äã&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;‚Äã&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;col-align-c&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;minner&quot;&gt;&lt;span class=&quot;mopen&quot;&gt;&lt;span class=&quot;delimsizing mult&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;delimsizinginner delim-size4&quot;&gt;&lt;span&gt;‚é£&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;delimsizinginner delim-size4&quot;&gt;&lt;span&gt;‚é°&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;‚Äã&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mtable&quot;&gt;&lt;span class=&quot;col-align-c&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord&quot;&gt;‚àí&lt;/span&gt;&lt;span class=&quot;mord mathrm&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathrm&quot;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathrm&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;‚Äã&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;col-align-c&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord&quot;&gt;‚àí&lt;/span&gt;&lt;span class=&quot;mord mathrm&quot;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathrm&quot;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathrm&quot;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;‚Äã&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;col-align-c&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord&quot;&gt;‚àí&lt;/span&gt;&lt;span class=&quot;mord mathrm&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathrm&quot;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathrm&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;‚Äã&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;&lt;span class=&quot;delimsizing mult&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;delimsizinginner delim-size4&quot;&gt;&lt;span&gt;‚é¶&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;delimsizinginner delim-size4&quot;&gt;&lt;span&gt;‚é§&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;‚Äã&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathit&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;mord mathit&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;mord mathit&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;mord mathit&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathit&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathit mtight&quot;&gt;y&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;‚Äã&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;‚Äã&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;col-align-c&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;minner&quot;&gt;&lt;span class=&quot;mopen&quot;&gt;&lt;span class=&quot;delimsizing mult&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;delimsizinginner delim-size4&quot;&gt;&lt;span&gt;‚é£&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;delimsizinginner delim-size4&quot;&gt;&lt;span&gt;‚é°&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;‚Äã&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mtable&quot;&gt;&lt;span class=&quot;col-align-c&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathrm&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathrm&quot;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathrm&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;‚Äã&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;col-align-c&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathrm&quot;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord&quot;&gt;‚àí&lt;/span&gt;&lt;span class=&quot;mord mathrm&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;mord mathrm&quot;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathrm&quot;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;‚Äã&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;col-align-c&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathrm&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathrm&quot;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathrm&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;‚Äã&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;&lt;span class=&quot;delimsizing mult&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;delimsizinginner delim-size4&quot;&gt;&lt;span&gt;‚é¶&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;delimsizinginner delim-size4&quot;&gt;&lt;span&gt;‚é§&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;‚Äã&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathit&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;mord mathit&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;mord mathit&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;mord mathit&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;mord mathit&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;mord mathit&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;mord mathit&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;mord mathit&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;mord mathit&quot;&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;‚Äã&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;With all the pieces in place, we now have a space-discretized version of our PDE that looks very much like a Cellular Automata: the time evolution of each discrete point in the raster grid depends only on its immediate neighbours. These discrete operators allow us to formalize our PDE as a CA. To double check that this is true, simply observe that as our grid becomes very fine, and the asynchronous updates approach uniformity, the dynamics of these discrete operators will reproduce the continuous dynamics of the original PDE as we defined it.&lt;/p&gt;
&lt;h4 id=&quot;to-neural-networks&quot;&gt;To Neural Networks&lt;/h4&gt;
&lt;p&gt;The final step in implementing the above general PDE for texture generation is to translate it to the language of deep learning. Fortunately, all the operations involved in iteratively evaluating the generalized PDE exist as common operations in most deep learning frameworks. We provide both a Tensorflow and a minimal PyTorch implementation for reference, and refer readers to these for details on our implementation.&lt;/p&gt;
&lt;h3 id=&quot;nca-as-pattern-generators&quot;&gt;NCA as pattern generators&lt;/h3&gt;
&lt;h4 id=&quot;model&quot;&gt;Model:&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;https://distill.pub/selforg/2021/textures/images/texture_model.svg&quot;/&gt; Texture NCA model.&lt;/p&gt;
&lt;p&gt;We build on the Growing CA NCA model , complete with built-in quantization of weights, stochastic updates, and the batch pool mechanism to approximate long-term training. For further details on the model and motivation, we refer readers to this work.&lt;/p&gt;
&lt;h4 id=&quot;loss-function-&quot;&gt;Loss function:&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;https://distill.pub/selforg/2021/textures/images/texture_training.svg&quot;/&gt; Texture NCA model.&lt;/p&gt;
&lt;p&gt;We use a well known deep convolutional network for image recognition, VGG (Visual Geometry Group Net ) as our differentiable discriminator of textures, for the same reasons outlined in Differentiable Parametrizations . We start with a template image, &lt;span&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;x‚Éó\vec{x}&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord accent&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathit&quot;&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;accent-body accent-vec&quot;&gt;&lt;span&gt;‚Éó&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;, which we feed into VGG. Then we collect statistics from certain layers (block[&lt;span&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;1...51‚Ä¶5&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord mathrm&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;mord mathrm&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mord mathrm&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mord mathrm&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mord mathrm&quot;&gt;5&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;]_conv1) in the form of the raw activation values of the neurons in these layers. Finally, we run our NCA forward for between 32 and 64 iterations, feeding the resulting RGB image into VGG. Our loss is the &lt;span&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;L2L_2&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathit&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathrm mtight&quot;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;‚Äã&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; distance between the gram matrix For a brief definition of gram matrices, see &lt;a href=&quot;https://www.tensorflow.org/tutorials/generative/style_transfer#calculate_style&quot;&gt;here&lt;/a&gt;. of activations of these neurons with the NCA as input and their activations with the template image as input. We keep the weights of VGG frozen and use ADAM to update the weights of the NCA.&lt;/p&gt;
&lt;h4 id=&quot;dataset-&quot;&gt;Dataset:&lt;/h4&gt;
&lt;p&gt;The template images for this dataset are from the Oxford Describable Textures Dataset . The aim of this dataset is to provide a benchmark for measuring the ability of vision models to recognize and categorize textures and describe textures using words. The textures were collected to match 47 ‚Äúattributes‚Äù such as ‚Äúbumpy‚Äù or ‚Äúpolka-dotted‚Äù. These 47 attributes were in turn distilled from a set of common words used to describe textures identified by Bhusan, Rao and Lohse .&lt;/p&gt;
&lt;h4 id=&quot;results&quot;&gt;Results:&lt;/h4&gt;
&lt;p&gt;After a few iterations of training, we see the NCA converge to a solution that at first glance looks similar to the input template, but not pixel-wise identical. The very first thing to notice is that the solution learned by the NCA is &lt;strong&gt;not&lt;/strong&gt; time-invariant if we continue to iterate the CA. In other words it is constantly changing!&lt;/p&gt;
&lt;p&gt;This is not completely unexpected. In &lt;em&gt;Differentiable Parametrizations&lt;/em&gt;, the authors noted that the images produced when backpropagating into image space would end up different each time the algorithm was run due to the stochastic nature of the parametrizations. To work around this, they introduced some tricks to maintain &lt;strong&gt;alignment&lt;/strong&gt; between different visualizations. In our model, we find that we attain such alignment along the temporal dimension without optimizing for it; a welcome surprise. We believe the reason is threefold. First, reaching and maintaining a static state in an NCA appears to be non-trivial in comparison to a dynamic one, so much so that in Growing CA a pool of NCA states at various iteration times had to be maintained and sampled as starting states to simulate loss being applied after a time period longer than the NCAs iteration period, to achieve a static stability. We employ the same sampling mechanism here to prevent the pattern from decaying, but in this case the loss doesn‚Äôt enforce a static fixed target; rather it guides the NCA towards any one of a number of states that minimizes the style loss. Second, we apply our loss after a random number of iterations of the NCA. This means that, at any given time step, the pattern must be in a state that minimizes the loss. Third, the stochastic updates, local communication, and quantization all limit and regularize the magnitude of updates at each iteration. This encourages changes to be small between one iteration and the next. We hypothesize that these properties combined encourage the NCA to find a solution where each iteration is &lt;strong&gt;aligned&lt;/strong&gt; with the previous iteration. We perceive this alignment through time as motion, and as we iterate the NCA we observe it traversing a manifold of locally aligned solutions.&lt;/p&gt;
&lt;p&gt;We now &lt;strong&gt;posit&lt;/strong&gt; &lt;em&gt;that finding temporally aligned solutions is equivalent to finding an algorithm, or process, that generates the template pattern&lt;/em&gt;, based on the aforementioned findings and qualitative observation of the NCA. We proceed to demonstrate some exciting behaviours of NCA trained on different template images.&lt;/p&gt;
&lt;p&gt;An NCA trained to create a pattern in the style of &lt;strong&gt;chequered_0121.jpg&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Here, we see that the NCA is trained using a template image of a simple black and white grid.&lt;/p&gt;
&lt;p&gt;We notice that:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Initially, a non-aligned grid of black and white quadrilaterals is formed.&lt;/li&gt;
&lt;li&gt;As time progresses, the quadrilaterals seemingly grow or shrink in both &lt;span&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;x‚Éó\vec{x}&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord accent&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathit&quot;&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;accent-body accent-vec&quot;&gt;&lt;span&gt;‚Éó&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; and &lt;span&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;y‚Éó\vec{y}&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord accent&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathit&quot;&gt;y&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;accent-body accent-vec&quot;&gt;&lt;span&gt;‚Éó&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;‚Äã&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; to more closely approximate squares. Quadrilaterals of both colours either emerge or disappear. Both of these behaviours seem to be an attempt to find local consistency.&lt;/li&gt;
&lt;li&gt;After a longer time, the grid tends to achieve perfect consistency.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Such behaviour is not entirely unlike what one would expect in a hand-engineered algorithm to produce a consistent grid with local communication. For instance, one potential hand-engineered approach would be to have cells first try and achieve local consistency, by choosing the most common colour from the cells surrounding them, then attempting to form a diamond of correct size by measuring distance to the four edges of this patch of consistent colour, and moving this boundary if it were incorrect. Distance could be measured by using a hidden channel to encode a gradient in each direction of interest, with each cell decreasing the magnitude of this channel as compared to its neighbour in that direction. A cell could then localize itself within a diamond by measuring the value of two such gradient channels. The appearance of such an algorithm would bear resemblance to the above - with patches of cells becoming either black, or white, diamonds then resizing themselves to achieve consistency.&lt;/p&gt;
&lt;p&gt;An NCA trained to create a pattern in the style of &lt;strong&gt;bubbly_0101.jpg&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;In this video, the NCA has learned to reproduce a texture based on a template of clear bubbles on a blue background. One of the most interesting behaviours we observe is that the density of the bubbles remains fairly constant. If we re-initialize the grid states, or interactively destroy states, we see a multitude of bubbles re-forming. However, as soon as two bubbles get too close to each other, one of them spontaneously collapses and disappears, ensuring a constant density of bubbles throughout the entire image. We regard these bubbles as ‚Äù&lt;a href=&quot;https://distill.pub/selforg/2021/textures/#an-aside-solitons-and-lenia&quot;&gt;solitons&lt;/a&gt;‚Ä≥ in the solution space of our NCA. This is a concept we will discuss and investigate at length below.&lt;/p&gt;
&lt;p&gt;If we speed the animation up, we see that different bubbles move at different speeds, yet they never collide or touch each other. Bubbles also maintain their structure by self-correcting; a damaged bubble can re-grow.&lt;/p&gt;
&lt;p&gt;This behaviour is remarkable because it arises spontaneously, without any external or auxiliary losses. All of these properties are learned from a combination of the template image, the information stored in the layers of VGG, and the inductive bias of the NCA. The NCA learned a rule that effectively approximates many of the properties of the bubbles in the original image. Moreover, it has learned a process that generates this pattern in a way that is robust to damage and looks realistic to humans.&lt;/p&gt;
&lt;p&gt;An NCA trained to create a pattern in the style of &lt;strong&gt;interlaced_0172.jpg&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Here we see one of our favourite patterns: a simple geometric ‚Äúweave‚Äù. Again, we notice the NCA seems to have learned an algorithm for producing this pattern. Each ‚Äúthread‚Äù alternately joins or detaches from other threads in order to produce the final pattern. This is strikingly similar to what one would attempt to implement, were one asked to programmatically generate the above pattern. One would try to design some sort of stochastic algorithm for weaving individual threads together with other nearby threads.&lt;/p&gt;
&lt;p&gt;An NCA trained to create a pattern in the style of &lt;strong&gt;banded_0037.jpg&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Here, misaligned stripe fragments travel up or down the stripe until either they merge to form a single straight stripe or a stripe shrinks and disappears. Were this to be implemented algorithmically with local communication, it is not infeasible that a similar algorithm for finding consistency among the stripes would be used.&lt;/p&gt;
&lt;h3 id=&quot;related-work&quot;&gt;Related work&lt;/h3&gt;
&lt;p&gt;This foray into pattern generation is by no means the first. There has been extensive work predating deep-learning, in particular suggesting deep connections between spatial patterning of anatomical structure and temporal patterning of cognitive and computational processes (e.g., reviewed in ). Hans Spemann, one of the heroes of classical developmental biology, said ‚ÄúAgain and again terms have been used which point not to physical but to psychical analogies. It was meant to be more than a poetical metaphor. It was meant to my conviction that the suitable reaction of a germ fragment, endowed with diverse potencies, in an embryonic ‚Äòfield‚Äô‚Ä¶ is not a common chemical reaction, like all vital processes, are comparable, to nothing we know in such degree as to vital processes of which we have the most intimate knowledge.‚Äù . More recently, Grossberg quantitatively laid out important similarities between developmental patterning and computational neuroscience . As briefly touched upon, the inspiration for much of the work came from Turing‚Äôs work on pattern generation through local interaction, and later papers based on this principle. However, we also wish to acknowledge some works that we feel have a particular kinship with ours.&lt;/p&gt;
&lt;h4 id=&quot;patch-sampling&quot;&gt;Patch sampling&lt;/h4&gt;
&lt;p&gt;Early work in pattern generation focused on texture sampling. Patches were often sampled from the original image and reconstructed or rejoined in different ways to obtain an approximation of the texture. This method has also seen recent success with the work of Gumin .&lt;/p&gt;
&lt;h4 id=&quot;deep-learning&quot;&gt;Deep learning&lt;/h4&gt;
&lt;p&gt;Gatys et. al‚Äôs work , referenced throughout, has been seminal with regards to the idea that statistics of certain layers in a pre-trained network can capture textures or styles in an image. There has been extensive work building on this idea, including playing with other parametrisations for image generation and optimizing the generation process .&lt;/p&gt;
&lt;p&gt;Other work has focused on using a convolutional generator combined with path sampling and trained using an adversarial loss to produce textures of similar quality .&lt;/p&gt;
&lt;h4 id=&quot;interactive-evolution-of-camouflage&quot;&gt;Interactive Evolution of Camouflage&lt;/h4&gt;
&lt;p&gt;Perhaps the most unconventional approach, with which we find kinship, is laid out in &lt;em&gt;Interactive Evolution of Camouflage&lt;/em&gt; . Craig Reynolds uses a texture description language, consisting of generators and operators, to parametrize a texture patch, which is presented to human viewers who have to decide which patches are the worst at ‚Äúcamouflaging‚Äù themselves against a chosen background texture. The population is updated in an evolutionary fashion to maximize ‚Äúcamouflage‚Äù, resulting in a texture exhibiting the most camouflage (to human eyes) after a number of iterations. We see strong parallels with our work - instead of a texture generation language, we have an NCA parametrize the texture, and instead of human reviewers we use VGG as an evaluator of the quality of a generated pattern. We believe a fundamental difference lies in the solution space of an NCA. A texture generation language comes with a number of inductive biases and learns a deterministic mapping from coordinates to colours. Our method appears to learn more general algorithms and behaviours giving rise to the target pattern.&lt;/p&gt;
&lt;p&gt;Two other noteworthy examples of similar work are Portilla et. al‚Äôs work with the wavelet transform , and work by Chen et al with reaction diffusion .&lt;/p&gt;
&lt;h2 id=&quot;feature-visualization&quot;&gt;Feature visualization&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://distill.pub/selforg/2021/textures/images/butterfly_eye.jpg&quot;/&gt; A butterfly with an ‚Äúeye-spot‚Äù on the wings.&lt;/p&gt;
&lt;p&gt;We have now explored some of the fascinating behaviours learned by the NCA when presented with a template image. What if we want to see them learn even more ‚Äúunconstrained‚Äù behaviour?&lt;/p&gt;
&lt;p&gt;Some butterflies have remarkably lifelike eyes on their wings. It‚Äôs unlikely the butterflies are even aware of this incredible artwork on their own bodies. Evolution placed these there to trigger a response of fear in potential predators or to deflect attacks from them . It is likely that neither the predator nor the butterfly has a concept for what an eye is or what an eye does, or even less so any &lt;a href=&quot;https://en.wikipedia.org/wiki/Theory_of_mind&quot;&gt;theory of mind&lt;/a&gt; regarding the consciousness of the other, but evolution has identified a region of morphospace for this organism that exploits pattern-identifying features of predators to trick them into fearing a harmless bug instead of consuming it.&lt;/p&gt;
&lt;p&gt;Even more remarkable is the fact that the individual cells composing the butterfly‚Äôs wings can self assemble into coherent, beautiful, shapes far larger than an individual cell - indeed a cell is on the order of &lt;span&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;1‚àí5m1^{-5}m&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathrm&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;‚àí&lt;/span&gt;&lt;span class=&quot;mord mathrm mtight&quot;&gt;5&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord mathit&quot;&gt;m&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; while the features on the wings will grow to as large as &lt;span&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;1‚àí3m1^{-3}m&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathrm&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;‚àí&lt;/span&gt;&lt;span class=&quot;mord mathrm mtight&quot;&gt;3&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord mathit&quot;&gt;m&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; . The coordination required to produce these features implies self-organization over hundreds or thousands of cells to generate a coherent image of an eye that evolved simply to act as a visual stimuli for an entirely different species, because of the local nature of cell-to-cell communication. Of course, this pales in comparison to the morphogenesis that occurs in animal and plant bodies, where structures consisting of millions of cells will specialize and coordinate to generate the target morphology.&lt;/p&gt;
&lt;p&gt;A common approach to investigating neural networks is to look at what inhibits or excites individual neurons in a network . Just as neuroscientists and biologists have often treated cells and cell structures and neurons as black-box models to be investigated, measured and reverse-engineered, there is a large contemporary body of work on doing the same with neural networks. For instance the work by Boettiger .&lt;/p&gt;
&lt;p&gt;We can explore this idea with minimal effort by taking our pattern-generating NCA and exploring what happens if we task it to enter a state that excites a given neuron in Inception. One of the common resulting NCAs we notice is eye and eye-related shapes - such as the video below - likely as a result of having to detect various animals in ImageNet. In the same way that cells form eye patterns on the wings of butterflies to excite neurons in the brains of predators, our NCA‚Äôs population of cells has learned to collaborate to produce a pattern that excites certain neurons in an external neural network.&lt;/p&gt;
&lt;p&gt;An NCA trained to excite &lt;strong&gt;mixed4a_472&lt;/strong&gt; in Inception.&lt;/p&gt;
&lt;h3 id=&quot;nca-with-inception&quot;&gt;NCA with Inception&lt;/h3&gt;
&lt;h4 id=&quot;model-&quot;&gt;Model:&lt;/h4&gt;
&lt;p&gt;We use a model identical to the one used for exploring pattern generation, but with a different discriminator network: Imagenet-trained Inception v1 network .&lt;/p&gt;
&lt;h4 id=&quot;loss-function-&quot;&gt;Loss function:&lt;/h4&gt;
&lt;p&gt;Our loss maximizes the activations of chosen neurons, when evaluated on the output of the NCA. We add an auxiliary loss to encourage the outputs of the NCA to be &lt;span&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;‚àà[0,1]\in [0,1]&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mrel&quot;&gt;‚àà&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mord mathrm&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;mpunct&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mord mathrm&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;]&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;, as this is not inherently built into the model. We keep the weights of the Inception frozen and use ADAM to update the weights of the NCA.&lt;/p&gt;
&lt;h4 id=&quot;dataset-&quot;&gt;Dataset:&lt;/h4&gt;
&lt;p&gt;There is no explicit dataset for this task. Inception is trained on ImageNet. The layers and neurons we chose to excite are chosen qualitatively using OpenAI Microscope.&lt;/p&gt;
&lt;h4 id=&quot;results&quot;&gt;Results:&lt;/h4&gt;
&lt;p&gt;Similar to the pattern generation experiment, we see quick convergence and a tendency to find temporally dynamic solutions. In other words, resulting NCAs do not stay still. We also observe that the majority of the NCAs learn to produce solitons of various kinds. We discuss a few below, but encourage readers to explore them in the demo.&lt;/p&gt;
&lt;p&gt;An NCA trained to excite &lt;strong&gt;mixed4c_439&lt;/strong&gt; in Inception.&lt;/p&gt;
&lt;p&gt;Solitons in the form of regular circle-like shapes with internal structure are quite commonly observed in the inception renderings. Two solitons approaching each other too closely may cause one or both of them to decay. We also observe that solitons can divide into two new solitons.&lt;/p&gt;
&lt;p&gt;An NCA trained to excite &lt;strong&gt;mixed3b_454&lt;/strong&gt; in Inception.&lt;/p&gt;
&lt;p&gt;In textures that are composed of threads or lines, or in certain excitations of Inception neurons where the resulting NCA has a ‚Äúthread-like‚Äù quality, the threads grow in their respective directions and will join other threads, or grow around them, as required. This behaviour is similar to the regular lines observed in the striped patterns during pattern generation.&lt;/p&gt;
&lt;h2 id=&quot;other-interesting-findings&quot;&gt;Other interesting findings&lt;/h2&gt;
&lt;h3 id=&quot;robustness&quot;&gt;Robustness&lt;/h3&gt;
&lt;h4 id=&quot;switching-manifolds&quot;&gt;Switching manifolds&lt;/h4&gt;
&lt;p&gt;We encode local information flow within the NCA using the same fixed Laplacian and gradient filters. As luck would have it, these can be defined for most underlying manifolds, giving us a way of placing our cells on various surfaces and in various configurations without having to modify the learned model. Suppose we want our cells to live in a hexagonal world. We can redefine our kernels as follows:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://distill.pub/selforg/2021/textures/images/hex_kernels.svg&quot;/&gt; Hexagonal grid convolutional filters.&lt;/p&gt;
&lt;p&gt;Our model, trained in a purely square environment, works out of the box on a hexagonal grid! Play with the corresponding setting in the demo to experiment with this. Zooming in allows observation of the individual hexagonal or square cells. As can be seen in the demo, the cells have no problem adjusting to a hexagonal world and producing identical patterns after a brief period of re-alignment.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://distill.pub/selforg/2021/textures/images/coral_square.png&quot;/&gt;&lt;img src=&quot;https://distill.pub/selforg/2021/textures/images/coral_hex.png&quot;/&gt; The same texture evaluated on a square and hexagonal grid, respectively.&lt;/p&gt;
&lt;h4 id=&quot;rotation&quot;&gt;Rotation&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;https://distill.pub/selforg/2021/textures/images/mond_rot0.png&quot;/&gt;&lt;img src=&quot;https://distill.pub/selforg/2021/textures/images/mond_rot1.png&quot;/&gt;&lt;img src=&quot;https://distill.pub/selforg/2021/textures/images/mond_rot2.png&quot;/&gt;&lt;img src=&quot;https://distill.pub/selforg/2021/textures/images/mond_rot3.png&quot;/&gt; Mondrian pattern where the cells are rotated in various directions. Note that the NCA is not re-trained - it gen- eralises to this new rotated paradigm without issue.&lt;/p&gt;
&lt;p&gt;In theory, the cells can be evaluated on any manifold where one can define approximations to the Sobel kernel and the Laplacian kernel. We demonstrate this in our demo by providing an aforementioned ‚Äúhexagonal‚Äù world for the cells to live in. Instead of having eight equally-spaced neighbours, each cell now has six equally-spaced neighbours. We further demonstrate this versatility by rotating the Sobel and Laplacian kernels. Each cell receives an innate global orientation based on these kernels, because they are defined with respect to the coordinate system of the state. Redefining the Sobel and Laplacian kernel with a rotated coordinate system is straightforward and can even be done on a per-cell level. Such versatility is exciting because it mirrors the extreme robustness found in biological cells in nature. Cells in most tissues will generally continue to operate whatever their location, direction, or exact placement relative to their neighbours. We believe this versatility in our model could even extend to a setting where the cells are placed on a manifold at random, rather than on an ordered grid.&lt;/p&gt;
&lt;h4 id=&quot;timesynchronization-&quot;&gt;Time-synchronization&lt;/h4&gt;
&lt;p&gt;Two NCAs running next to each other, at different speeds, with some stochasticity in speed. They can communicate through their shared edge; the vertical boundary between them in the center of the state space.&lt;/p&gt;
&lt;p&gt;Stochastic updates teach the cells to be robust to asynchronous updates. We investigate this property by taking it to an extreme and asking &lt;em&gt;how&lt;/em&gt; &lt;em&gt;do the cells react if two manifolds are allowed to communicate but one runs the NCA at a different speed than the other&lt;/em&gt;? The result is surprisingly stable; the CA is still able to construct and maintain a consistent texture across the combined manifold. The time discrepancy between the two CAs sharing the state is far larger than anything the NCA experiences during training, showing remarkable robustness of the learned behaviour. Parallels can be drawn to organic matter self repairing, for instance a fingernail can regrow in adulthood despite the underlying finger already having fully developed; the two do not need to be sync. This result also hints at the possibility of designing distributed systems without having to engineer for a global clock, synchronization of compute units or even homogenous compute capacity.&lt;/p&gt;
&lt;p&gt;An NCA is evaluated for a number of steps. The surrounding border of cells are then also turned into NCA cells. The cells have no difficulty communicating with the ‚Äúfinished‚Äù pattern and achieving consistency.&lt;/p&gt;
&lt;p&gt;An even more drastic example of this robustness to time asynchronicity can be seen above. Here, an NCA is iterated until it achieves perfect consistency in a pattern. Then, the state space is expanded, introducing a border of new cells around the existing state. This border quickly interfaces with the existing cells and settles in a consistent pattern, with almost no perturbation to the already-converged inner state.&lt;/p&gt;
&lt;h4 id=&quot;failure-cases&quot;&gt;Failure cases&lt;/h4&gt;
&lt;p&gt;The failure modes of a complex system can teach us a great deal about its internal structure and process. Our model has many quirks and sometimes these prevent it from learning certain patterns. Below are some examples.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://distill.pub/selforg/2021/textures/images/fail_mondrian.jpeg&quot;/&gt;&lt;img src=&quot;https://distill.pub/selforg/2021/textures/images/fail_sprinkle.jpeg&quot;/&gt;&lt;img src=&quot;https://distill.pub/selforg/2021/textures/images/fail_chequerboard.jpeg&quot;/&gt; Three failure cases of the NCA. Bottom row shows target texture samples, top row are corresponding NCA outputs. Failure modes include incorrect colours, chequerboard artefacts, and incoherent image structure.&lt;/p&gt;
&lt;p&gt;Some patterns are reproduced somewhat accurately in terms of structure, but not in colour, while some are the opposite. Others fail completely. It is difficult to determine whether these failure cases have their roots in the parametrization (the NCA), or in the hard-to-interpret gradient signals from VGG, or Inception. Existing work with style transfer suggests that using a loss on Gram matrices in VGG can introduce instabilities , that are similar to the ones we see here. We hypothesize that this effect explains the failures in reproducing colors. The structural failures, meanwhile, may be caused by the NCA parameterization, which makes it difficult for cells to establish long-distance communication with one another.&lt;/p&gt;
&lt;h3 id=&quot;hidden-states&quot;&gt;Hidden states&lt;/h3&gt;
&lt;p&gt;When biological cells communicate with each other, they do so through a multitude of available communication channels. Cells can emit or absorb different ions and proteins, sense physical motion or ‚Äústiffness‚Äù of other cells, and even emit different chemical signals to diffuse over the local substrate .&lt;/p&gt;
&lt;p&gt;There are various ways to visualize communication channels in real cells. One of them is to add to cells a potential-activated dye. Doing so gives a clear picture of the voltage potential the cell is under with respect to the surrounding substrate. This technique provides useful insight into the communication patterns within groups of cells and helps scientists visualize both local and global communication over a variety of time-scales.&lt;/p&gt;
&lt;p&gt;As luck would have it, we can do something similar with our Neural Cellular Automata. Recall that our NCA model contains 16 channels. The first three are visible RGB channels and the rest we treat as latent channels which are visible to adjacent cells during update steps, but excluded from loss functions. Below we map the first three principle components of the hidden channels to the R,G, and B channels respectively. Hidden channels can be considered ‚Äúfloating,‚Äù to abuse a term from circuit theory. In other words, they are not pulled to any specific final state or intermediate state by the loss. Instead, they converge to some form of a dynamical system which assists the cell in fulfilling its objective with respect to its visible channels. There is no pre-defined assignment of different roles or meaning to different hidden channels, and there is almost certainly redundancy and correlation between different hidden channels. Such correlation may not be visible when we visualize the first three principal components in isolation. But this concern aside, the visualization yields some interesting insights anyways.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Left:&lt;/strong&gt; RGB channels of NCA. &lt;strong&gt;Right:&lt;/strong&gt; Intensities of top three principal components of hidden states.&lt;/p&gt;&lt;p&gt;An NCA trained to excite &lt;strong&gt;mixed4b_70&lt;/strong&gt; in Inception. Notice the hidden states appear to encode information about structure. ‚ÄúThreads‚Äù along the major diagonal (NW - SE) appear primarily green, while those running along the anti-diagonal appear blue, indicating that these have differing internal states, despite being effectively indistinguishable in RGB space.&lt;/p&gt;
&lt;p&gt;In the principal components of this coral-like texture, we see a pattern which is similar to the visible channels. However, the ‚Äúthreads‚Äù pointing in each diagonal direction have different colours - one diagonal is green and the other is a pale blue. This suggests that one of the things encoded into the hidden states is the direction of a ‚Äúthread‚Äù, likely to allow cells that are inside one of these threads to keep track of which direction the thread is growing, or moving, in.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Left:&lt;/strong&gt; RGB channels of NCA. &lt;strong&gt;Right:&lt;/strong&gt; Intensities of top three principal components of hidden states.&lt;/p&gt;&lt;p&gt;An NCA trained to produce a texture based on DTD image &lt;strong&gt;cheqeuered_0121&lt;/strong&gt;. Notice the structure of squares - with a gradient occurring inside the structure of each square, evidencing that structure is being encoded in hidden state.&lt;/p&gt;
&lt;p&gt;The chequerboard pattern likewise lends itself to some qualitative analysis and hints at a fairly simple mechanism for maintaining the shape of squares. Each square has a clear gradient in PCA space across the diagonal, and the values this gradient traverses differ for the white and black squares. We find it likely the gradient is used to provide a local coordinate system for creating and sizing the squares.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Left:&lt;/strong&gt; RGB channels of NCA. &lt;strong&gt;Right:&lt;/strong&gt; Intensities of top three principal components of hidden states.&lt;/p&gt;&lt;p&gt;An NCA trained to excite &lt;strong&gt;mixed4c_208&lt;/strong&gt; in Inception. The visible body of the eye is clearly demarcated in the hidden states. There is also a ‚Äúhalo‚Äù which appears to modulate growth of any solitons immediately next to each other. This halo is barely visible in the RGB channels.&lt;/p&gt;
&lt;p&gt;We find surprising insight in NCA trained on Inception as well. In this case, the structure of the eye is clearly encoded in the hidden state with the body composed primarily of one combination of principal components, and an halo, seemingly to prevent collisions of the eye solitons, composed of another set of principal components.&lt;/p&gt;
&lt;p&gt;Analysis of these hidden states is something of a dark art; it is not always possible to draw rigorous conclusions about what is happening. We welcome future work in this direction, as we believe qualitative analysis of these behaviours will be useful for understanding more complex behaviours of CAs. We also hypothesize that it may be possible to modify or alter hidden states in order to affect the morphology and behaviour of NCA.&lt;/p&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;In this work, we selected texture templates and individual neurons as targets and then optimized NCA populations so as to produce similar excitations in a pre-trained neural network. This procedure yielded NCAs that could render nuanced and hypnotic textures. During our analysis, we found that these NCAs have interesting and unexpected properties. Many of the solutions for generating certain patterns in an image appear similar to the underlying model or physical behaviour producing the pattern. For example, our learned NCAs seem to have a bias for treating objects in the pattern as individual objects and letting them move freely across space. While this effect was present in many of our models, it was particularly strong in the bubble and eye models. The NCA is forced to find algorithms that can produce such a pattern with purely local interaction. This constraint seems to produce models that favor high-level consistency and robustness.&lt;/p&gt;
&lt;section id=&quot;thread-nav&quot; class=&quot;thread-info&quot; readability=&quot;4.4846416382253&quot;&gt;&lt;img class=&quot;thread-icon&quot; src=&quot;https://distill.pub/selforg/2021/textures/images/multiple-pages.svg&quot; width=&quot;43px&quot; height=&quot;50px&quot;/&gt;&lt;p class=&quot;explanation&quot;&gt;This article is part of the &lt;a href=&quot;https://distill.pub/2020/selforg/&quot;&gt;Differentiable Self-organizing Systems Thread&lt;/a&gt;, an experimental format collecting invited short articles delving into differentiable self-organizing systems, interspersed with critical commentary from several experts in adjacent fields.&lt;/p&gt;
&lt;a class=&quot;prev&quot; href=&quot;https://distill.pub/2020/selforg/mnist/&quot;&gt;Self-classifying MNIST Digits&lt;/a&gt;&lt;/section&gt;&lt;h3 id=&quot;acknowledgments&quot;&gt;Acknowledgments&lt;/h3&gt;
&lt;p&gt;We‚Äôd like to thank Sam Greydanus for especially thoughtful proofreading and giving extensive feedback throughout the article. We also extend our gratitude to the other reviewers; Maximilian Otte, Aleksandr Groznykh, and Smitty van Bodegom. Finally, we would like to acknowledge the continued support from Blaise Ag√ºera y Arcas and Dominik Roblek, without whom this work wouldn‚Äôt be possible.&lt;/p&gt;
&lt;h3 id=&quot;author-contributions&quot;&gt;Author Contributions&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Research&lt;/strong&gt;: Alexander proposed using Neural CA for texture synthesis and feature visualization and prototyped the TF and PyTorch implementations. Eyvind refined the implementation and performed most of the article experiments.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Demos&lt;/strong&gt;: Alexander implemented the WebGL NCA engine. Eyvind implemented the demo UI.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Writing and Diagrams&lt;/strong&gt;: Eyvind wrote most of the article text and created most of the diagrams and videos. Michael provided the biological context for the article. Alexander and Ettore contributed to the content.&lt;/p&gt;
&lt;h3 id=&quot;an-aside-solitons-and-lenia&quot;&gt;An Aside: Solitons and Lenia&lt;/h3&gt;
&lt;p&gt;The motion of waves propagating through a medium can be described using the classical wave equation. The equation below defines the change of some quantity &lt;span&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;uu&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord mathit&quot;&gt;u&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; (be it the surface height map of a body of water, the position of a vibrating string, etc.) with respect to the laplacian of &lt;span&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;uu&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord mathit&quot;&gt;u&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;. &lt;span&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;cc&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord mathit&quot;&gt;c&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; ends up being the propagation speed of the wave.&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;u¬®=c2‚àá2u\ddot u = c^2 \nabla^2 u&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord accent&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;mord mathit&quot;&gt;u&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;accent-body&quot;&gt;&lt;span&gt;¬®&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathit&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathrm mtight&quot;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathrm&quot;&gt;‚àá&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathrm mtight&quot;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord mathit&quot;&gt;u&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;One can imagine waves to come either as a single wave, or as a larger mixture of waves of different frequencies (a phenomenon referred to as a group or a packet). Physical phenomena, however, are rarely as structured and regular as we would like them to be. To describe the propagation of real-world waves in most physical media, such as waves in water, or sound, we must use somewhat more complex partial differential equations. Many of these systems, with the notable exception of light, share a property that waves of different frequencies will travel at different speeds. ‚ÄúSpeed‚Äù in such a context is a tricky thing to define - however in this case we are referring to the speed of any localized quantity of energy - how fast its peak travels in space. In the above, classic, wave equation this corresponds to &lt;span&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;cc&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord mathit&quot;&gt;c&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;. However, in the real world, when waves of different frequencies have different speeds, groups of waves are no longer cohesive and will experience ‚Äúdispersion‚Äù: the envelope of the group of waves will change shape over time and potentially not remain cohesive. Even in wave groups with dispersive properties, it is possible to find solutions to their partial differential equations where nonlinearities in the propagation and interaction between waves will counteract the dispersive properties of the wave group. This phenomenon, while lacking a strict definition, is called a ‚Äúsoliton‚Äù. It describes a wave packet which retains its shape during propagation.&lt;/p&gt;
&lt;p&gt;Recall the idea (touched upon in &lt;a href=&quot;https://distill.pub/2020/growing-ca/&quot;&gt;Growing Neural Cellular Automata&lt;/a&gt;) that a grid of communicating NCAs can be thought of as a finite difference approximation of a partial differential equation in both time and space. Several of the patterns we render in the pattern-generation experiment, as well as in the inception experiment, consist of well-defined structures such as circles or polygons. We consider such structures to be functionally equivalent to solitons and refer to them as such. Such a classification is inspired by B. Chan‚Äôs reference to solitons in ‚ÄúLenia.‚Äù He defines them as solid, self-maintaining structures which arise in the continuous approximation of the Game of Life.&lt;/p&gt;
&lt;h3 id=&quot;attribution&quot;&gt;Attribution&lt;/h3&gt;
&lt;p&gt;The ‚Äù&lt;a href=&quot;https://thenounproject.com/term/mouse-scroll/496854/&quot;&gt;mouse&lt;/a&gt;‚Ä≥ and ‚Äù&lt;a href=&quot;https://thenounproject.com/search/?q=swipe&amp;amp;i=893260&quot;&gt;swipe&lt;/a&gt;‚Ä≥ icons in the demo are licensed under CC-BY.&lt;/p&gt;
&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;
&lt;ol id=&quot;references-list&quot; class=&quot;references&quot;&gt;&lt;li id=&quot;Mordvintsev_Randazzo_Niklasson_Levin_2020&quot;&gt;&lt;span class=&quot;title&quot;&gt;Growing Neural Cellular Automata&lt;/span&gt; ‚ÄÇ&lt;a href=&quot;https://distill.pub/2020/growing-ca&quot;&gt;[link]&lt;/a&gt;&lt;br/&gt;Mordvintsev, A., Randazzo, E., Niklasson, E. and Levin, M., 2020. Distill, Vol 5(2), pp. e23. &lt;a href=&quot;https://doi.org/10.23915/distill.00023&quot;&gt;DOI: 10.23915/distill.00023&lt;/a&gt;&lt;/li&gt;
&lt;li id=&quot;Sandler_Zhmoginov_Luo_Mordvintsev_Randazzo_Arcas_2020&quot;&gt;&lt;span class=&quot;title&quot;&gt;Image segmentation via Cellular Automata&lt;/span&gt; ‚ÄÇ&lt;a href=&quot;http://arxiv.org/pdf/2008.04965.pdf&quot;&gt;[PDF]&lt;/a&gt;&lt;br/&gt;Sandler, M., Zhmoginov, A., Luo, L., Mordvintsev, A., Randazzo, E. and Arcas, B.A.y., 2020. arXiv [cs.CV].&lt;/li&gt;
&lt;li id=&quot;Randazzo_Mordvintsev_Niklasson_Levin_Greydanus_2020&quot;&gt;&lt;span class=&quot;title&quot;&gt;Self-classifying MNIST Digits&lt;/span&gt; ‚ÄÇ&lt;a href=&quot;https://distill.pub/2020/selforg/mnist&quot;&gt;[link]&lt;/a&gt;&lt;br/&gt;Randazzo, E., Mordvintsev, A., Niklasson, E., Levin, M. and Greydanus, S., 2020. Distill, Vol 5(8). &lt;a href=&quot;https://doi.org/10.23915/distill.00027.002&quot;&gt;DOI: 10.23915/distill.00027.002&lt;/a&gt;&lt;/li&gt;
&lt;li id=&quot;Mordvintsev_Pezzotti_Schubert_Olah_2018&quot;&gt;&lt;span class=&quot;title&quot;&gt;Differentiable Image Parameterizations&lt;/span&gt; ‚ÄÇ&lt;a href=&quot;https://distill.pub/2018/differentiable-parameterizations&quot;&gt;[link]&lt;/a&gt;&lt;br/&gt;Mordvintsev, A., Pezzotti, N., Schubert, L. and Olah, C., 2018. Distill, Vol 3(7). &lt;a href=&quot;https://doi.org/10.23915/distill.00012&quot;&gt;DOI: 10.23915/distill.00012&lt;/a&gt;&lt;/li&gt;
&lt;li id=&quot;Turing_1952&quot;&gt;&lt;span class=&quot;title&quot;&gt;The chemical basis of morphogenesis&lt;/span&gt; ‚ÄÇ&lt;a href=&quot;https://doi.org/10.1098/rstb.1952.0012&quot;&gt;[link]&lt;/a&gt;&lt;br/&gt;Turing, A.M., 1952. Philosophical transactions of the Royal Society of London. Series B, Biological sciences, Vol 237(641), pp. 37‚Äì72. Royal Society. &lt;a href=&quot;https://doi.org/10.1098/rstb.1952.0012&quot;&gt;DOI: 10.1098/rstb.1952.0012&lt;/a&gt;&lt;/li&gt;
&lt;li id=&quot;Marcon_Sharpe_2012&quot;&gt;&lt;span class=&quot;title&quot;&gt;Turing patterns in development: what about the horse part?&lt;/span&gt; ‚ÄÇ&lt;a href=&quot;http://dx.doi.org/10.1016/j.gde.2012.11.013&quot;&gt;[link]&lt;/a&gt;&lt;br/&gt;Marcon, L. and Sharpe, J., 2012. Current opinion in genetics &amp;amp; development, Vol 22(6), pp. 578‚Äì584. &lt;a href=&quot;https://doi.org/10.1016/j.gde.2012.11.013&quot;&gt;DOI: 10.1016/j.gde.2012.11.013&lt;/a&gt;&lt;/li&gt;
&lt;li id=&quot;Schaerli_Munteanu_Gili_Cotterell_Sharpe_Isalan_2014&quot;&gt;&lt;span class=&quot;title&quot;&gt;A unified design space of synthetic stripe-forming networks&lt;/span&gt; ‚ÄÇ&lt;a href=&quot;http://dx.doi.org/10.1038/ncomms5905&quot;&gt;[link]&lt;/a&gt;&lt;br/&gt;Schaerli, Y., Munteanu, A., Gili, M., Cotterell, J., Sharpe, J. and Isalan, M., 2014. Nature communications, Vol 5, pp. 4905. &lt;a href=&quot;https://doi.org/10.1038/ncomms5905&quot;&gt;DOI: 10.1038/ncomms5905&lt;/a&gt;&lt;/li&gt;
&lt;li id=&quot;Hiscock_Tschopp_Tabin_2017&quot;&gt;&lt;span class=&quot;title&quot;&gt;On the Formation of Digits and Joints during Limb Development&lt;/span&gt; ‚ÄÇ&lt;a href=&quot;http://dx.doi.org/10.1016/j.devcel.2017.04.021&quot;&gt;[link]&lt;/a&gt;&lt;br/&gt;Hiscock, T.W., Tschopp, P. and Tabin, C.J., 2017. Developmental cell, Vol 41(5), pp. 459‚Äì465. &lt;a href=&quot;https://doi.org/10.1016/j.devcel.2017.04.021&quot;&gt;DOI: 10.1016/j.devcel.2017.04.021&lt;/a&gt;&lt;/li&gt;
&lt;li id=&quot;Raspopovic_Marcon_Russo_Sharpe_2014&quot;&gt;&lt;span class=&quot;title&quot;&gt;Modeling digits. Digit patterning is controlled by a Bmp-Sox9-Wnt Turing network modulated by morphogen gradients&lt;/span&gt; ‚ÄÇ&lt;a href=&quot;http://dx.doi.org/10.1126/science.1252960&quot;&gt;[link]&lt;/a&gt;&lt;br/&gt;Raspopovic, J., Marcon, L., Russo, L. and Sharpe, J., 2014. Science, Vol 345(6196), pp. 566‚Äì570. &lt;a href=&quot;https://doi.org/10.1126/science.1252960&quot;&gt;DOI: 10.1126/science.1252960&lt;/a&gt;&lt;/li&gt;
&lt;li id=&quot;Landge_Jordan_Diego_M√ºller_2020&quot;&gt;&lt;span class=&quot;title&quot;&gt;Pattern formation mechanisms of self-organizing reaction-diffusion systems&lt;/span&gt; ‚ÄÇ&lt;a href=&quot;http://dx.doi.org/10.1016/j.ydbio.2019.10.031&quot;&gt;[link]&lt;/a&gt;&lt;br/&gt;Landge, A.N., Jordan, B.M., Diego, X. and M√ºller, P., 2020. Developmental biology, Vol 460(1), pp. 2‚Äì11. &lt;a href=&quot;https://doi.org/10.1016/j.ydbio.2019.10.031&quot;&gt;DOI: 10.1016/j.ydbio.2019.10.031&lt;/a&gt;&lt;/li&gt;
&lt;li id=&quot;Pietak_Levin_2017&quot;&gt;&lt;span class=&quot;title&quot;&gt;Bioelectric gene and reaction networks: computational modelling of genetic, biochemical and bioelectrical dynamics in pattern regulation&lt;/span&gt; ‚ÄÇ&lt;a href=&quot;http://dx.doi.org/10.1098/rsif.2017.0425&quot;&gt;[link]&lt;/a&gt;&lt;br/&gt;Pietak, A. and Levin, M., 2017. Journal of the Royal Society, Interface / the Royal Society, Vol 14(134). &lt;a href=&quot;https://doi.org/10.1098/rsif.2017.0425&quot;&gt;DOI: 10.1098/rsif.2017.0425&lt;/a&gt;&lt;/li&gt;
&lt;li id=&quot;Brodsky&quot;&gt;&lt;span class=&quot;title&quot;&gt;Turing-like patterns can arise from purely bioelectric mechanisms&lt;/span&gt; ‚ÄÇ&lt;a href=&quot;http://dx.doi.org/10.1101/336461&quot;&gt;[link]&lt;/a&gt;&lt;br/&gt;Brodsky, M.. Draft. &lt;a href=&quot;https://doi.org/10.1101/336461&quot;&gt;DOI: 10.1101/336461&lt;/a&gt;&lt;/li&gt;
&lt;li id=&quot;Goldbeter_2018&quot;&gt;&lt;span class=&quot;title&quot;&gt;Dissipative structures in biological systems: bistability, oscillations, spatial patterns and waves&lt;/span&gt; ‚ÄÇ&lt;a href=&quot;http://dx.doi.org/10.1098/rsta.2017.0376&quot;&gt;[link]&lt;/a&gt;&lt;br/&gt;Goldbeter, A., 2018. Philosophical transactions. Series A, Mathematical, physical, and engineering sciences, Vol 376(2124). &lt;a href=&quot;https://doi.org/10.1098/rsta.2017.0376&quot;&gt;DOI: 10.1098/rsta.2017.0376&lt;/a&gt;&lt;/li&gt;
&lt;li id=&quot;Isalan_2009&quot;&gt;&lt;span class=&quot;title&quot;&gt;Gene networks and liar paradoxes&lt;/span&gt; ‚ÄÇ&lt;a href=&quot;http://dx.doi.org/10.1002/bies.200900072&quot;&gt;[link]&lt;/a&gt;&lt;br/&gt;Isalan, M., 2009. BioEssays: news and reviews in molecular, cellular and developmental biology, Vol 31(10), pp. 1110‚Äì1115. &lt;a href=&quot;https://doi.org/10.1002/bies.200900072&quot;&gt;DOI: 10.1002/bies.200900072&lt;/a&gt;&lt;/li&gt;
&lt;li id=&quot;Gatys_Ecker_Bethge_2015&quot;&gt;&lt;span class=&quot;title&quot;&gt;Texture Synthesis Using Convolutional Neural Networks&lt;/span&gt; ‚ÄÇ&lt;a href=&quot;http://arxiv.org/pdf/1505.07376.pdf&quot;&gt;[PDF]&lt;/a&gt;&lt;br/&gt;Gatys, L.A., Ecker, A.S. and Bethge, M., 2015. arXiv [cs.CV].&lt;/li&gt;
&lt;li id=&quot;Turing_1990&quot;&gt;&lt;span class=&quot;title&quot;&gt;The chemical basis of morphogenesis. 1953&lt;/span&gt; ‚ÄÇ&lt;a href=&quot;http://dx.doi.org/10.1007/BF02459572&quot;&gt;[link]&lt;/a&gt;&lt;br/&gt;Turing, A.M., 1990. Bulletin of mathematical biology, Vol 52(1-2), pp. 153‚Äì97; discussion 119‚Äì52. &lt;a href=&quot;https://doi.org/10.1007/BF02459572&quot;&gt;DOI: 10.1007/BF02459572&lt;/a&gt;&lt;/li&gt;
&lt;li id=&quot;Lee_McCormick_Ouyang_Swinney_1993&quot;&gt;&lt;span class=&quot;title&quot;&gt;Pattern formation by interacting chemical fronts&lt;/span&gt; ‚ÄÇ&lt;a href=&quot;http://dx.doi.org/10.1126/science.261.5118.192&quot;&gt;[link]&lt;/a&gt;&lt;br/&gt;Lee, K.J., McCormick, W.D., Ouyang, Q. and Swinney, H.L., 1993. Science, Vol 261(5118), pp. 192‚Äì194. &lt;a href=&quot;https://doi.org/10.1126/science.261.5118.192&quot;&gt;DOI: 10.1126/science.261.5118.192&lt;/a&gt;&lt;/li&gt;
&lt;li id=&quot;Pearson_1993&quot;&gt;&lt;span class=&quot;title&quot;&gt;Complex patterns in a simple system&lt;/span&gt; ‚ÄÇ&lt;a href=&quot;http://dx.doi.org/10.1126/science.261.5118.189&quot;&gt;[link]&lt;/a&gt;&lt;br/&gt;Pearson, J.E., 1993. Science, Vol 261(5118), pp. 189‚Äì192. &lt;a href=&quot;https://doi.org/10.1126/science.261.5118.189&quot;&gt;DOI: 10.1126/science.261.5118.189&lt;/a&gt;&lt;/li&gt;
&lt;li id=&quot;Simonyan_Zisserman_2014&quot;&gt;&lt;span class=&quot;title&quot;&gt;Very Deep Convolutional Networks for Large-Scale Image Recognition&lt;/span&gt; ‚ÄÇ&lt;a href=&quot;http://arxiv.org/pdf/1409.1556.pdf&quot;&gt;[PDF]&lt;/a&gt;&lt;br/&gt;Simonyan, K. and Zisserman, A., 2014. arXiv [cs.CV].&lt;/li&gt;
&lt;li id=&quot;Kingma_Ba_2014&quot;&gt;&lt;span class=&quot;title&quot;&gt;Adam: A Method for Stochastic Optimization&lt;/span&gt; ‚ÄÇ&lt;a href=&quot;http://arxiv.org/pdf/1412.6980.pdf&quot;&gt;[PDF]&lt;/a&gt;&lt;br/&gt;Kingma, D.P. and Ba, J., 2014. arXiv [cs.LG].&lt;/li&gt;
&lt;li id=&quot;Cimpoi_Maji_Kokkinos_Mohamed_Vedaldi_2013&quot;&gt;&lt;span class=&quot;title&quot;&gt;Describing Textures in the Wild&lt;/span&gt; ‚ÄÇ&lt;a href=&quot;http://arxiv.org/pdf/1311.3618.pdf&quot;&gt;[PDF]&lt;/a&gt;&lt;br/&gt;Cimpoi, M., Maji, S., Kokkinos, I., Mohamed, S. and Vedaldi, A., 2013. arXiv [cs.CV].&lt;/li&gt;
&lt;li id=&quot;Bhushan_Rao_Lohse_1997&quot;&gt;&lt;span class=&quot;title&quot;&gt;The texture lexicon: Understanding the categorization of visual texture terms and their relationship to texture images&lt;/span&gt; ‚ÄÇ&lt;a href=&quot;http://doi.wiley.com/10.1207/s15516709cog2102_4&quot;&gt;[link]&lt;/a&gt;&lt;br/&gt;Bhushan, N., Rao, A.R. and Lohse, G.L., 1997. Cognitive science, Vol 21(2), pp. 219‚Äì246. Wiley. &lt;a href=&quot;https://doi.org/10.1207/s15516709cog2102_4&quot;&gt;DOI: 10.1207/s15516709cog2102_4&lt;/a&gt;&lt;/li&gt;
&lt;li id=&quot;Pezzulo_Levin_2015&quot;&gt;&lt;span class=&quot;title&quot;&gt;Re-membering the body: applications of computational neuroscience to the top-down control of regeneration of limbs and other complex organs&lt;/span&gt; ‚ÄÇ&lt;a href=&quot;http://dx.doi.org/10.1039/c5ib00221d&quot;&gt;[link]&lt;/a&gt;&lt;br/&gt;Pezzulo, G. and Levin, M., 2015. Integrative biology: quantitative biosciences from nano to macro, Vol 7(12), pp. 1487‚Äì1517. &lt;a href=&quot;https://doi.org/10.1039/c5ib00221d&quot;&gt;DOI: 10.1039/c5ib00221d&lt;/a&gt;&lt;/li&gt;
&lt;li id=&quot;Speman_1938&quot;&gt;&lt;span class=&quot;title&quot;&gt;Embryonic Development and Induction&lt;/span&gt; ‚ÄÇ&lt;a href=&quot;http://dx.doi.org/10.1097/00000441-193811000-00047&quot;&gt;[link]&lt;/a&gt;&lt;br/&gt;Speman, H., 1938. The American Journal of the Medical Sciences, Vol 196(5), pp. 738. &lt;a href=&quot;https://doi.org/10.1097/00000441-193811000-00047&quot;&gt;DOI: 10.1097/00000441-193811000-00047&lt;/a&gt;&lt;/li&gt;
&lt;li id=&quot;Grossberg_1978&quot;&gt;&lt;span class=&quot;title&quot;&gt;Communication, Memory, and Development&lt;/span&gt; ‚ÄÇ&lt;a href=&quot;https://linkinghub.elsevier.com/retrieve/pii/B9780125431057500129&quot;&gt;[link]&lt;/a&gt;&lt;br/&gt;Grossberg, S., 1978. Progress in Theoretical Biology, pp. 183‚Äì232. Elsevier. &lt;a href=&quot;https://doi.org/10.1016/b978-0-12-543105-7.50012-9&quot;&gt;DOI: 10.1016/b978-0-12-543105-7.50012-9&lt;/a&gt;&lt;/li&gt;
&lt;li id=&quot;Gumin&quot;&gt;&lt;span class=&quot;title&quot;&gt;WaveFunctionCollapse&lt;/span&gt; ‚ÄÇ&lt;a href=&quot;https://github.com/mxgmn/WaveFunctionCollapse&quot;&gt;[link]&lt;/a&gt;&lt;br/&gt;Gumin, M.. Github.&lt;/li&gt;
&lt;li id=&quot;Ulyanov_Lebedev_Vedaldi_Lempitsky_2016&quot;&gt;&lt;span class=&quot;title&quot;&gt;Texture Networks: Feed-forward Synthesis of Textures and Stylized Images&lt;/span&gt; ‚ÄÇ&lt;a href=&quot;http://arxiv.org/pdf/1603.03417.pdf&quot;&gt;[PDF]&lt;/a&gt;&lt;br/&gt;Ulyanov, D., Lebedev, V., Vedaldi, A. and Lempitsky, V., 2016. arXiv [cs.CV].&lt;/li&gt;
&lt;li id=&quot;Xian_Sangkloy_Agrawal_Raj_Lu_Fang_Yu_Hays_2018&quot;&gt;&lt;span class=&quot;title&quot;&gt;TextureGAN: Controlling deep image synthesis with texture patches&lt;/span&gt; ‚ÄÇ&lt;a href=&quot;https://openaccess.thecvf.com/content_cvpr_2018/papers/Xian_TextureGAN_Controlling_Deep_CVPR_2018_paper.pdf&quot;&gt;[PDF]&lt;/a&gt;&lt;br/&gt;Xian, W., Sangkloy, P., Agrawal, V., Raj, A., Lu, J., Fang, C., Yu, F. and Hays, J., 2018. 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. IEEE. &lt;a href=&quot;https://doi.org/10.1109/cvpr.2018.00882&quot;&gt;DOI: 10.1109/cvpr.2018.00882&lt;/a&gt;&lt;/li&gt;
&lt;li id=&quot;Reynolds_2011&quot;&gt;&lt;span class=&quot;title&quot;&gt;Interactive evolution of camouflage&lt;/span&gt; ‚ÄÇ&lt;a href=&quot;http://dx.doi.org/10.1162/artl_a_00023&quot;&gt;[link]&lt;/a&gt;&lt;br/&gt;Reynolds, C., 2011. Artificial life, Vol 17(2), pp. 123‚Äì136. &lt;a href=&quot;https://doi.org/10.1162/artl_a_00023&quot;&gt;DOI: 10.1162/artl_a_00023&lt;/a&gt;&lt;/li&gt;
&lt;li id=&quot;Portilla_Simoncelli_2000&quot;&gt;&lt;span class=&quot;title&quot;&gt;A parametric texture model based on joint statistics of complex wavelet coefficients&lt;/span&gt; ‚ÄÇ&lt;a href=&quot;https://www.cns.nyu.edu/pub/eero/portilla99-reprint.pdf&quot;&gt;[PDF]&lt;/a&gt;&lt;br/&gt;Portilla, J. and Simoncelli, E.P., 2000.&lt;/li&gt;
&lt;li id=&quot;Chen_Pock_2017&quot;&gt;&lt;span class=&quot;title&quot;&gt;Trainable Nonlinear Reaction Diffusion: A Flexible Framework for Fast and Effective Image Restoration&lt;/span&gt; ‚ÄÇ&lt;a href=&quot;http://dx.doi.org/10.1109/TPAMI.2016.2596743&quot;&gt;[link]&lt;/a&gt;&lt;br/&gt;Chen, Y. and Pock, T., 2017. IEEE transactions on pattern analysis and machine intelligence, Vol 39(6), pp. 1256‚Äì1272. &lt;a href=&quot;https://doi.org/10.1109/TPAMI.2016.2596743&quot;&gt;DOI: 10.1109/TPAMI.2016.2596743&lt;/a&gt;&lt;/li&gt;
&lt;li id=&quot;Kodandaramaiah_2011&quot;&gt;&lt;span class=&quot;title&quot;&gt;The evolutionary significance of butterfly eyespots&lt;/span&gt; ‚ÄÇ&lt;a href=&quot;https://www.researchgate.net/publication/227464385_The_evolutionary_significance_of_butterfly_eyespots&quot;&gt;[link]&lt;/a&gt;&lt;br/&gt;Kodandaramaiah, U., 2011. Behavioral ecology: official journal of the International Society for Behavioral Ecology, Vol 22(6), pp. 1264‚Äì1271. Oxford University Press (OUP). &lt;a href=&quot;https://doi.org/10.1093/beheco/arr123&quot;&gt;DOI: 10.1093/beheco/arr123&lt;/a&gt;&lt;/li&gt;
&lt;li id=&quot;Ohno_Otaki_2015&quot;&gt;&lt;span class=&quot;title&quot;&gt;Live Cell Imaging of Butterfly Pupal and Larval Wings In Vivo&lt;/span&gt; ‚ÄÇ&lt;a href=&quot;http://dx.doi.org/10.1371/journal.pone.0128332&quot;&gt;[link]&lt;/a&gt;&lt;br/&gt;Ohno, Y. and Otaki, J.M., 2015. PloS one, Vol 10(6), pp. e0128332. &lt;a href=&quot;https://doi.org/10.1371/journal.pone.0128332&quot;&gt;DOI: 10.1371/journal.pone.0128332&lt;/a&gt;&lt;/li&gt;
&lt;li id=&quot;Iwata_Otaki_2016&quot;&gt;&lt;span class=&quot;title&quot;&gt;Focusing on butterfly eyespot focus: uncoupling of white spots from eyespot bodies in nymphalid butterflies&lt;/span&gt; ‚ÄÇ&lt;a href=&quot;http://dx.doi.org/10.1186/s40064-016-2969-8&quot;&gt;[link]&lt;/a&gt;&lt;br/&gt;Iwata, M. and Otaki, J.M., 2016. SpringerPlus, Vol 5(1), pp. 1287. &lt;a href=&quot;https://doi.org/10.1186/s40064-016-2969-8&quot;&gt;DOI: 10.1186/s40064-016-2969-8&lt;/a&gt;&lt;/li&gt;
&lt;li id=&quot;Schubert_Petrov_Carter_Cammarata_Goh_Olah_2020&quot;&gt;&lt;span class=&quot;title&quot;&gt;OpenAI Microscope&lt;/span&gt; ‚ÄÇ&lt;a href=&quot;https://openai.com/blog/microscope/&quot;&gt;[link]&lt;/a&gt;&lt;br/&gt;Schubert, L., Petrov, M., Carter, S., Cammarata, N., Goh, G. and Olah, C., 2020. OpenAI.&lt;/li&gt;
&lt;li id=&quot;Boettiger_Ermentrout_Oster_2009&quot;&gt;&lt;span class=&quot;title&quot;&gt;The neural origins of shell structure and pattern in aquatic mollusks&lt;/span&gt; ‚ÄÇ&lt;a href=&quot;http://dx.doi.org/10.1073/pnas.0810311106&quot;&gt;[link]&lt;/a&gt;&lt;br/&gt;Boettiger, A., Ermentrout, B. and Oster, G., 2009. Proceedings of the National Academy of Sciences of the United States of America, Vol 106(16), pp. 6837‚Äì6842. &lt;a href=&quot;https://doi.org/10.1073/pnas.0810311106&quot;&gt;DOI: 10.1073/pnas.0810311106&lt;/a&gt;&lt;/li&gt;
&lt;li id=&quot;Boettiger_Oster_2009&quot;&gt;&lt;span class=&quot;title&quot;&gt;Emergent complexity in simple neural systems&lt;/span&gt; ‚ÄÇ&lt;a href=&quot;http://dx.doi.org/10.4161/cib.2.6.9260&quot;&gt;[link]&lt;/a&gt;&lt;br/&gt;Boettiger, A.N. and Oster, G., 2009. Communicative &amp;amp; integrative biology, Vol 2(6), pp. 467‚Äì470. &lt;a href=&quot;https://doi.org/10.4161/cib.2.6.9260&quot;&gt;DOI: 10.4161/cib.2.6.9260&lt;/a&gt;&lt;/li&gt;
&lt;li id=&quot;szegedy2015going&quot;&gt;&lt;span class=&quot;title&quot;&gt;Going deeper with convolutions&lt;/span&gt; ‚ÄÇ&lt;a href=&quot;https://arxiv.org/pdf/1409.4842.pdf&quot;&gt;[PDF]&lt;/a&gt;&lt;br/&gt;Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Vanhoucke, V. and Rabinovich, A., 2015. Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 1--9.&lt;/li&gt;
&lt;li id=&quot;Risser_Wilmot_Barnes_2017&quot;&gt;&lt;span class=&quot;title&quot;&gt;Stable and Controllable Neural Texture Synthesis and Style Transfer Using Histogram Losses&lt;/span&gt; ‚ÄÇ&lt;a href=&quot;http://arxiv.org/pdf/1701.08893.pdf&quot;&gt;[PDF]&lt;/a&gt;&lt;br/&gt;Risser, E., Wilmot, P. and Barnes, C., 2017. arXiv [cs.GR].&lt;/li&gt;
&lt;li id=&quot;Hadden_Young_2017&quot;&gt;&lt;span class=&quot;title&quot;&gt;Stem cell migration and mechanotransduction on linear stiffness gradient hydrogels&lt;/span&gt; ‚ÄÇ&lt;a href=&quot;http://dx.doi.org/10.1073/pnas.1618239114&quot;&gt;[link]&lt;/a&gt;&lt;br/&gt;Hadden, W.J., Young, J.L., Holle, A.W., McFetridge, M.L., Kim, D.Y., Wijesinghe, P., Taylor-Weiner, H., Wen, J.H., Lee, A.R., Bieback, K. and al., e., 2017. Proceedings of the National Academy of Sciences of the United States of America, Vol 114(22), pp. 5647‚Äì5652. &lt;a href=&quot;https://doi.org/10.1073/pnas.1618239114&quot;&gt;DOI: 10.1073/pnas.1618239114&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;updates-and-corrections&quot;&gt;Updates and Corrections&lt;/h3&gt;
&lt;p&gt;If you see mistakes or want to suggest changes, please &lt;a href=&quot;https://github.com/distillpub/post--selforg-textures/issues/new&quot;&gt;create an issue on GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&quot;reuse&quot;&gt;Reuse&lt;/h3&gt;
&lt;p&gt;Diagrams and text are licensed under Creative Commons Attribution &lt;a href=&quot;https://creativecommons.org/licenses/by/4.0/&quot;&gt;CC-BY 4.0&lt;/a&gt; with the &lt;a class=&quot;github&quot; href=&quot;https://github.com/distillpub/post--selforg-textures&quot;&gt;source available on GitHub&lt;/a&gt;, unless noted otherwise. The figures that have been reused from other sources don‚Äôt fall under this license and can be recognized by a note in their caption: ‚ÄúFigure from ‚Ä¶‚Äù.&lt;/p&gt;
&lt;h3 id=&quot;citation&quot;&gt;Citation&lt;/h3&gt;
&lt;p&gt;For attribution in academic contexts, please cite this work as&lt;/p&gt;
&lt;pre class=&quot;citation short&quot;&gt;
Niklasson, et al., &quot;Self-Organising Textures&quot;, Distill, 2021.
&lt;/pre&gt;
&lt;p&gt;BibTeX citation&lt;/p&gt;
&lt;pre class=&quot;citation long&quot;&gt;
@article{niklasson2021self-organising,
  author = {Niklasson, Eyvind and Mordvintsev, Alexander and Randazzo, Ettore and Levin, Michael},
  title = {Self-Organising Textures},
  journal = {Distill},
  year = {2021},
  note = {https://distill.pub/selforg/2021/textures},
  doi = {10.23915/distill.00027.003}
}
&lt;/pre&gt;

&lt;/body&gt;</description>
<pubDate>Fri, 12 Feb 2021 12:34:05 +0000</pubDate>
<dc:creator>fenomas</dc:creator>
<og:type>article</og:type>
<og:title>Self-Organising Textures</og:title>
<og:description>Neural Cellular Automata learn to generate textures, exhibiting surprising properties.</og:description>
<og:url>https://distill.pub/selforg/2021/textures</og:url>
<og:image>https://distill.pub/selforg/2021/textures/thumbnail.jpg</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://distill.pub/selforg/2021/textures/</dc:identifier>
</item>
<item>
<title>Chick Corea has died</title>
<link>https://chickcorea.com/</link>
<guid isPermaLink="true" >https://chickcorea.com/</guid>
<description>&lt;div id=&quot;cs-content&quot; class=&quot;cs-content&quot;&gt;
&lt;div class=&quot;e245-1 x-section&quot;&gt;
&lt;div class=&quot;e245-2 x-container&quot;&gt;

&lt;div class=&quot;e245-5 x-column x-sm x-1-3&quot;&gt;

&lt;div class=&quot;e245-7 x-text&quot;&gt;Introducing an exclusive documentary special taking viewers behind the scenes with Grammy Award-winning jazz legend, Chick Corea and the making of ‚ÄúThe Spanish Heart Band ‚Äì Antidote‚Äù album. An unprecedented, intimate look featuring stories and explorations from his remarkable career.&lt;/div&gt;
&lt;div class=&quot;e245-8 x-bar-content-area&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://found.ee/ChickCoreaGrammy26&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Attend the Screening&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;e245-9 x-container x-hide-lg x-hide-md x-hide-sm x-hide-xl x-hide-xs&quot;&gt;
&lt;div class=&quot;e245-10 x-column x-sm x-2-3&quot;&gt;
&lt;div class=&quot;e245-11 x-bar-content-area&quot;&gt;

&lt;img src=&quot;https://chickcorea.com/wp-content/uploads/2019/01/Trilogy-2019-Web-Banner.jpg&quot; title=&quot;Homepage&quot; data-bg=&quot;f:contain;&quot; class=&quot;rev-slidebg&quot; data-no-retina=&quot;&quot;/&gt;&lt;h2&gt;The New Chick Corea Trio Album: Trilogy 2&lt;/h2&gt;
&lt;br/&gt;&lt;h3&gt;with Christian McBride and Brian Blade | Read more&lt;/h3&gt;
&lt;img src=&quot;https://chickcorea.com/wp-content/uploads/2019/07/Chick-Corea-SpHB-Homepage-Banner.jpg&quot; title=&quot;Homepage&quot; data-bg=&quot;f:contain;&quot; class=&quot;rev-slidebg&quot; data-no-retina=&quot;&quot;/&gt;&lt;h2&gt;Brand-New Studio Album! Watch the video &amp;gt;&amp;gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;e245-12 x-column x-sm x-1-3&quot;&gt;

&lt;div class=&quot;e245-14 x-text&quot;&gt;Get tour schedules, insider-only merch deals and &amp;amp; more!&lt;/div&gt;
&lt;div class=&quot;e245-15 x-bar-content-area&quot;&gt;&lt;a href=&quot;https://chick-corea.lpages.co/leadbox/145f1cd73f72a2%3A11ce83b9ab46dc/5649050225344512/&quot; target=&quot;_blank&quot;&gt;HOOK ME UP!&lt;/a&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;e245-19 x-container&quot;&gt;
&lt;div class=&quot;e245-20 x-column x-sm x-1-3&quot;&gt;
&lt;blockquote class=&quot;e245-21 x-quote&quot;&gt;
&lt;div class=&quot;x-quote-content&quot;&gt;
&lt;div class=&quot;x-quote-text&quot;&gt;A luminary, ebullient and eternally youthful.&lt;/div&gt;
&lt;footer class=&quot;x-quote-cite&quot;&gt;&lt;span class=&quot;x-quote-cite-text&quot;&gt;The New York Times&lt;/span&gt;&lt;/footer&gt;&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&quot;e245-22 x-column x-sm x-1-3&quot;&gt;
&lt;blockquote class=&quot;e245-23 x-quote&quot;&gt;
&lt;div class=&quot;x-quote-content&quot;&gt;
&lt;div class=&quot;x-quote-text&quot;&gt;A venerated maestro.&lt;/div&gt;
&lt;footer class=&quot;x-quote-cite&quot;&gt;&lt;span class=&quot;x-quote-cite-text&quot;&gt;BBC&lt;/span&gt;&lt;/footer&gt;&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&quot;e245-24 x-column x-sm x-1-3&quot;&gt;
&lt;blockquote class=&quot;e245-25 x-quote&quot;&gt;
&lt;div class=&quot;x-quote-content&quot;&gt;
&lt;div class=&quot;x-quote-text&quot;&gt;Gale force intensity, gloriously impassioned.&lt;/div&gt;
&lt;footer class=&quot;x-quote-cite&quot;&gt;&lt;span class=&quot;x-quote-cite-text&quot;&gt;Jazzwise Magazine&lt;/span&gt;&lt;/footer&gt;&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class=&quot;e245-29 x-section&quot;&gt;

&lt;div class=&quot;e245-33 x-container&quot;&gt;
&lt;div class=&quot;e245-34 x-column x-sm x-1-3&quot;&gt;&lt;span class=&quot;e245-35 x-image&quot;&gt;&lt;img alt=&quot;Image&quot; src=&quot;https://chickcorea.com/wp-content/uploads/2015/01/1o1-ad300x200.jpg&quot; width=&quot;300&quot; height=&quot;200&quot;/&gt;&lt;/span&gt;
&lt;div class=&quot;e245-36 x-text x-text-headline&quot;&gt;
&lt;div class=&quot;x-text-content&quot;&gt;
&lt;div class=&quot;x-text-content-text&quot;&gt;
&lt;h2 class=&quot;x-text-content-text-primary&quot;&gt;One-on-One with Chick Corea&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;e245-37 x-text&quot;&gt;
&lt;p&gt;An intimate online video workshop series, created and presented by Chick.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;e245-38 x-column x-sm x-1-3&quot;&gt;&lt;span class=&quot;e245-39 x-image&quot;&gt;&lt;img alt=&quot;Image&quot; src=&quot;https://chickcorea.com/wp-content/uploads/2013/06/podcast.jpg&quot; width=&quot;300&quot; height=&quot;200&quot;/&gt;&lt;/span&gt;
&lt;div class=&quot;e245-40 x-text x-text-headline&quot;&gt;
&lt;div class=&quot;x-text-content&quot;&gt;
&lt;div class=&quot;x-text-content-text&quot;&gt;
&lt;h2 class=&quot;x-text-content-text-primary&quot;&gt;Music Magic Podcasts&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;e245-41 x-text&quot;&gt;
&lt;p&gt;Chick talks with musicians and friends about the inner workings of the musical universe.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;e245-42 x-column x-sm x-1-3&quot;&gt;&lt;span class=&quot;e245-43 x-image&quot;&gt;&lt;img alt=&quot;Image&quot; src=&quot;https://chickcorea.com/wp-content/uploads/2015/01/songbook.jpg&quot; width=&quot;300&quot; height=&quot;200&quot;/&gt;&lt;/span&gt;
&lt;div class=&quot;e245-44 x-text x-text-headline&quot;&gt;
&lt;div class=&quot;x-text-content&quot;&gt;
&lt;div class=&quot;x-text-content-text&quot;&gt;
&lt;h2 class=&quot;x-text-content-text-primary&quot;&gt;The Vigil Songbook&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;e245-45 x-text&quot;&gt;
&lt;p&gt;Chick‚Äôs own charts from 7 original tunes off his acclaimed 2013 album, &lt;em&gt;The Vigil&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class=&quot;e245-49 x-section&quot;&gt;
&lt;div class=&quot;e245-50 x-container&quot;&gt;
&lt;div class=&quot;e245-51 x-column x-sm x-1-2&quot;&gt;

&lt;div class=&quot;e245-53 x-bar-content-area&quot;&gt;
&lt;div class=&quot;tg-grid-wrapper ccp-posts tg-txt&quot; id=&quot;grid-4224&quot; data-version=&quot;2.7.1&quot;&gt;


&lt;div class=&quot;tg-grid-holder tg-layout-masonry&quot; data-name=&quot;Recent Blog Posts&quot; data-style=&quot;masonry&quot; data-row=&quot;1&quot; data-layout=&quot;vertical&quot; data-rtl=&quot;&quot; data-fitrows=&quot;&quot; data-filtercomb=&quot;&quot; data-filterlogic=&quot;AND&quot; data-filterload=&quot;&quot; data-sortbyload=&quot;&quot; data-orderload=&quot;false&quot; data-fullwidth=&quot;&quot; data-fullheight=&quot;null&quot; data-gutters=&quot;[[320,8],[480,8],[768,8],[980,8],[1200,8],[9999,8]]&quot; data-slider=&quot;{&amp;quot;itemNav&amp;quot;:&amp;quot;null&amp;quot;,&amp;quot;swingSpeed&amp;quot;:0.1,&amp;quot;cycleBy&amp;quot;:&amp;quot;null&amp;quot;,&amp;quot;cycle&amp;quot;:5000,&amp;quot;startAt&amp;quot;:1}&quot; data-ratio=&quot;1.78&quot; data-cols=&quot;[[320,1],[480,1],[768,1],[980,1],[1200,1],[9999,1]]&quot; data-rows=&quot;[[320,200],[480,200],[768,220],[980,220],[1200,240],[9999,240]]&quot; data-animation=&quot;{&amp;quot;name&amp;quot;:&amp;quot;Fade in&amp;quot;,&amp;quot;visible&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;hidden&amp;quot;:&amp;quot;&amp;quot;}&quot; data-transition=&quot;700ms&quot; data-ajaxmethod=&quot;load_more&quot; data-ajaxdelay=&quot;100&quot; data-preloader=&quot;&quot; data-itemdelay=&quot;100&quot; data-gallery=&quot;&quot; data-ajax=&quot;&quot;&gt;
&lt;article class=&quot;tg-item tg-post-5556 tg-recent-posts f121 f86&quot; data-row=&quot;1&quot; data-col=&quot;1&quot;&gt;&lt;div class=&quot;tg-item-inner&quot;&gt;

&lt;div class=&quot;tg-item-content-holder tg-dark image-format&quot; data-position=&quot;bottom&quot;&gt;

&lt;p class=&quot;tg-item-excerpt tg-element-2&quot;&gt;It‚Äôs been a few months, but we‚Äôre officially back on the road! When we last left off, Chick had finished a couple orchestral gigs in the Pacific Northwest with the Seattle and Portland Symphony Orchestras and...&lt;/p&gt;


&lt;/div&gt;
&lt;/div&gt;
&lt;/article&gt;&lt;article class=&quot;tg-item tg-post-5312 tg-recent-posts f121 f86&quot; data-row=&quot;1&quot; data-col=&quot;1&quot;&gt;&lt;div class=&quot;tg-item-inner&quot;&gt;

&lt;div class=&quot;tg-item-content-holder tg-dark image-format&quot; data-position=&quot;bottom&quot;&gt;

&lt;p class=&quot;tg-item-excerpt tg-element-2&quot;&gt;Hi all, With the finish line in sight, Trilogy wrapped up the final week of their North American Tour in flying colors ‚Äî spanning 7 different cities in 9 days! The balmy port town of Wilmington, NC was first...&lt;/p&gt;


&lt;/div&gt;
&lt;/div&gt;
&lt;/article&gt;&lt;article class=&quot;tg-item tg-post-5039 tg-recent-posts f121 f86&quot; data-row=&quot;1&quot; data-col=&quot;1&quot;&gt;&lt;div class=&quot;tg-item-inner&quot;&gt;

&lt;div class=&quot;tg-item-content-holder tg-dark image-format&quot; data-position=&quot;bottom&quot;&gt;

&lt;p class=&quot;tg-item-excerpt tg-element-2&quot;&gt;Hi all! The Trilogy tour continues to roll right along through North America ‚Äì this week hitting three separate college campuses across 1,900 miles! Starting where we last left off ‚Äì in Boulder, CO ‚Äì the group...&lt;/p&gt;


&lt;/div&gt;
&lt;/div&gt;
&lt;/article&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;e245-54 x-column x-sm x-1-2&quot;&gt;

&lt;div class=&quot;e245-56 x-bar-content-area&quot;&gt;&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/ABvAt58iN_k&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;[embedded content]&lt;/iframe&gt;&lt;/div&gt;

&lt;div class=&quot;e245-58 x-bar-content-area&quot;&gt;&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/xrGtuXCIBe0&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;[embedded content]&lt;/iframe&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
</description>
<pubDate>Fri, 12 Feb 2021 06:35:04 +0000</pubDate>
<dc:creator>rock_artist</dc:creator>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://chickcorea.com/</dc:identifier>
</item>
<item>
<title>Apple redirects Google Safe Browsing traffic through proxy servers in iOS 14.5</title>
<link>https://the8-bit.com/apple-proxies-google-safe-browsing-privacy/</link>
<guid isPermaLink="true" >https://the8-bit.com/apple-proxies-google-safe-browsing-privacy/</guid>
<description>&lt;p&gt;&lt;strong&gt;Update 1:58 AM PT:&lt;/strong&gt; &lt;em&gt;Updated the post to clear confusion about how Google‚Äôs Safe Browsing feature works.&lt;/em&gt;&lt;/p&gt;
&lt;hr class=&quot;wp-block-separator is-cnvs-separator-id-1613071543086&quot;/&gt;&lt;p&gt;Apple‚Äôs privacy push is much more widespread than it seems at the surface. A perfect example is the new privacy feature in &lt;a href=&quot;https://the8-bit.com/ios-14-5-changes/&quot; class=&quot;rank-math-link&quot;&gt;iOS 14.5 Beta 1 (V2)&lt;/a&gt; which redirects Google Safe Browsing traffic through Apple‚Äôs own proxy servers to enhance users‚Äô privacy and to not let Google see your IP address. &lt;/p&gt;
&lt;p&gt;Google Safe Browsing is a security service created by Google that checks whether a website is malicious. When you access a website on the desktop version of Chrome on your Mac or PC, for instance, Google Safe Browsing checks if a website is safe to browse and displays a warning accordingly. The user ultimately has the choice, however.&lt;/p&gt;
&lt;p&gt;As Reddit user u/jaydenkieran explains, Apple uses Google Safe Browsing when you enable ‚ÄúFraudulent Website Warning‚Äù within the Safari settings in the Settings app on iPhone or iPad.&lt;/p&gt;
&lt;p&gt;&lt;a aria-label=&quot;According to Google (opens in a new tab)&quot; href=&quot;https://support.google.com/transparencyreport/answer/7380435?hl=en#zippy=%2Chow-do-you-determine-that-a-site-is-unsafe&quot; target=&quot;_blank&quot; rel=&quot;noreferrer noopener&quot; class=&quot;rank-math-link&quot;&gt;According to Google&lt;/a&gt;, its Safe Browsing system works by scanning sections of Google‚Äôs web index and ‚Äúidentifying potentially compromised websites.‚Äù Then, Google tests those websites by using a virtual machine to check if the website compromises the system. If it does, it‚Äôs added to Google‚Äôs online database. Google also identifies phishing websites by using statistical models. &lt;/p&gt;
&lt;p&gt;&lt;a aria-label=&quot;According to Apple (opens in a new tab)&quot; href=&quot;https://support.apple.com/en-ae/HT210675&quot; target=&quot;_blank&quot; rel=&quot;noreferrer noopener&quot; class=&quot;rank-math-link&quot;&gt;According to Apple&lt;/a&gt;, before visiting a website, Safari may send hashed prefixes of the URL (Apple terms it ‚Äúinformation calculated from the website address‚Äù) to Google Safe Browsing to check if there‚Äôs a match. &lt;/p&gt;
&lt;p&gt;Since Apple uses a hashed prefix, Google cannot learn which website the user is trying to visit. Up until iOS 14.5, Google could also see the IP address of where that request is coming from. However, since Apple now proxies Google Safe Browsing traffic, it further safeguards users‚Äô privacy while browsing using Safari.&lt;/p&gt;
&lt;p&gt;Apple has been intensifying its push for privacy with iOS 14 what with the &lt;a href=&quot;https://the8-bit.com/app-tracking-transparency-guide/&quot; class=&quot;rank-math-link&quot;&gt;App Tracking Transparency update and the inclusion of App Privacy Reports in the App Store&lt;/a&gt;. &lt;/p&gt;&lt;div class=&quot;inline-post clearfix&quot;&gt;&lt;p&gt;See also&lt;/p&gt;&lt;div id=&quot;block-wrap-72229&quot; class=&quot;block-wrap-native block-wrap block-wrap-23 block-css-72229 block-wrap-classic columns__m--1 elements-design-2 block-ani block-skin-0 tipi-box rounded-corners block-wrap-thumbnail ppl-m-1 clearfix&quot; data-id=&quot;72229&quot; data-base=&quot;0&quot;&gt;&lt;div class=&quot;tipi-row-inner-style clearfix&quot;&gt;&lt;div class=&quot;tipi-row-inner-box contents sticky--wrap&quot;&gt;&lt;div class=&quot;block block-23 clearfix&quot;&gt;&lt;article class=&quot;tipi-xs-12 clearfix with-fi ani-base tipi-xs-typo split-1 split-design-1 loop-0 preview-thumbnail preview-23 elements-design-2 post-18470 post type-post status-publish format-standard has-post-thumbnail hentry category-software tag-news mv-content-wrapper&quot;&gt;&lt;div class=&quot;preview-mini-wrap clearfix&quot;&gt;&lt;div class=&quot;mask&quot;&gt;&lt;a href=&quot;https://the8-bit.com/icloud-passwords-chrome-extension-now-available/&quot; class=&quot;mask-img&quot; title=&quot;New_Step_4&quot;&gt;&lt;img width=&quot;100&quot; height=&quot;100&quot; src=&quot;https://the8-bit.com/wp-content/uploads/2021/02/New_Step_4-100x100.jpg&quot; class=&quot;attachment-thumbnail size-thumbnail wp-post-image&quot; alt=&quot;New Step 4&quot; srcset=&quot;https://the8-bit.com/wp-content/uploads/2021/02/New_Step_4-100x100.jpg 100w, https://the8-bit.com/wp-content/uploads/2021/02/New_Step_4-80x80.jpg 80w, https://the8-bit.com/wp-content/uploads/2021/02/New_Step_4-293x293.jpg 293w, https://the8-bit.com/wp-content/uploads/2021/02/New_Step_4-752x752.jpg 752w, https://the8-bit.com/wp-content/uploads/2021/02/New_Step_4-849x849.jpg 849w, https://the8-bit.com/wp-content/uploads/2021/02/New_Step_4-1044x1044.jpg 1044w&quot; sizes=&quot;(max-width: 100px) 100vw, 100px&quot;/&gt;&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/article&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;At the same time, companies like Facebook are actively opposing the Cupertino giant, accusing it of negatively affecting the advertising industry. Apple‚Äôs response has been simple: &lt;/p&gt;
&lt;p class=&quot;has-background&quot;&gt;‚ÄúWe believe that this is a simple matter of standing up for our users. Users should know when their data is being collected and shared across other apps and websites ‚Äî and they should have the choice to allow that or not. App Tracking Transparency in iOS 14 does not require Facebook to change its approach to tracking users and creating targeted advertising, it simply requires they give users a choice.‚Äù &lt;/p&gt;
&lt;p&gt;Google itself &lt;a href=&quot;https://appleinsider.com/articles/21/02/04/google-still-hasnt-updated-its-ios-apps-while-pondering-android-privacy-controls&quot; target=&quot;_blank&quot; aria-label=&quot;had been holding off (opens in a new tab)&quot; rel=&quot;noreferrer noopener&quot; class=&quot;rank-math-link&quot;&gt;had been holding off&lt;/a&gt; on updating its host of apps on the App Store due to the App Privacy Health Reports in the App Store that lets users view how an app tracks them. However, Google later disclosed that it will update its apps to include as little tracking as possible.&lt;/p&gt;
&lt;p&gt;Having said that, it‚Äôs interesting to see Apple focus on enhancing user privacy as much as they can. And setting up a proxy server to filter Google Safe Browsing traffic just so Google cannot users‚Äô browsing activity will be a welcome move for a lot of users.&lt;/p&gt;
</description>
<pubDate>Fri, 12 Feb 2021 05:07:03 +0000</pubDate>
<dc:creator>CharlesW</dc:creator>
<og:type>article</og:type>
<og:title>Apple redirects Google Safe Browsing traffic through its own proxy servers to prevent disclosing users' IP addresses to Google in iOS 14.5</og:title>
<og:description>Update 1:58 AM PT: Updated the post to clear confusion about how Google's Safe Browsing feature works.</og:description>
<og:url>https://the8-bit.com/apple-proxies-google-safe-browsing-privacy/</og:url>
<og:image>https://the8-bit.com/wp-content/uploads/2021/02/safebrowsing.jpg</og:image>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://the8-bit.com/apple-proxies-google-safe-browsing-privacy/</dc:identifier>
</item>
<item>
<title>Computer Networks: A Systems Approach</title>
<link>https://book.systemsapproach.org/</link>
<guid isPermaLink="true" >https://book.systemsapproach.org/</guid>
<description>&lt;a class=&quot;reference external image-reference&quot; href=&quot;https://systemsapproach.org&quot;&gt;&lt;img alt=&quot;_images/SystemsApproachLogoURL.png&quot; class=&quot;align-center&quot; src=&quot;https://book.systemsapproach.org/_images/SystemsApproachLogoURL.png&quot;/&gt;&lt;/a&gt;&lt;div class=&quot;section&quot; id=&quot;computer-networks-a-systems-approach&quot;&gt;

&lt;div class=&quot;section&quot; id=&quot;larry-peterson-and-bruce-davie&quot;&gt;
&lt;h2&gt;Larry Peterson and Bruce Davie&lt;a class=&quot;headerlink&quot; href=&quot;https://book.systemsapproach.org/#larry-peterson-and-bruce-davie&quot; title=&quot;Permalink to this headline&quot;&gt;¬∂&lt;/a&gt;&lt;/h2&gt;

&lt;div class=&quot;toctree-wrapper compound&quot;&gt;
&lt;p class=&quot;caption&quot;&gt;&lt;span class=&quot;caption-text&quot;&gt;Table of Contents&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
<pubDate>Fri, 12 Feb 2021 04:40:04 +0000</pubDate>
<dc:creator>Ballu</dc:creator>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://book.systemsapproach.org/</dc:identifier>
</item>
<item>
<title>Comparison of Rust async and Linux thread context switch time and memory use</title>
<link>https://github.com/jimblandy/context-switch</link>
<guid isPermaLink="true" >https://github.com/jimblandy/context-switch</guid>
<description>&lt;p&gt;These are a few programs that try to measure context switch time and task memory use in various ways. In summary:&lt;/p&gt;
&lt;ul readability=&quot;8.5&quot;&gt;&lt;li readability=&quot;3&quot;&gt;
&lt;p&gt;A context switch takes around 0.2¬µs between async tasks, versus 1.7¬µs between kernel threads. But this advantage goes away if the context switch is due to I/O readiness: both converge to 1.7¬µs. The async advantage also goes away in our microbenchmark if the program is pinned to a single core. So inter-core communication is something to watch out for.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;Creating a new task takes ~0.3¬µs for an async task, versus ~17¬µs for a new kernel thread.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;3&quot;&gt;
&lt;p&gt;Memory consumption per task (i.e. for a task that doesn't do much) starts at around a few hundred bytes for an async task, versus around 20KiB (9.5KiB user, 10KiB kernel) for a kernel thread. This is a minimum: more demanding tasks will naturally use more.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;5&quot;&gt;
&lt;p&gt;It's no problem to create 250,000 async tasks, but I was only able to get my laptop to run 80,000 threads (4 core, two way HT, 32GiB).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;These are probably not the limiting factors in your application, but it's nice to know that the headroom is there.&lt;/p&gt;
&lt;h2&gt;Measuring thread context switch time&lt;/h2&gt;
&lt;p&gt;The programs &lt;code&gt;thread-brigade&lt;/code&gt; and &lt;code&gt;async-brigade&lt;/code&gt; each create 500 tasks connected by pipes (like a ‚Äúbucket brigade‚Äù) and measure how long it takes to propagate a single byte from the first to the last. One is implemented with threads, and the other is implemented with the Tokio crate's async I/O.&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;$ cd async-brigade/
$ /bin/time cargo run --release
    Finished release [optimized] target(s) in 0.02s
     Running `/home/jimb/rust/context-switch/target/release/async-brigade`
500 tasks, 10000 iterations:
mean 1.795ms per iteration, stddev 82.016¬µs (3.589¬µs per task per iter)
9.83user 8.33system 0:18.19elapsed 99%CPU (0avgtext+0avgdata 17144maxresident)k
0inputs+0outputs (0major+2283minor)pagefaults 0swaps
$

$ cd ../thread-brigade
$ /bin/time cargo run --release
    Finished release [optimized] target(s) in 0.02s
     Running `/home/jimb/rust/context-switch/target/release/thread-brigade`
500 tasks, 10000 iterations:
mean 2.657ms per iteration, stddev 231.822¬µs (5.313¬µs per task per iter)
9.14user 27.88system 0:26.91elapsed 137%CPU (0avgtext+0avgdata 16784maxresident)k
0inputs+0outputs (0major+3381minor)pagefaults 0swaps
$
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;In these runs, I'm seeing 18.19s / 26.91s ‚âÖ 0.68 or a 30% speedup from going async. However, if I pin the threaded version to a single core, the speed advantage of async disappears:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;$ taskset --cpu-list 1 /bin/time cargo run --release
    Finished release [optimized] target(s) in 0.02s
     Running `/home/jimb/rust/context-switch/target/release/thread-brigade`
500 tasks, 10000 iterations:
mean 1.709ms per iteration, stddev 102.926¬µs (3.417¬µs per task per iter)
4.81user 12.50system 0:17.37elapsed 99%CPU (0avgtext+0avgdata 16744maxresident)k
0inputs+0outputs (0major+3610minor)pagefaults 0swaps
$
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;I don't know why.&lt;/p&gt;
&lt;p&gt;It would be interesting to see whether/how the number of tasks in the brigade affects these numbers.&lt;/p&gt;
&lt;p&gt;Per-thread resident memory use in &lt;code&gt;thread-brigade&lt;/code&gt; is about 9.5KiB, whereas per-async-task memory use in &lt;code&gt;async-brigade&lt;/code&gt; is around 0.4KiB, a factor of ~20. See 'Measuring memory use', below.&lt;/p&gt;
&lt;p&gt;There are differences in the system calls performed by the two versions:&lt;/p&gt;
&lt;ul readability=&quot;8&quot;&gt;&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;In &lt;code&gt;thread-brigade&lt;/code&gt;, each task does a single &lt;code&gt;recvfrom&lt;/code&gt; and a &lt;code&gt;write&lt;/code&gt; per iteration, taking 5.5¬µs.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;7&quot;&gt;
&lt;p&gt;In &lt;code&gt;async-brigade&lt;/code&gt;, each task does one &lt;code&gt;recvfrom&lt;/code&gt; and one &lt;code&gt;write&lt;/code&gt;, neither of which block, and then one more &lt;code&gt;recvfrom&lt;/code&gt;, which returns &lt;code&gt;EAGAIN&lt;/code&gt; and suspends the task. Then control returns to the executor. The reactor thread calls &lt;code&gt;epoll&lt;/code&gt; to see which pipes are readable, and tells the executor which task to run next. All this takes 3.6¬µs.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;5&quot;&gt;
&lt;p&gt;In &lt;code&gt;one-thread-brigade&lt;/code&gt;, we build the pipes but just have a single thread loop through them all and do the reads and writes. This gives us a baseline cost for the I/O operations themselves, which we can subtract off from the times in the other two programs, in hopes that the remainder reflects the cost of the context switches alone.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;The &lt;code&gt;async-brigade&lt;/code&gt; performance isn't affected much if we switch from Tokio's default multi-thread executor to a single-threaded executor, so it's not spending much time in kernel context switches. &lt;code&gt;thread-brigade&lt;/code&gt; does a kernel context switch from each task to the next. I think this means that context switches are more expensive than a &lt;code&gt;recvfrom&lt;/code&gt; and &lt;code&gt;epoll&lt;/code&gt; system call.&lt;/p&gt;
&lt;p&gt;If we run the test with 50000 tasks (and reduce the number of iterations to 100), the speedup doesn't change much, but &lt;code&gt;thread-brigade&lt;/code&gt; requires a 466MiB resident set, whereas &lt;code&gt;async-brigade&lt;/code&gt; runs in around 21MiB. That's 10kiB of memory being actively touched by each task, versus 0.4kiB, about a twentieth. This isn't just the effect of pessimistically-sized thread stacks: we're looking at the resident set size, which shouldn't include pages allocated to the stack that the thread never actually touches. So the way Rust right-sizes futures seems really effective.&lt;/p&gt;
&lt;p&gt;This microbenchmark doesn't do much, but a real application would add to each task's working set, and that difference might become less significant. But I was able to run async-brigade with 250,000 tasks; I wasn't able to get my laptop to run 250,000 threads at all.&lt;/p&gt;
&lt;p&gt;The other programs are minor variations, or make other measurements:&lt;/p&gt;
&lt;ul readability=&quot;3.5&quot;&gt;&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;&lt;code&gt;async-mem-brigade&lt;/code&gt; uses &lt;code&gt;tokio:sync::mpsc&lt;/code&gt; channels to send &lt;code&gt;usize&lt;/code&gt; values from one async channel to another. This performs the same number of task-to-task switches, but avoids the overhead of the pipe I/O. It seems that Tokio's channels do use futexes on Linux to signal readiness.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;&lt;code&gt;one-thread-brigade&lt;/code&gt; attempts to measure the cost of the pipe I/O alone, by creating all the pipes but having a single thread do all the reading and writing to propagate the byte from the first to the last.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;code&gt;thread-creation&lt;/code&gt; and &lt;code&gt;async-creation&lt;/code&gt; attempt to measure the time required to create a thread / async task.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;h2&gt;Measuring memory use&lt;/h2&gt;
&lt;p&gt;The scripts &lt;code&gt;thread-brigade/rss-per-thread.sh&lt;/code&gt; and &lt;code&gt;async-brigade/rss-per-task.sh&lt;/code&gt; run their respective brigade microbenchmarks with varying numbers of tasks, and measure the virtual and resident memory consumption at each count. You can then do a linear regression to see the memory use of a single task. Note that &lt;code&gt;async-brigade/rss-per-task.sh&lt;/code&gt; runs 10x as many tasks, to keep the noise down.&lt;/p&gt;
&lt;p&gt;As mentioned above, in my measurements, each thread costs around 9.5KiB, and each async task costs around 0.4KiB, so the async version uses about 1/20th as much memory as the threaded version.&lt;/p&gt;
&lt;p&gt;To run this script, you'll need to have the Linux &lt;code&gt;pmap&lt;/code&gt; utility installed; this gives an accurate measurement of resident set size. On Fedora, this is included in the &lt;code&gt;procps-ng&lt;/code&gt; package. (Pull requests for info about other major distributions welcome.)&lt;/p&gt;
&lt;h2&gt;Running tests with large numbers of threads&lt;/h2&gt;
&lt;p&gt;It's interesting to play with the number of tasks to see how that affects the relative speed of the async and threaded bucket brigades. But in order to test large numbers of threads, you may need to remove some of your system's guardrails.&lt;/p&gt;
&lt;p&gt;On Linux:&lt;/p&gt;
&lt;ul readability=&quot;57.5&quot;&gt;&lt;li readability=&quot;4&quot;&gt;
&lt;p&gt;You will run out of file descriptors. Each task needs two file descriptors, one for the reading end of the upstream pipe, and one for the writing end of the downstream pipe. The process also needs a few file descriptors for miscellaneous purposes. For 50000 tasks, say:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;$ ulimit -n 100010
&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
&lt;li readability=&quot;7&quot;&gt;
&lt;p&gt;You may run out of process id numbers. Each thread needs its own pid. So, perhaps something like:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;$ sudo sysctl kernel.pid_max=4194304
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;This is overkill, but why worry about this? (The number above is the default in Fedora 33, 4 √ó 1024 √ó 1024; apparently systemd was worried about pid rollover.)&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;5&quot;&gt;
&lt;p&gt;You will run out of memory map areas. Each thread has its own stack, with an unmapped guard page at the low end to catch stack overflows. There seem to be other constraints as well. In practice, this seems to work for 50000 tasks:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;$ sudo sysctl vm.max_map_count=200000
&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
&lt;li readability=&quot;64&quot;&gt;
&lt;p&gt;Process ID numbers can also be limited by the &lt;code&gt;pids&lt;/code&gt; cgroup controller.&lt;/p&gt;
&lt;p&gt;A cgroup is a collection of processes on which you can impose system resource limits as a group. Every process belongs to exactly one cgroup. When one process creates another, the new process is placed in the same cgroup as its parent.&lt;/p&gt;
&lt;p&gt;Cgroups are arranged in a tree, where limits set on a cgroup apply to that group and all its descendants. Only leaf cgroups actually contain processes/threads. The cgroups in the hierarchy have names that look like filesystem paths; the root cgroup is named &lt;code&gt;/&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;You can see which cgroup your shell belongs to like this:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;$ cat /proc/$$/cgroup
0::/user.slice/user-1000.slice/gargle/howl.scope
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;This indicates that my shell is in a cgroup named &lt;code&gt;/user.slice/user-1000.slice/gargle/howl.scope&lt;/code&gt;. The names can get quite long, so this example is simplified.&lt;/p&gt;
&lt;p&gt;On Fedora, at least, the cgroup hierarchy is reflected in the ordinary filesystem as a directory tree under &lt;code&gt;/sys/fs/cgroup&lt;/code&gt;, so my shell's cgroup appears as a directory here:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;$ ls /sys/fs/cgroup/user.slice/user-1000.slice/gargle/howl.scope
cgroup.controllers          cpu.stat             memory.pressure
cgroup.events               io.pressure          memory.stat
cgroup.freeze               memory.current           memory.swap.current
cgroup.max.depth            memory.events            memory.swap.events
cgroup.max.descendants  memory.events.local  memory.swap.high
cgroup.procs                memory.high          memory.swap.max
cgroup.stat                     memory.low               pids.current
cgroup.subtree_control  memory.max               pids.events
cgroup.threads              memory.min           pids.max
cgroup.type                     memory.numa_stat
cpu.pressure                memory.oom.group
$
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;You can inspect and manipulate cgroups by looking at these files. Some represent different resources that can be limited, while others relate to the cgroup hierarchy itself.&lt;/p&gt;
&lt;p&gt;In particular, the file &lt;code&gt;pids.max&lt;/code&gt; shows the limit this cgroup imposes on my shell:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;$ cat /sys/fs/cgroup/user.slice/user-1000.slice/gargle/howl.scope/pids.max
max
$
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;A limit of &lt;code&gt;max&lt;/code&gt; means that there's no limit. But limits set on parent cgroups also apply to their descendants, so we need to check our ancestor groups:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;$ cat /sys/fs/cgroup/user.slice/user-1000.slice/gargle/pids.max
10813
$ cat /sys/fs/cgroup/user.slice/user-1000.slice/pids.max
84184
$ cat /sys/fs/cgroup/user.slice/pids.max
max
$ cat /sys/fs/cgroup/pids.max
cat: /sys/fs/cgroup/pids.max: No such file or directory
$
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Apparently there's a limit of 10813 pids imposed by my shell's cgroup's parent, and a higher limit of 84184 pids set for me as a user. (On Fedora, these limits are established by systemd configuration files.) To raise that limit, we can simply write another value to these files, as root:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;$ sudo sh -c 'echo 100000 &amp;gt; /sys/fs/cgroup/user.slice/user-1000.slice/pids.max'
$ sudo sh -c 'echo max    &amp;gt; /sys/fs/cgroup/user.slice/user-1000.slice/gargle/pids.max'
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;The cgroup machinery seems to vary not only from one Linux distribution to the next, but even from one version to another. So while I hope this is helpful, you may need to consult other documentation. &lt;code&gt;man cgroups(7)&lt;/code&gt; is a good place to start, but beware, it makes my explanation here look short.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;The kernel parameter &lt;code&gt;kernel.threads-max&lt;/code&gt; is a system-wide limit on the number of threads. You probably won't run into this.&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;$ sysctl kernel.threads-max
kernel.threads-max = 255208
$
&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
&lt;li readability=&quot;5&quot;&gt;
&lt;p&gt;There is a limit on the number of processes that can run under a given real user ID:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;$ ulimit -u
127604
$
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;At the system call level, this is the &lt;code&gt;getrlimit(2)&lt;/code&gt; system call's &lt;code&gt;RLIMIT_NPROC&lt;/code&gt; resource. This, too, you're unlikely to run into.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;13&quot;&gt;
&lt;p&gt;The default thread stack size is 8MiB:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;$ ulimit -s
8192
$
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;You might expect this to limit a 32GiB (x86_64) machine to 4096 threads, but the kernel only allocates physical memory to a stack as the thread touches its pages, so the initial memory consumption of a thread in user space is actually only around 8kiB. At this size, 32GiB could accommodate 4Mi threads. Again, this is unlikely to be the limiting factor.&lt;/p&gt;
&lt;p&gt;Although it doesn't matter, &lt;code&gt;thread-brigade&lt;/code&gt; program in this repository requests a 1MiB stack for each thread, which is plenty for our purposes.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;With these changes made, I was able to run &lt;code&gt;thread-brigade&lt;/code&gt; with 80000 tasks.&lt;/p&gt;
&lt;h2&gt;Does any of this matter?&lt;/h2&gt;
&lt;p&gt;In GitHub issue #1, @spacejam raised a good point:&lt;/p&gt;
&lt;blockquote readability=&quot;14&quot;&gt;
&lt;p&gt;overall, there are a lot of things here that really fade into insignificance when you consider the simple effort required to deserialize JSON or handle TLS. People often see that there's some theoretical benefit of async and then they accept far less ergonomic coding styles and the additional bug classes that only happen on async due to accidental blocking etc... despite the fact that when you consider a real-world deployed application, those &quot;benefits&quot; become indistinguishable from noise. However, due to the additional bug classes and worse ergonomics, there is now less energy for actually optimizing the business logic, which is where all of the cycles and resource use are anyway, so in-practice async implementations tend to be buggier and slower.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Below is my reply to them, lightly edited:&lt;/p&gt;
&lt;blockquote readability=&quot;54&quot;&gt;
&lt;p&gt;I have a few responses to this.&lt;/p&gt;
&lt;p&gt;First of all, the reason I carried out the experiments in this repo in the first place was that I basically agreed with all of your points here. I think async is wildly oversold as &quot;faster&quot; without any real investigation into why that would be. It is hard to pin down exactly how the alleged advantages would arise. The same I/O operations have to be carried out either way (or worse); kernel context switches have been heavily optimized over the years (although the Spectre mitigations made them worse); and the whole story of the creation of NPTL was about it beating IBM's competing M-on-N thread implementation (which I see as analogous to async task systems) in the very microbenchmarks in which the M-on-N thread library was expected to have an advantage.&lt;/p&gt;
&lt;p&gt;However, in conversations that I sought out with people with experience implementing high-volume servers, both with threads and with async designs, my async skepticism met a lot of pushback. They consistently reported struggling with threaded designs and not being able to get performance under control until they went async. Big caveat: they were not using Rust - these were older designs in C++ and even C. But it jibes well with the other successful designs you see out there, like nginx and Elixir (which is used by WhatsApp, among others), which are all essentially async.&lt;/p&gt;
&lt;p&gt;So the purpose of these experiments was to see if I could isolate some of the sources of async's apparent advantages. It came down to memory consumption, creation time, and context switch time each having best-case order-of-magnitude advantages. Taken together, those advantages are beyond the point that I'm willing to call negligible. How often the best case actually arises is unclear, but one can argue that that, at least, is under the programmer's control, so the ceiling on how far implementation effort can get you is higher, in an async design.&lt;/p&gt;
&lt;p&gt;Ultimately, as far as this repo is concerned, you need to decide whether you trust your readers to understand both the value and the limitations of microbenchmarks. If you assume your readers are in Twitter mode---they're just going to glance at the headlines and come away with a binary, &quot;async good, two legs bad&quot; kind of conclusion---then maybe it's better not to publish microbenchmarks at all, because they're misleading. Reality is more sensitive to details. But I think the benefit of offering these microbenchmarks and the README's analysis to careful readers might(?) outweigh the harm done by the noise from careless readers, because I think the careful readers are more likely to use the material in a way that has lasting impact. The wind changes; the forest does not.&lt;/p&gt;
&lt;p&gt;The 2nd edition of Programming Rust (due out in June 2021) has a chapter on async that ends with a discussion of the rationale for async programming. It tries to dismiss some of the commonly heard bogus arguments, and present the advantages that async does have with the appropriate qualifications. It mentions tooling disadvantages. Generally, the chapter describes Rust's async implementation in a decent amount of detail, because we want our readers to be able to anticipate how it will perform and where it might help; the summary attempts to make clear what all that machinery can and cannot accomplish.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The only thing I'd add is that the measurements reported here for asynchronous performance were taken of an implementation that uses &lt;code&gt;epoll&lt;/code&gt;-style system calls. The newer &lt;code&gt;io_uring&lt;/code&gt;-style APIs seem radically different, and I'm curious to see whether these might change the story here.&lt;/p&gt;
</description>
<pubDate>Fri, 12 Feb 2021 04:01:13 +0000</pubDate>
<dc:creator>viraptor</dc:creator>
<og:image>https://avatars.githubusercontent.com/u/751272?s=400&amp;v=4</og:image>
<og:type>object</og:type>
<og:title>jimblandy/context-switch</og:title>
<og:url>https://github.com/jimblandy/context-switch</og:url>
<og:description>Comparison of Rust async and Linux thread context switch time. - jimblandy/context-switch</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://github.com/jimblandy/context-switch</dc:identifier>
</item>
<item>
<title>Amsterdam displaces London as Europe&amp;#039;s top stocks centre after Brexit</title>
<link>https://www.reuters.com/article/us-britain-eu-markets/amsterdam-displaces-london-as-europes-top-stocks-centre-after-brexit-idUSKBN2AB0I8</link>
<guid isPermaLink="true" >https://www.reuters.com/article/us-britain-eu-markets/amsterdam-displaces-london-as-europes-top-stocks-centre-after-brexit-idUSKBN2AB0I8</guid>
<description>&lt;div class=&quot;ArticleBody-byline-container-3H6dy&quot;&gt;
&lt;p class=&quot;Byline-byline-1sVmo ArticleBody-byline-10B7D&quot;&gt;By &lt;a class=&quot;TextLabel__text-label___3oCVw TextLabel__black-to-orange___23uc0 TextLabel__serif___3lOpX Byline-author-2BSir&quot; href=&quot;https://www.reuters.com/journalists/huw-jones&quot; target=&quot;_blank&quot;&gt;Huw Jones&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;ArticleBody-read-time-and-social-2VOIr&quot;&gt;
&lt;p class=&quot;TextLabel__text-label___3oCVw TextLabel__gray___1V4fk TextLabel__small-all-caps-spaced-out___3O9H4 ReadTime-read-time-1s3CG ArticleBody-read-time-29pGN&quot;&gt;5 Min Read&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;p class=&quot;Paragraph-paragraph-2Bgue ArticleBody-para-TD_9x&quot;&gt;LONDON (Reuters) - Amsterdam has displaced London as Europe‚Äôs biggest share trading centre after Britain left the European Union‚Äôs single market, and picked up a chunk of UK derivatives business along the way, according to data published on Thursday.&lt;/p&gt;

&lt;p class=&quot;Paragraph-paragraph-2Bgue ArticleBody-para-TD_9x&quot;&gt;Stock exchanges in the Dutch capital traded 9.2 billion euros ($11.15 billion) a day in January, compared to London‚Äôs 8.6 billion, according to the Cboe exchange, which operates in both cities.&lt;/p&gt;
&lt;p class=&quot;Paragraph-paragraph-2Bgue ArticleBody-para-TD_9x&quot;&gt;This compares with an average of 17.5 billion euros traded daily in London during 2020, when Frankfurt was second with 5.9 billion and Amsterdam sixth at 2.6 billion, Cboe said.&lt;/p&gt;
&lt;p class=&quot;Paragraph-paragraph-2Bgue ArticleBody-para-TD_9x&quot;&gt;The City of London had long warned of the consequences of leaving the EU single market without adequate provisions for trade in services, and notably finance, which accounted for more than 10% of UK tax receipts before Brexit.&lt;/p&gt;
&lt;p class=&quot;Paragraph-paragraph-2Bgue ArticleBody-para-TD_9x&quot;&gt;The EU‚Äôs securities watchdog ESMA said on Thursday the shift of share trading from London to the bloc is permanent.&lt;/p&gt;

&lt;p class=&quot;Paragraph-paragraph-2Bgue ArticleBody-para-TD_9x&quot;&gt;The EU has shown no sign of reversing its position that euro-denominated shares must be traded in the EU - whose internal market Britain left on Jan. 1.&lt;/p&gt;
&lt;p class=&quot;Paragraph-paragraph-2Bgue ArticleBody-para-TD_9x&quot;&gt;The gap may narrow, however, as trading in Swiss shares resumed in Britain this month. It is averaging 250 million euros and is expected to build up towards over a billion euros a day - the level reached before trading of Swiss shares in London stopped in June 2019.&lt;/p&gt;
&lt;p class=&quot;Paragraph-paragraph-2Bgue ArticleBody-para-TD_9x&quot;&gt;Separate data published on Thursday showed how chunks of trading in euro-denominated interest rate swaps have shifted from London, the world‚Äôs biggest swaps trading centre, to platforms in the EU and New York since January.&lt;/p&gt;
&lt;p class=&quot;Paragraph-paragraph-2Bgue ArticleBody-para-TD_9x&quot;&gt;Platforms in Amsterdam, and to a much lesser extent Paris, accounted for a quarter of the euro rate swaps market in January, up from just 10% last July, IHS Markit said.&lt;/p&gt;
&lt;div class=&quot;RelatedCoverage-container-3AnSP ArticleBody-related-coverage-7S2f1&quot;&gt;
&lt;p class=&quot;TextLabel__text-label___3oCVw TextLabel__gray___1V4fk TextLabel__small-all-caps___2Z2RG&quot;&gt;Related Coverage&lt;/p&gt;

&lt;button class=&quot;RelatedCoverage-show-all-button-5XWJe&quot;&gt;
&lt;p class=&quot;TextLabel__text-label___3oCVw TextLabel__blue-to-orange___1SFN2 TextLabel__regular___2X0ym RelatedCoverage-text-c3wuC&quot;&gt;See more stories&lt;/p&gt;
&lt;/button&gt;&lt;/div&gt;
&lt;p class=&quot;Paragraph-paragraph-2Bgue ArticleBody-para-TD_9x&quot;&gt;Over the same period, London‚Äôs share fell from just under 40% to just over 10%, with U.S. platforms doubling volumes to 20% of the total euro swaps market.&lt;/p&gt;
&lt;p class=&quot;Paragraph-paragraph-2Bgue ArticleBody-para-TD_9x&quot;&gt;‚ÄòPROGRESSIVE EQUIVALENCE DISCUSSIONS‚Äô&lt;/p&gt;
&lt;p class=&quot;Paragraph-paragraph-2Bgue ArticleBody-para-TD_9x&quot;&gt;As with shares, the swaps market has been fragmented by Brussels ‚Äúobliging‚Äù EU-based firms to trade interest rate swaps and credit default swaps either on a platform inside the bloc, or in a non-EU country whose platforms have been approved for use, such as the United States.&lt;/p&gt;
&lt;p class=&quot;Paragraph-paragraph-2Bgue ArticleBody-para-TD_9x&quot;&gt;London has not yet secured that ‚Äúequivalence‚Äù because Brussels says it needs information about Britain‚Äôs intentions to diverge from EU rules.&lt;/p&gt;

&lt;p class=&quot;Paragraph-paragraph-2Bgue ArticleBody-para-TD_9x&quot;&gt;Prime Minister Boris Johnson‚Äôs spokesman said London had already supplied the necessary paperwork and was ‚Äúone of the world‚Äôs most pre-eminent financial centres, with a strong regulatory system‚Äù, adding that fragmenting markets was in no one‚Äôs interests.&lt;/p&gt;
&lt;p class=&quot;Paragraph-paragraph-2Bgue ArticleBody-para-TD_9x&quot;&gt;The EU‚Äôs financial services chief Mairead McGuinness said on Thursday the bloc will discuss equivalence with Britain ‚Äúprogressively‚Äù and take into account its intentions regarding rules on a case-by-case basis, but there ‚Äúcannot be equivalence and wide divergence‚Äù.&lt;/p&gt;
&lt;p class=&quot;Paragraph-paragraph-2Bgue ArticleBody-para-TD_9x&quot;&gt;One of her senior officials has said the three-way split between Britain, the EU and United States in swaps due to the EU ‚Äúderivatives trading obligation‚Äù or DTO will not be reversed.&lt;/p&gt;
&lt;p class=&quot;Paragraph-paragraph-2Bgue ArticleBody-para-TD_9x&quot;&gt;‚ÄúFor the foreseeable future, all three jurisdictions will have trading venues that offer all currencies in such volumes that keep the DTO in all currencies,‚Äù Tilman Lueder, head of securities markets at the EU executive, told a Bloomberg event.&lt;/p&gt;

&lt;p&gt;FILE PHOTO: Overview of Amsterdam's stock exchange interior as Prosus begins trading on the Euronext stock exchange in Amsterdam, Netherlands, September 11, 2019. REUTERS/Piroschka van de Wouw/File Photo&lt;/p&gt;
&lt;p class=&quot;Paragraph-paragraph-2Bgue ArticleBody-para-TD_9x&quot;&gt;‚ÄúThe three-way liquidity split is going to stabilise.‚Äù&lt;/p&gt;
&lt;p class=&quot;Paragraph-paragraph-2Bgue ArticleBody-para-TD_9x&quot;&gt;The Bank for International Settlements says the gross market value of euro rate swaps in the first half of last year was the equivalent of $5.2 trillion.&lt;/p&gt;
&lt;p class=&quot;Paragraph-paragraph-2Bgue ArticleBody-para-TD_9x&quot;&gt;Brussels had been clear that it wanted euro-denominated financial activity shifted from London to build up its own capital market and have direct supervision.&lt;/p&gt;
&lt;p class=&quot;Paragraph-paragraph-2Bgue ArticleBody-para-TD_9x&quot;&gt;Over 6 billion euros in daily trading left London on Jan. 4 for EU-based platforms.&lt;/p&gt;

&lt;p class=&quot;Paragraph-paragraph-2Bgue ArticleBody-para-TD_9x&quot;&gt;The rise of Amsterdam, home to the world‚Äôs oldest stock exchange, had been well flagged as pan-European share platforms - Cboe and London Stock Exchange‚Äôs Turquoise in London - began preparing to open in the Amsterdam after Britain voted in 2016 to leave the EU.&lt;/p&gt;
&lt;p class=&quot;Paragraph-paragraph-2Bgue ArticleBody-para-TD_9x&quot;&gt;The ICE exchange announced this week that trading in EU carbon emissions worth a billion euros daily will move from London to the Dutch city during the second quarter.&lt;/p&gt;
&lt;h2 class=&quot;Headline-headline-2FXIq Headline-black-OogpV ArticleBody-heading-3h695&quot;&gt;($1 = 0.8251&lt;/h2&gt;
&lt;div readability=&quot;5.8383233532934&quot;&gt;
&lt;div class=&quot;Attribution-attribution-Y5JpY&quot; readability=&quot;8&quot;&gt;
&lt;p&gt;Additional reporting by Padraic Halpin in Dublin; Editing by Timothy Heritage and Kevin Liffey and Kirsten Donovan&lt;/p&gt;
&lt;/div&gt;

&lt;/div&gt;
</description>
<pubDate>Thu, 11 Feb 2021 20:33:28 +0000</pubDate>
<dc:creator>Someone</dc:creator>
<og:title>Amsterdam displaces London as Europe's top stocks centre after Brexit</og:title>
<og:description>Amsterdam has displaced London as Europe's biggest share trading centre after Britain left the European Union's single market, and picked up a chunk of UK derivatives business along the way, according to data published on Thursday.</og:description>
<og:image>https://static.reuters.com/resources/r/?m=02&amp;d=20210211&amp;t=2&amp;i=1551142535&amp;r=LYNXMPEH1A0CN&amp;w=800</og:image>
<og:url>https://www.reuters.com/article/uk-britain-eu-markets-idUSKBN2AB0IO</og:url>
<og:type>article</og:type>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.reuters.com/article/us-britain-eu-markets/amsterdam-displaces-london-as-europes-top-stocks-centre-after-brexit-idUSKBN2AB0I8</dc:identifier>
</item>
</channel>
</rss>