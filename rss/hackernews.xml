<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=hnrss.org%2Fnewest%3Fpoints%3D200&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://hnrss.org/newest?points=200" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>Hacker News: Newest</title>
<link>https://news.ycombinator.com/newest</link>
<description>Hacker News RSS</description>
<item>
<title>Samsung Foundry: New $17B Fab in the USA by Late 2023</title>
<link>https://www.anandtech.com/show/16483/samsung-in-the-usa-a-17-billion-usd-fab-by-late-2023</link>
<guid isPermaLink="true" >https://www.anandtech.com/show/16483/samsung-in-the-usa-a-17-billion-usd-fab-by-late-2023</guid>
<description>&lt;p&gt;&lt;span&gt;Samsung Foundry has filed documents with authorities in Arizona, New York, and Texas seeking to build a leading-edge semiconductor manufacturing facility in the U&lt;/span&gt;&lt;span&gt;SA. The potential fab near Austin, Texas, is expected to cost over $17 billion and to create 1,800 jobs. If everything goes as planned, it will go online by the fourth quarter of 2023. There is an intrigue about the new fab though: Samsung hasn't stated which process node it will be designed for. &lt;/span&gt;Could Samsung be the first to 3nm in the USA?&lt;/p&gt;
&lt;h3&gt;Samsung Foundry to Expand in the USA&lt;/h3&gt;
&lt;p&gt;As demand for semiconductors is increasing, Samsung Foundry and other makers of chips are expanding their manufacturing capacities. In the recent years the company made chips using its leading-edge manufacturing technologies solely in South Korea, whereas its S2 manufacturing facility in Austin, Texas, was left with 14LPP (and derivatives down to 11LPP) and older fabrication processes that are too outdated for leading edge products. When it comes to chip design, Samsung has enough customers inside the US (such as IBM, Nvidia, Qualcomm, Tesla, just to name a few) that need to use its most advanced nodes and would prefer to use fabs located in the USA, which is why it needs to build a new manufacturing facility in this country. Furthermore, the company also needs a new leading-edge fab in North America to better compete against its rival TSMC, which plans to build a semiconductor production facility in Arizona by 2024.&lt;/p&gt;
&lt;p&gt;Samsung Foundry officially began to explore possibilities to build a new fab in Arizona, New York, and Texas recently, according to &lt;a href=&quot;https://eu.statesman.com/story/business/2021/02/04/samsung-austin-expansion-chip-plant-seeks-1-billion-taxpayer-incentives/4309503001/&quot;&gt;Austin American-Statesman&lt;/a&gt;. The current plan submitted to the government of Texas includes a 7 million square feet (650 thousand square meters) facility on the company's 640-acre site (i.e., the fab will be adjacent to the existing S2) that will cost over $17 billion. The company has no plans to upgrade the S2 in the foreseeable future as mature process technologies are still required by its clients.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a href=&quot;https://images.anandtech.com/doci/16483/samsung_foundry_fabs.png&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://images.anandtech.com/doci/16483/samsung_foundry_fabs_575px.png&quot;/&gt;&lt;/a&gt;&lt;br/&gt;&lt;em&gt;Showing the existing S2 fab&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;There are four criteria that the new location must meet in a bid to make sense for Samsung's leading-edge fab, according to the &lt;a href=&quot;https://assets.comptroller.texas.gov/ch313/1554/1554-manor-samsung-app.pdf&quot;&gt;documents&lt;/a&gt; filed with the Texas authorities: access to talent, existing semiconductor manufacturing ecosystem, speed to market, and strong public- private partnership (i.e., incentives). Samsung already has a fab in Texas, so it already has talent and a supplier ecosystem in the state. By contrast, it will have to fight both for talent and supplies in Arizona (against Intel and TSMC) and New York (against GlobalFoundries).&lt;/p&gt;
&lt;p&gt;To build a leading-edge manufacturing facility, Samsung needs rather huge incentives from authorities. In particular, Samsung is requesting combined tax abatements of $805.5 million over 20 years from Travis County and the city of Austin, according to &lt;a href=&quot;https://www.reuters.com/article/us-usa-semiconductors-samsung-elec/samsung-considers-austin-for-17-billion-chip-plant-eyes-tax-breaks-of-at-least-806-million-documents-idUSKBN2A433B&quot;&gt;Reuters&lt;/a&gt;, which essentially means that Samsung demands a 100% tax abatement from the county and 50% from the city. In addition, Samsung is seeking $252.9 million in tax breaks from the Manor school district based on the Texas Tax Code that allows property tax breaks for economic development projects. So far, no company has received a 100% tax abatement anywhere in the USA, according to market observers. Nonetheless, the deal still makes a lot of sense for the state, and there is likely going to be interest from the federal government as well.&lt;/p&gt;
&lt;blockquote readability=&quot;14&quot;&gt;
&lt;p&gt;&lt;em&gt;&quot;As there are other highly competitive markets seeking to win this expansion deal, it is imperative that our state and local governments work together to ensure Austin comes out on top,&quot; said Amber Gunst, CEO of the Austin Technology Council. &quot;Not only does this provide 1,800 jobs that will be available to Central Texans of all education and skill levels, this expansion creates an even stronger relationship between Samsung and Austin, a relationship we value immensely.&quot;&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Samsung expects the new fab to have an economic output of around $8.642 billion and salaries for permanent workers to total $7.323 billion in the first 20 years of its operation.&lt;/p&gt;
&lt;h2&gt;Project Silicon Silver: Coming Online in Q4 2023&lt;/h2&gt;
&lt;p&gt;The plans for the new fab are called Project Silicon Silver (PSS), and it will be located adjacent to S2. It will not use any of the existing buildings of S2, but will be a completely new fab constructed from the ground up. It will have its own operations support, central utility building, industrial waste treatment, air separation plans, storage for inert gases, and other constructions.&lt;/p&gt;
&lt;blockquote readability=&quot;9&quot;&gt;
&lt;p&gt;&quot;The only currently-contemplated interconnections between the new facility and the surrounding existing property may be a pedestrian and/or material bridge or walkway constructed between the existing improvements on the site and the new construction,&quot; the document submitted to the authorities reads.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Samsung will spend $5.069 billion on buildings and real estate property improvements as well as $9.931 billion in semiconductor manufacturing equipment.&lt;/p&gt;
&lt;p&gt;Samsung Foundry does not disclose many details about the new fab. At present, we know that if the company signs all necessary papers with the authorities in Austin, it will break ground by Q2 of 2021 with the expectation that production will be up and running by Q4 of 2023. In addition, we also know that the facility will occupy 650 thousand square meters of land. To put that number into context, TSMC's &lt;a href=&quot;https://www.anandtech.com/show/12377/tsmc-starts-to-build-fab-18-5nm-in-early-2020&quot;&gt;Fab 18&lt;/a&gt; in Tainan (in the Southern Taiwan Science Park) will occupy 950 thousand square meters of land when it is fully built. In general, Samsung is planning to build a rather huge manufacturing facility. TSMC's Fab 18 has a goal of 120k-140k wafer starts per month at full volume, so we should expect PSS to be around the 70k-100k mark assuming identical requirements and scaling.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a href=&quot;https://images.anandtech.com/doci/16483/samsung-foundry-processes.jpg&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://images.anandtech.com/doci/16483/samsung-foundry-processes_575px.jpg&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Samsung Foundry does not disclose which process technologies it plans to use at the new fab, but it is safe to say that they will use extreme ultraviolet (EUV) lithography. Considering the fact that Samsung expects its &lt;a href=&quot;https://www.anandtech.com/show/14333/samsung-announces-3nm-gaa-mbcfet-pdk-version-01&quot;&gt;3 nm technology&lt;/a&gt; based on gate-all-around (GAA) multi-bridge channel field effect transistors (MBCFETs) to be ready in 2021 ~ 2022 timeframe, it is logical to expect it to be used at the fab along with other technologies. In the end, Samsung's V1 fab in South Korea will be used for &lt;a href=&quot;https://www.anandtech.com/show/15538/samsung-starts-mass-production-at-v1-a-dedicated-euv-fab-for-7nm-6nm-5nm-4nm-3nm-nodes&quot;&gt;multiple nodes&lt;/a&gt;, including 3 nm.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a href=&quot;https://images.anandtech.com/doci/16483/SFF2019-1%20%2812%29.jpg&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://images.anandtech.com/doci/16483/SFF2019-1%20%2812%29_575px.jpg&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Based on currently available information, Samsung is planning a bigger project than its rival TSMC. TSMC's &lt;a href=&quot;https://www.tomshardware.com/news/tsmc-arizona-fab-investment&quot;&gt;planned fab&lt;/a&gt; in Arizona will have an initial production capacity target of about 20,000 wafer starts per month (WSPM) and will employ 1,600 people directly. TSMC intends to spend $12 billion on its new fab from 2021 to 2029, which indicates that TSMC's new fab will be a smaller facility when compared to the new Samsung fab in Texas.&lt;/p&gt;
&lt;h3&gt;No R&amp;amp;D Activities, Manufacturing Only&lt;/h3&gt;
&lt;p&gt;The documents that Samsung has submitted to the authorities clearly indicate that the Project Silicon Silver is a purely manufacturing facility and the company does not plan to run any R&amp;amp;D activities there.&lt;/p&gt;
&lt;p&gt;Since there will be no research and development done at the new fab, Samsung Foundry will not be able to apply for any kind of USA government help when it comes to semiconductors R&amp;amp;D even after &lt;a href=&quot;https://www.tomshardware.com/news/governments-help-advanced-technologies&quot;&gt;appropriate programs&lt;/a&gt; will be passed by the legislators.&lt;/p&gt;
&lt;p&gt;Furthermore, Samsung's S2 fab does not have the USA Department of Defense's Trusted Foundry status, so it does not look like the company makes any chips for the DoD. In fact, it is unclear whether it is interested in military contracts in the USA in general.&lt;/p&gt;
&lt;h3&gt;Summary&lt;/h3&gt;
&lt;p&gt;After GlobalFoundries &lt;a href=&quot;https://www.anandtech.com/show/13277/globalfoundries-stops-all-7nm-development&quot;&gt;pulled out&lt;/a&gt; from developing leading-edge process technologies in 2018 and Intel lost its process technology lead to TSMC and Samsung Foundry, the USA government has been more willing to help local chipmakers in a bid to ensure that the country is self-reliant and does not depend on chips produced elsewhere.&lt;/p&gt;
&lt;p&gt;TSMC was the first to take advantage of the USA willingness to assist local semiconductor production and its $12 billion fab in Arizona will start production of chips using its N5 node (and probably N5P and N4 derivatives) in 2024. Meanwhile, TSMC's fab in Arizona with an initial 20,000 WSPM capacity will not be as large as the facilities it has in Taiwan. To serve the USA government orders, TSMC's facility will have to gain the Trusted Foundry status, if/once it gets it, it will be able to sell authorities chips produced using a very advanced node. In addition to TSMC, some of its suppliers are also &lt;a href=&quot;https://asia.nikkei.com/Business/Tech/Semiconductors/TSMC-supplier-LCY-to-build-US-plant-as-chip-supply-chain-shifts&quot;&gt;gearing up&lt;/a&gt; to build new facilities in the USA.&lt;/p&gt;
&lt;p&gt;Samsung Foundry, the world's second largest contract maker of chips, is another foundry to build a leading-edge fab in the USA The company's Project Silicon Silver manufacturing facility in Texas will cost over $17 billion and is projected to be larger when compared to TSMC's fab in Arizona. It remains to be seen which process technology SF plans to use at the fab, but one of the options is its 3 nm MBCFET-based leading-edge node. Meanwhile, it is unclear whether Samsung is seeking to build chips for the USA government agencies.&lt;/p&gt;
&lt;p&gt;While the USA government would prefer to help local chipmakers, such as Intel or GlobalFoundries, its initiatives to assist production of chips in the country have so far gathered significant interest from Taiwan-based TSMC and South Korea-based Samsung. In any case, it looks like the plan to bring leading-edge semiconductor manufacturing back to the USA works and a $27 million planned investment is a good proof of that, depending on tax abatements throughout the process.&lt;/p&gt;
&lt;h3&gt;Related Reading:&lt;/h3&gt;




</description>
<pubDate>Wed, 10 Feb 2021 20:45:31 +0000</pubDate>
<dc:creator>manojkr</dc:creator>
<og:title>Samsung Foundry: New $17 Billion Fab in the USA by Late 2023</og:title>
<og:type>article</og:type>
<og:url>https://www.anandtech.com/show/16483/samsung-in-the-usa-a-17-billion-usd-fab-by-late-2023</og:url>
<og:image>https://images.anandtech.com/doci/16483/samsung-foundry-hero_678x452.jpg</og:image>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.anandtech.com/show/16483/samsung-in-the-usa-a-17-billion-usd-fab-by-late-2023</dc:identifier>
</item>
<item>
<title>Golang generics proposal has been accepted</title>
<link>https://github.com/golang/go/issues/43651#issuecomment-776944155</link>
<guid isPermaLink="true" >https://github.com/golang/go/issues/43651#issuecomment-776944155</guid>
<description>&lt;head&gt;&lt;meta charset=&quot;utf-8&quot;/&gt;&lt;link rel=&quot;dns-prefetch&quot; href=&quot;https://github.githubassets.com&quot;/&gt;&lt;link rel=&quot;dns-prefetch&quot; href=&quot;https://avatars.githubusercontent.com&quot;/&gt;&lt;link rel=&quot;dns-prefetch&quot; href=&quot;https://github-cloud.s3.amazonaws.com&quot;/&gt;&lt;link rel=&quot;dns-prefetch&quot; href=&quot;https://user-images.githubusercontent.com/&quot;/&gt;&lt;link crossorigin=&quot;anonymous&quot; media=&quot;all&quot; integrity=&quot;sha512-rF3cnLJE5IkKUWFkw54emxUMV82DhbZ9aJun83zhvBgJ7J7ZXC20bEFVuLY9RRRC60Ig+pHQO57DuYBrYO+cAA==&quot; rel=&quot;stylesheet&quot; href=&quot;https://github.githubassets.com/assets/frameworks-ac5ddc9cb244e4890a516164c39e1e9b.css&quot; type=&quot;text/css&quot;/&gt;&lt;link crossorigin=&quot;anonymous&quot; media=&quot;all&quot; integrity=&quot;sha512-tO1butB3aXG+Ab9M+171Fjde3B2uzMU0DEAKzjbXJ0GLJWfiaIVEhM9QS3/G9Ck32IEZLmaSTscoyA9Z66IglQ==&quot; rel=&quot;stylesheet&quot; href=&quot;https://github.githubassets.com/assets/site-b4ed5bbad0776971be01bf4cfb5ef516.css&quot; type=&quot;text/css&quot;/&gt;&lt;link crossorigin=&quot;anonymous&quot; media=&quot;all&quot; integrity=&quot;sha512-QbKgFXj+JoU12QsMYLRWqW9sWAzGHCCMC7FlsHunxzfLL4jGwfsmyAtbn4F/deHyBtQOmEQLz5mPljNOKjwErw==&quot; rel=&quot;stylesheet&quot; href=&quot;https://github.githubassets.com/assets/behaviors-41b2a01578fe268535d90b0c60b456a9.css&quot; type=&quot;text/css&quot;/&gt;&lt;link crossorigin=&quot;anonymous&quot; media=&quot;all&quot; integrity=&quot;sha512-2QYLOTG1Aa/Nq1CKgmlPElI1RfCFxxTHzoci3iVz8x9x8Q/oYsPTjeACbyE/5wa1kvmSiJ4z50ZUKOmkiZA7Fg==&quot; rel=&quot;stylesheet&quot; href=&quot;https://github.githubassets.com/assets/github-d9060b3931b501afcdab508a82694f12.css&quot; type=&quot;text/css&quot;/&gt;&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width&quot;/&gt;&lt;title&gt;spec: add generic programming using type parameters · Issue #43651 · golang/go · GitHub&lt;/title&gt;&lt;meta name=&quot;description&quot; content=&quot;We propose adding support for type parameters to Go. This will change the Go language to support a form of generic programming. A detailed design draft has already been published, with input from many members of the Go community. We are ...&quot;/&gt;&lt;link rel=&quot;search&quot; type=&quot;application/opensearchdescription+xml&quot; href=&quot;/opensearch.xml&quot; title=&quot;GitHub&quot;/&gt;&lt;link rel=&quot;fluid-icon&quot; href=&quot;https://github.com/fluidicon.png&quot; title=&quot;GitHub&quot;/&gt;&lt;meta property=&quot;fb:app_id&quot; content=&quot;1401488693436528&quot;/&gt;&lt;meta name=&quot;apple-itunes-app&quot; content=&quot;app-id=1477376905&quot;/&gt;&lt;meta name=&quot;twitter:image:src&quot; content=&quot;https://avatars.githubusercontent.com/u/4314092?s=400&amp;amp;v=4&quot;/&gt;&lt;meta name=&quot;twitter:site&quot; content=&quot;@github&quot;/&gt;&lt;meta name=&quot;twitter:card&quot; content=&quot;summary&quot;/&gt;&lt;meta name=&quot;twitter:title&quot; content=&quot;spec: add generic programming using type parameters · Issue #43651 · golang/go&quot;/&gt;&lt;meta name=&quot;twitter:description&quot; content=&quot;We propose adding support for type parameters to Go. This will change the Go language to support a form of generic programming. A detailed design draft has already been published, with input from m...&quot;/&gt;&lt;meta property=&quot;og:image&quot; content=&quot;https://avatars.githubusercontent.com/u/4314092?s=400&amp;amp;v=4&quot;/&gt;&lt;meta property=&quot;og:site_name&quot; content=&quot;GitHub&quot;/&gt;&lt;meta property=&quot;og:type&quot; content=&quot;object&quot;/&gt;&lt;meta property=&quot;og:title&quot; content=&quot;spec: add generic programming using type parameters · Issue #43651 · golang/go&quot;/&gt;&lt;meta property=&quot;og:url&quot; content=&quot;https://github.com/golang/go/issues/43651&quot;/&gt;&lt;meta property=&quot;og:description&quot; content=&quot;We propose adding support for type parameters to Go. This will change the Go language to support a form of generic programming. A detailed design draft has already been published, with input from m...&quot;/&gt;&lt;link rel=&quot;assets&quot; href=&quot;https://github.githubassets.com/&quot;/&gt;&lt;meta name=&quot;request-id&quot; content=&quot;EB3B:26CB:18DF54:22B6A0:602481DF&quot; data-pjax-transient=&quot;true&quot;/&gt;&lt;meta name=&quot;html-safe-nonce&quot; content=&quot;94c2df449778bb642879153dab7e9239c85ed21489fb43ce95cf4b9809a1bef9&quot; data-pjax-transient=&quot;true&quot;/&gt;&lt;meta name=&quot;visitor-payload&quot; content=&quot;eyJyZWZlcnJlciI6Imh0dHA6Ly93d3cuZ29vZ2xlLmNvLnVrL3VybD9zYT10XHUwMDI2c291cmNlPXdlYlx1MDAyNmNkPTEiLCJyZXF1ZXN0X2lkIjoiRUIzQjoyNkNCOjE4REY1NDoyMkI2QTA6NjAyNDgxREYiLCJ2aXNpdG9yX2lkIjoiNzc1NjAyNzY5NDc5MTU1NzU5OSIsInJlZ2lvbl9lZGdlIjoiaWFkIiwicmVnaW9uX3JlbmRlciI6ImlhZCJ9&quot; data-pjax-transient=&quot;true&quot;/&gt;&lt;meta name=&quot;visitor-hmac&quot; content=&quot;b1bcf1cd705bf7e8669300645d873f5bc1cef48b8c9845f43cfc82bcceb37c10&quot; data-pjax-transient=&quot;true&quot;/&gt;&lt;meta name=&quot;hovercard-subject-tag&quot; content=&quot;issue:784443929&quot; data-pjax-transient=&quot;&quot;/&gt;&lt;meta name=&quot;github-keyboard-shortcuts&quot; content=&quot;repository,issues&quot; data-pjax-transient=&quot;true&quot;/&gt;&lt;meta name=&quot;selected-link&quot; value=&quot;repo_issues&quot; data-pjax-transient=&quot;&quot;/&gt;&lt;meta name=&quot;google-site-verification&quot; content=&quot;c1kuD-K2HIVF635lypcsWPoD4kilo5-jA_wBFyT4uMY&quot;/&gt;&lt;meta name=&quot;google-site-verification&quot; content=&quot;KT5gs8h0wvaagLKAVWq8bbeNwnZZK1r1XQysX3xurLU&quot;/&gt;&lt;meta name=&quot;google-site-verification&quot; content=&quot;ZzhVyEFwb7w3e0-uOTltm8Jsck2F5StVihD0exw2fsA&quot;/&gt;&lt;meta name=&quot;google-site-verification&quot; content=&quot;GXs5KoUUkNCoaAZn7wPN-t01Pywp9M3sEjnt_3_ZWPc&quot;/&gt;&lt;meta name=&quot;octolytics-host&quot; content=&quot;collector.githubapp.com&quot;/&gt;&lt;meta name=&quot;octolytics-app-id&quot; content=&quot;github&quot;/&gt;&lt;meta name=&quot;octolytics-event-url&quot; content=&quot;https://collector.githubapp.com/github-external/browser_event&quot;/&gt;&lt;meta name=&quot;analytics-location&quot; content=&quot;/&amp;lt;user-name&amp;gt;/&amp;lt;repo-name&amp;gt;/issues/show&quot; data-pjax-transient=&quot;true&quot;/&gt;&lt;meta name=&quot;optimizely-datafile&quot; content=&quot;{&amp;quot;version&amp;quot;: &amp;quot;4&amp;quot;, &amp;quot;rollouts&amp;quot;: [], &amp;quot;typedAudiences&amp;quot;: [], &amp;quot;anonymizeIP&amp;quot;: true, &amp;quot;projectId&amp;quot;: &amp;quot;16737760170&amp;quot;, &amp;quot;variables&amp;quot;: [], &amp;quot;featureFlags&amp;quot;: [], &amp;quot;experiments&amp;quot;: [], &amp;quot;audiences&amp;quot;: [{&amp;quot;conditions&amp;quot;: &amp;quot;[\&amp;quot;or\&amp;quot;, {\&amp;quot;match\&amp;quot;: \&amp;quot;exact\&amp;quot;, \&amp;quot;name\&amp;quot;: \&amp;quot;$opt_dummy_attribute\&amp;quot;, \&amp;quot;type\&amp;quot;: \&amp;quot;custom_attribute\&amp;quot;, \&amp;quot;value\&amp;quot;: \&amp;quot;$opt_dummy_value\&amp;quot;}]&amp;quot;, &amp;quot;id&amp;quot;: &amp;quot;$opt_dummy_audience&amp;quot;, &amp;quot;name&amp;quot;: &amp;quot;Optimizely-Generated Audience for Backwards Compatibility&amp;quot;}], &amp;quot;groups&amp;quot;: [], &amp;quot;attributes&amp;quot;: [{&amp;quot;id&amp;quot;: &amp;quot;16822470375&amp;quot;, &amp;quot;key&amp;quot;: &amp;quot;user_id&amp;quot;}, {&amp;quot;id&amp;quot;: &amp;quot;17143601254&amp;quot;, &amp;quot;key&amp;quot;: &amp;quot;spammy&amp;quot;}, {&amp;quot;id&amp;quot;: &amp;quot;18175660309&amp;quot;, &amp;quot;key&amp;quot;: &amp;quot;organization_plan&amp;quot;}, {&amp;quot;id&amp;quot;: &amp;quot;18813001570&amp;quot;, &amp;quot;key&amp;quot;: &amp;quot;is_logged_in&amp;quot;}, {&amp;quot;id&amp;quot;: &amp;quot;19073851829&amp;quot;, &amp;quot;key&amp;quot;: &amp;quot;geo&amp;quot;}], &amp;quot;botFiltering&amp;quot;: false, &amp;quot;accountId&amp;quot;: &amp;quot;16737760170&amp;quot;, &amp;quot;events&amp;quot;: [{&amp;quot;experimentIds&amp;quot;: [], &amp;quot;id&amp;quot;: &amp;quot;17911811441&amp;quot;, &amp;quot;key&amp;quot;: &amp;quot;hydro_click.dashboard.teacher_toolbox_cta&amp;quot;}, {&amp;quot;experimentIds&amp;quot;: [], &amp;quot;id&amp;quot;: &amp;quot;18124116703&amp;quot;, &amp;quot;key&amp;quot;: &amp;quot;submit.organizations.complete_sign_up&amp;quot;}, {&amp;quot;experimentIds&amp;quot;: [], &amp;quot;id&amp;quot;: &amp;quot;18145892387&amp;quot;, &amp;quot;key&amp;quot;: &amp;quot;no_metric.tracked_outside_of_optimizely&amp;quot;}, {&amp;quot;experimentIds&amp;quot;: [], &amp;quot;id&amp;quot;: &amp;quot;18178755568&amp;quot;, &amp;quot;key&amp;quot;: &amp;quot;click.org_onboarding_checklist.add_repo&amp;quot;}, {&amp;quot;experimentIds&amp;quot;: [], &amp;quot;id&amp;quot;: &amp;quot;18180553241&amp;quot;, &amp;quot;key&amp;quot;: &amp;quot;submit.repository_imports.create&amp;quot;}, {&amp;quot;experimentIds&amp;quot;: [], &amp;quot;id&amp;quot;: &amp;quot;18186103728&amp;quot;, &amp;quot;key&amp;quot;: &amp;quot;click.help.learn_more_about_repository_creation&amp;quot;}, {&amp;quot;experimentIds&amp;quot;: [], &amp;quot;id&amp;quot;: &amp;quot;18188530140&amp;quot;, &amp;quot;key&amp;quot;: &amp;quot;test_event.do_not_use_in_production&amp;quot;}, {&amp;quot;experimentIds&amp;quot;: [], &amp;quot;id&amp;quot;: &amp;quot;18191963644&amp;quot;, &amp;quot;key&amp;quot;: &amp;quot;click.empty_org_repo_cta.transfer_repository&amp;quot;}, {&amp;quot;experimentIds&amp;quot;: [], &amp;quot;id&amp;quot;: &amp;quot;18195612788&amp;quot;, &amp;quot;key&amp;quot;: &amp;quot;click.empty_org_repo_cta.import_repository&amp;quot;}, {&amp;quot;experimentIds&amp;quot;: [], &amp;quot;id&amp;quot;: &amp;quot;18210945499&amp;quot;, &amp;quot;key&amp;quot;: &amp;quot;click.org_onboarding_checklist.invite_members&amp;quot;}, {&amp;quot;experimentIds&amp;quot;: [], &amp;quot;id&amp;quot;: &amp;quot;18211063248&amp;quot;, &amp;quot;key&amp;quot;: &amp;quot;click.empty_org_repo_cta.create_repository&amp;quot;}, {&amp;quot;experimentIds&amp;quot;: [], &amp;quot;id&amp;quot;: &amp;quot;18215721889&amp;quot;, &amp;quot;key&amp;quot;: &amp;quot;click.org_onboarding_checklist.update_profile&amp;quot;}, {&amp;quot;experimentIds&amp;quot;: [], &amp;quot;id&amp;quot;: &amp;quot;18224360785&amp;quot;, &amp;quot;key&amp;quot;: &amp;quot;click.org_onboarding_checklist.dismiss&amp;quot;}, {&amp;quot;experimentIds&amp;quot;: [], &amp;quot;id&amp;quot;: &amp;quot;18234832286&amp;quot;, &amp;quot;key&amp;quot;: &amp;quot;submit.organization_activation.complete&amp;quot;}, {&amp;quot;experimentIds&amp;quot;: [], &amp;quot;id&amp;quot;: &amp;quot;18252392383&amp;quot;, &amp;quot;key&amp;quot;: &amp;quot;submit.org_repository.create&amp;quot;}, {&amp;quot;experimentIds&amp;quot;: [], &amp;quot;id&amp;quot;: &amp;quot;18257551537&amp;quot;, &amp;quot;key&amp;quot;: &amp;quot;submit.org_member_invitation.create&amp;quot;}, {&amp;quot;experimentIds&amp;quot;: [], &amp;quot;id&amp;quot;: &amp;quot;18259522260&amp;quot;, &amp;quot;key&amp;quot;: &amp;quot;submit.organization_profile.update&amp;quot;}, {&amp;quot;experimentIds&amp;quot;: [], &amp;quot;id&amp;quot;: &amp;quot;18564603625&amp;quot;, &amp;quot;key&amp;quot;: &amp;quot;view.classroom_select_organization&amp;quot;}, {&amp;quot;experimentIds&amp;quot;: [], &amp;quot;id&amp;quot;: &amp;quot;18568612016&amp;quot;, &amp;quot;key&amp;quot;: &amp;quot;click.classroom_sign_in_click&amp;quot;}, {&amp;quot;experimentIds&amp;quot;: [], &amp;quot;id&amp;quot;: &amp;quot;18572592540&amp;quot;, &amp;quot;key&amp;quot;: &amp;quot;view.classroom_name&amp;quot;}, {&amp;quot;experimentIds&amp;quot;: [], &amp;quot;id&amp;quot;: &amp;quot;18574203855&amp;quot;, &amp;quot;key&amp;quot;: &amp;quot;click.classroom_create_organization&amp;quot;}, {&amp;quot;experimentIds&amp;quot;: [], &amp;quot;id&amp;quot;: &amp;quot;18582053415&amp;quot;, &amp;quot;key&amp;quot;: &amp;quot;click.classroom_select_organization&amp;quot;}, {&amp;quot;experimentIds&amp;quot;: [], &amp;quot;id&amp;quot;: &amp;quot;18589463420&amp;quot;, &amp;quot;key&amp;quot;: &amp;quot;click.classroom_create_classroom&amp;quot;}, {&amp;quot;experimentIds&amp;quot;: [], &amp;quot;id&amp;quot;: &amp;quot;18591323364&amp;quot;, &amp;quot;key&amp;quot;: &amp;quot;click.classroom_create_first_classroom&amp;quot;}, {&amp;quot;experimentIds&amp;quot;: [], &amp;quot;id&amp;quot;: &amp;quot;18591652321&amp;quot;, &amp;quot;key&amp;quot;: &amp;quot;click.classroom_grant_access&amp;quot;}, {&amp;quot;experimentIds&amp;quot;: [], &amp;quot;id&amp;quot;: &amp;quot;18607131425&amp;quot;, &amp;quot;key&amp;quot;: &amp;quot;view.classroom_creation&amp;quot;}, {&amp;quot;experimentIds&amp;quot;: [], &amp;quot;id&amp;quot;: &amp;quot;18831680583&amp;quot;, &amp;quot;key&amp;quot;: &amp;quot;upgrade_account_plan&amp;quot;}, {&amp;quot;experimentIds&amp;quot;: [], &amp;quot;id&amp;quot;: &amp;quot;19064064515&amp;quot;, &amp;quot;key&amp;quot;: &amp;quot;click.signup&amp;quot;}, {&amp;quot;experimentIds&amp;quot;: [], &amp;quot;id&amp;quot;: &amp;quot;19075373687&amp;quot;, &amp;quot;key&amp;quot;: &amp;quot;click.view_account_billing_page&amp;quot;}, {&amp;quot;experimentIds&amp;quot;: [], &amp;quot;id&amp;quot;: &amp;quot;19077355841&amp;quot;, &amp;quot;key&amp;quot;: &amp;quot;click.dismiss_signup_prompt&amp;quot;}, {&amp;quot;experimentIds&amp;quot;: [], &amp;quot;id&amp;quot;: &amp;quot;19079713938&amp;quot;, &amp;quot;key&amp;quot;: &amp;quot;click.contact_sales&amp;quot;}, {&amp;quot;experimentIds&amp;quot;: [], &amp;quot;id&amp;quot;: &amp;quot;19120963070&amp;quot;, &amp;quot;key&amp;quot;: &amp;quot;click.compare_account_plans&amp;quot;}, {&amp;quot;experimentIds&amp;quot;: [], &amp;quot;id&amp;quot;: &amp;quot;19151690317&amp;quot;, &amp;quot;key&amp;quot;: &amp;quot;click.upgrade_account_cta&amp;quot;}, {&amp;quot;experimentIds&amp;quot;: [], &amp;quot;id&amp;quot;: &amp;quot;19424193129&amp;quot;, &amp;quot;key&amp;quot;: &amp;quot;click.open_account_switcher&amp;quot;}, {&amp;quot;experimentIds&amp;quot;: [], &amp;quot;id&amp;quot;: &amp;quot;19520330825&amp;quot;, &amp;quot;key&amp;quot;: &amp;quot;click.visit_account_profile&amp;quot;}, {&amp;quot;experimentIds&amp;quot;: [], &amp;quot;id&amp;quot;: &amp;quot;19540970635&amp;quot;, &amp;quot;key&amp;quot;: &amp;quot;click.switch_account_context&amp;quot;}, {&amp;quot;experimentIds&amp;quot;: [], &amp;quot;id&amp;quot;: &amp;quot;19730198868&amp;quot;, &amp;quot;key&amp;quot;: &amp;quot;submit.homepage_signup&amp;quot;}, {&amp;quot;experimentIds&amp;quot;: [], &amp;quot;id&amp;quot;: &amp;quot;19820830627&amp;quot;, &amp;quot;key&amp;quot;: &amp;quot;click.homepage_signup&amp;quot;}, {&amp;quot;experimentIds&amp;quot;: [], &amp;quot;id&amp;quot;: &amp;quot;19988571001&amp;quot;, &amp;quot;key&amp;quot;: &amp;quot;click.create_enterprise_trial&amp;quot;}], &amp;quot;revision&amp;quot;: &amp;quot;420&amp;quot;}&quot;/&gt;&lt;meta name=&quot;hostname&quot; content=&quot;github.com&quot;/&gt;&lt;meta name=&quot;user-login&quot; content=&quot;&quot;/&gt;&lt;meta name=&quot;expected-hostname&quot; content=&quot;github.com&quot;/&gt;&lt;meta name=&quot;enabled-features&quot; content=&quot;MARKETPLACE_PENDING_INSTALLATIONS,ACTIONS_SHORT_SHA_WARNING&quot;/&gt;&lt;meta http-equiv=&quot;x-pjax-version&quot; content=&quot;d00cbc4bdd1ea16b6bc4566eb69728a8fb280a4de10e7f947710135b5108bff7&quot;/&gt;&lt;meta name=&quot;go-import&quot; content=&quot;github.com/golang/go git https://github.com/golang/go.git&quot;/&gt;&lt;meta name=&quot;octolytics-dimension-user_id&quot; content=&quot;4314092&quot;/&gt;&lt;meta name=&quot;octolytics-dimension-user_login&quot; content=&quot;golang&quot;/&gt;&lt;meta name=&quot;octolytics-dimension-repository_id&quot; content=&quot;23096959&quot;/&gt;&lt;meta name=&quot;octolytics-dimension-repository_nwo&quot; content=&quot;golang/go&quot;/&gt;&lt;meta name=&quot;octolytics-dimension-repository_public&quot; content=&quot;true&quot;/&gt;&lt;meta name=&quot;octolytics-dimension-repository_is_fork&quot; content=&quot;false&quot;/&gt;&lt;meta name=&quot;octolytics-dimension-repository_network_root_id&quot; content=&quot;23096959&quot;/&gt;&lt;meta name=&quot;octolytics-dimension-repository_network_root_nwo&quot; content=&quot;golang/go&quot;/&gt;&lt;meta name=&quot;browser-stats-url&quot; content=&quot;https://api.github.com/_private/browser/stats&quot;/&gt;&lt;meta name=&quot;browser-errors-url&quot; content=&quot;https://api.github.com/_private/browser/errors&quot;/&gt;&lt;meta name=&quot;browser-optimizely-client-errors-url&quot; content=&quot;https://api.github.com/_private/browser/optimizely_client/errors&quot;/&gt;&lt;link rel=&quot;mask-icon&quot; href=&quot;https://github.githubassets.com/pinned-octocat.svg&quot; color=&quot;#000000&quot;/&gt;&lt;link rel=&quot;alternate icon&quot; class=&quot;js-site-favicon&quot; type=&quot;image/png&quot; href=&quot;https://github.githubassets.com/favicons/favicon.png&quot;/&gt;&lt;link rel=&quot;icon&quot; class=&quot;js-site-favicon&quot; type=&quot;image/svg+xml&quot; href=&quot;https://github.githubassets.com/favicons/favicon.svg&quot;/&gt;&lt;meta name=&quot;theme-color&quot; content=&quot;#1e2327&quot;/&gt;&lt;link rel=&quot;manifest&quot; href=&quot;/manifest.json&quot; crossorigin=&quot;use-credentials&quot;/&gt;&lt;/head&gt;&lt;body class=&quot;logged-out env-production page-responsive&quot; id=&quot;readabilityBody&quot; readability=&quot;28.10355987055&quot;&gt;


&lt;div data-pjax-replace=&quot;&quot; id=&quot;js-flash-container&quot;&gt;
&lt;div class=&quot;flash flash-full {{ className }}&quot;&gt;
&lt;div class=&quot; px-2&quot;&gt;
&lt;p&gt;{{ message }}&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;application-main&quot; data-commit-hovercards-enabled=&quot;&quot; data-discussion-hovercards-enabled=&quot;&quot; data-issue-and-pr-hovercards-enabled=&quot;&quot;&gt;
&lt;div itemscope=&quot;&quot; itemtype=&quot;http://schema.org/SoftwareSourceCode&quot; class=&quot;&quot;&gt;

&lt;div class=&quot;container-xl clearfix new-discussion-timeline px-3 px-md-4 px-lg-5&quot;&gt;
&lt;div id=&quot;repo-content-pjax-container&quot; class=&quot;repository-content&quot;&gt;
&lt;div class=&quot;js-check-all-container&quot; data-pjax=&quot;&quot;&gt;
&lt;div id=&quot;show_issue&quot; class=&quot;js-issues-results js-socket-channel js-updatable-content&quot; data-channel=&quot;eyJjIjoiaXNzdWU6Nzg0NDQzOTI5OnRpbWVsaW5lIiwidCI6MTYxMzAwNTI2M30=--35d7ad5c2c0af27948f06596c074be2fe980fd204d06a792c39fb2609767ce78&quot;&gt;


&lt;h2 class=&quot;sr-only&quot;&gt;Comments&lt;/h2&gt;
&lt;div id=&quot;discussion_bucket&quot;&gt;
&lt;div class=&quot;gutter-condensed gutter-lg flex-column flex-md-row d-flex&quot;&gt;
&lt;div class=&quot;flex-shrink-0 col-12 col-md-9 mb-4 mb-md-0&quot;&gt;
&lt;div class=&quot;js-quote-selection-container&quot; data-quote-markdown=&quot;.js-comment-body&quot; data-discussion-hovercards-enabled=&quot;&quot; data-issue-and-pr-hovercards-enabled=&quot;&quot; data-team-hovercards-enabled=&quot;&quot;&gt;
&lt;div class=&quot;js-discussion ml-0 pl-0 ml-md-6 pl-md-3&quot;&gt;

&lt;div&gt;




















































&lt;div class=&quot;js-timeline-item js-timeline-progressive-focus-container&quot; data-gid=&quot;MDI2Ok1vdmVkQ29sdW1uc0luUHJvamVjdEV2ZW50NDMxNjUwNDIyMg==&quot;&gt;

&lt;div class=&quot;TimelineItem js-targetable-element&quot; data-team-hovercards-enabled=&quot;&quot; id=&quot;event-4316504302&quot;&gt;

&lt;div class=&quot;TimelineItem-body&quot;&gt;&lt;a class=&quot;d-inline-block&quot; data-hovercard-type=&quot;user&quot; data-hovercard-url=&quot;/users/rsc/hovercard&quot; data-octo-click=&quot;hovercard-link-click&quot; data-octo-dimensions=&quot;link_type:self&quot; href=&quot;https://github.com/rsc&quot;&gt;&lt;img class=&quot;avatar avatar-user&quot; height=&quot;20&quot; width=&quot;20&quot; alt=&quot;@rsc&quot; src=&quot;https://avatars.githubusercontent.com/u/104030?s=60&amp;amp;u=7776f9d68ea1bc349af0227c03fca30350a05477&amp;amp;v=4&quot;/&gt;&lt;/a&gt; &lt;a class=&quot;author link-gray-dark text-bold&quot; data-hovercard-type=&quot;user&quot; data-hovercard-url=&quot;/users/rsc/hovercard&quot; data-octo-click=&quot;hovercard-link-click&quot; data-octo-dimensions=&quot;link_type:self&quot; href=&quot;https://github.com/rsc&quot;&gt;rsc&lt;/a&gt; changed the title &lt;del class=&quot;text-bold&quot;&gt;proposal: spec: add generic programming using type parameters&lt;/del&gt; &lt;ins class=&quot;text-bold no-underline&quot;&gt;spec: add generic programming using type parameters&lt;/ins&gt; &lt;a href=&quot;https://github.com/golang/go/issues/43651#event-4316504302&quot; class=&quot;link-gray&quot;&gt;Feb 10, 2021&lt;/a&gt;&lt;/div&gt;
&lt;/div&gt;


&lt;/div&gt;




&lt;/div&gt;
&lt;/div&gt;


&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;You can’t perform that action at this time.&lt;/p&gt;
&lt;div class=&quot;js-stale-session-flash flash flash-warn flash-banner&quot; hidden=&quot;&quot;&gt;&lt;span class=&quot;js-stale-session-flash-signed-in&quot; hidden=&quot;&quot;&gt;You signed in with another tab or window. &lt;a href=&quot;https://github.com/golang/go/issues/43651&quot;&gt;Reload&lt;/a&gt; to refresh your session.&lt;/span&gt; &lt;span class=&quot;js-stale-session-flash-signed-out&quot; hidden=&quot;&quot;&gt;You signed out in another tab or window. &lt;a href=&quot;https://github.com/golang/go/issues/43651&quot;&gt;Reload&lt;/a&gt; to refresh your session.&lt;/span&gt;&lt;/div&gt;
&lt;details class=&quot;details-reset details-overlay details-overlay-dark lh-default text-gray-dark hx_rsm&quot; open=&quot;&quot;&gt;
&lt;/details&gt;
&lt;/body&gt;</description>
<pubDate>Wed, 10 Feb 2021 19:48:30 +0000</pubDate>
<dc:creator>komuW</dc:creator>
<og:image>https://avatars.githubusercontent.com/u/4314092?s=400&amp;v=4</og:image>
<og:type>object</og:type>
<og:title>spec: add generic programming using type parameters · Issue #43651 · golang/go</og:title>
<og:url>https://github.com/golang/go/issues/43651</og:url>
<og:description>We propose adding support for type parameters to Go. This will change the Go language to support a form of generic programming. A detailed design draft has already been published, with input from m...</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://github.com/golang/go/issues/43651</dc:identifier>
</item>
<item>
<title>Kenyan recycles plastic waste into bricks stronger than concrete</title>
<link>https://www.reuters.com/article/us-kenya-environment-recycling-idUSKBN2A211N</link>
<guid isPermaLink="true" >https://www.reuters.com/article/us-kenya-environment-recycling-idUSKBN2A211N</guid>
<description>&lt;div class=&quot;ArticleBody-byline-container-3H6dy&quot;&gt;
&lt;p class=&quot;Byline-byline-1sVmo ArticleBody-byline-10B7D&quot;&gt;By &lt;a class=&quot;TextLabel__text-label___3oCVw TextLabel__black-to-orange___23uc0 TextLabel__serif___3lOpX Byline-author-2BSir&quot; href=&quot;https://www.reuters.com/journalists/edwin-waita&quot; target=&quot;_blank&quot;&gt;Edwin Waita&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;ArticleBody-read-time-and-social-2VOIr&quot;&gt;
&lt;p class=&quot;TextLabel__text-label___3oCVw TextLabel__gray___1V4fk TextLabel__small-all-caps-spaced-out___3O9H4 ReadTime-read-time-1s3CG ArticleBody-read-time-29pGN&quot;&gt;2 Min Read&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;p class=&quot;Paragraph-paragraph-2Bgue ArticleBody-para-TD_9x&quot;&gt;NAIROBI (Reuters) - Nzambi Matee hurls a brick hard against a school footpath constructed from bricks made of recycled plastic that her factory turns out in the Kenyan capital.&lt;/p&gt;

&lt;p class=&quot;Paragraph-paragraph-2Bgue ArticleBody-para-TD_9x&quot;&gt;It makes a loud bang, but does not crack.&lt;/p&gt;
&lt;p class=&quot;Paragraph-paragraph-2Bgue ArticleBody-para-TD_9x&quot;&gt;“Our product is almost five to seven times stronger than concrete,” said Matee, the founder of Nairobi-based Gjenge Makers, which transforms plastic waste into durable building materials.&lt;/p&gt;
&lt;p class=&quot;Paragraph-paragraph-2Bgue ArticleBody-para-TD_9x&quot;&gt;“There is that waste they cannot process anymore; they cannot recycle. That is what we get,” Matee said, strolling past sacks of plastic waste.&lt;/p&gt;

&lt;p class=&quot;Paragraph-paragraph-2Bgue ArticleBody-para-TD_9x&quot;&gt;Matee gets the waste from packaging factories for free, although she pays for the plastic she gets from other recyclers.&lt;/p&gt;
&lt;p class=&quot;Paragraph-paragraph-2Bgue ArticleBody-para-TD_9x&quot;&gt;Her factory produces 1,500 bricks each day, made from a mix of different kinds of plastic.&lt;/p&gt;
&lt;p class=&quot;Paragraph-paragraph-2Bgue ArticleBody-para-TD_9x&quot;&gt;These are high density polyethylene, used in milk and shampoo bottles; low density polyethylene, often used for bags for cerals or sandwiches; and polypropylene, used for ropes, flip-top lids and buckets.&lt;/p&gt;
&lt;div class=&quot;ArticleBody-slideshow-small-mFJ54&quot;&gt;&lt;button type=&quot;button&quot; class=&quot;FullscreenOverlay-button-1FTU6 Slideshow-inline-image-container-1dktB&quot; aria-label=&quot;slideshow&quot;&gt;


&lt;/button&gt;Slideshow &lt;span&gt;( 5 images )&lt;/span&gt;&lt;/div&gt;
&lt;p class=&quot;Paragraph-paragraph-2Bgue ArticleBody-para-TD_9x&quot;&gt;But she does not work with polyethylene terephthalate or PET, commonly used for plastic bottles.&lt;/p&gt;
&lt;p class=&quot;Paragraph-paragraph-2Bgue ArticleBody-para-TD_9x&quot;&gt;The plastic waste is mixed with sand, heated and then compressed into bricks, which are sold at varying prices, depending on thickness and colour. Their common grey bricks cost 850 Kenyan shillings ($7.70) per square metre, for example.&lt;/p&gt;
&lt;p class=&quot;Paragraph-paragraph-2Bgue ArticleBody-para-TD_9x&quot;&gt;Matee, a materials engineer who designed her own machines, said her factory has recycled 20 tonnes of waste plastic since its founding in 2017.&lt;/p&gt;

&lt;p class=&quot;Paragraph-paragraph-2Bgue ArticleBody-para-TD_9x&quot;&gt;She plans to add another, bigger, production line that could triple capacity, and hopes to break even by year end.&lt;/p&gt;
&lt;p class=&quot;Paragraph-paragraph-2Bgue ArticleBody-para-TD_9x&quot;&gt;Matee set up her factory after she ran out of patience waiting for the government to solve the problem of plastic pollution.&lt;/p&gt;
&lt;p class=&quot;Paragraph-paragraph-2Bgue ArticleBody-para-TD_9x&quot;&gt;“I was tired of being on the sidelines,” she said.&lt;/p&gt;
&lt;p class=&quot;Paragraph-paragraph-2Bgue ArticleBody-para-TD_9x&quot;&gt;($1=110.0500 Kenyan shillings)&lt;/p&gt;
&lt;div readability=&quot;5.776397515528&quot;&gt;
&lt;div class=&quot;Attribution-attribution-Y5JpY&quot; readability=&quot;8&quot;&gt;
&lt;p&gt;Reporting by Edwin Waita; Additional reporting and writing by George Obulutsa; Editing by Clarence Fernandez&lt;/p&gt;
&lt;/div&gt;

&lt;/div&gt;
</description>
<pubDate>Wed, 10 Feb 2021 19:26:39 +0000</pubDate>
<dc:creator>elorant</dc:creator>
<og:title>Kenyan recycles plastic waste into bricks stronger than concrete</og:title>
<og:description>Nzambi Matee hurls a brick hard against a school footpath constructed from bricks made of recycled plastic that her factory turns out in the Kenyan capital.</og:description>
<og:image>https://static.reuters.com/resources/r/?m=02&amp;d=20210202&amp;t=2&amp;i=1549970897&amp;r=LYNXMPEH110LD&amp;w=800</og:image>
<og:url>https://www.reuters.com/article/us-kenya-environment-recycling-idUSKBN2A211N</og:url>
<og:type>article</og:type>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.reuters.com/article/us-kenya-environment-recycling-idUSKBN2A211N</dc:identifier>
</item>
<item>
<title>Viral &amp;#039;I&amp;#039;m not a cat&amp;#039; filter is decades-old software</title>
<link>https://www.bbc.co.uk/news/technology-56010156</link>
<guid isPermaLink="true" >https://www.bbc.co.uk/news/technology-56010156</guid>
<description>[unable to retrieve full-text content]
&lt;p&gt;Article URL: &lt;a href=&quot;https://www.bbc.co.uk/news/technology-56010156&quot;&gt;https://www.bbc.co.uk/news/technology-56010156&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Comments URL: &lt;a href=&quot;https://news.ycombinator.com/item?id=26093070&quot;&gt;https://news.ycombinator.com/item?id=26093070&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Points: 360&lt;/p&gt;
&lt;p&gt;# Comments: 169&lt;/p&gt;
</description>
<pubDate>Wed, 10 Feb 2021 18:39:28 +0000</pubDate>
<dc:creator>beermonster</dc:creator>
<og:description>The filter is not from Zoom itself but came pre-installed on Dell laptops.</og:description>
<og:image>https://ichef.bbci.co.uk/news/1024/branded_news/5149/production/_116890802_p096j77c.jpg</og:image>
<og:title>Viral 'I'm not a cat' filter is decades-old software</og:title>
<og:type>article</og:type>
<og:url>https://www.bbc.com/news/technology-56010156</og:url>
<dc:language>en-GB</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.bbc.co.uk/news/technology-56010156</dc:identifier>
</item>
<item>
<title>Block Facebook Servers</title>
<link>https://github.com/jmdugan/blocklists/tree/master/corporations/facebook</link>
<guid isPermaLink="true" >https://github.com/jmdugan/blocklists/tree/master/corporations/facebook</guid>
<description>&lt;head&gt;&lt;meta charset=&quot;utf-8&quot;/&gt;&lt;link rel=&quot;dns-prefetch&quot; href=&quot;https://github.githubassets.com&quot;/&gt;&lt;link rel=&quot;dns-prefetch&quot; href=&quot;https://avatars.githubusercontent.com&quot;/&gt;&lt;link rel=&quot;dns-prefetch&quot; href=&quot;https://github-cloud.s3.amazonaws.com&quot;/&gt;&lt;link rel=&quot;dns-prefetch&quot; href=&quot;https://user-images.githubusercontent.com/&quot;/&gt;&lt;link crossorigin=&quot;anonymous&quot; media=&quot;all&quot; integrity=&quot;sha512-rF3cnLJE5IkKUWFkw54emxUMV82DhbZ9aJun83zhvBgJ7J7ZXC20bEFVuLY9RRRC60Ig+pHQO57DuYBrYO+cAA==&quot; rel=&quot;stylesheet&quot; href=&quot;https://github.githubassets.com/assets/frameworks-ac5ddc9cb244e4890a516164c39e1e9b.css&quot; type=&quot;text/css&quot;/&gt;&lt;link crossorigin=&quot;anonymous&quot; media=&quot;all&quot; integrity=&quot;sha512-tO1butB3aXG+Ab9M+171Fjde3B2uzMU0DEAKzjbXJ0GLJWfiaIVEhM9QS3/G9Ck32IEZLmaSTscoyA9Z66IglQ==&quot; rel=&quot;stylesheet&quot; href=&quot;https://github.githubassets.com/assets/site-b4ed5bbad0776971be01bf4cfb5ef516.css&quot; type=&quot;text/css&quot;/&gt;&lt;link crossorigin=&quot;anonymous&quot; media=&quot;all&quot; integrity=&quot;sha512-QbKgFXj+JoU12QsMYLRWqW9sWAzGHCCMC7FlsHunxzfLL4jGwfsmyAtbn4F/deHyBtQOmEQLz5mPljNOKjwErw==&quot; rel=&quot;stylesheet&quot; href=&quot;https://github.githubassets.com/assets/behaviors-41b2a01578fe268535d90b0c60b456a9.css&quot; type=&quot;text/css&quot;/&gt;&lt;link crossorigin=&quot;anonymous&quot; media=&quot;all&quot; integrity=&quot;sha512-2QYLOTG1Aa/Nq1CKgmlPElI1RfCFxxTHzoci3iVz8x9x8Q/oYsPTjeACbyE/5wa1kvmSiJ4z50ZUKOmkiZA7Fg==&quot; rel=&quot;stylesheet&quot; href=&quot;https://github.githubassets.com/assets/github-d9060b3931b501afcdab508a82694f12.css&quot; type=&quot;text/css&quot;/&gt;&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width&quot;/&gt;&lt;title&gt;blocklists/corporations/facebook at master · jmdugan/blocklists · GitHub&lt;/title&gt;&lt;meta name=&quot;description&quot; content=&quot;Shared lists of problem domains people may want to block with hosts files - jmdugan/blocklists&quot;/&gt;&lt;link rel=&quot;search&quot; type=&quot;application/opensearchdescription+xml&quot; href=&quot;/opensearch.xml&quot; title=&quot;GitHub&quot;/&gt;&lt;link rel=&quot;fluid-icon&quot; href=&quot;https://github.com/fluidicon.png&quot; title=&quot;GitHub&quot;/&gt;&lt;meta property=&quot;fb:app_id&quot; content=&quot;1401488693436528&quot;/&gt;&lt;meta name=&quot;apple-itunes-app&quot; content=&quot;app-id=1477376905&quot;/&gt;&lt;meta name=&quot;twitter:image:src&quot; content=&quot;https://avatars.githubusercontent.com/u/25763?s=400&amp;amp;v=4&quot;/&gt;&lt;meta name=&quot;twitter:site&quot; content=&quot;@github&quot;/&gt;&lt;meta name=&quot;twitter:card&quot; content=&quot;summary&quot;/&gt;&lt;meta name=&quot;twitter:title&quot; content=&quot;jmdugan/blocklists&quot;/&gt;&lt;meta name=&quot;twitter:description&quot; content=&quot;Shared lists of problem domains people may want to block with hosts files - jmdugan/blocklists&quot;/&gt;&lt;meta property=&quot;og:image&quot; content=&quot;https://avatars.githubusercontent.com/u/25763?s=400&amp;amp;v=4&quot;/&gt;&lt;meta property=&quot;og:site_name&quot; content=&quot;GitHub&quot;/&gt;&lt;meta property=&quot;og:type&quot; content=&quot;object&quot;/&gt;&lt;meta property=&quot;og:title&quot; content=&quot;jmdugan/blocklists&quot;/&gt;&lt;meta property=&quot;og:url&quot; content=&quot;https://github.com/jmdugan/blocklists&quot;/&gt;&lt;meta property=&quot;og:description&quot; content=&quot;Shared lists of problem domains people may want to block with hosts files - jmdugan/blocklists&quot;/&gt;&lt;link rel=&quot;assets&quot; href=&quot;https://github.githubassets.com/&quot;/&gt;&lt;meta name=&quot;request-id&quot; content=&quot;EB3A:0837:10F60D:19FD31:602481DF&quot; data-pjax-transient=&quot;true&quot;/&gt;&lt;meta name=&quot;html-safe-nonce&quot; content=&quot;04737b34c7d020426bf7cbe9de99c31401a6a8bb4673bcb1c9185b4cdf526f1a&quot; data-pjax-transient=&quot;true&quot;/&gt;&lt;meta name=&quot;visitor-payload&quot; content=&quot;eyJyZWZlcnJlciI6Imh0dHA6Ly93d3cuZ29vZ2xlLmNvLnVrL3VybD9zYT10XHUwMDI2c291cmNlPXdlYlx1MDAyNmNkPTEiLCJyZXF1ZXN0X2lkIjoiRUIzQTowODM3OjEwRjYwRDoxOUZEMzE6NjAyNDgxREYiLCJ2aXNpdG9yX2lkIjoiMzY3OTk2OTI0Njg3MTU4NTI0NyIsInJlZ2lvbl9lZGdlIjoiaWFkIiwicmVnaW9uX3JlbmRlciI6ImlhZCJ9&quot; data-pjax-transient=&quot;true&quot;/&gt;&lt;meta name=&quot;visitor-hmac&quot; content=&quot;bef286b0fa54bb37086eb00321436b5d437404aea44a08d3fbb942da99c376af&quot; data-pjax-transient=&quot;true&quot;/&gt;&lt;meta name=&quot;hovercard-subject-tag&quot; content=&quot;repository:59844792&quot; data-pjax-transient=&quot;&quot;/&gt;&lt;meta name=&quot;github-keyboard-shortcuts&quot; content=&quot;repository,source-code&quot; data-pjax-transient=&quot;true&quot;/&gt;&lt;meta name=&quot;selected-link&quot; value=&quot;repo_source&quot; data-pjax-transient=&quot;&quot;/&gt;&lt;meta name=&quot;google-site-verification&quot; content=&quot;c1kuD-K2HIVF635lypcsWPoD4kilo5-jA_wBFyT4uMY&quot;/&gt;&lt;meta name=&quot;google-site-verification&quot; content=&quot;KT5gs8h0wvaagLKAVWq8bbeNwnZZK1r1XQysX3xurLU&quot;/&gt;&lt;meta name=&quot;google-site-verification&quot; content=&quot;ZzhVyEFwb7w3e0-uOTltm8Jsck2F5StVihD0exw2fsA&quot;/&gt;&lt;meta name=&quot;google-site-verification&quot; content=&quot;GXs5KoUUkNCoaAZn7wPN-t01Pywp9M3sEjnt_3_ZWPc&quot;/&gt;&lt;meta name=&quot;octolytics-host&quot; content=&quot;collector.githubapp.com&quot;/&gt;&lt;meta name=&quot;octolytics-app-id&quot; content=&quot;github&quot;/&gt;&lt;meta name=&quot;octolytics-event-url&quot; content=&quot;https://collector.githubapp.com/github-external/browser_event&quot;/&gt;&lt;meta name=&quot;analytics-location&quot; content=&quot;/&amp;lt;user-name&amp;gt;/&amp;lt;repo-name&amp;gt;/files/disambiguate&quot; data-pjax-transient=&quot;true&quot;/&gt;&lt;meta name=&quot;hostname&quot; content=&quot;github.com&quot;/&gt;&lt;meta name=&quot;user-login&quot; content=&quot;&quot;/&gt;&lt;meta name=&quot;expected-hostname&quot; content=&quot;github.com&quot;/&gt;&lt;meta name=&quot;enabled-features&quot; content=&quot;MARKETPLACE_PENDING_INSTALLATIONS,ACTIONS_SHORT_SHA_WARNING&quot;/&gt;&lt;meta http-equiv=&quot;x-pjax-version&quot; content=&quot;23a593132acf8377452acb276ca608e2f47f020fa5dd6bb74cd12cecef1610d0&quot;/&gt;&lt;link href=&quot;https://github.com/jmdugan/blocklists/commits/master.atom&quot; rel=&quot;alternate&quot; title=&quot;Recent Commits to blocklists:master&quot; type=&quot;application/atom+xml&quot;/&gt;&lt;meta name=&quot;go-import&quot; content=&quot;github.com/jmdugan/blocklists git https://github.com/jmdugan/blocklists.git&quot;/&gt;&lt;meta name=&quot;octolytics-dimension-user_id&quot; content=&quot;25763&quot;/&gt;&lt;meta name=&quot;octolytics-dimension-user_login&quot; content=&quot;jmdugan&quot;/&gt;&lt;meta name=&quot;octolytics-dimension-repository_id&quot; content=&quot;59844792&quot;/&gt;&lt;meta name=&quot;octolytics-dimension-repository_nwo&quot; content=&quot;jmdugan/blocklists&quot;/&gt;&lt;meta name=&quot;octolytics-dimension-repository_public&quot; content=&quot;true&quot;/&gt;&lt;meta name=&quot;octolytics-dimension-repository_is_fork&quot; content=&quot;false&quot;/&gt;&lt;meta name=&quot;octolytics-dimension-repository_network_root_id&quot; content=&quot;59844792&quot;/&gt;&lt;meta name=&quot;octolytics-dimension-repository_network_root_nwo&quot; content=&quot;jmdugan/blocklists&quot;/&gt;&lt;link rel=&quot;canonical&quot; href=&quot;https://github.com/jmdugan/blocklists/tree/master/corporations/facebook&quot; data-pjax-transient=&quot;&quot;/&gt;&lt;meta name=&quot;browser-stats-url&quot; content=&quot;https://api.github.com/_private/browser/stats&quot;/&gt;&lt;meta name=&quot;browser-errors-url&quot; content=&quot;https://api.github.com/_private/browser/errors&quot;/&gt;&lt;meta name=&quot;browser-optimizely-client-errors-url&quot; content=&quot;https://api.github.com/_private/browser/optimizely_client/errors&quot;/&gt;&lt;link rel=&quot;mask-icon&quot; href=&quot;https://github.githubassets.com/pinned-octocat.svg&quot; color=&quot;#000000&quot;/&gt;&lt;link rel=&quot;alternate icon&quot; class=&quot;js-site-favicon&quot; type=&quot;image/png&quot; href=&quot;https://github.githubassets.com/favicons/favicon.png&quot;/&gt;&lt;link rel=&quot;icon&quot; class=&quot;js-site-favicon&quot; type=&quot;image/svg+xml&quot; href=&quot;https://github.githubassets.com/favicons/favicon.svg&quot;/&gt;&lt;meta name=&quot;theme-color&quot; content=&quot;#1e2327&quot;/&gt;&lt;link rel=&quot;manifest&quot; href=&quot;/manifest.json&quot; crossorigin=&quot;use-credentials&quot;/&gt;&lt;/head&gt;&lt;body class=&quot;logged-out env-production page-responsive&quot; id=&quot;readabilityBody&quot; readability=&quot;15.66265060241&quot;&gt;


&lt;div data-pjax-replace=&quot;&quot; id=&quot;js-flash-container&quot;&gt;
&lt;div class=&quot;flash flash-full {{ className }}&quot;&gt;
&lt;div class=&quot; px-2&quot;&gt;
&lt;p&gt;{{ message }}&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;application-main&quot; data-commit-hovercards-enabled=&quot;&quot; data-discussion-hovercards-enabled=&quot;&quot; data-issue-and-pr-hovercards-enabled=&quot;&quot;&gt;
&lt;div itemscope=&quot;&quot; itemtype=&quot;http://schema.org/SoftwareSourceCode&quot; class=&quot;&quot;&gt;

&lt;div class=&quot;container-xl clearfix new-discussion-timeline px-3 px-md-4 px-lg-5&quot;&gt;
&lt;div id=&quot;repo-content-pjax-container&quot; class=&quot;repository-content&quot;&gt;
&lt;div readability=&quot;1.5130434782609&quot;&gt;


&lt;div class=&quot;Box mb-3&quot; readability=&quot;1.7483380816714&quot;&gt;

&lt;h2 id=&quot;files&quot; class=&quot;sr-only&quot;&gt;Files&lt;/h2&gt;
&lt;a class=&quot;d-none js-permalink-shortcut&quot; data-hotkey=&quot;y&quot; href=&quot;https://github.com/jmdugan/blocklists/tree/12d6ecfece4f22d587d923cc272753b58f3833ba/corporations/facebook&quot;&gt;Permalink&lt;/a&gt;
&lt;p&gt;Failed to load latest commit information.&lt;/p&gt;
&lt;div class=&quot;js-details-container Details&quot;&gt;
&lt;div role=&quot;grid&quot; aria-labelledby=&quot;files&quot; class=&quot;Details-content--hidden-not-important js-navigation-container js-active-navigation-container d-block&quot; data-pjax=&quot;&quot;&gt;
&lt;div class=&quot;sr-only&quot; role=&quot;row&quot;&gt;
&lt;p&gt;Type&lt;/p&gt;
&lt;p&gt;Name&lt;/p&gt;
&lt;p&gt;Latest commit message&lt;/p&gt;
&lt;p&gt;Commit time&lt;/p&gt;
&lt;/div&gt;

&lt;div role=&quot;row&quot; class=&quot;Box-row Box-row--focus-gray py-2 d-flex position-relative js-navigation-item&quot;&gt;



&lt;p&gt;Jun 24, 2020&lt;/p&gt;
&lt;/div&gt;
&lt;div role=&quot;row&quot; class=&quot;Box-row Box-row--focus-gray py-2 d-flex position-relative js-navigation-item&quot;&gt;



&lt;p&gt;Jun 24, 2020&lt;/p&gt;
&lt;/div&gt;
&lt;div role=&quot;row&quot; class=&quot;Box-row Box-row--focus-gray py-2 d-flex position-relative js-navigation-item&quot;&gt;



&lt;p&gt;Jun 24, 2020&lt;/p&gt;
&lt;/div&gt;
&lt;div role=&quot;row&quot; class=&quot;Box-row Box-row--focus-gray py-2 d-flex position-relative js-navigation-item&quot;&gt;



&lt;p&gt;Jun 24, 2020&lt;/p&gt;
&lt;/div&gt;
&lt;div role=&quot;row&quot; class=&quot;Box-row Box-row--focus-gray py-2 d-flex position-relative js-navigation-item&quot;&gt;



&lt;p&gt;Jun 24, 2020&lt;/p&gt;
&lt;/div&gt;
&lt;div role=&quot;row&quot; class=&quot;Box-row Box-row--focus-gray py-2 d-flex position-relative js-navigation-item&quot;&gt;



&lt;p&gt;Jun 24, 2020&lt;/p&gt;
&lt;/div&gt;
&lt;div role=&quot;row&quot; class=&quot;Box-row Box-row--focus-gray py-2 d-flex position-relative js-navigation-item&quot;&gt;



&lt;p&gt;Sep 24, 2019&lt;/p&gt;
&lt;/div&gt;
&lt;div role=&quot;row&quot; class=&quot;Box-row Box-row--focus-gray py-2 d-flex position-relative js-navigation-item&quot;&gt;



&lt;p&gt;Feb 6, 2020&lt;/p&gt;
&lt;/div&gt;
&lt;div role=&quot;row&quot; class=&quot;Box-row Box-row--focus-gray py-2 d-flex position-relative js-navigation-item&quot;&gt;



&lt;p&gt;Feb 7, 2020&lt;/p&gt;
&lt;/div&gt;
&lt;div role=&quot;row&quot; class=&quot;Box-row Box-row--focus-gray py-2 d-flex position-relative js-navigation-item&quot;&gt;



&lt;p&gt;Sep 24, 2019&lt;/p&gt;
&lt;/div&gt;
&lt;div role=&quot;row&quot; class=&quot;Box-row Box-row--focus-gray py-2 d-flex position-relative js-navigation-item&quot;&gt;



&lt;p&gt;Feb 6, 2020&lt;/p&gt;
&lt;/div&gt;
&lt;div role=&quot;row&quot; class=&quot;Box-row Box-row--focus-gray py-2 d-flex position-relative js-navigation-item&quot;&gt;



&lt;p&gt;Feb 7, 2020&lt;/p&gt;
&lt;/div&gt;
&lt;div role=&quot;row&quot; class=&quot;Box-row Box-row--focus-gray py-2 d-flex position-relative js-navigation-item&quot;&gt;



&lt;p&gt;Apr 12, 2018&lt;/p&gt;
&lt;/div&gt;
&lt;div role=&quot;row&quot; class=&quot;Box-row Box-row--focus-gray py-2 d-flex position-relative js-navigation-item&quot;&gt;



&lt;p&gt;Feb 6, 2020&lt;/p&gt;
&lt;/div&gt;
&lt;div role=&quot;row&quot; class=&quot;Box-row Box-row--focus-gray py-2 d-flex position-relative js-navigation-item&quot;&gt;



&lt;p&gt;Feb 7, 2020&lt;/p&gt;
&lt;/div&gt;
&lt;div role=&quot;row&quot; class=&quot;Box-row Box-row--focus-gray py-2 d-flex position-relative js-navigation-item&quot;&gt;



&lt;p&gt;Feb 7, 2020&lt;/p&gt;
&lt;/div&gt;
&lt;div role=&quot;row&quot; class=&quot;Box-row Box-row--focus-gray py-2 d-flex position-relative js-navigation-item&quot;&gt;



&lt;p&gt;Feb 7, 2020&lt;/p&gt;
&lt;/div&gt;
&lt;div role=&quot;row&quot; class=&quot;Box-row Box-row--focus-gray py-2 d-flex position-relative js-navigation-item&quot;&gt;



&lt;p&gt;Feb 7, 2020&lt;/p&gt;
&lt;/div&gt;
&lt;div role=&quot;row&quot; class=&quot;Box-row Box-row--focus-gray py-2 d-flex position-relative js-navigation-item&quot;&gt;



&lt;p&gt;May 27, 2016&lt;/p&gt;
&lt;/div&gt;
&lt;div role=&quot;row&quot; class=&quot;Box-row Box-row--focus-gray py-2 d-flex position-relative js-navigation-item&quot;&gt;



&lt;p&gt;Feb 6, 2020&lt;/p&gt;
&lt;/div&gt;
&lt;div role=&quot;row&quot; class=&quot;Box-row Box-row--focus-gray py-2 d-flex position-relative js-navigation-item&quot;&gt;



&lt;p&gt;Feb 7, 2020&lt;/p&gt;
&lt;/div&gt;
&lt;div role=&quot;row&quot; class=&quot;Box-row Box-row--focus-gray py-2 d-flex position-relative js-navigation-item&quot;&gt;



&lt;p&gt;Apr 2, 2018&lt;/p&gt;
&lt;/div&gt;
&lt;div role=&quot;row&quot; class=&quot;Box-row Box-row--focus-gray py-2 d-flex position-relative js-navigation-item&quot;&gt;



&lt;p&gt;Feb 6, 2020&lt;/p&gt;
&lt;/div&gt;
&lt;div role=&quot;row&quot; class=&quot;Box-row Box-row--focus-gray py-2 d-flex position-relative js-navigation-item&quot;&gt;



&lt;p&gt;Feb 7, 2020&lt;/p&gt;
&lt;/div&gt;
&lt;div role=&quot;row&quot; class=&quot;Box-row Box-row--focus-gray py-2 d-flex position-relative js-navigation-item&quot;&gt;



&lt;p&gt;May 27, 2016&lt;/p&gt;
&lt;/div&gt;
&lt;div role=&quot;row&quot; class=&quot;Box-row Box-row--focus-gray py-2 d-flex position-relative js-navigation-item&quot;&gt;



&lt;p&gt;Feb 6, 2020&lt;/p&gt;
&lt;/div&gt;
&lt;div role=&quot;row&quot; class=&quot;Box-row Box-row--focus-gray py-2 d-flex position-relative js-navigation-item&quot;&gt;



&lt;p&gt;Feb 7, 2020&lt;/p&gt;
&lt;/div&gt;
&lt;div role=&quot;row&quot; class=&quot;Box-row Box-row--focus-gray py-2 d-flex position-relative js-navigation-item&quot;&gt;



&lt;p&gt;Feb 7, 2020&lt;/p&gt;
&lt;/div&gt;
&lt;div role=&quot;row&quot; class=&quot;Box-row Box-row--focus-gray py-2 d-flex position-relative js-navigation-item&quot;&gt;



&lt;p&gt;Feb 7, 2020&lt;/p&gt;
&lt;/div&gt;
&lt;div role=&quot;row&quot; class=&quot;Box-row Box-row--focus-gray py-2 d-flex position-relative js-navigation-item&quot;&gt;



&lt;p&gt;Feb 7, 2020&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;You can’t perform that action at this time.&lt;/p&gt;
&lt;div class=&quot;js-stale-session-flash flash flash-warn flash-banner&quot; hidden=&quot;&quot;&gt;&lt;span class=&quot;js-stale-session-flash-signed-in&quot; hidden=&quot;&quot;&gt;You signed in with another tab or window. &lt;a href=&quot;https://github.com/jmdugan/blocklists/tree/master/corporations/facebook&quot;&gt;Reload&lt;/a&gt; to refresh your session.&lt;/span&gt; &lt;span class=&quot;js-stale-session-flash-signed-out&quot; hidden=&quot;&quot;&gt;You signed out in another tab or window. &lt;a href=&quot;https://github.com/jmdugan/blocklists/tree/master/corporations/facebook&quot;&gt;Reload&lt;/a&gt; to refresh your session.&lt;/span&gt;&lt;/div&gt;
&lt;details class=&quot;details-reset details-overlay details-overlay-dark lh-default text-gray-dark hx_rsm&quot; open=&quot;&quot;&gt;
&lt;/details&gt;
&lt;/body&gt;</description>
<pubDate>Wed, 10 Feb 2021 18:21:33 +0000</pubDate>
<dc:creator>prakhargurunani</dc:creator>
<og:image>https://avatars.githubusercontent.com/u/25763?s=400&amp;v=4</og:image>
<og:type>object</og:type>
<og:title>jmdugan/blocklists</og:title>
<og:url>https://github.com/jmdugan/blocklists</og:url>
<og:description>Shared lists of problem domains people may want to block with hosts files - jmdugan/blocklists</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://github.com/jmdugan/blocklists/tree/master/corporations/facebook</dc:identifier>
</item>
<item>
<title>Hello system, a FreeBSD-based OS designed to resemble Mac</title>
<link>https://hellosystem.github.io/docs/</link>
<guid isPermaLink="true" >https://hellosystem.github.io/docs/</guid>
<description>&lt;a class=&quot;reference internal image-reference&quot; href=&quot;https://raw.githubusercontent.com/helloSystem/hello/1d1e69be8a689c5e0a176df821c14f0b49b241a4/branding/hello_variation.svg&quot;&gt;&lt;img alt=&quot;https://raw.githubusercontent.com/helloSystem/hello/1d1e69be8a689c5e0a176df821c14f0b49b241a4/branding/hello_variation.svg&quot; class=&quot;align-center&quot; src=&quot;https://raw.githubusercontent.com/helloSystem/hello/1d1e69be8a689c5e0a176df821c14f0b49b241a4/branding/hello_variation.svg&quot; width=&quot;300px&quot;/&gt;&lt;/a&gt;&lt;p class=&quot;centered&quot;&gt;&lt;strong&gt;Willkommen • Welcome • 欢迎 • Bienvenue • Benvenuto • Bienvenido • ようこそ • Mabuhay • Välkommen • Добро пожаловать • Merhaba • Bonvenon • 歡迎光臨&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;section&quot; id=&quot;hello&quot;&gt;

&lt;p&gt;&lt;strong&gt;hello&lt;/strong&gt; (also known as &lt;strong&gt;helloSystem&lt;/strong&gt;) is a desktop system for creators with focus on simplicity, elegance, and usability. Its design follows the “Less, but better” philosophy. It is intended as a system for “mere mortals”, welcoming to switchers from the Mac. &lt;a class=&quot;reference external&quot; href=&quot;https://www.freebsd.org/&quot;&gt;FreeBSD&lt;/a&gt; is used as the core operating system. Please refer to &lt;a class=&quot;reference external&quot; href=&quot;https://github.com/helloSystem/hello&quot;&gt;https://github.com/helloSystem/hello&lt;/a&gt; if you would like to learn more about the ideas and principles behind hello.&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;Screenshot&quot; src=&quot;https://github.com/helloSystem/hello/blob/master/screenshots/20210210-desktop-0.4.png?raw=true&quot;/&gt;&lt;/p&gt;


&lt;/div&gt;
</description>
<pubDate>Wed, 10 Feb 2021 17:22:53 +0000</pubDate>
<dc:creator>gautamcgoel</dc:creator>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://hellosystem.github.io/docs/</dc:identifier>
</item>
<item>
<title>Illegal CFC emissions have stopped since scientists raised alarm</title>
<link>https://www.nature.com/articles/d41586-021-00360-0</link>
<guid isPermaLink="true" >https://www.nature.com/articles/d41586-021-00360-0</guid>
<description>&lt;div class=&quot;content position-relative cleared clear mq1200-padded&quot; data-component=&quot;article-container&quot; role=&quot;main&quot;&gt;
&lt;header class=&quot;article-item__header clear cleared pull--both&quot;&gt;&lt;div class=&quot;article__type&quot;&gt;NEWS
&lt;div class=&quot;ml10 article__date&quot;&gt;&lt;time itemprop=&quot;datePublished&quot;&gt;10 February 2021&lt;/time&gt;&lt;/div&gt;
&lt;/div&gt;


&lt;div class=&quot;article-item__teaser-text&quot;&gt;Analyses suggest that China has successfully curbed production of an ozone-depleting chemical, a win for the international treaty that protects the ozone layer.&lt;/div&gt;
&lt;/header&gt;
&lt;div class=&quot;bordered-container clear cleared pull--both&quot;&gt;
&lt;div id=&quot;author-affiliations&quot; class=&quot;tab-group text14&quot; role=&quot;tablist&quot; data-test=&quot;author-affiliations&quot; data-tab-group=&quot;&quot;&gt;
&lt;div class=&quot;cleared&quot;&gt;
&lt;div id=&quot;author-affiliation-news-0&quot; class=&quot;tab-box js-box-wrapper&quot;&gt;
&lt;h3 id=&quot;author-affiliation-news-0-head&quot; data-track=&quot;click&quot; data-track-label=&quot;view author info&quot; class=&quot;sans-serif strong tab tab-skin ma0&quot; role=&quot;tab&quot; aria-controls=&quot;author-affiliation-news-0-content&quot; data-tooltip=&quot;Show author information&quot;&gt;Jeff Tollefson&lt;/h3&gt;
&lt;div id=&quot;author-affiliation-news-0-content&quot; class=&quot;tab-content pin-right grid grid-12 last&quot; role=&quot;tabpanel&quot;&gt;
&lt;div class=&quot;pa10&quot; aria-labelledby=&quot;author-affiliation-news-0-head&quot;&gt;
&lt;div class=&quot;clear cleared&quot;&gt;
&lt;div class=&quot;align-left&quot;&gt;
&lt;h4 class=&quot;sans-serif&quot;&gt;Search for this author in:&lt;/h4&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;align-left&quot;&gt;
&lt;div class=&quot;article__body cleared&quot;&gt;
&lt;div class=&quot;embed intensity--high&quot;&gt;&lt;img class=&quot;figure__image&quot; alt=&quot;The Earth's stratosphere&quot; data-src=&quot;//media.nature.com/lw800/magazine-assets/d41586-021-00360-0/d41586-021-00360-0_18848488.jpg&quot;/&gt;&lt;noscript&gt;
&lt;p&gt;&lt;img class=&quot;&quot; alt=&quot;The Earth's stratosphere&quot; src=&quot;https://media.nature.com/lw800/magazine-assets/d41586-021-00360-0/d41586-021-00360-0_18848488.jpg&quot;/&gt;&lt;/p&gt;
&lt;/noscript&gt;
&lt;p class=&quot;figure__caption sans-serif&quot;&gt;&lt;span class=&quot;mr10&quot;&gt;Production of the ozone-destroying chemical CFC-11 has been banned since 2010.&lt;/span&gt;&lt;span&gt;Credit: NASA&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Illegal emissions of an ozone-destroying chemical once used in refrigerants and foam insulation have virtually come to a halt, scientists reported this week, nearly three years after the rogue emissions were first documented. Researchers say the result is a major win for the international treaty that protects the ozone layer.&lt;/p&gt;
&lt;p&gt;In May 2018, &lt;a href=&quot;https://www.nature.com/articles/d41586-018-07269-1&quot; data-track=&quot;click&quot; data-label=&quot;https://www.nature.com/articles/d41586-018-07269-1&quot; data-track-category=&quot;body text link&quot;&gt;researchers documented&lt;/a&gt; a mysterious spike in atmospheric concentrations of trichlorofluoromethane&lt;sup&gt;&lt;a href=&quot;https://www.nature.com/articles/d41586-021-00360-0#ref-CR1&quot; data-track=&quot;click&quot; data-action=&quot;anchor-link&quot; data-track-label=&quot;go to reference&quot; data-track-category=&quot;references&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;, or CFC-11, that had begun in around 2013. Production of the chemical had been banned since 2010 under the Montreal Protocol, a legally binding treaty that has been remarkably successful in curbing the use of ozone-depleting substances, so scientists surmised that the sudden increase was probably the result of a new source of illegal emissions. By May 2019, scientists had traced the &lt;a href=&quot;https://www.nature.com/articles/d41586-019-01647-z&quot; data-track=&quot;click&quot; data-label=&quot;https://www.nature.com/articles/d41586-019-01647-z&quot; data-track-category=&quot;body text link&quot;&gt;bulk of the emissions&lt;/a&gt; to eastern China&lt;sup&gt;&lt;a href=&quot;https://www.nature.com/articles/d41586-021-00360-0#ref-CR2&quot; data-track=&quot;click&quot; data-action=&quot;anchor-link&quot; data-track-label=&quot;go to reference&quot; data-track-category=&quot;references&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;. In response to &lt;a href=&quot;https://www.nature.com/articles/d41586-019-02109-2&quot; data-track=&quot;click&quot; data-label=&quot;https://www.nature.com/articles/d41586-019-02109-2&quot; data-track-category=&quot;body text link&quot;&gt;significant international pressure&lt;/a&gt;, the country committed to rectifying the problem.&lt;/p&gt;
&lt;p&gt;In a pair of studies published in &lt;em&gt;Nature&lt;/em&gt; on 10 February, scientists report that atmospheric concentrations of CFC-11 have dropped precipitously since 2018&lt;sup&gt;&lt;a href=&quot;https://www.nature.com/articles/d41586-021-00360-0#ref-CR3&quot; data-track=&quot;click&quot; data-action=&quot;anchor-link&quot; data-track-label=&quot;go to reference&quot; data-track-category=&quot;references&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;sup&gt;,&lt;/sup&gt;&lt;sup&gt;&lt;a href=&quot;https://www.nature.com/articles/d41586-021-00360-0#ref-CR4&quot; data-track=&quot;click&quot; data-action=&quot;anchor-link&quot; data-track-label=&quot;go to reference&quot; data-track-category=&quot;references&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;. Assuming the current trend continues, the damage to the ozone layer from several years of illegal emissions will be negligible, says Stephen Montzka, an atmospheric chemist at the National Oceanic and Atmospheric Administration in Boulder, Colorado, who led one of the studies.&lt;/p&gt;
&lt;p&gt;“The treaty did its job,” says Durwood Zaelke, president of the Institute for Governance &amp;amp; Sustainable Development, an advocacy group based in Washington DC. “Whoever the offending parties were — including most definitely China — they got their act together.” However, the sources of illegal emissions outside China remain a mystery.&lt;/p&gt;
&lt;p&gt;China’s Ministry of Ecology and Environment did not reply to several requests for comment in relation to the latest results and the actions it has taken to halt illegal CFC-11 emissions.&lt;/p&gt;
&lt;h2&gt;Global surveillance&lt;/h2&gt;
&lt;p&gt;CFC-11 survives in the atmosphere for about 50 years, so, if sources were completely eliminated, global emissions should decline by around 2% annually. But the actual rate is slower, owing to continued emissions of the chemical from old refrigeration systems and from insulating foam when buildings are demolished. Between 2002 and 2012, CFC-11 emissions fell by around 0.85% a year. But that rate halved — to about 0.4% — after 2013, a sign that somebody was pumping around 13,000 tonnes a year of newly produced CFCs into the atmosphere, Montzka’s team calculated in 2018. The most likely culprit was the manufacture and use of foam insulation.&lt;/p&gt;
&lt;p&gt;The analysis published this week, using data from two independent global air-monitoring networks, indicates that concentrations of CFC-11 began to decline more rapidly in 2018. By late 2019, CFC-11 concentrations were dropping by around 1% a year — the fastest pace on record&lt;sup&gt;&lt;a href=&quot;https://www.nature.com/articles/d41586-021-00360-0#ref-CR3&quot; data-track=&quot;click&quot; data-action=&quot;anchor-link&quot; data-track-label=&quot;go to reference&quot; data-track-category=&quot;references&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;In a second paper, Montzka and colleagues used measurements from air-monitoring stations in South Korea and Japan, as well as detailed atmospheric-transport modelling, to show that the largest source of the rogue emissions — in eastern China — has been shut down. The study incorporated independent analyses from four different research groups and two models, all of which showed consistent results, says Luke Western, an atmospheric scientist at the University of Bristol, UK, and a co-author on the paper.&lt;/p&gt;
&lt;p&gt;“Around 60% of the global increase came from that region, and 60% of the recent decrease also came from there,” Western says.&lt;/p&gt;
&lt;h2&gt;Data gaps&lt;/h2&gt;
&lt;p&gt;The research can’t account for some of the decline in emissions, however, which points to gaps in data collection around the world, including in industrially important countries such as India and Brazil. Although 60% of the recent decrease has been accounted for, “we still don’t know where the other 40% was coming from”, says Martin Vollmer, an atmospheric scientist at the Swiss Federal Laboratories for Materials Science and Technology in Dübendorf. Nonetheless, the episode should send a warning signal to those who might be tempted to break the rules in future.&lt;/p&gt;
&lt;p&gt;Montzka says discussions are under way among parties to the Montreal Protocol to expand the network of monitoring stations. But for now, he says, it’s encouraging — and a bit surprising — to see governments respond to the science and take action to halt illegal emissions. “We were there to catch the problem, and now we can be there to announce that they have addressed it,” Montzka says. “It’s a nice thing.”&lt;/p&gt;
&lt;/div&gt;


&lt;div id=&quot;references&quot; class=&quot;references&quot; data-toggle=&quot;anchor-links-section&quot; data-label=&quot;References&quot; data-concertina=&quot;true&quot;&gt;
&lt;section aria-labelledby=&quot;Bib1&quot;&gt;&lt;div class=&quot;serif article-section js-article-section cleared clear&quot; id=&quot;Bib1-section&quot;&gt;
&lt;h2 class=&quot;js-section-title section-title strong position-relative tighten-line-height background-gray-light pt20 pb6 pl0 pr20 standard-space-below small-space-above mq640-pt10 mq640-pb10 mq640-pl20 mq640-mt0 mq640-ml-20 mq640-mr-20 extend-left&quot; id=&quot;Bib1&quot;&gt;References&lt;/h2&gt;
&lt;div class=&quot;pl20 mq875-pl0 js-collapsible-section&quot; id=&quot;Bib1-content&quot;&gt;
&lt;div data-container-section=&quot;references&quot;&gt;
&lt;ol class=&quot;clean-list ma0 standard-space-below indented-list&quot; data-test=&quot;references-list&quot;&gt;&lt;li class=&quot;small-space-below border-gray-medium border-bottom-1 position-relative js-ref-item&quot; itemprop=&quot;citation&quot; itemscope=&quot;itemscope&quot; itemtype=&quot;http://schema.org/Article&quot; data-test=&quot;citation&quot;&gt;&lt;span class=&quot;indented-counter serif h2 tighten-line-height text-right position-absolute grade-c-hide&quot;&gt;1.&lt;/span&gt;
&lt;p class=&quot;tiny-space-below&quot; id=&quot;ref-CR1&quot;&gt;Montzka, S. A. &lt;em&gt;et al.&lt;/em&gt; &lt;em&gt;Nature&lt;/em&gt; &lt;strong&gt;557&lt;/strong&gt;, 413–417 (2018).&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;small-space-below border-gray-medium border-bottom-1 position-relative js-ref-item&quot; itemprop=&quot;citation&quot; itemscope=&quot;itemscope&quot; itemtype=&quot;http://schema.org/Article&quot; data-test=&quot;citation&quot;&gt;&lt;span class=&quot;indented-counter serif h2 tighten-line-height text-right position-absolute grade-c-hide&quot;&gt;2.&lt;/span&gt;
&lt;p class=&quot;tiny-space-below&quot; id=&quot;ref-CR2&quot;&gt;Rigby, M. &lt;em&gt;et al.&lt;/em&gt; &lt;em&gt;Nature&lt;/em&gt; &lt;strong&gt;569&lt;/strong&gt;, 546–550 (2019).&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;small-space-below border-gray-medium border-bottom-1 position-relative js-ref-item&quot; itemprop=&quot;citation&quot; itemscope=&quot;itemscope&quot; itemtype=&quot;http://schema.org/Article&quot; data-test=&quot;citation&quot;&gt;&lt;span class=&quot;indented-counter serif h2 tighten-line-height text-right position-absolute grade-c-hide&quot;&gt;3.&lt;/span&gt;
&lt;p class=&quot;tiny-space-below&quot; id=&quot;ref-CR3&quot;&gt;Montzka, S. A. &lt;em&gt;et al. Nature&lt;/em&gt; https://doi.org/10.1038/s41586-021-03260-5 (2021).&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;small-space-below border-gray-medium border-bottom-1 position-relative js-ref-item&quot; itemprop=&quot;citation&quot; itemscope=&quot;itemscope&quot; itemtype=&quot;http://schema.org/Article&quot; data-test=&quot;citation&quot;&gt;&lt;span class=&quot;indented-counter serif h2 tighten-line-height text-right position-absolute grade-c-hide&quot;&gt;4.&lt;/span&gt;
&lt;p class=&quot;tiny-space-below&quot; id=&quot;ref-CR4&quot;&gt;Park, S. &lt;em&gt;et al. Nature&lt;/em&gt; https://doi.org/10.1038/s41586-021-03277-w (2021).&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;p class=&quot;hide-print text-right&quot;&gt;&lt;a href=&quot;https://www.nature.com/articles/d41586-021-00360-0-references.ris&quot; class=&quot;text14 sans-serif strong&quot; data-track=&quot;click&quot; data-track-action=&quot;download citation references&quot; data-track-label=&quot;link&quot;&gt;Download references&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/section&gt;&lt;/div&gt;
&lt;aside class=&quot;c-latest-content mt40 hide-print&quot; data-simple-tab=&quot;&quot; data-tab-group=&quot;&quot; data-component-id=&quot;latest-news&quot; data-track=&quot;in-view&quot; data-track-action=&quot;in-view&quot; data-track-category=&quot;latest content&quot; data-track-label=&quot;visible&quot;&gt;&lt;div id=&quot;latest-content&quot; role=&quot;tablist&quot;&gt;
&lt;p class=&quot;strong&quot;&gt;Latest on:&lt;/p&gt;
&lt;div class=&quot;cleared&quot;&gt;

&lt;div id=&quot;latest-content-1&quot; class=&quot;c-latest-content__container&quot; data-container=&quot;&quot;&gt;
&lt;p id=&quot;latest-content-1-head&quot; class=&quot;c-latest-content__category c-latest-content__switch&quot; data-switch=&quot;&quot; role=&quot;tab&quot; aria-controls=&quot;latest-content-1-content&quot; data-track=&quot;click&quot; data-track-label=&quot;latest tag (rank:1)&quot;&gt;Climate sciences&lt;/p&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/aside&gt;&lt;div class=&quot;js-jobs-career-wrapper&quot;&gt;
&lt;section class=&quot;section__jobs-career u-highlighted-section--light cleared&quot; data-track=&quot;in-view&quot; data-track-action=&quot;in-view&quot; data-track-category=&quot;career&quot; data-track-label=&quot;visible&quot;&gt;&lt;div class=&quot;u-container c-component&quot;&gt;
&lt;h3 class=&quot;u-serif c-component__title&quot;&gt;&lt;a data-track=&quot;click&quot; data-track-action=&quot;section-link&quot; data-track-category=&quot;career&quot; data-track-label=&quot;jobs list title&quot; href=&quot;https://www.nature.com/naturecareers/&quot; class=&quot;js-job-title-link&quot;&gt;Jobs from Nature Careers&lt;/a&gt;&lt;/h3&gt;
&lt;ul class=&quot;u-flex u-flex--wrap u-clean-list mb0&quot;&gt;&lt;li class=&quot;u-flex u-col u-col--lg-4-4 u-flex--wrap&quot;&gt;
&lt;ul class=&quot;u-flex u-flex--wrap u-clean-list mb0&quot;&gt;&lt;li class=&quot;u-flex u-col&quot;&gt;
&lt;/li&gt;
&lt;li class=&quot;u-flex u-col pa10&quot;&gt;
&lt;ul class=&quot;u-flex u-flex--wrap mb0 u-clean-list c-card__article-list--career&quot;&gt;&lt;li class=&quot;u-flex u-col&quot;&gt;
&lt;div class=&quot;c-card c-card--regular c-card--career u-flex&quot;&gt;
&lt;div class=&quot;c-card__container u-flex u-flex-align-items--flex-start&quot;&gt;
&lt;div class=&quot;c-card__copy u-flex__content u-col&quot;&gt;
&lt;h3 class=&quot;c-card__title c-card__title--career u-serif u-text17 u-font-weight--regular&quot;&gt;Scientist- RNA Therapeutics&lt;/h3&gt;
&lt;p class=&quot;mb10&quot;&gt;Houston Methodist Research Institute&lt;/p&gt;
&lt;p&gt;Houston, TX, United States&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li class=&quot;u-flex u-col&quot;&gt;
&lt;div class=&quot;c-card c-card--regular c-card--career u-flex&quot;&gt;
&lt;div class=&quot;c-card__container u-flex u-flex-align-items--flex-start&quot;&gt;
&lt;div class=&quot;c-card__copy u-flex__content u-col&quot;&gt;
&lt;h3 class=&quot;c-card__title c-card__title--career u-serif u-text17 u-font-weight--regular&quot;&gt;Senior Research Investigator&lt;/h3&gt;
&lt;p class=&quot;mb10&quot;&gt;Thomas Jefferson University (TJU)&lt;/p&gt;
&lt;p&gt;Philadelphia, PA, United States&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li class=&quot;u-flex u-col&quot;&gt;
&lt;div class=&quot;c-card c-card--regular c-card--career u-flex&quot;&gt;
&lt;div class=&quot;c-card__container u-flex u-flex-align-items--flex-start&quot;&gt;
&lt;div class=&quot;c-card__copy u-flex__content u-col&quot;&gt;
&lt;h3 class=&quot;c-card__title c-card__title--career u-serif u-text17 u-font-weight--regular&quot;&gt;Postdoctoral Scholar in Stem Cell Biology and Endocrinology&lt;/h3&gt;
&lt;p class=&quot;mb10&quot;&gt;University of California San Francisco (UCSF)&lt;/p&gt;
&lt;p&gt;San Francisco, CA, United States&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li class=&quot;u-flex u-col&quot;&gt;
&lt;div class=&quot;c-card c-card--regular c-card--career u-flex&quot;&gt;
&lt;div class=&quot;c-card__container u-flex u-flex-align-items--flex-start&quot;&gt;
&lt;div class=&quot;c-card__copy u-flex__content u-col&quot;&gt;
&lt;h3 class=&quot;c-card__title c-card__title--career u-serif u-text17 u-font-weight--regular&quot;&gt;Postdoctoral Fellow-Proteomics/Mass Spectrometry&lt;/h3&gt;
&lt;p class=&quot;mb10&quot;&gt;Tulane University School of Medicine (SOM)&lt;/p&gt;
&lt;p&gt;New Orleans, United States&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;
&lt;/section&gt;&lt;/div&gt;
&lt;div class=&quot;nature-briefing nature-briefing-box mt0 cleared hide-print&quot; data-component-id=&quot;nature-briefing-box&quot; data-track=&quot;in-view&quot; data-track-action=&quot;in-view&quot; data-track-category=&quot;nature briefing&quot; data-track-label=&quot;inPage box visible&quot;&gt;
&lt;div class=&quot;nature-briefing-box__header pa20&quot;&gt;

&lt;p class=&quot;nature-briefing-box__standfirst mb0 sans-serif tighten-line-height&quot;&gt;An essential round-up of science news, opinion and analysis, delivered to your inbox every weekday.&lt;/p&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;aside class=&quot;article__aside align-right&quot;&gt;&lt;div class=&quot;related-content shrink--aside hide-print&quot;&gt;
&lt;h3 class=&quot;aside__title sans-serif&quot;&gt;Related Articles&lt;/h3&gt;
&lt;/div&gt;

&lt;div id=&quot;div-gpt-ad-right-2&quot; class=&quot;div-gpt-ad medium-rectangle advert js-ad text-center hide-print grade-c-hide&quot; data-gpt-unitpath=&quot;/285/nature.com/article&quot; data-gpt-sizes=&quot;300x250&quot; data-gpt-targeting=&quot;pos=right;artid=/articles/d41586-021-00360-0;path=/articles/d41586-021-00360-0&quot; data-ad-type=&quot;right&quot;&gt;&lt;noscript&gt;
&lt;p&gt;&lt;a href=&quot;https://pubads.g.doubleclick.net/gampad/jump?iu=/285/nature.com/article&amp;amp;sz=300x250&amp;amp;c=-1720929880&amp;amp;t=pos%3Dright%26artid%3D/articles/d41586-021-00360-0&quot;&gt;&lt;img data-test=&quot;gpt-advert-fallback-img&quot; src=&quot;https://pubads.g.doubleclick.net/gampad/ad?iu=/285/nature.com/article&amp;amp;sz=300x250&amp;amp;c=-1720929880&amp;amp;t=pos%3Dright%26artid%3D/articles/d41586-021-00360-0&quot; alt=&quot;Advertisement&quot; width=&quot;300&quot; height=&quot;250&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/noscript&gt;&lt;/div&gt;

&lt;/aside&gt;&lt;/div&gt;
</description>
<pubDate>Wed, 10 Feb 2021 16:39:31 +0000</pubDate>
<dc:creator>samizdis</dc:creator>
<og:url>https://www.nature.com/articles/d41586-021-00360-0</og:url>
<og:type>article</og:type>
<og:title>Illegal CFC emissions have stopped since scientists raised alarm</og:title>
<og:description>Analyses suggest that China has successfully curbed production of an ozone-depleting chemical, a win for the international treaty that protects the ozone layer.</og:description>
<og:image>https://media.nature.com/lw1024/magazine-assets/d41586-021-00360-0/d41586-021-00360-0_18848484.jpg</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.nature.com/articles/d41586-021-00360-0</dc:identifier>
</item>
<item>
<title>CS193p: Developing Apps for iOS</title>
<link>https://cs193p.sites.stanford.edu/</link>
<guid isPermaLink="true" >https://cs193p.sites.stanford.edu/</guid>
<description>&lt;p class=&quot;text-align-center&quot;&gt; &lt;/p&gt;
&lt;p class=&quot;text-align-center&quot;&gt;The lectures for the Spring 2020 version of Stanford University's course CS193p (Developing Applications for iOS using SwiftUI) were delivered to our students in an on-line fashion due to the novel coronavirus outbreak.  Stanford has made these lecture videos available to all by posting them on its YouTube channel (links below).  This website was set up to give everyone access to the supporting material that was distributed to students during the quarter (homework, demo code, etc.).&lt;/p&gt;
&lt;p class=&quot;text-align-center&quot;&gt;For more, check out the &lt;a href=&quot;https://cs193p.sites.stanford.edu/about&quot; title=&quot;About&quot;&gt;About&lt;/a&gt; page.&lt;/p&gt;
&lt;p class=&quot;text-align-center&quot;&gt;Also check out the &lt;a href=&quot;https://cs193p.sites.stanford.edu/wwdc&quot; title=&quot;WWDC&quot;&gt;Xcode 12&lt;/a&gt; page to see how some the latest changes to SwiftUI could be applied to the lecture materials after the quarter ended.&lt;/p&gt;
</description>
<pubDate>Wed, 10 Feb 2021 16:14:28 +0000</pubDate>
<dc:creator>rangoon626</dc:creator>
<og:url>https://cs193p.sites.stanford.edu/home</og:url>
<og:title>CS193p - Developing Apps for iOS</og:title>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://cs193p.sites.stanford.edu/</dc:identifier>
</item>
<item>
<title>Web Scraping 101 with Python</title>
<link>https://www.scrapingbee.com/blog/web-scraping-101-with-python/</link>
<guid isPermaLink="true" >https://www.scrapingbee.com/blog/web-scraping-101-with-python/</guid>
<description>&lt;p&gt;Learn web scraping with Python with this step-by-step tutorial. We will see the different ways to scrape the web in Python through lots of example.&lt;/p&gt;&lt;div property=&quot;articleBody&quot; readability=&quot;584.39185257032&quot;&gt;
&lt;div class=&quot;img&quot;&gt;&lt;img class=&quot;lazyload&quot; data-sizes=&quot;auto&quot; data-srcset=&quot; , https://d33wubrfki0l68.cloudfront.net/adfd4c7273134e8e7b76e7e2a7d2d5a32326f6fc/914d1/blog/web-scraping-101-with-python/python_101_cover_hu8a8d68b1832e8346b89f5afc8f3d2a1b_50362_825x0_resize_q75_catmullrom.jpg 825w&quot; data-src=&quot;https://d33wubrfki0l68.cloudfront.net/2d0fcdc12a1b40d9c2e0090b2d17e6edb33384cb/2bcf3/blog/web-scraping-101-with-python/python_101_cover.jpg&quot; width=&quot;1024&quot; height=&quot;512&quot; alt=&quot;Web Scraping 101 with Python&quot;/&gt;&lt;noscript&gt;
&lt;p&gt;&lt;img loading=&quot;lazy&quot; srcset=&quot; , https://d33wubrfki0l68.cloudfront.net/adfd4c7273134e8e7b76e7e2a7d2d5a32326f6fc/914d1/blog/web-scraping-101-with-python/python_101_cover_hu8a8d68b1832e8346b89f5afc8f3d2a1b_50362_825x0_resize_q75_catmullrom.jpg 825w&quot; src=&quot;https://d33wubrfki0l68.cloudfront.net/2d0fcdc12a1b40d9c2e0090b2d17e6edb33384cb/2bcf3/blog/web-scraping-101-with-python/python_101_cover.jpg&quot; width=&quot;1024&quot; height=&quot;512&quot; alt=&quot;Web Scraping 101 with Python&quot;/&gt;&lt;/p&gt;
&lt;/noscript&gt;&lt;/div&gt;
&lt;br/&gt;&lt;h2 id=&quot;introduction&quot;&gt;Introduction:&lt;/h2&gt;
&lt;p&gt;In this post, which can be read as a follow-up to our &lt;a href=&quot;https://www.scrapingbee.com/blog/web-scraping-without-getting-blocked&quot;&gt;ultimate web scraping guide&lt;/a&gt;, we will cover almost all of the tools Python offers to scrape the web. We will go from the basic to advanced ones, covering the pros and cons of each. Of course, we won't be able to cover every aspect of every tool we discuss, but this post should give you a good idea of what each tool does, and when to use one.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Note: When I talk about Python in this blog post you should assume that I talk about Python3.&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&quot;0-web-fundamentals&quot;&gt;0. Web Fundamentals&lt;/h2&gt;
&lt;p&gt;The internet is &lt;strong&gt;complex&lt;/strong&gt;: there are many underlying technologies and concepts involved to view a simple web page in your browser. I don’t have the pretension to explain everything, but I will explain the most important to understand for extracting data from the web.&lt;/p&gt;
&lt;h3 id=&quot;hypertext-transfer-protocol&quot;&gt;HyperText Transfer Protocol&lt;/h3&gt;
&lt;p&gt;HyperText Transfer Protocol (HTTP) uses a &lt;strong&gt;client/server&lt;/strong&gt; model. An HTTP client (a browser, your Python program, cURL, Requests…) opens a connection and sends a message (“I want to see that page : /product”)to an HTTP server (Nginx, Apache…). Then the server answers with a response (the HTML code for example) and closes the connection.&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;HTTP is called a &lt;em&gt;&lt;strong&gt;stateless protocol&lt;/strong&gt;&lt;/em&gt; because each transaction (request/response) is independent. FTP, for example, is stateful.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Basically, when you type a website address in your browser, the HTTP request looks like this:&lt;/p&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;18&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;GET /product/ HTTP/1.1
Host: example.com
Accept: text/html,application/xhtml+xml,application/xml;q&lt;span&gt;=&lt;/span&gt;0.9,image/web&lt;span&gt;\
&lt;/span&gt;p,*/*;q&lt;span&gt;=&lt;/span&gt;0.8
Accept-Encoding: gzip, deflate, sdch, br
Connection: keep-alive
User-Agent: Mozilla/5.0 &lt;span&gt;(&lt;/span&gt;Macintosh; Intel Mac OS X 10_11_6&lt;span&gt;)&lt;/span&gt; AppleWebKit&lt;span&gt;\
&lt;/span&gt;/537.36 &lt;span&gt;(&lt;/span&gt;KHTML, like Gecko&lt;span&gt;)&lt;/span&gt; Chrome/56.0.2924.87 Safari/537.36
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In the first line of this request, you can see the following:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;The GET verb or method: This means we request data from the specific path: &lt;code&gt;/product/&lt;/code&gt;. There are other HTTP verbs, and you can see the full list &lt;a href=&quot;https://www.w3schools.com/tags/ref_httpmethods.asp&quot;&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;The version of the HTTP protocol: In this tutorial we will focus on HTTP 1.&lt;/li&gt;
&lt;li&gt;Multiple headers fields: Connection, User-Agent… Here is an exhaustive list of &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers&quot;&gt;HTTP headers&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Here are the most important header fields :&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Host:&lt;/strong&gt; This is the domain name of the server. If no port number is given, it is assumed to be &lt;strong&gt;80&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;User-Agent:&lt;/strong&gt; This contains information about the client originating the request, including the OS. In this case, it is my web browser (Chrome) on macOS. This header is important because it is either used for statistics (how many users visit my website on mobile vs desktop) or to prevent violations by bots. Because these headers are sent by the clients, they can be modified (&lt;em&gt;“Header Spoofing”&lt;/em&gt;). This is exactly what we will do with our scrapers - make our scrapers look like a regular web browser.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Accept:&lt;/strong&gt; These are the content types that are acceptable as a response. There are lots of different content types and sub-types: &lt;strong&gt;text/plain, text/html, image/jpeg, application/json&lt;/strong&gt; …&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cookie&lt;/strong&gt; : This header field contains a list of name-value pairs (name1=value1;name2=value2). These session cookies are used to store data. Cookies are what websites use to authenticate users and/or store data in your browser. For example, when you fill a login form, the server will check if the credentials you entered are correct. If so, it will redirect you and inject a session cookie in your browser. Your browser will then send this cookie with every subsequent request to that server.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Referrer&lt;/strong&gt;: The Referrer header contains the URL from which the actual URL has been requested. This header is important because websites use this header to change their behavior based on where the user came from. For example, lots of news websites have a paying subscription and let you view only 10% of a post, but if the user comes from a news aggregator like Reddit, they let you view the full content. They use the referrer to check this. Sometimes we will have to spoof this header to get to the content we want to extract.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;And the list goes on…you can find the full header list &lt;a href=&quot;https://en.wikipedia.org/wiki/List_of_HTTP_header_fields&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;A server will respond with something like this:&lt;/p&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;8&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;HTTP/1.1 &lt;span&gt;200&lt;/span&gt; OK
Server: nginx/1.4.6 &lt;span&gt;(&lt;/span&gt;Ubuntu&lt;span&gt;)&lt;/span&gt; Content-Type: text/html; charset&lt;span&gt;=&lt;/span&gt;utf-8 &amp;lt;!DOCTYPE html&amp;gt;
&amp;lt;html&amp;gt;
&amp;lt;head&amp;gt;
&amp;lt;meta charset&lt;span&gt;=&lt;/span&gt;&lt;span&gt;&quot;utf-8&quot;&lt;/span&gt; /&amp;gt; ...&lt;span&gt;[&lt;/span&gt;HTML CODE&lt;span&gt;]&lt;/span&gt;
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;On the first line, we have a new piece of information, the HTTP code &lt;code&gt;200 OK&lt;/code&gt;. This means the request has succeeded. As for the request headers, there are lots of HTTP codes. They are split into four common classes: 2XX for successful requests, 3XX for redirects, 4XX for bad requests (the most famous being “404 Not Found”), and 5XX for server errors.&lt;/p&gt;
&lt;p&gt;Then, if you are sending this HTTP request with your web browser, the browser will parse the HTML code, fetch all the eventual assets (Javascript files, CSS files, images…), and render the result into the main window.&lt;/p&gt;
&lt;p&gt;We will go through the different ways to perform HTTP requests with Python and extract the data we want from the responses.&lt;/p&gt;
&lt;h2 id=&quot;1-manually-opening-a-socket-and-sending-the-http-request&quot;&gt;1. Manually Opening a Socket and Sending the HTTP Request&lt;/h2&gt;
&lt;h3 id=&quot;socket&quot;&gt;Socket&lt;/h3&gt;
&lt;p&gt;The most basic way to perform an HTTP request in Python is to open a &lt;a href=&quot;https://docs.python.org/3/howto/sockets.html&quot;&gt;socket&lt;/a&gt; and manually send the HTTP request.&lt;/p&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;12&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span&gt;import&lt;/span&gt; socket

HOST &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;www.google.com&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;  &lt;span&gt;# Server hostname or IP address&lt;/span&gt;
PORT &lt;span&gt;=&lt;/span&gt; &lt;span&gt;80&lt;/span&gt;        &lt;span&gt;# Port&lt;/span&gt;

client_socket &lt;span&gt;=&lt;/span&gt; socket&lt;span&gt;.&lt;/span&gt;socket(socket&lt;span&gt;.&lt;/span&gt;AF_INET, socket&lt;span&gt;.&lt;/span&gt;SOCK_STREAM)
server_address &lt;span&gt;=&lt;/span&gt; (HOST, PORT)
client_socket&lt;span&gt;.&lt;/span&gt;connect(server_address)

request_header &lt;span&gt;=&lt;/span&gt; &lt;span&gt;b&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;GET / HTTP/1.0&lt;/span&gt;&lt;span&gt;\r&lt;/span&gt;&lt;span&gt;\n&lt;/span&gt;&lt;span&gt;Host: www.google.com&lt;/span&gt;&lt;span&gt;\r&lt;/span&gt;&lt;span&gt;\n&lt;/span&gt;&lt;span&gt;\r&lt;/span&gt;&lt;span&gt;\n&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;
client_socket&lt;span&gt;.&lt;/span&gt;sendall(request_header)

response &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;
&lt;span&gt;while&lt;/span&gt; True:
    recv &lt;span&gt;=&lt;/span&gt; client_socket&lt;span&gt;.&lt;/span&gt;recv(&lt;span&gt;1024&lt;/span&gt;)
    &lt;span&gt;if&lt;/span&gt; &lt;span&gt;not&lt;/span&gt; recv:
        &lt;span&gt;break&lt;/span&gt;
    response &lt;span&gt;+&lt;/span&gt;&lt;span&gt;=&lt;/span&gt; str(recv)

&lt;span&gt;print&lt;/span&gt;(response)
client_socket&lt;span&gt;.&lt;/span&gt;close()  
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now that we have the HTTP response, the most basic way to extract data from it is to use regular expressions.&lt;/p&gt;
&lt;h3 id=&quot;regular-expressions&quot;&gt;Regular Expressions&lt;/h3&gt;
&lt;p&gt;A regular expression (RE or regex) is a search pattern for strings.&lt;/p&gt;
&lt;p&gt;With regex, you can search for a particular character/word in a bigger body of text.&lt;/p&gt;
&lt;p&gt;For example, you could identify all phone numbers in a web page.&lt;/p&gt;
&lt;p&gt;You can also replace items with a regex. For example, you could replace all uppercase tags in a poorly formatted HTML with lowercase tags.&lt;/p&gt;
&lt;p&gt;You can also validate some inputs …&lt;/p&gt;
&lt;p&gt;The pattern used by a regex is applied from left to right, and each source character is only used once.&lt;/p&gt;
&lt;p&gt;You may be wondering why it is important understand regular expressions when doing web scraping.&lt;/p&gt;
&lt;p&gt;After all, there are many different Python modules to parse HTML, with XPath and CSS selectors.&lt;/p&gt;
&lt;p&gt;In an ideal &lt;a href=&quot;https://en.wikipedia.org/wiki/Semantic_Web&quot;&gt;semantic world,&lt;/a&gt; data is easily machine-readable, and the information is embedded inside relevant HTML elements, with meaningful attributes.&lt;/p&gt;
&lt;p&gt;But the real world is messy. You will often find huge amounts of text inside a p element. For example, if you want to extract specific data inside a large text (a price, a date, a name…), you will have to use regular expressions.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Here is a great website to test your regex: &lt;a href=&quot;https://regex101.com/&quot;&gt;https://regex101.com/&lt;/a&gt;. Also, here is an &lt;a href=&quot;https://www.rexegg.com/&quot;&gt;awesome blog&lt;/a&gt; to learn more about them. This post will only cover a small fraction of what you can do with regex.&lt;/p&gt;
&lt;p&gt;Regular expressions can be useful when you have this kind of data:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-html&quot; data-lang=&quot;html&quot;&gt;    &amp;lt;&lt;span&gt;p&lt;/span&gt;&amp;gt;Price : 19.99$&amp;lt;/&lt;span&gt;p&lt;/span&gt;&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We could select this text node with an Xpath expression and then use this kind of regex to extract the price:&lt;/p&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;7&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;    &lt;span&gt;^&lt;/span&gt;Price\s:\s(\d&lt;span&gt;+&lt;/span&gt;\&lt;span&gt;.&lt;/span&gt;\d{&lt;span&gt;2&lt;/span&gt;})\&lt;span&gt;$&lt;/span&gt;
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To extract the text inside an HTML tag, it is annoying but doable to use a regex:&lt;/p&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;9&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span&gt;import&lt;/span&gt; re

html_content &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;&amp;lt;p&amp;gt;Price : 19.99$&amp;lt;/p&amp;gt;&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;

m &lt;span&gt;=&lt;/span&gt; re&lt;span&gt;.&lt;/span&gt;match(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;&amp;lt;p&amp;gt;(.+)&amp;lt;&lt;/span&gt;&lt;span&gt;\&lt;/span&gt;&lt;span&gt;/p&amp;gt;&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, html_content)
&lt;span&gt;if&lt;/span&gt; m:
        &lt;span&gt;print&lt;/span&gt;(m&lt;span&gt;.&lt;/span&gt;group(&lt;span&gt;1&lt;/span&gt;))
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;As you can see, manually sending the HTTP request with a socket and parsing the response with regular expression can be done, but it's complicated and there are higher-level API that can make this task easier.&lt;/p&gt;
&lt;h2 id=&quot;2-urllib3--lxml&quot;&gt;2. urllib3 &amp;amp; LXML&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Disclaimer&lt;/strong&gt;: It is easy to get lost in the urllib universe in Python. The standard library contains urllib and urllib2 (and sometimes urllib3). In Python3 urllib2 was split into multiple modules and urllib3 won't be part of the standard library anytime soon. This confusing situation will be the subject of another blog post. In this section, I've decided to only talk about urllib3 because it is widely used in the Python world, including by Pip and Requests.&lt;/p&gt;
&lt;p&gt;Urllib3 is a high-level package that allows you to do pretty much whatever you want with an HTTP request. We urllib3 we could do what we did in the previous section with way fewer lines of code.&lt;/p&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;9&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span&gt;import&lt;/span&gt; urllib3
http &lt;span&gt;=&lt;/span&gt; urllib3&lt;span&gt;.&lt;/span&gt;PoolManager()
r &lt;span&gt;=&lt;/span&gt; http&lt;span&gt;.&lt;/span&gt;request(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;GET&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, &lt;span&gt;'&lt;/span&gt;&lt;span&gt;http://www.google.com&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;)
&lt;span&gt;print&lt;/span&gt;(r&lt;span&gt;.&lt;/span&gt;data)
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;As you can see, this is much more concise than the socket version. Not only that, the API is straightforward. Also, you can easily do many other things, like adding HTTP headers, using a proxy, POSTing forms …&lt;/p&gt;
&lt;p&gt;For example, had we decided to set some headers and use a proxy, we would only have to do the following (you can learn more about proxy servers at &lt;a href=&quot;https://www.bestproxyreviews.com/proxy-server/&quot;&gt;bestproxyreviews.com&lt;/a&gt;):&lt;/p&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;11&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span&gt;import&lt;/span&gt; urllib3
user_agent_header &lt;span&gt;=&lt;/span&gt; urllib3&lt;span&gt;.&lt;/span&gt;make_headers(user_agent&lt;span&gt;=&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;&amp;lt;USER AGENT&amp;gt;&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;)
pool &lt;span&gt;=&lt;/span&gt; urllib3&lt;span&gt;.&lt;/span&gt;ProxyManager(f&lt;span&gt;'&lt;/span&gt;&lt;span&gt;&amp;lt;PROXY IP&amp;gt;&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, headers&lt;span&gt;=&lt;/span&gt;user_agent_header)
r &lt;span&gt;=&lt;/span&gt; pool&lt;span&gt;.&lt;/span&gt;request(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;GET&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, &lt;span&gt;'&lt;/span&gt;&lt;span&gt;https://www.google.com/&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;)
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;See? There are exactly the same number of lines. However, there are some things that urllib3 does not handle very easily. For example, if we want to add a cookie, we have to manually create the corresponding headers and add it to the request.&lt;/p&gt;
&lt;p&gt;There are also things that urllib3 can do that requests can't: creation and management of a pool and proxy pool, control of retry strategy for example.&lt;/p&gt;
&lt;p&gt;To put it simply, urllib3 is between Requests and Socket in terms of abstraction, although it's way closer to requests than socket.&lt;/p&gt;
&lt;p&gt;Next, to parse the response, we are going to use the LXML package and XPath expressions.&lt;/p&gt;
&lt;h3 id=&quot;xpath&quot;&gt;XPath&lt;/h3&gt;
&lt;p&gt;XPath is a technology that uses path expressions to select nodes or node- sets in an XML document (or HTML document). As with the Document Object Model, Xpath has been a W3C standard since 1999. Although XPath is not a programming language in itself, it allows you to write expressions that can directly access a specific node, or a specific node-set, without having to go through the entire HTML tree (or XML tree).&lt;/p&gt;
&lt;p&gt;Think of XPath as regex, but specifically for XML/HMTL.&lt;/p&gt;
&lt;p&gt;To extract data from an HTML document with XPath we need three things:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;an HTML document&lt;/li&gt;
&lt;li&gt;some XPath expressions&lt;/li&gt;
&lt;li&gt;an XPath engine that will run those expressions&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;To begin, we will use the HTML we got from urllib3,. Imagine we want to extract all of the links from the Google homepage.&lt;/p&gt;
&lt;p&gt;So, we will use one simple XPath expression: &lt;code&gt;//a&lt;/code&gt;. And we will use LXML to run it. LXML is a fast and easy to use XML and HTML processing library that supports XPATH.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Installation&lt;/em&gt;:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;    pip install lxml
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Below is the code that comes just after the previous snippet:&lt;/p&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;11&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span&gt;from&lt;/span&gt; lxml &lt;span&gt;import&lt;/span&gt; html

&lt;span&gt;# We reuse the response from urllib3&lt;/span&gt;
data_string &lt;span&gt;=&lt;/span&gt; r&lt;span&gt;.&lt;/span&gt;data&lt;span&gt;.&lt;/span&gt;decode(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;utf-8&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, errors&lt;span&gt;=&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;ignore&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;)
&lt;span&gt;# We instantiate a tree object from the HTML&lt;/span&gt;
tree &lt;span&gt;=&lt;/span&gt; html&lt;span&gt;.&lt;/span&gt;fromstring(data_string)
&lt;span&gt;# We run the XPath against this HTML&lt;/span&gt;
&lt;span&gt;# This returns an array of element&lt;/span&gt;
links &lt;span&gt;=&lt;/span&gt; tree&lt;span&gt;.&lt;/span&gt;xpath(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;//a&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;)
&lt;span&gt;for&lt;/span&gt; link &lt;span&gt;in&lt;/span&gt; links:
    &lt;span&gt;# For each element we can easily get back the URL&lt;/span&gt;
    &lt;span&gt;print&lt;/span&gt;(link&lt;span&gt;.&lt;/span&gt;get(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;href&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;))
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And the output should look like this:&lt;/p&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;10&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;https:&lt;span&gt;/&lt;/span&gt;&lt;span&gt;/&lt;/span&gt;books&lt;span&gt;.&lt;/span&gt;google&lt;span&gt;.&lt;/span&gt;fr&lt;span&gt;/&lt;/span&gt;bkshp&lt;span&gt;?&lt;/span&gt;hl&lt;span&gt;=&lt;/span&gt;fr&lt;span&gt;&amp;amp;&lt;/span&gt;tab&lt;span&gt;=&lt;/span&gt;wp
https:&lt;span&gt;/&lt;/span&gt;&lt;span&gt;/&lt;/span&gt;www&lt;span&gt;.&lt;/span&gt;google&lt;span&gt;.&lt;/span&gt;fr&lt;span&gt;/&lt;/span&gt;shopping&lt;span&gt;?&lt;/span&gt;hl&lt;span&gt;=&lt;/span&gt;fr&lt;span&gt;&amp;amp;&lt;/span&gt;source&lt;span&gt;=&lt;/span&gt;og&lt;span&gt;&amp;amp;&lt;/span&gt;tab&lt;span&gt;=&lt;/span&gt;wf
https:&lt;span&gt;/&lt;/span&gt;&lt;span&gt;/&lt;/span&gt;www&lt;span&gt;.&lt;/span&gt;blogger&lt;span&gt;.&lt;/span&gt;com&lt;span&gt;/&lt;/span&gt;&lt;span&gt;?&lt;/span&gt;tab&lt;span&gt;=&lt;/span&gt;wj
https:&lt;span&gt;/&lt;/span&gt;&lt;span&gt;/&lt;/span&gt;photos&lt;span&gt;.&lt;/span&gt;google&lt;span&gt;.&lt;/span&gt;com&lt;span&gt;/&lt;/span&gt;&lt;span&gt;?&lt;/span&gt;tab&lt;span&gt;=&lt;/span&gt;wq&lt;span&gt;&amp;amp;&lt;/span&gt;pageId&lt;span&gt;=&lt;/span&gt;none
http:&lt;span&gt;/&lt;/span&gt;&lt;span&gt;/&lt;/span&gt;video&lt;span&gt;.&lt;/span&gt;google&lt;span&gt;.&lt;/span&gt;fr&lt;span&gt;/&lt;/span&gt;&lt;span&gt;?&lt;/span&gt;hl&lt;span&gt;=&lt;/span&gt;fr&lt;span&gt;&amp;amp;&lt;/span&gt;tab&lt;span&gt;=&lt;/span&gt;wv
https:&lt;span&gt;/&lt;/span&gt;&lt;span&gt;/&lt;/span&gt;docs&lt;span&gt;.&lt;/span&gt;google&lt;span&gt;.&lt;/span&gt;com&lt;span&gt;/&lt;/span&gt;document&lt;span&gt;/&lt;/span&gt;&lt;span&gt;?&lt;/span&gt;usp&lt;span&gt;=&lt;/span&gt;docs_alc
&lt;span&gt;.&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;
https:&lt;span&gt;/&lt;/span&gt;&lt;span&gt;/&lt;/span&gt;www&lt;span&gt;.&lt;/span&gt;google&lt;span&gt;.&lt;/span&gt;fr&lt;span&gt;/&lt;/span&gt;intl&lt;span&gt;/&lt;/span&gt;fr&lt;span&gt;/&lt;/span&gt;about&lt;span&gt;/&lt;/span&gt;products&lt;span&gt;?&lt;/span&gt;tab&lt;span&gt;=&lt;/span&gt;wh
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Keep in mind that this example is really really simple and doesn't show you how powerful XPath can be (Note: This XPath expression should have been changed to &lt;code&gt;//a/@href&lt;/code&gt; to avoid having to iterate on &lt;code&gt;links&lt;/code&gt; to get their &lt;code&gt;href&lt;/code&gt; ).&lt;/p&gt;
&lt;p&gt;If you want to learn more about XPath, you can read &lt;a href=&quot;https://librarycarpentry.org/lc-webscraping/02-xpath/index.html&quot;&gt;this helpful introduction&lt;/a&gt;. The LXML documentation is also &lt;a href=&quot;https://lxml.de/tutorial.html&quot;&gt;well-written and is a good starting point&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;XPath expressions, like regex, are powerful and one of the fastest way to extract information from HTML. And like regex, XPath can quickly become messy, hard to read, and hard to maintain.&lt;/p&gt;
&lt;p&gt;If you'd like to learn more about XPath, do not hesitate to read my dedicated blog post about &lt;a href=&quot;https://www.scrapingbee.com/blog/practical-xpath-for-web-scraping/&quot;&gt;XPath applied to web scraping&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&quot;text-center&quot; readability=&quot;25.066901408451&quot;&gt;
&lt;div readability=&quot;6.3661971830986&quot;&gt;
&lt;p&gt;&lt;strong&gt;Tired of getting blocked while scraping the web?&lt;/strong&gt; &lt;span&gt;Our API handles headless browsers and rotates proxies for you.&lt;/span&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&quot;3-requests--beautifulsoup&quot;&gt;3. Requests &amp;amp; BeautifulSoup&lt;/h2&gt;
&lt;h3 id=&quot;requests&quot;&gt;Requests&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/psf/requests&quot;&gt;Requests&lt;/a&gt; is the king of Python packages. With more than 11,000,000 downloads, it is the most widely used package for Python.&lt;/p&gt;
&lt;p&gt;Installation:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;    pip install requests
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Making a request with Requests (no comment) is easy:&lt;/p&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;7&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span&gt;import&lt;/span&gt; requests

r &lt;span&gt;=&lt;/span&gt; requests&lt;span&gt;.&lt;/span&gt;get(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;https://www.scrapingninja.co&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;)
&lt;span&gt;print&lt;/span&gt;(r&lt;span&gt;.&lt;/span&gt;text)
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;With Requests, it is easy to perform POST requests, handle cookies, query parameters…&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Authentication to Hacker News&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Let's say we want to create a tool to automatically submit our blog post to Hacker news or any other forum, like Buffer. We would need to authenticate to those websites before posting our link. That's what we are going to do with Requests and BeautifulSoup!&lt;/p&gt;
&lt;p&gt;Here is the Hacker News login form and the associated DOM:&lt;/p&gt;
&lt;div class=&quot;img&quot;&gt;&lt;img class=&quot;lazyload&quot; data-sizes=&quot;auto&quot; data-srcset=&quot; , https://d33wubrfki0l68.cloudfront.net/5ee9dc0f3d26d09de8fdbbbcd355d6b0babf2f27/71207/blog/web-scraping-101-with-python/screenshot_hn_login_form_hu473e87119dfc02f5ff573cd876eebf05_248908_825x0_resize_catmullrom_2.png 825w , https://d33wubrfki0l68.cloudfront.net/4c3520afd92d70231d2cabef23bf44ad7ebab43d/db28e/blog/web-scraping-101-with-python/screenshot_hn_login_form_hu473e87119dfc02f5ff573cd876eebf05_248908_1200x0_resize_catmullrom_2.png 1200w , https://d33wubrfki0l68.cloudfront.net/6d362434439620df8edf6df6896ad9517b5cbc36/3c64a/blog/web-scraping-101-with-python/screenshot_hn_login_form_hu473e87119dfc02f5ff573cd876eebf05_248908_1500x0_resize_catmullrom_2.png 1500w&quot; data-src=&quot;https://d33wubrfki0l68.cloudfront.net/b073cf3427b6c488041224c036fe399f72c972cc/4d9ea/blog/web-scraping-101-with-python/screenshot_hn_login_form.png&quot; width=&quot;1812&quot; height=&quot;1476&quot; alt=&quot;Hacker News login form&quot;/&gt;&lt;noscript&gt;
&lt;p&gt;&lt;img loading=&quot;lazy&quot; srcset=&quot; , https://d33wubrfki0l68.cloudfront.net/5ee9dc0f3d26d09de8fdbbbcd355d6b0babf2f27/71207/blog/web-scraping-101-with-python/screenshot_hn_login_form_hu473e87119dfc02f5ff573cd876eebf05_248908_825x0_resize_catmullrom_2.png 825w , https://d33wubrfki0l68.cloudfront.net/4c3520afd92d70231d2cabef23bf44ad7ebab43d/db28e/blog/web-scraping-101-with-python/screenshot_hn_login_form_hu473e87119dfc02f5ff573cd876eebf05_248908_1200x0_resize_catmullrom_2.png 1200w , https://d33wubrfki0l68.cloudfront.net/6d362434439620df8edf6df6896ad9517b5cbc36/3c64a/blog/web-scraping-101-with-python/screenshot_hn_login_form_hu473e87119dfc02f5ff573cd876eebf05_248908_1500x0_resize_catmullrom_2.png 1500w&quot; src=&quot;https://d33wubrfki0l68.cloudfront.net/b073cf3427b6c488041224c036fe399f72c972cc/4d9ea/blog/web-scraping-101-with-python/screenshot_hn_login_form.png&quot; width=&quot;1812&quot; height=&quot;1476&quot; alt=&quot;Hacker News login form&quot;/&gt;&lt;/p&gt;
&lt;/noscript&gt;&lt;/div&gt;
&lt;p&gt;There are three &lt;code&gt;&amp;lt;input&amp;gt;&lt;/code&gt; tags on this form. The first one has a type hidden with a name “goto”, and the two others are the username and password.&lt;/p&gt;
&lt;p&gt;If you submit the form inside your Chrome browser, you will see that there is a lot going on: a redirect and a cookie is being set. This cookie will be sent by Chrome on each subsequent request in order for the server to know that you are authenticated.&lt;/p&gt;
&lt;p&gt;Doing this with Requests is easy. It will handle redirects automatically for us, and handling cookies can be done with the &lt;em&gt;Session&lt;/em&gt; object.&lt;/p&gt;
&lt;h3 id=&quot;beautifulsoup&quot;&gt;BeautifulSoup&lt;/h3&gt;
&lt;p&gt;The next thing we will need is BeautifulSoup, which is a Python library that will help us parse the HTML returned by the server, to find out if we are logged in or not.&lt;/p&gt;
&lt;p&gt;Installation:&lt;/p&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;7&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;    pip install beautifulsoup4
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;So, all we have to do is POST these three inputs with our credentials to the /login endpoint and check for the presence of an element that is only displayed once logged in:&lt;/p&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;14&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span&gt;import&lt;/span&gt; requests
&lt;span&gt;from&lt;/span&gt; bs4 &lt;span&gt;import&lt;/span&gt; BeautifulSoup

BASE_URL &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;https://news.ycombinator.com&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;
USERNAME &lt;span&gt;=&lt;/span&gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;
PASSWORD &lt;span&gt;=&lt;/span&gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;

s &lt;span&gt;=&lt;/span&gt; requests&lt;span&gt;.&lt;/span&gt;Session()

data &lt;span&gt;=&lt;/span&gt; {&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;goto&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;news&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;acct&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: USERNAME, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;pw&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: PASSWORD}
r &lt;span&gt;=&lt;/span&gt; s&lt;span&gt;.&lt;/span&gt;post(f&lt;span&gt;'&lt;/span&gt;&lt;span&gt;{BASE_URL}/login&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, data&lt;span&gt;=&lt;/span&gt;data)

soup &lt;span&gt;=&lt;/span&gt; BeautifulSoup(r&lt;span&gt;.&lt;/span&gt;text, &lt;span&gt;'&lt;/span&gt;&lt;span&gt;html.parser&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;)
&lt;span&gt;if&lt;/span&gt; soup&lt;span&gt;.&lt;/span&gt;find(id&lt;span&gt;=&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;logout&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;) &lt;span&gt;is&lt;/span&gt; &lt;span&gt;not&lt;/span&gt; None:
        &lt;span&gt;print&lt;/span&gt;(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;Successfully logged in&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;)
&lt;span&gt;else&lt;/span&gt;:
        &lt;span&gt;print&lt;/span&gt;(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;Authentication Error&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;)
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In order to learn more about BeautifulSoup, we could try to extract every links on the homepage.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;By the way, Hacker News offers a &lt;a href=&quot;https://github.com/HackerNews/API&quot;&gt;powerful API&lt;/a&gt;, so we're doing this as an example, but you should use the API instead of scraping it!&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The first thing we need to do is inspect Hacker News's home-page to understand the structure and the different CSS classes that we will have to select:&lt;/p&gt;
&lt;div class=&quot;img&quot;&gt;&lt;img class=&quot;lazyload&quot; data-sizes=&quot;auto&quot; data-srcset=&quot; , https://d33wubrfki0l68.cloudfront.net/a2fd47934b4fa1ac40da5e6c5a3ea280dcf0eb68/9ad1f/blog/web-scraping-101-with-python/bnzjaqymjptmpuyc_hu6c733b35dc7770a897a28c447f70ae26_70520_825x0_resize_q75_catmullrom.jpg 825w&quot; data-src=&quot;https://d33wubrfki0l68.cloudfront.net/9a8598c89dad82e7ea705a4410591bec13ffd951/57733/blog/web-scraping-101-with-python/bnzjaqymjptmpuyc.jpg&quot; width=&quot;1022&quot; height=&quot;605&quot; alt=&quot;Hacker news's HTML&quot;/&gt;&lt;noscript&gt;
&lt;p&gt;&lt;img loading=&quot;lazy&quot; srcset=&quot; , https://d33wubrfki0l68.cloudfront.net/a2fd47934b4fa1ac40da5e6c5a3ea280dcf0eb68/9ad1f/blog/web-scraping-101-with-python/bnzjaqymjptmpuyc_hu6c733b35dc7770a897a28c447f70ae26_70520_825x0_resize_q75_catmullrom.jpg 825w&quot; src=&quot;https://d33wubrfki0l68.cloudfront.net/9a8598c89dad82e7ea705a4410591bec13ffd951/57733/blog/web-scraping-101-with-python/bnzjaqymjptmpuyc.jpg&quot; width=&quot;1022&quot; height=&quot;605&quot; alt=&quot;Hacker news's HTML&quot;/&gt;&lt;/p&gt;
&lt;/noscript&gt;&lt;/div&gt;
&lt;p&gt;We can see that all of the posts are inside a &lt;code&gt;&amp;lt;tr class=&quot;athing&quot;&amp;gt;&lt;/code&gt;. So, the first thing we will need to do is to select all of these tags. This can be easily done with the following:&lt;/p&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;8&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;    links &lt;span&gt;=&lt;/span&gt; soup&lt;span&gt;.&lt;/span&gt;findAll(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;tr&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, class_&lt;span&gt;=&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;athing&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;)
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then, for each link, we will extract its id, title, url and rank:&lt;/p&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;16&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span&gt;import&lt;/span&gt; requests
&lt;span&gt;from&lt;/span&gt; bs4 &lt;span&gt;import&lt;/span&gt; BeautifulSoup

r &lt;span&gt;=&lt;/span&gt; requests&lt;span&gt;.&lt;/span&gt;get(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;https://news.ycombinator.com&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;)
soup &lt;span&gt;=&lt;/span&gt; BeautifulSoup(r&lt;span&gt;.&lt;/span&gt;text, &lt;span&gt;'&lt;/span&gt;&lt;span&gt;html.parser&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;)
links &lt;span&gt;=&lt;/span&gt; soup&lt;span&gt;.&lt;/span&gt;findAll(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;tr&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, class_&lt;span&gt;=&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;athing&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;)

formatted_links &lt;span&gt;=&lt;/span&gt; []

&lt;span&gt;for&lt;/span&gt; link &lt;span&gt;in&lt;/span&gt; links:
        data &lt;span&gt;=&lt;/span&gt; {
                &lt;span&gt;'&lt;/span&gt;&lt;span&gt;id&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;: link[&lt;span&gt;'&lt;/span&gt;&lt;span&gt;id&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;],
                &lt;span&gt;'&lt;/span&gt;&lt;span&gt;title&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;: link&lt;span&gt;.&lt;/span&gt;find_all(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;td&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;)[&lt;span&gt;2&lt;/span&gt;]&lt;span&gt;.&lt;/span&gt;a&lt;span&gt;.&lt;/span&gt;text,
                &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;url&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: link&lt;span&gt;.&lt;/span&gt;find_all(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;td&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;)[&lt;span&gt;2&lt;/span&gt;]&lt;span&gt;.&lt;/span&gt;a[&lt;span&gt;'&lt;/span&gt;&lt;span&gt;href&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;],
                &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;rank&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: int(links[&lt;span&gt;0&lt;/span&gt;]&lt;span&gt;.&lt;/span&gt;td&lt;span&gt;.&lt;/span&gt;span&lt;span&gt;.&lt;/span&gt;text&lt;span&gt;.&lt;/span&gt;replace(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, &lt;span&gt;'&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;))
        }
        formatted_links&lt;span&gt;.&lt;/span&gt;append(data)

&lt;span&gt;print&lt;/span&gt;(formatted_links)
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;As you can see, Requests and BeautifulSoup are great libraries for extracting data and automate different actions by posting forms. If you want to do large-scale web scraping projects, you could still use Requests, but you would need to handle lots of parts yourself.&lt;/p&gt;
&lt;p&gt;If you want to learn more about Python, BeautifulSoup and particularly CSS selectors, I recommend reading &lt;a href=&quot;https://www.scrapingbee.com/blog/python-web-scraping-beautiful-soup/&quot;&gt;this&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;When you need to scrape a lots of webpages, there are many things you have to take care of:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Finding a way to parallelize your code to make it faster&lt;/li&gt;
&lt;li&gt;Handling errors&lt;/li&gt;
&lt;li&gt;Storing results&lt;/li&gt;
&lt;li&gt;Filtering results&lt;/li&gt;
&lt;li&gt;Throttling your request so you don't over-load the server&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Fortunately for us, tools exist that can handle those for us.&lt;/p&gt;
&lt;h3 id=&quot;grequests&quot;&gt;Grequests&lt;/h3&gt;
&lt;p&gt;While the &lt;code&gt;requests&lt;/code&gt; package is easy-to-use, you might find it a bit slow if you have hundreds of pages to scrape.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;requests&lt;/code&gt; package, out of the box, only allows you to make synchronous requests, meaning that if you have 25 URLs to scrape, you will have to do it one by one.&lt;/p&gt;
&lt;p&gt;So if one page takes ten seconds to be fetched, will take you 25*10 seconds to fetch 25 pages.&lt;/p&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;7&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span&gt;import&lt;/span&gt; requests

&lt;span&gt;# An array with 25 urls&lt;/span&gt;
urls &lt;span&gt;=&lt;/span&gt; [&lt;span&gt;.&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;] 

&lt;span&gt;for&lt;/span&gt; url &lt;span&gt;in&lt;/span&gt; urls:
    result &lt;span&gt;=&lt;/span&gt; requests&lt;span&gt;.&lt;/span&gt;get(url)
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The easiest way to speed-up this process is to make several calls at the same time. This means that instead of sending every request sequentially, you can send requests in batches of five.&lt;/p&gt;
&lt;p&gt;If you send five requests simultaneously, you will wait for all of them to complete. Then, you will send another batch of five requests and wait again, repeating this until you don't have any more URLs to scrape.&lt;/p&gt;
&lt;p&gt;This way, you can send 25 requests in five batches of five requests. Meaning all the URLs can be scrape in 5*10=50 seconds instead of 25*10=250 seconds.&lt;/p&gt;
&lt;p&gt;Usually, this kind of behaviour is implemented using &lt;a href=&quot;https://docs.python.org/3/library/threading.html&quot;&gt;thread-based parallelism&lt;/a&gt;. It can be tricky for beginners. Fortunately, there is a version of the &lt;code&gt;requests&lt;/code&gt; package that does all the hard work for us.&lt;/p&gt;
&lt;p&gt;It's called &lt;code&gt;grequest&lt;/code&gt;, for &lt;code&gt;g&lt;/code&gt; + &lt;code&gt;requests&lt;/code&gt;, with the &lt;code&gt;g&lt;/code&gt; standing for &lt;code&gt;gevent&lt;/code&gt;, an asynchronous Python API widely used for web application.&lt;/p&gt;
&lt;p&gt;This library allows us to send multiple requests at the same time and in an easy and elegant way.&lt;/p&gt;
&lt;p&gt;Here is how to send our 25 initial URLs in batches of 5:&lt;/p&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;14&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span&gt;# pip install grequests&lt;/span&gt;
&lt;span&gt;import&lt;/span&gt; grequests

BATCH_LENGTH &lt;span&gt;=&lt;/span&gt; &lt;span&gt;5&lt;/span&gt;

&lt;span&gt;# An array with 25 urls&lt;/span&gt;
urls &lt;span&gt;=&lt;/span&gt; [&lt;span&gt;.&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;] 
&lt;span&gt;# Our empty results array&lt;/span&gt;
results &lt;span&gt;=&lt;/span&gt; []

&lt;span&gt;while&lt;/span&gt; urls:
    &lt;span&gt;# get our first batch of 5 URLs&lt;/span&gt;
    batch &lt;span&gt;=&lt;/span&gt; urls[:BATCH_LENGTH]
    &lt;span&gt;# create a set of unsent Requests&lt;/span&gt;
    rs &lt;span&gt;=&lt;/span&gt; (grequests&lt;span&gt;.&lt;/span&gt;get(url) &lt;span&gt;for&lt;/span&gt; url &lt;span&gt;in&lt;/span&gt; batch)
    &lt;span&gt;# send them all at the same time&lt;/span&gt;
    batch_results &lt;span&gt;=&lt;/span&gt; grequests&lt;span&gt;.&lt;/span&gt;map(rs)
    &lt;span&gt;# appending results to our main results array&lt;/span&gt;
    results &lt;span&gt;+&lt;/span&gt;&lt;span&gt;=&lt;/span&gt; batch_results
    &lt;span&gt;# removing fetched URLs from urls&lt;/span&gt;
    urls &lt;span&gt;=&lt;/span&gt; urls[BATCH_LENGTH:]

&lt;span&gt;print&lt;/span&gt;(results)
&lt;span&gt;# [&amp;lt;Response [200]&amp;gt;, &amp;lt;Response [200]&amp;gt;, ..., &amp;lt;Response [200]&amp;gt;, &amp;lt;Response [200]&amp;gt;]&lt;/span&gt;
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And that's it. Grequest is perfect for small scripts but is not suited for production code or high-scale web scraping. For that, we have Scrapy 👇.&lt;/p&gt;
&lt;h2 id=&quot;4-web-crawling-frameworks&quot;&gt;4. Web Crawling Frameworks&lt;/h2&gt;
&lt;h3 id=&quot;scrapy&quot;&gt;Scrapy&lt;/h3&gt;
&lt;div class=&quot;img&quot;&gt;&lt;img class=&quot;lazyload&quot; data-sizes=&quot;auto&quot; data-srcset=&quot;&quot; data-src=&quot;https://d33wubrfki0l68.cloudfront.net/3bfbc9471a7af1ea4081e21ccfd8196d2223f034/06866/blog/web-scraping-101-with-python/azolsdgwblzasffo.jpg&quot; width=&quot;600&quot; height=&quot;350&quot; alt=&quot;Scrapy Logo&quot;/&gt;&lt;noscript&gt;
&lt;p&gt;&lt;img loading=&quot;lazy&quot; srcset=&quot;&quot; src=&quot;https://d33wubrfki0l68.cloudfront.net/3bfbc9471a7af1ea4081e21ccfd8196d2223f034/06866/blog/web-scraping-101-with-python/azolsdgwblzasffo.jpg&quot; width=&quot;600&quot; height=&quot;350&quot; alt=&quot;Scrapy Logo&quot;/&gt;&lt;/p&gt;
&lt;/noscript&gt;&lt;/div&gt;
&lt;p&gt;Scrapy is a powerful Python web scraping and web crawling framework.&lt;/p&gt;
&lt;p&gt;Scrapy provides many features to download web pages asynchronously, process them and save them. It handles multithreading, crawling (the process of going from link to link to find every URL in a website), sitemap crawling, and more.&lt;/p&gt;
&lt;p&gt;Scrapy also has an interactive mode called the Scrapy Shell. With the Scrapy Shell you can test your scraping code quickly, like XPath expressions or CSS selectors.&lt;/p&gt;
&lt;p&gt;The downside of Scrapy is that the learning curve is steep. There is a lot to learn.&lt;/p&gt;
&lt;p&gt;To follow up on our example about Hacker News, we are going to write a Scrapy Spider that scrapes the first 15 pages of results, and saves everything in a CSV file.&lt;/p&gt;
&lt;p&gt;You can easily install Scrapy with pip:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;    pip install Scrapy
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then you can use the Scrapy CLI to generate the boilerplate code for our project:&lt;/p&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;7&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;    scrapy startproject hacker_news_scraper
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Inside &lt;code&gt;hacker_news_scraper/spider&lt;/code&gt; we will create a new Python file with our Spider's code:&lt;/p&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;18&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span&gt;from&lt;/span&gt; bs4 &lt;span&gt;import&lt;/span&gt; BeautifulSoup
&lt;span&gt;import&lt;/span&gt; scrapy


&lt;span&gt;class&lt;/span&gt; &lt;span&gt;HnSpider&lt;/span&gt;(scrapy&lt;span&gt;.&lt;/span&gt;Spider):
    name &lt;span&gt;=&lt;/span&gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;hacker-news&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;
    allowed_domains &lt;span&gt;=&lt;/span&gt; [&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;news.ycombinator.com&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;]
    start_urls &lt;span&gt;=&lt;/span&gt; [f&lt;span&gt;'&lt;/span&gt;&lt;span&gt;https://news.ycombinator.com/news?p={i}&lt;/span&gt;&lt;span&gt;'&lt;/span&gt; &lt;span&gt;for&lt;/span&gt; i &lt;span&gt;in&lt;/span&gt; range(&lt;span&gt;1&lt;/span&gt;,&lt;span&gt;16&lt;/span&gt;)]

    &lt;span&gt;def&lt;/span&gt; &lt;span&gt;parse&lt;/span&gt;(self, response):
        soup &lt;span&gt;=&lt;/span&gt; BeautifulSoup(response&lt;span&gt;.&lt;/span&gt;text, &lt;span&gt;'&lt;/span&gt;&lt;span&gt;html.parser&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;)
        links &lt;span&gt;=&lt;/span&gt; soup&lt;span&gt;.&lt;/span&gt;findAll(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;tr&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, class_&lt;span&gt;=&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;athing&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;)

        &lt;span&gt;for&lt;/span&gt; link &lt;span&gt;in&lt;/span&gt; links:
                &lt;span&gt;yield&lt;/span&gt; {
                        &lt;span&gt;'&lt;/span&gt;&lt;span&gt;id&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;: link[&lt;span&gt;'&lt;/span&gt;&lt;span&gt;id&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;],
                        &lt;span&gt;'&lt;/span&gt;&lt;span&gt;title&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;: link&lt;span&gt;.&lt;/span&gt;find_all(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;td&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;)[&lt;span&gt;2&lt;/span&gt;]&lt;span&gt;.&lt;/span&gt;a&lt;span&gt;.&lt;/span&gt;text,
                        &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;url&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: link&lt;span&gt;.&lt;/span&gt;find_all(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;td&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;)[&lt;span&gt;2&lt;/span&gt;]&lt;span&gt;.&lt;/span&gt;a[&lt;span&gt;'&lt;/span&gt;&lt;span&gt;href&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;],
                        &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;rank&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: int(link&lt;span&gt;.&lt;/span&gt;td&lt;span&gt;.&lt;/span&gt;span&lt;span&gt;.&lt;/span&gt;text&lt;span&gt;.&lt;/span&gt;replace(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, &lt;span&gt;'&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;))
                }
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;There is a lot of convention in Scrapy. Here we define an array of starting URLs. The attribute name will be used to call our Spider with the Scrapy command line.&lt;/p&gt;
&lt;p&gt;The parse method will be called on each URL in the &lt;code&gt;start_urls&lt;/code&gt; array&lt;/p&gt;
&lt;p&gt;We then need to tune Scrapy a bit in order for our Spider to behave nicely against the target website.&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;# Enable and configure the AutoThrottle extension (disabled by default)
# See https://doc.scrapy.org/en/latest/topics/autothrottle.html
AUTOTHROTTLE_ENABLED = True
# The initial download delay
AUTOTHROTTLE_START_DELAY = 5
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;You should always turn this on. It will make sure the target website is not slowed down by your spiders. It does this by analyzing the response time and adapting the numbers of concurrent threads.&lt;/p&gt;
&lt;p&gt;You can run this code with the Scrapy CLI and with different output formats (CSV, JSON, XML…):&lt;/p&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;7&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;    scrapy crawl hacker-news -o links.json
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And that's it! You will now have all your links in a nicely formatted JSON file.&lt;/p&gt;
&lt;p&gt;There is much more to say about this tool. So, if you wish to learn more, don't hesitate to check out our dedicated blog post about &lt;a href=&quot;https://www.scrapingbee.com/blog/web-scraping-with-scrapy/&quot;&gt;web scraping with Scrapy&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&quot;pyspider&quot;&gt;PySpider&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;http://docs.pyspider.org/en/latest/Quickstart/&quot;&gt;PySpider&lt;/a&gt; is an alternative to Scrapy, albeit a bit outdated. Its last release is from 2018. However it is still relevant because it does many things that Scrapy does not out of the box.&lt;/p&gt;
&lt;p&gt;First, PySpider works well with JavaScript pages (SPA and Ajax call) because it comes with PhantomJS, a headless browsing library. In Scrapy, you would need to install &lt;a href=&quot;https://www.scrapingbee.com/blog/scrapy-javascript/&quot;&gt;middlewares to do this&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Also, PySpider comes with a nice UI that makes it easy to monitor all of your crawling jobs.&lt;/p&gt;
&lt;div class=&quot;img&quot;&gt;&lt;img class=&quot;lazyload&quot; data-sizes=&quot;auto&quot; data-srcset=&quot; , https://d33wubrfki0l68.cloudfront.net/bff8705c254ca6d592c5f39e799b221c51189a87/623e3/blog/web-scraping-101-with-python/pyspider_hu72d10f2b4e9ebf9da0e76061b1f5e91f_78397_825x0_resize_catmullrom_2.png 825w , https://d33wubrfki0l68.cloudfront.net/48c68fae04192413f0665fcb0bab3ea82c8ee404/4b06b/blog/web-scraping-101-with-python/pyspider_hu72d10f2b4e9ebf9da0e76061b1f5e91f_78397_1200x0_resize_catmullrom_2.png 1200w , https://d33wubrfki0l68.cloudfront.net/32997e71f4d622de07241eb9f171bd7fe267b4e6/b5a25/blog/web-scraping-101-with-python/pyspider_hu72d10f2b4e9ebf9da0e76061b1f5e91f_78397_1500x0_resize_catmullrom_2.png 1500w&quot; data-src=&quot;https://d33wubrfki0l68.cloudfront.net/bac4901e3bfb74054fabe0fb14fb23d7dea00e1a/0b7ca/blog/web-scraping-101-with-python/pyspider.png&quot; width=&quot;1548&quot; height=&quot;320&quot; alt=&quot;PySpider interface&quot;/&gt;&lt;noscript&gt;
&lt;p&gt;&lt;img loading=&quot;lazy&quot; srcset=&quot; , https://d33wubrfki0l68.cloudfront.net/bff8705c254ca6d592c5f39e799b221c51189a87/623e3/blog/web-scraping-101-with-python/pyspider_hu72d10f2b4e9ebf9da0e76061b1f5e91f_78397_825x0_resize_catmullrom_2.png 825w , https://d33wubrfki0l68.cloudfront.net/48c68fae04192413f0665fcb0bab3ea82c8ee404/4b06b/blog/web-scraping-101-with-python/pyspider_hu72d10f2b4e9ebf9da0e76061b1f5e91f_78397_1200x0_resize_catmullrom_2.png 1200w , https://d33wubrfki0l68.cloudfront.net/32997e71f4d622de07241eb9f171bd7fe267b4e6/b5a25/blog/web-scraping-101-with-python/pyspider_hu72d10f2b4e9ebf9da0e76061b1f5e91f_78397_1500x0_resize_catmullrom_2.png 1500w&quot; src=&quot;https://d33wubrfki0l68.cloudfront.net/bac4901e3bfb74054fabe0fb14fb23d7dea00e1a/0b7ca/blog/web-scraping-101-with-python/pyspider.png&quot; width=&quot;1548&quot; height=&quot;320&quot; alt=&quot;PySpider interface&quot;/&gt;&lt;/p&gt;
&lt;/noscript&gt;&lt;/div&gt;
&lt;small&gt;&lt;em&gt;PySpider interface&lt;/em&gt;&lt;/small&gt;
&lt;p&gt;However, you might still prefer to use Scrapy for several reasons:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;A much better documentation than PySpider with easy-to-understand guides&lt;/li&gt;
&lt;li&gt;A built-in HTTP cache system that can speed up your program&lt;/li&gt;
&lt;li&gt;Automatic HTTP authentication&lt;/li&gt;
&lt;li&gt;3XX redirection supported through HTML meta refresh&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;5-headless-browsing&quot;&gt;5. Headless browsing&lt;/h2&gt;
&lt;h3 id=&quot;selenium--chrome&quot;&gt;Selenium &amp;amp; Chrome&lt;/h3&gt;
&lt;p&gt;Scrapy is great for large-scale web scraping tasks. However, it is not enough if you need to scrape a Single Page Application written with Javascript frameworks because it won't be able to render the Javascript code.&lt;/p&gt;
&lt;p&gt;It can be challenging to scrape SPAs because there are often lots of AJAX calls and websockets connections involved. If performance is an issue, always try to reproduce the Javascript code. This means manually inspecting all of the network calls with your browser inspector, and replicating the AJAX calls containing the interesting data.&lt;/p&gt;
&lt;p&gt;In some cases, there are too many asynchronous HTTP calls involved to get the data you want and it can be easier to render the page in a headless browser.&lt;/p&gt;
&lt;p&gt;Another great use case would be to take a screenshot of a page, and this is what we are going to do with the Hacker News homepage (again !)&lt;/p&gt;
&lt;p&gt;You can install the Selenium package with pip:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;    pip install selenium
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You will also need &lt;a href=&quot;http://chromedriver.chromium.org/&quot;&gt;Chromedriver&lt;/a&gt;:&lt;/p&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;7&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;    brew install chromedriver
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then, we just have to import the Webdriver from the Selenium package, configure Chrome with headless=True and set a window size (otherwise it is really small):&lt;/p&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;12&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span&gt;from&lt;/span&gt; selenium &lt;span&gt;import&lt;/span&gt; webdriver
&lt;span&gt;from&lt;/span&gt; selenium.webdriver.chrome.options &lt;span&gt;import&lt;/span&gt; Options

options &lt;span&gt;=&lt;/span&gt; Options()
options&lt;span&gt;.&lt;/span&gt;headless &lt;span&gt;=&lt;/span&gt; True
options&lt;span&gt;.&lt;/span&gt;add_argument(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;--window-size=1920,1200&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;)
driver &lt;span&gt;=&lt;/span&gt; webdriver&lt;span&gt;.&lt;/span&gt;Chrome(options&lt;span&gt;=&lt;/span&gt;options, executable_path&lt;span&gt;=&lt;/span&gt;&lt;span&gt;r&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;/usr/local/bin/chromedriver&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;)
driver&lt;span&gt;.&lt;/span&gt;get(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;https://news.ycombinator.com/&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;)
driver&lt;span&gt;.&lt;/span&gt;save_screenshot(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;hn_homepage.png&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;)
driver&lt;span&gt;.&lt;/span&gt;quit()
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You should get a nice screenshot of the homepage:&lt;/p&gt;
&lt;div class=&quot;img&quot;&gt;&lt;img class=&quot;lazyload&quot; data-sizes=&quot;auto&quot; data-srcset=&quot; , https://d33wubrfki0l68.cloudfront.net/f7027168dfe1c95151fded7ac27a9b3e78920680/e4ac2/blog/web-scraping-101-with-python/kfyrfqpxoyhubqzq_hufaa451c96ca0e1ea3e4fd7db67ef5049_518602_825x0_resize_catmullrom_2.png 825w , https://d33wubrfki0l68.cloudfront.net/9aba87c58435520999d8b660ff81aaaa9a44e5fb/e505a/blog/web-scraping-101-with-python/kfyrfqpxoyhubqzq_hufaa451c96ca0e1ea3e4fd7db67ef5049_518602_1200x0_resize_catmullrom_2.png 1200w , https://d33wubrfki0l68.cloudfront.net/02f99f19f2149aa55e4e0f711d25efe2ac649e0c/dbf5d/blog/web-scraping-101-with-python/kfyrfqpxoyhubqzq_hufaa451c96ca0e1ea3e4fd7db67ef5049_518602_1500x0_resize_catmullrom_2.png 1500w&quot; data-src=&quot;https://d33wubrfki0l68.cloudfront.net/7584b8303926e24e7d3bbccf22431499a0436aae/61e25/blog/web-scraping-101-with-python/kfyrfqpxoyhubqzq.png&quot; width=&quot;2000&quot; height=&quot;1250&quot; alt=&quot;Hacker News's front page&quot;/&gt;&lt;noscript&gt;
&lt;p&gt;&lt;img loading=&quot;lazy&quot; srcset=&quot; , https://d33wubrfki0l68.cloudfront.net/f7027168dfe1c95151fded7ac27a9b3e78920680/e4ac2/blog/web-scraping-101-with-python/kfyrfqpxoyhubqzq_hufaa451c96ca0e1ea3e4fd7db67ef5049_518602_825x0_resize_catmullrom_2.png 825w , https://d33wubrfki0l68.cloudfront.net/9aba87c58435520999d8b660ff81aaaa9a44e5fb/e505a/blog/web-scraping-101-with-python/kfyrfqpxoyhubqzq_hufaa451c96ca0e1ea3e4fd7db67ef5049_518602_1200x0_resize_catmullrom_2.png 1200w , https://d33wubrfki0l68.cloudfront.net/02f99f19f2149aa55e4e0f711d25efe2ac649e0c/dbf5d/blog/web-scraping-101-with-python/kfyrfqpxoyhubqzq_hufaa451c96ca0e1ea3e4fd7db67ef5049_518602_1500x0_resize_catmullrom_2.png 1500w&quot; src=&quot;https://d33wubrfki0l68.cloudfront.net/7584b8303926e24e7d3bbccf22431499a0436aae/61e25/blog/web-scraping-101-with-python/kfyrfqpxoyhubqzq.png&quot; width=&quot;2000&quot; height=&quot;1250&quot; alt=&quot;Hacker News's front page&quot;/&gt;&lt;/p&gt;
&lt;/noscript&gt;&lt;/div&gt;
&lt;p&gt;You can do many more with the Selenium API and Chrome:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Executing Javascript&lt;/li&gt;
&lt;li&gt;Filling forms&lt;/li&gt;
&lt;li&gt;Clicking on Elements&lt;/li&gt;
&lt;li&gt;Extracting elements with CSS selectors / XPath expressions&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Selenium and Chrome in headless mode are the ultimate combination to scrape anything you want. You can automate everything that you could do with your regular Chrome browser.&lt;/p&gt;
&lt;p&gt;The big drawback is that Chrome needs lots of memory / CPU power. With some fine-tuning you can reduce the memory footprint to 300-400mb per Chrome instance, but you still need 1 CPU core per instance.&lt;/p&gt;
&lt;p&gt;Don't hesitate to check out our &lt;a href=&quot;https://www.scrapingbee.com/blog/selenium-python/&quot;&gt;in-depth article about Selenium and Python&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you want to run several Chrome instances concurrently, you will need powerful servers (the cost goes up quickly) and constant monitoring of resources.&lt;/p&gt;
&lt;h3 id=&quot;robobrowser&quot;&gt;RoboBrowser&lt;/h3&gt;
&lt;p&gt;RoboBrowser is a Python library that will allow you to browse the web by wrapping &lt;code&gt;requests&lt;/code&gt; and &lt;code&gt;BeautifulSoup&lt;/code&gt; in an easy-to-use interface.&lt;/p&gt;
&lt;p&gt;It is not a headless browser &lt;em&gt;per se&lt;/em&gt; because it does not rely on any web-browser binary. Instead, it's a lightweight library that allows you to write scripts as if you were executing them in a “browser-like” environment.&lt;/p&gt;
&lt;p&gt;For example, if you want to login to Hacker-News, instead of manually crafting a request with &lt;code&gt;requests&lt;/code&gt;, you can write a script that will populate the form and “press” the login button:&lt;/p&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;10&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span&gt;# pip install RoboBrowser&lt;/span&gt;
&lt;span&gt;from&lt;/span&gt; robobrowser &lt;span&gt;import&lt;/span&gt; RoboBrowser

browser &lt;span&gt;=&lt;/span&gt; RoboBrowser()
browser&lt;span&gt;.&lt;/span&gt;open(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;https://news.ycombinator.com/login&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;)

&lt;span&gt;# Get the signup form&lt;/span&gt;
signin_form &lt;span&gt;=&lt;/span&gt; browser&lt;span&gt;.&lt;/span&gt;get_form(action&lt;span&gt;=&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;login&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;)


&lt;span&gt;# Fill it out&lt;/span&gt;
signin_form[&lt;span&gt;'&lt;/span&gt;&lt;span&gt;acct&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;]&lt;span&gt;.&lt;/span&gt;value &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;account&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;
signin_form[&lt;span&gt;'&lt;/span&gt;&lt;span&gt;password&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;]&lt;span&gt;.&lt;/span&gt;value &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;secret&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;

&lt;span&gt;# Submit the form&lt;/span&gt;
browser&lt;span&gt;.&lt;/span&gt;submit_form(signin_form)

&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;As you can see, the code is written as if you were manually doing the task in a real browser, even though it is not a real headless browsing library.&lt;/p&gt;
&lt;p&gt;RoboBrowser is cool because its lightweight approach allows you to easily parallelize it on your computer. However, because it's not using a real browser, it won't be able to deal with JavaScript execution like AJAX calls or Single Page Application.&lt;/p&gt;
&lt;p&gt;Unfortunately, its &lt;a href=&quot;https://github.com/jmcarp/robobrowser&quot;&gt;documentation&lt;/a&gt; is also lightweight, and I would not recommend it for newcomers or people not already used to the &lt;code&gt;BeautilfulSoup&lt;/code&gt; or &lt;code&gt;requests&lt;/code&gt; API.&lt;/p&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Here is a quick recap table of every technology we discussed in this blog post. Do not hesitate to comment if you know some resources that you feel belong here.&lt;/p&gt;

&lt;p&gt;I hope you enjoyed this blog post! This was a quick introduction to the most used Python tools for web scraping. In the next posts we're going to go deeper with each tools or topics like XPath and CSS selectors.&lt;/p&gt;
&lt;p&gt;Happy Scraping!&lt;/p&gt;
&lt;/div&gt;</description>
<pubDate>Wed, 10 Feb 2021 15:17:58 +0000</pubDate>
<dc:creator>daolf</dc:creator>
<og:title>Web Scraping 101 with Python</og:title>
<og:description>Learn web scraping with Python with this step-by-step tutorial. We will see the different ways to scrape the web in Python through lots of example.</og:description>
<og:image>https://www.scrapingbee.com/images/post/python-101/python_101_cover.jpg</og:image>
<og:url>https://www.scrapingbee.com/blog/web-scraping-101-with-python/</og:url>
<og:type>article</og:type>
<dc:language>en-us</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.scrapingbee.com/blog/web-scraping-101-with-python/</dc:identifier>
</item>
<item>
<title>Patterns of Distributed Systems (2020)</title>
<link>https://martinfowler.com/articles/patterns-of-distributed-systems/</link>
<guid isPermaLink="true" >https://martinfowler.com/articles/patterns-of-distributed-systems/</guid>
<description>&lt;div id=&quot;WhatThisIsAbout&quot;&gt;&lt;h2&gt;What this is about&lt;/h2&gt;
&lt;p&gt;For the last several months, I have been conducting workshops on distributed systems at ThoughtWorks. One of the key challenges faced while conducting the workshops was how to map theory of distributed systems to open source code bases like Kafka or Cassandra, whilst keeping the discussions generic enough to cover a broad range of solutions. The concept of patterns provided a nice way out.&lt;/p&gt;
&lt;p&gt;Pattern structure, by its very nature, allows us to focus on a specific problem, making it very clear why a particular solution is needed. Then the solution description allows us to give a code structure, which is concrete enough to show the actual solution, but generic enough to cover a broad range of variations. Patterns technique also allows us to link various patterns together to build a complete system. This gives a nice vocabulary to discuss distributed system implementations.&lt;/p&gt;
&lt;p&gt;What follows is a first set of patterns observed in mainstream open source distributed systems. I hope that these set of patterns will be useful to all developers.&lt;/p&gt;
&lt;section id=&quot;DistributedSystems-AnImplementationPerspective&quot; readability=&quot;18.425403225806&quot;&gt;&lt;h3&gt;Distributed systems - An implementation perspective&lt;/h3&gt;
&lt;p&gt;Today's enterprise architecture is full of platforms and frameworks which are distributed by nature. If we see the sample list of frameworks and platforms used in typical enterprise architecture today, it will look something like following:&lt;/p&gt;
&lt;table class=&quot;examples-of-types&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Type of platform/framework&lt;/th&gt;
&lt;th&gt;Example&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody readability=&quot;5.5&quot;&gt;&lt;tr&gt;&lt;td&gt;Databases&lt;/td&gt;
&lt;td&gt;Cassandra, HBase, Riak&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Message Brokers&lt;/td&gt;
&lt;td&gt;Kafka, Pulsar&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;6&quot;&gt;&lt;td&gt;Infrastructure&lt;/td&gt;
&lt;td&gt;Kubernetes, Mesos, Zookeeper, etcd, Consul&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;5&quot;&gt;&lt;td&gt;In Memory Data/Compute Grids&lt;/td&gt;
&lt;td&gt;Hazelcast, Pivotal Gemfire&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Stateful Microservices&lt;/td&gt;
&lt;td&gt;Akka Actors, Axon&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;File Systems&lt;/td&gt;
&lt;td&gt;HDFS, Ceph&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;All these are 'distributed' by nature. What does it mean for a system to be distributed? There are two aspects:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;They run on multiple servers. The number of servers in a cluster can vary from as few as three servers to a few thousand servers.&lt;/li&gt;
&lt;li&gt;They manage data. So these are inherently 'stateful' systems.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;There are several ways in which things can go wrong when multiple servers are involved in storing data. All the above mentioned systems need to solve those problems. The implementation of these systems have some recurring solutions to these problems. Understanding these solutions in their general form, helps in understanding the implementation of the broad spectrum of these systems and can also serve as a good guidance when new systems need to be built. Enter patterns.&lt;/p&gt;
&lt;section id=&quot;Patterns&quot; readability=&quot;8.8867924528302&quot;&gt;&lt;h4&gt;Patterns&lt;/h4&gt;
&lt;p&gt;&lt;a href=&quot;https://martinfowler.com/articles/writingPatterns.html&quot;&gt;Patterns&lt;/a&gt;, a concept introduced by Christopher Alexander, is widely accepted in the software community to document design constructs which are used to build software systems. Patterns provide a structured way of looking at a problem space with the solutions which are seen multiple times and proven. An interesting way to use patterns is the ability to link several patterns together, in a form of pattern sequence or pattern language, which gives some guidance of implementing a ‘whole’ or a complete system. Looking at distributed systems as a series of patterns is a useful way to gain insights into their implementation.&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;/div&gt;&lt;div id=&quot;ProblemsAndTheirRecurringSolutions.&quot;&gt;&lt;h2&gt;Problems and Their Recurring Solutions.&lt;/h2&gt;
&lt;p&gt;There are several things which can go wrong when data is stored on multiple servers.&lt;/p&gt;
&lt;section id=&quot;ProcessCrashes&quot; readability=&quot;33.757604562738&quot;&gt;&lt;h3&gt;Process crashes&lt;/h3&gt;
&lt;p&gt;Processes can crash at any time. Either due to hardware faults or software faults. There are numerous ways in which a process can crash.&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;It can be taken down for routine maintenance by system administrators.&lt;/li&gt;
&lt;li&gt;It can be killed doing some file IO because the disk is full and the exception is not properly handled.&lt;/li&gt;
&lt;li&gt;In cloud environments, it can be even trickier, as some unrelated events can bring the servers down.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;The bottom line is that if the processes are responsible for storing data, they must be designed to give a durability guarantee for the data stored on the servers. Even if a process crashes abruptly, it should preserve all the data for which it has notified the user that it's stored successfully. Depending on the access patterns, different storage engines have different storage structures, ranging from a simple hash map to a sophisticated graph storage. Because flushing data to the disk is one of the most time consuming operations, every insert or update to the storage can not be flushed to disk. So most databases have in-memory storage structures which are only periodically flushed to disk. This poses a risk of losing all the data if the process abruptly crashes.&lt;/p&gt;
&lt;p&gt;A technique called &lt;a href=&quot;https://martinfowler.com/articles/patterns-of-distributed-systems/wal.html&quot;&gt;Write-Ahead Log&lt;/a&gt; is used to tackle this situation. Servers store each state change as a command in an append-only file on a hard disk. Appending a file is generally a very fast operation, so it can be done without impacting performance. A single log, which is appended sequentially, is used to store each update. At the server startup, the log can be replayed to build in memory state again.&lt;/p&gt;
&lt;p&gt;This gives a durability guarantee. The data will not get lost even if the server abruptly crashes, and then restarts. But clients will not be able to get or store any data till the server is back up. So we lack availability in the case of server failure.&lt;/p&gt;
&lt;p&gt;One of the obvious solutions is to store the data on multiple servers. So we can replicate the write ahead log on multiple servers.&lt;/p&gt;
&lt;p&gt;When multiple servers are involved, there are a lot more failure scenarios which need to be considered.&lt;/p&gt;
&lt;/section&gt;&lt;section id=&quot;NetworkDelays&quot; readability=&quot;66.218203033839&quot;&gt;&lt;h3&gt;Network delays&lt;/h3&gt;
&lt;p&gt;In TCP/IP protocol stack, there is no upper bound on delays caused in transmitting messages across a network. It can vary based on the load on the network. For example, a 1 Gbps network link can get flooded with a big data job that's triggered, filling the network buffers, and can cause arbitrary delay for some messages to reach the servers.&lt;/p&gt;
&lt;p&gt;In a typical data center, servers are packed together in racks, and there are multiple racks connected by a top of the rack switch. There might be a tree of switches connecting one part of the datacenter to the other. It is possible in some cases, that a set of servers can communicate with each other, but are disconnected from another set of servers. This situation is called a network partition. One of the fundamental issues with servers communicating over a network then is, when to know a particular server has failed.&lt;/p&gt;
&lt;p&gt;There are two problems to be tackled here.&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;A particular server can not wait indefinitely to know if another server has crashed.&lt;/li&gt;
&lt;li&gt;There should not be two sets of servers, each considering another set to have failed, and therefore continuing to serve different sets of clients. This is called the split brain.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;To tackle the first problem, every server sends a &lt;a href=&quot;https://martinfowler.com/articles/patterns-of-distributed-systems/heartbeat.html&quot;&gt;HeartBeat&lt;/a&gt; message to other servers at a regular interval. If a heartbeat is missed, the server sending the heartbeat is considered crashed. The heartbeat interval is small enough to make sure that it does not take a lot of time to detect server failure. As we will see below, in the worst case scenario, the server might be up and running, but the cluster as a group can move ahead considering the server to be failing. This makes sure that services provided to clients are not interrupted.&lt;/p&gt;
&lt;p&gt;The second problem is the split brain. With split brain, if two sets of servers accept updates independently, different clients can get and set different data, and once the split brain is resolved, it's impossible to resolve conflicts automatically.&lt;/p&gt;
&lt;p&gt;To take care of the split brain issue, we must ensure that the two sets of servers, which are disconnected from each other, should not be able to make progress independently. To ensure this, every action the server takes, is considered successful only if the majority of the servers can confirm the action. If servers can not get majority, they will not be able to provide the required services, and some group of the clients might not be receiving the service, but servers in the cluster will always be in a consistent state. The number of servers making the majority is called a &lt;a href=&quot;https://martinfowler.com/articles/patterns-of-distributed-systems/quorum.html&quot;&gt;Quorum&lt;/a&gt;. How to decide on the quorum? That is decided based on the number of failures the cluster can tolerate. So if we have a cluster of five nodes, we need a quorum of three. In general, if we want to tolerate f failures we need a cluster size of 2f + 1.&lt;/p&gt;
&lt;p&gt;Quorum makes sure that we have enough copies of data to survive some server failures. But it is not enough to give strong consistency guarantees to clients. Lets say a client initiates a write operation on the quorum, but the write operation succeeds only on one server. The other servers in the quorum still have old values. When a client reads the values from the quorum, it might get the latest value, if the server having the latest value is available. But it can very well get an old value if, just when the client starts reading the value, the server with the latest value is not available. To avoid such situations, someone needs to track if the quorum agrees on a particular operation and only send values to clients which are guaranteed to be available on all the servers. &lt;a href=&quot;https://martinfowler.com/articles/patterns-of-distributed-systems/leader-follower.html&quot;&gt;Leader and Followers&lt;/a&gt; is used in this situation. One of the servers is elected a leader and the other servers act as followers. The leader controls and coordinates the replication on the followers. The leader now needs to decide, which changes should be made visible to the clients. &lt;a href=&quot;https://martinfowler.com/articles/patterns-of-distributed-systems/high-watermark.html&quot;&gt;High-Water Mark&lt;/a&gt; is used to track the entry in the write ahead log that is known to have successfully replicated to a Quorum of followers. All the entries upto high-water mark are made visible to the clients. The leader also propagates the high-water mark to the followers. So in case the leader fails and one of the followers becomes the new leader, there are no inconsistencies in what a client sees.&lt;/p&gt;
&lt;/section&gt;&lt;section id=&quot;ProcessPauses&quot; readability=&quot;12.777777777778&quot;&gt;&lt;h3&gt;Process Pauses&lt;/h3&gt;
&lt;p&gt;But this is not all, even with Quorums and Leader And Followers, there is a tricky problem that needs to be solved. Leader processes can pause arbitrarily. There are a lot of reasons a process can pause. For languages which support garbage collection, there can be a long garbage collection pause. A leader with a long garbage collection pause, can be disconnected from the followers, and will continue sending messages to followers after the pause is over. In the meanwhile, because followers did not receive any heartbeat from the leader, they might have elected a new leader and accepted updates from the clients. If the requests from the old leader are processed as it is, they might overwrite some of the updates. So we need a mechanism to detect requests from out of date leaders. &lt;a href=&quot;https://martinfowler.com/articles/patterns-of-distributed-systems/generation.html&quot;&gt;Generation Clock&lt;/a&gt; is used to mark and detect requests from older leaders. The generation is a number which is monotonically increasing.&lt;/p&gt;
&lt;/section&gt;&lt;section id=&quot;UnsynchronizedClocksAndOrderingEvents&quot; readability=&quot;22.723516153268&quot;&gt;&lt;h3&gt;Unsynchronized Clocks and Ordering Events&lt;/h3&gt;
&lt;p&gt;The problem of detecting older leader messages from newer ones is the problem of maintaining ordering of messages. It might appear that we can use system timestamps to order a set of messages, but we can not. The main reason we can not use system clocks is that system clocks across servers are not guaranteed to be synchronized. A time of the day clock in a computer is managed by a quartz crystal and measures time based on the oscillations of the crystal.&lt;/p&gt;
&lt;p&gt;This mechanism is error prone, as the crystals can oscillate faster or slower and so different servers can have very different times. The clocks across a set of servers are synchronized by a service called NTP. This service periodically checks a set of global time servers, and adjusts the computer clock accordingly.&lt;/p&gt;
&lt;p&gt;Because this happens with communication over a network, and network delays can vary as discussed in the above sections, the clock synchronization might be delayed because of a network issue. This can cause server clocks to drift away from each other, and after the NTP sync happens, even move back in time. Because of these issues with computer clocks, time of day is generally not used for ordering events. Instead a simple technique called Lamport’s timestamp is used. &lt;a href=&quot;https://martinfowler.com/articles/patterns-of-distributed-systems/generation.html&quot;&gt;Generation Clock&lt;/a&gt; is an example of that.&lt;/p&gt;
&lt;/section&gt;&lt;/div&gt;&lt;div id=&quot;PuttingItAllTogether-AnExampleDistributedSystem&quot;&gt;&lt;h2&gt;Putting it all together - An example distributed system&lt;/h2&gt;
&lt;p&gt;We can see how understanding these patterns, helps us build a complete system, from the ground up. We will take consensus implementation as an example. Distributed Consensus is a special case of distributed system implementation, which provides the strongest consistency guarantee. Common examples seen in popular enterprise systems are, &lt;a href=&quot;https://zookeeper.apache.org/&quot;&gt;Zookeeper&lt;/a&gt;, &lt;a href=&quot;https://etcd.io/&quot;&gt;etcd&lt;/a&gt; and &lt;a href=&quot;https://www.consul.io/&quot;&gt;Consul&lt;/a&gt;. They implement consensus algorithms like &lt;a href=&quot;https://zookeeper.apache.org/doc/r3.4.13/zookeeperInternals.html#sc_atomicBroadcast&quot;&gt;zab&lt;/a&gt; and &lt;a href=&quot;https://raft.github.io/&quot;&gt;Raft&lt;/a&gt; to provide replication and strong consistency. There are other popular algorithms to implement consensus, &lt;a href=&quot;https://en.wikipedia.org/wiki/Paxos_(computer_science)&quot;&gt;Paxos&lt;/a&gt; which is used in Google's &lt;a href=&quot;https://research.google/pubs/pub27897/&quot;&gt;Chubby&lt;/a&gt; locking service, view stamp replication and &lt;a href=&quot;https://www.cs.cornell.edu/ken/History.pdf&quot;&gt;virtual-synchrony&lt;/a&gt;. In very simple terms, Consensus refers to a set of servers which agree on stored data, the order in which the data is stored and when to make that data visible to the clients.&lt;/p&gt;
&lt;section id=&quot;PatternSequenceForImplementingConsensus&quot; readability=&quot;19.206479956068&quot;&gt;&lt;h3&gt;Pattern Sequence for implementing consensus&lt;/h3&gt;
&lt;p&gt;Consensus implementations use &lt;a href=&quot;https://en.wikipedia.org/wiki/State_machine_replication&quot;&gt;state machine replication&lt;/a&gt; to achieve fault tolerance. In state machine replication, the storage services, like a key value store, are replicated on all the servers, and the user inputs are executed in the same order on each server. The key implementation technique used to achieve this is to replicate &lt;a href=&quot;https://martinfowler.com/articles/patterns-of-distributed-systems/wal.html&quot;&gt;Write-Ahead Log&lt;/a&gt; on all the servers to have a 'Replicated Wal'.&lt;/p&gt;
&lt;p&gt;We can put the patterns together to implement Replicated Wal as follows.&lt;/p&gt;
&lt;p&gt;For providing durability guarantees, use &lt;a href=&quot;https://martinfowler.com/articles/patterns-of-distributed-systems/wal.html&quot;&gt;Write-Ahead Log&lt;/a&gt;. Write Ahead Log is divided into multiple segments using &lt;a href=&quot;https://martinfowler.com/articles/patterns-of-distributed-systems/log-segmentation.html&quot;&gt;Segmented Log&lt;/a&gt;. This helps with log cleaning which is handled by &lt;a href=&quot;https://martinfowler.com/articles/patterns-of-distributed-systems/low-watermark.html&quot;&gt;Low-Water Mark&lt;/a&gt;. Fault tolerance is provided by replicating the write ahead log on multiple servers. Replication amongst the servers is managed by using &lt;a href=&quot;https://martinfowler.com/articles/patterns-of-distributed-systems/leader-follower.html&quot;&gt;Leader and Followers&lt;/a&gt;. &lt;a href=&quot;https://martinfowler.com/articles/patterns-of-distributed-systems/quorum.html&quot;&gt;Quorum&lt;/a&gt; is used to update &lt;a href=&quot;https://martinfowler.com/articles/patterns-of-distributed-systems/high-watermark.html&quot;&gt;High-Water Mark&lt;/a&gt; to decide which values are visible to clients. All the requests are processed in strict order, by using &lt;a href=&quot;https://martinfowler.com/articles/patterns-of-distributed-systems/singular-update-queue.html&quot;&gt;Singular Update Queue&lt;/a&gt;. The order is maintained while sending the requests from leaders to followers using &lt;a href=&quot;https://martinfowler.com/articles/patterns-of-distributed-systems/single-socket-channel.html&quot;&gt;Single Socket Channel&lt;/a&gt;. To optimize for throughput and latency over a single socket channel, &lt;a href=&quot;https://martinfowler.com/articles/patterns-of-distributed-systems/request-pipeline.html&quot;&gt;Request Pipeline&lt;/a&gt; is used. Followers know about availability of leader by &lt;a href=&quot;https://martinfowler.com/articles/patterns-of-distributed-systems/heartbeat.html&quot;&gt;HeartBeat&lt;/a&gt; received from the leader. If leader is temporarily disconnected from the cluster because of network partition, it is detected by using &lt;a href=&quot;https://martinfowler.com/articles/patterns-of-distributed-systems/generation.html&quot;&gt;Generation Clock&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;This way, understanding problems and their recurring solutions in their general form, helps in understanding building blocks of a complete system&lt;/p&gt;
&lt;/section&gt;&lt;/div&gt;</description>
<pubDate>Wed, 10 Feb 2021 14:39:16 +0000</pubDate>
<dc:creator>sbmthakur</dc:creator>
<og:title>Patterns of Distributed Systems</og:title>
<og:url>https://martinfowler.com/articles/patterns-of-distributed-systems/</og:url>
<og:description>A catalog of patterns to better understand, communicate, and teach the design of distributed systems</og:description>
<og:image>https://martinfowler.com/articles/patterns-of-distributed-systems/card.png</og:image>
<og:type>article</og:type>
<dc:format>text/html</dc:format>
<dc:identifier>https://martinfowler.com/articles/patterns-of-distributed-systems/</dc:identifier>
</item>
</channel>
</rss>