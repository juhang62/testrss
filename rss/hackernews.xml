<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=hnrss.org%2Fnewest%3Fpoints%3D200&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://hnrss.org/newest?points=200" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>Hacker News: Newest</title>
<link>https://news.ycombinator.com/newest</link>
<description>Hacker News RSS</description>
<item>
<title>Tech Companies Are Deleting Evidence of War Crimes</title>
<link>https://www.theatlantic.com/ideas/archive/2019/05/facebook-algorithms-are-making-it-harder/588931/</link>
<guid isPermaLink="true" >https://www.theatlantic.com/ideas/archive/2019/05/facebook-algorithms-are-making-it-harder/588931/</guid>
<description>&lt;section class=&quot;l-article__section s-cms-content&quot; itemprop=&quot;articleBody&quot; id=&quot;article-section-0&quot;&gt;&lt;p class=&quot;dropcap&quot;&gt;I&lt;span class=&quot;smallcaps&quot;&gt;f grisly images&lt;/span&gt; stay up on Facebook or YouTube long enough, self-appointed detectives around the world sometimes use them to reconstruct a crime scene. In July 2017, a video capturing the execution of 18 people appeared on Facebook. The clip opened with a half-dozen armed men presiding over several rows of detainees. Dressed in bright-orange jumpsuits and black hoods, the captives knelt in the gravel, hands tied behind their back. They never saw what was coming. The gunmen raised their weapons and fired, and the first row of victims crumpled to the earth. The executioners repeated this act four times, following the orders of a confident young man dressed in a black cap and camouflage trousers. If you slowed the video down frame by frame, you could see that his black T-shirt bore the logo of the Al-Saiqa Brigade, an elite unit of the Libyan National Army. That was clue No. 1: This happened in Libya.&lt;/p&gt;


&lt;p&gt;Facebook took down the bloody video, whose source has yet to be conclusively determined, shortly after it surfaced. But it existed online long enough for copies to spread to other social-networking sites. Independently, human-rights activists, prosecutors, and other internet users in multiple countries scoured the clip for clues and soon established that the killings had occurred on the outskirts of Benghazi. The ringleader, these investigators concluded, was Mahmoud Mustafa Busayf al-Werfalli, an Al-Saiqa commander. Within a month, the International Criminal Court had charged Werfalli with the murder of 33 people in seven separate incidents—from June 2016 to the July 2017 killings that landed on Facebook. In &lt;a href=&quot;https://www.icc-cpi.int/CourtRecords/CR2017_05031.PDF&quot; data-omni-click=&quot;r'article',r'',d,r'intext',r'0',r'None'&quot;&gt;the ICC arrest warrant&lt;/a&gt;, prosecutors relied heavily on digital evidence collected from social-media sites.&lt;/p&gt;
&lt;/section&gt;&lt;section class=&quot;l-article__section s-cms-content&quot; itemprop=&quot;articleBody&quot; id=&quot;article-section-1&quot;&gt;
&lt;p&gt;Werfalli has thus far evaded justice. But human-rights activists still hail the case as a breakthrough for a powerful new tool: online open-source investigations. Even in no-go combat zones, war crimes and other abuses often leave behind an information trail. By piecing together information that becomes publicly accessible on social media and other sites, internet users can hold the perpetrators accountable—that is, unless algorithms developed by the tech giants expunge the evidence first.&lt;/p&gt;

&lt;p&gt;Shortly after the Werfalli arrest warrant was issued, Hadi Al Khatib, a Syrian-born open-source investigator based in Berlin, noticed something that distressed him: User-generated videos depicting firsthand accounts from the war in Syria were vanishing from the internet by the thousands. Khatib is the founder of the &lt;a href=&quot;https://syrianarchive.org/en&quot; data-omni-click=&quot;r'article',r'',d,r'intext',r'1',r'None'&quot;&gt;Syrian Archive&lt;/a&gt;, a collective of activists that, since 2014, has been scouring for digital materials posted by people left behind in Syria’s war zone. The Syrian Archive’s aim is “to build a kind of visual documentation relating to human-rights violations and other crimes committed by all sides during the eight-year-old conflict,” Khatib said in an interview.&lt;/p&gt;

&lt;p&gt;In the late summer of 2017, Khatib and his colleagues were systematically building a case against the regime of Bashar al-Assad in much the same way ICC investigators pursued Werfalli. They had amassed scores and scores of citizens’ accounts, including video and photos that purportedly showed Assad was targeting hospitals and medical clinics in bombing campaigns. “We were collecting, archiving, and geolocating evidence, doing all sorts of verification for the case,” Khatib recalled. “Then one day we noticed that all the videos that we had been going through, all of a sudden, all of them were gone.”&lt;/p&gt;
&lt;p&gt;It wasn’t a sophisticated hack attack by pro-Assad forces that wiped out their work. It was the ruthlessly efficient work of machine-learning algorithms deployed by social networks, particularly YouTube and Facebook.&lt;/p&gt;
&lt;p class=&quot;dropcap&quot;&gt;W&lt;span class=&quot;smallcaps&quot;&gt;ith some reluctance&lt;/span&gt;, technology companies in Silicon Valley have taken on the role of prosecutors, judges, and juries in decisions about which words and images should be banished from the public’s sight. Lately, tech companies have become almost as skilled at muzzling speech as they are at enabling it. This hasn’t gone unnoticed by government entities that are keen to transform social networks into listening posts. Government, in effect, is “subcontracting” social-media platforms to be its eyes and ears on all kinds of content it deems objectionable, says Fionnuala Ní Aoláin, a law professor and &lt;a href=&quot;https://www.ohchr.org/EN/Issues/Terrorism/Pages/SRTerrorismIndex.aspx&quot; data-omni-click=&quot;r'article',r'',d,r'intext',r'2',r'None'&quot;&gt;special rapporteur for the United Nations Human Rights Council&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;But some of what governments ask tech companies to do, such as suppressing violent content, cuts against other legitimate goals, such as bringing warlords and dictators to justice. Balancing these priorities is hard enough when humans are making judgments in accordance with established legal norms. In contrast, tech giants operate largely in the dark. They are governed by opaque terms-of-service policies that, more and more, are enforced by artificial-intelligence tools developed in-house with little to no input from the public. “We don’t even know what goes into the algorithms, what kind of in-built biases and structures there are,” Ní Aoláin said in an interview.&lt;/p&gt;
&lt;/section&gt;&lt;section class=&quot;l-article__section s-cms-content&quot; itemprop=&quot;articleBody&quot; id=&quot;article-section-2&quot;&gt;&lt;p&gt;For years, social networks relied on users to flag objectionable content, all manner of hate speech, and calls to arms that, among other things, espoused violence. But as this content continued to fill up the fringes and spill into clear sight, pressure mounted on Facebook, YouTube, Twitter, and other popular social networks to automate the cleanup. They turned to machine learning, a powerful subset of artificial intelligence that can make sense of huge amounts of data with little to no oversight from human minders.&lt;/p&gt;

&lt;p&gt;Designed to identify and take down content posted by “extremists”—“extremists” as defined by software engineers—machine-learning software has become a potent catch-and-kill tool to keep the world’s largest social networks remarkably more sanitized places than they were just a year ago. Google and Facebook break out the numbers in their quarterly transparency reports. &lt;a href=&quot;https://transparencyreport.google.com/youtube-policy/removals&quot; data-omni-click=&quot;r'article',r'',d,r'intext',r'3',r'None'&quot;&gt;YouTube pulled&lt;/a&gt; 33 million videos off its network in 2018—roughly 90,000 a day. Of the videos removed after automated systems flagged them, 73 percent were removed so fast that no community members ever saw them. Meanwhile, &lt;a href=&quot;https://transparency.facebook.com/community-standards-enforcement#terrorist-propaganda&quot; data-omni-click=&quot;r'article',r'',d,r'intext',r'4',r'None'&quot;&gt;Facebook removed&lt;/a&gt; 15 million pieces of content it deemed “terrorist propaganda” from October 2017 to September 2018. In the third quarter of 2018, machines performed 99.5 percent of Facebook’s “terrorist content” takedowns. Just 0.5 percent of the purged material was reported by users first.&lt;/p&gt;
&lt;p&gt;Those statistics are deeply troubling to open-source investigators, who complain that the machine-learning tools are black boxes. Few people, if any, in the human-rights world know how they’re programmed. Are these AI-powered vacuum cleaners able to discern that a video from Syria, Yemen, or Libya might be a valuable piece of evidence, something someone risked his or her life to post, and therefore worth preserving? YouTube, for one, says it’s working with human-rights experts to fine-tune its take-down procedures. But deeper discussions about the technology involved are rare.&lt;/p&gt;

&lt;p&gt;“Companies are very loath to let civil society talk directly to engineers,” says &lt;a href=&quot;https://witness.org/portfolio_page/dia-kayyali/&quot; data-omni-click=&quot;r'article',r'',d,r'intext',r'5',r'None'&quot;&gt;Dia Kayyali&lt;/a&gt;, a technology-advocacy program manager at Witness, a human-rights organization that works with Khatib and the Syrian Archive. “It’s something that I’ve pushed for. A lot.”&lt;/p&gt;
&lt;p&gt;These concerns are being drowned out by a counterargument, this one from governments, that tech companies should clamp down harder. Authoritarian countries routinely impose social-media blackouts during national crises, as Sri Lanka did after the Easter-morning terror bombings and as Venezuela did during the May 1 uprising. But politicians in healthy democracies are pressing social networks for round-the-clock controls in an effort to protect impressionable minds from violent content that could radicalize them. If these platforms fail to comply, they could face hefty fines and even jail time for their executives. New Zealand Prime Minister Jacinda Ardern and French President Emmanuel Macron intend to up the ante at &lt;a href=&quot;https://www.theguardian.com/world/2019/apr/24/christchurch-call-ardern-leads-push-against-online-terror-content&quot; data-omni-click=&quot;r'article',r'',d,r'intext',r'6',r'None'&quot;&gt;a summit next week&lt;/a&gt; calling on tech execs and world leaders to band together to eliminate the publication of extremist online content. After the March 15 mosque massacre in Christchurch, New Zealand, was streamed live on Facebook, countries including New Zealand, Australia, and the United Kingdom passed or proposed comprehensive new online-terror laws.&lt;/p&gt;
&lt;/section&gt;&lt;section class=&quot;l-article__section s-cms-content&quot; itemprop=&quot;articleBody&quot; id=&quot;article-section-3&quot;&gt;
&lt;p&gt;&lt;a href=&quot;http://www.europarl.europa.eu/doceo/document/A-8-2019-0193_EN.html?redirect&quot; data-omni-click=&quot;r'article',r'',d,r'intext',r'7',r'None'&quot;&gt;A proposed European Union law&lt;/a&gt; has been in the works for months. It would require technology companies to pull down harmful user-generated material—whether words or images—that “incites or solicits the commission or contribution of terrorist offenses, or promotes the participation in activities of a terrorist group.” That standard is extraordinarily broad. But if the companies don’t eliminate such posts within one hour, they face fines of up to &lt;a href=&quot;https://www.theverge.com/2019/3/21/18274201/european-terrorist-content-regulation-extremist-terreg-upload-filter-one-hour-takedown-eu&quot; data-omni-click=&quot;r'article',r'',d,r'intext',r'8',r'None'&quot;&gt;4 percent of global revenues&lt;/a&gt;.&lt;/p&gt;
&lt;p class=&quot;dropcap&quot;&gt;H&lt;span class=&quot;smallcaps&quot;&gt;uman-rights advocates&lt;/span&gt; worry about the decisions tech giants and their algorithms will make under such outside pressure. “The danger is that governments will often get the balance wrong,” argued Ní Aoláin. “But actually we have the methods and means to challenge governments when they do so. But private entities? We don’t have the legal processes. These are private companies. And the legal basis upon which they regulate their relationships with their users, whether they’re in conflict zones or not, is determined by [the company’s] terms of service. It’s neither transparent nor fair. Your recourse is quite limited.”&lt;/p&gt;

&lt;p&gt;In July, she wrote &lt;a href=&quot;https://www.ohchr.org/Documents/Issues/Terrorism/OL_OTH_46_2018.pdf&quot; data-omni-click=&quot;r'article',r'',d,r'intext',r'9',r'None'&quot;&gt;an open letter&lt;/a&gt; to Facebook’s founder, Mark Zuckerberg, finding fault with how Facebook defines terrorism-related content, a key determination in what it decides to flag and take down. From what Ní Aoláin can tell, “they just came up with a definition for terrorism that bears no relationship to the global definition agreed by states, which I think is a very dangerous precedent. I made that very clear in my communications with them.”&lt;/p&gt;
&lt;p&gt;When I asked Facebook to comment on Ní Aoláin’s complaint, a company spokesperson &lt;a href=&quot;https://fbnewsroomus.files.wordpress.com/2018/11/12.11.18-Content-Standard-Forum-Minutes-.pdf&quot; data-omni-click=&quot;r'article',r'',d,r'intext',r'10',r'None'&quot;&gt;shared detailed minutes&lt;/a&gt; from a December content-standards forum. The minutes are a remarkable document, one that underscores the complexity of the judgments tech companies are being asked to make as they seek to monetize human interactions on a global scale. Is a terrorist organization one that “engages in premeditated acts of violence against persons or property,” or should the definition expand to include any non-state group that “engages in or advocates and lends substantial support” to “purposive and planned acts of violence”? “It would shock me,” one person at the meeting commented, “if in a year we don’t come back and say we need to refine this definition again.” (A company spokesperson said recently that there’s no update on the matter to announce.)&lt;/p&gt;

&lt;p&gt;How the tech giants’ algorithms will implement these subtle standards is an open question. But a new crop of anti-terrorism bills, post-Christchurch, will thrust technology companies into an even more assertive enforcement role. Under the threat of massive fines, tech giants are likely to invest more in aggressive machine-learning content filters to suppress potentially objectionable material. All this will have a chilling effect on those who are trying to expose wrongdoing in war zones.&lt;/p&gt;
&lt;/section&gt;&lt;section class=&quot;l-article__section s-cms-content&quot; itemprop=&quot;articleBody&quot; id=&quot;article-section-4&quot;&gt;&lt;p&gt;Khatib, at the Syrian Archive, said the rise of machine-learning algorithms has made his job far more difficult in recent months. But the push for more filters continues. (As a Brussels-based digital-rights lobbyist in a separate conversation deadpanned, “Filters are the new black, essentially.”) The EU’s online-terrorism bill, Khatib noted, sends the message that sweeping unsavory content under the rug is okay; the social-media platforms will see to it that nobody sees it. He fears the unintended consequences of such a law—that in cracking down on content that’s deemed off-limits in the West, it could have ripple effects that make life even harder for those residing in repressive societies, or worse, in war zones. Any further crackdown on what people can share online, he said, “would definitely be a gift for all authoritarian regimes. It would be a gift for Assad.”&lt;/p&gt;
&lt;p&gt;“On the ground in Syria,” he continued, “Assad is doing everything he can to make sure the physical evidence [of potential human-rights violations] is destroyed, and the digital evidence, too. The combination of all this—the filters, the machine-learning algorithms, and new laws—will make it harder for us to document what’s happening in closed societies.” That, he fears, is what dictators want.&lt;/p&gt;
&lt;section class=&quot;c-foundation-line&quot; id=&quot;foundation-line&quot;&gt;&lt;p class=&quot;c-foundation-line__text&quot;&gt;This article is part of “The Speech Wars,” a project supported by the Charles Koch Foundation, the Reporters Committee for the Freedom of the Press, and the Fetzer Institute.&lt;/p&gt;
&lt;/section&gt;&lt;section class=&quot;c-letters-cta&quot;&gt;&lt;p class=&quot;c-letters-cta__text&quot;&gt;We want to hear what you think about this article. &lt;a href=&quot;https://www.theatlantic.com/contact/letters/&quot; class=&quot;c-letters-cta__link&quot;&gt;Submit a letter&lt;/a&gt; to the editor or write to letters@theatlantic.com.&lt;/p&gt;
&lt;/section&gt;

&lt;address id=&quot;article-writer-0&quot; class=&quot;c-article-writer lazyload&quot; data-author-id=&quot;23539&quot; data-include=&quot;css:https://cdn.theatlantic.com/assets/static/b/frontend/dist/theatlantic/css/components/article-writer.ccce81ff6d92.css&quot; itemprop=&quot;author&quot; itemtype=&quot;https://schema.org/Person&quot; itemscope=&quot;&quot;/&gt;
&lt;div class=&quot;c-article-writer__content&quot;&gt;
&lt;div class=&quot;c-article-writer__bio&quot; itemprop=&quot;description&quot;&gt;&lt;a href=&quot;https://www.theatlantic.com/author/bernhard-warner/&quot; class=&quot;author-link&quot; data-omni-click=&quot;inherit&quot;&gt;Bernhard Warner&lt;/a&gt; is a journalist based in Rome.&lt;/div&gt;
&lt;/div&gt;
&lt;/section&gt;</description>
<pubDate>Thu, 09 May 2019 03:00:10 +0000</pubDate>
<dc:creator>anfilt</dc:creator>
<og:title>Tech Companies Are Deleting Evidence of War Crimes</og:title>
<og:type>article</og:type>
<og:url>https://www.theatlantic.com/ideas/archive/2019/05/facebook-algorithms-are-making-it-harder/588931/</og:url>
<og:image>https://cdn.theatlantic.com/assets/media/img/mt/2019/05/RTS6BJ1/facebook.jpg?1557324903</og:image>
<og:description>Algorithms that take down “terrorist” videos could hamstring efforts to bring human-rights abusers to justice.</og:description>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.theatlantic.com/ideas/archive/2019/05/facebook-algorithms-are-making-it-harder/588931/</dc:identifier>
</item>
<item>
<title>Amazon S3 Path Deprecation Plan – The Rest of the Story</title>
<link>https://aws.amazon.com/blogs/aws/amazon-s3-path-deprecation-plan-the-rest-of-the-story/</link>
<guid isPermaLink="true" >https://aws.amazon.com/blogs/aws/amazon-s3-path-deprecation-plan-the-rest-of-the-story/</guid>
<description>&lt;table id=&quot;amazon-polly-audio-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td id=&quot;amazon-polly-audio-tab&quot;&gt;


&lt;div id=&quot;amazon-polly-by-tab&quot;&gt;&lt;a href=&quot;https://aws.amazon.com/polly/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;&lt;img src=&quot;https://a0.awsstatic.com/aws-blog/images/Voiced_by_Amazon_Polly_EN.png&quot; width=&quot;554&quot; height=&quot;56&quot;/&gt;&lt;/a&gt;&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;img src=&quot;https://media.amazonwebservices.com/blog/2019/ritchie_and_thompson_pdp11_1.jpeg&quot;/&gt;Last week we made a fairly quiet (too quiet, in fact) announcement of our plan to slowly and carefully deprecate the path-based access model that is used to specify the address of an object in an S3 bucket. I spent some time talking to the S3 team in order to get a better understanding of the situation in order to write this blog post. Here’s what I learned…&lt;/p&gt;&lt;p&gt;We &lt;a href=&quot;https://aws.amazon.com/blogs/aws/amazon_s3/&quot;&gt;launched S3&lt;/a&gt; in early 2006. Jeff Bezos’ original spec for S3 was very succinct – he wanted &lt;code&gt;malloc&lt;/code&gt; (a key memory allocation function for C programs) for the Internet. From that starting point, S3 has grown to the point where it now stores many trillions of objects and processes millions of requests per second for them. Over the intervening 13 years, we have added many new storage options, features, and security controls to S3.&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;Old vs. New&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;S3 currently supports two different addressing models: path-style and virtual-hosted style. Let’s take a quick look at each one. The path-style model looks like either this (the global S3 endpoint):&lt;/p&gt;
&lt;p&gt;&lt;code&gt;https://s3.amazonaws.com/jbarr-public/images/ritchie_and_thompson_pdp11.jpeg&lt;/code&gt;&lt;br/&gt;&lt;code&gt;https://s3.amazonaws.com/jeffbarr-public/classic_amazon_door_desk.png&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Or this (one of the regional S3 endpoints):&lt;/p&gt;
&lt;p&gt;&lt;code&gt;https://s3-us-east-2.amazonaws.com/jbarr-public/images/ritchie_and_thompson_pdp11.jpeg&lt;/code&gt;&lt;br/&gt;&lt;code&gt;https://s3-us-east-2.amazonaws.com/jeffbarr-public/classic_amazon_door_desk.png&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;In this example, &lt;code&gt;jbarr-public&lt;/code&gt; and &lt;code&gt;jeffbarr-public&lt;/code&gt; are bucket names; &lt;code&gt;/images/ritchie_and_thompson_pdp11.jpeg&lt;/code&gt; and &lt;code&gt;/jeffbarr-public/classic_amazon_door_desk.png&lt;/code&gt; are object keys.&lt;/p&gt;
&lt;p&gt;Even though the objects are owned by distinct AWS accounts and are in different S3 buckets (and possibly in distinct AWS regions), both of them are in the DNS subdomain &lt;code&gt;s3.amazonaws.com&lt;/code&gt;. Hold that thought while we look at the equivalent virtual-hosted style references (although you might think of these as “new,” they have been around since at least 2010):&lt;/p&gt;
&lt;p&gt;&lt;code&gt;https://jbarr-public.s3.amazonaws.com/images/ritchie_and_thompson_pdp11.jpeg&lt;/code&gt;&lt;br/&gt;&lt;code&gt;https://jeffbarr-public.s3.amazonaws.com/classic_amazon_door_desk.png&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;These URLs reference the same objects, but the objects are now in distinct DNS subdomains (&lt;code&gt;jbarr-public.s3.amazonaws.com&lt;/code&gt; and &lt;code&gt;jeffbarr-public.s3.amazonaws.com&lt;/code&gt;, respectively). The difference is subtle, but very important. When you use a URL to reference an object, DNS resolution is used to map the subdomain name to an IP address. With the path-style model, the subdomain is always &lt;code&gt;s3.amazonaws.com&lt;/code&gt; or one of the regional endpoints; with the virtual-hosted style, the subdomain is specific to the bucket. This additional degree of endpoint specificity is the key that opens the door to many important improvements to S3.&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;Out with the Old&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;In response to feedback on the original deprecation plan that we announced last week, we are making an important change. Here’s the executive summary:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Original Plan&lt;/strong&gt; – Support for the path-style model ends on September 30, 2020.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Revised Plan&lt;/strong&gt; – Support for the path-style model continues for buckets created on or before September 30, 2020. Buckets created after that date must be referenced using the virtual-hosted model.&lt;/p&gt;
&lt;p&gt;We are moving to virtual-hosted references for two reasons:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;First,&lt;/strong&gt; anticipating a world with billions of buckets homed in many dozens of regions, routing all incoming requests directly to a small set of endpoints makes less and less sense over time. DNS resolution, scaling, security, and traffic management (including DDoS protection) are more challenging with this centralized model. The virtual-hosted model reduces the area of impact (which we call the “blast radius” internally) when problems arise; this helps us to increase availability and performance.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Second&lt;/strong&gt;, the team has a lot of powerful features in the works, many of which depend on the use of unique, virtual-hosted style subdomains. Moving to this model will allow you to benefit from these new features as soon as they are announced. For example, we are planning to deprecate some of the oldest security ciphers and versions (details to come later). The deprecation process is easier and smoother (for you and for us) if you are using virtual-hosted references.&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;In With the New&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;As just one example of what becomes possible when using virtual-hosted references, we are thinking about providing you with increased control over the security configuration (including ciphers and cipher versions) for each bucket. If you have ideas of your own, feel free to get in touch.&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;Moving Ahead&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;Here are some things to know about our plans:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Identifying Path-Style References&lt;/strong&gt; – You can use &lt;a href=&quot;https://docs.aws.amazon.com/AmazonS3/latest/dev/ServerLogs.html&quot;&gt;S3 Access Logs&lt;/a&gt; (look for the &lt;code&gt;Host Header&lt;/code&gt; field) and AWS &lt;a href=&quot;https://docs.aws.amazon.com/awscloudtrail/latest/userguide/logging-management-and-data-events-with-cloudtrail.html?shortFooter=true#logging-data-events-examples&quot;&gt;CloudTrail Data Events&lt;/a&gt; (look for the &lt;code&gt;host&lt;/code&gt; element of the &lt;code&gt;requestParameters&lt;/code&gt; entry) to identify the applications that are making path-style requests.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Programmatic Access&lt;/strong&gt; – If your application accesses S3 using one of the &lt;a href=&quot;https://aws.amazon.com/tools/&quot; title=&quot;&quot;&gt;AWS SDKs&lt;/a&gt;, you don’t need to do anything, other than ensuring that your SDK is current. The SDKs already use virtual-hosted references to S3, except if the bucket name contains one or more “.” characters.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Bucket Names with Dots&lt;/strong&gt; – It is important to note that bucket names with “.” characters are perfectly valid for &lt;a href=&quot;https://docs.aws.amazon.com/AmazonS3/latest/dev/WebsiteHosting.html&quot;&gt;website hosting&lt;/a&gt; and other use cases. However, there are some known issues with TLS and with SSL certificates. We are hard at work on a plan to support virtual-host requests to these buckets, and will share the details well ahead of September 30, 2020.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Non-Routable Names&lt;/strong&gt; – Some characters that are valid in the path component of a URL are not valid as part of a domain name. Also, paths are case-sensitive, but domain and subdomain names are not. We’ve been enforcing more stringent rules for new bucket names since last year. If you have data in a bucket with a non-routable name and you want to switch to virtual-host requests, you can use the new &lt;a href=&quot;https://aws.amazon.com/blogs/aws/new-amazon-s3-batch-operations/&quot;&gt;S3 Batch Operations&lt;/a&gt; feature to move the data. However, if this is not a viable option, please reach out to &lt;a href=&quot;https://aws.amazon.com/premiumsupport/plans/developers/&quot;&gt;AWS Developer Support&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Documentation&lt;/strong&gt; – We are planning to update the &lt;a href=&quot;https://docs.aws.amazon.com/s3/index.html&quot;&gt;S3 Documentation&lt;/a&gt; to encourage all developers to build applications that use virtual-host requests. The &lt;a href=&quot;https://docs.aws.amazon.com/AmazonS3/latest/dev/VirtualHosting.html&quot;&gt;Virtual Hosting&lt;/a&gt; documentation is a good starting point.&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;We’re Here to Help&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;The S3 team has been working with some of our customers to help them to migrate, and they are ready to work with many more.&lt;/p&gt;
&lt;p&gt;Our goal is to make this deprecation smooth and uneventful, and we want to help minimize any costs you may incur! Please do not hesitate to reach out to us if you have questions, challenges, or concerns.&lt;/p&gt;
&lt;p&gt;— &lt;a href=&quot;https://twitter.com/jeffbarr&quot;&gt;Jeff&lt;/a&gt;;&lt;/p&gt;
&lt;p&gt;PS – Stay tuned for more information on tools and other resources.&lt;/p&gt;
</description>
<pubDate>Thu, 09 May 2019 00:47:03 +0000</pubDate>
<dc:creator>jeffbarr</dc:creator>
<og:title>Amazon S3 Path Deprecation Plan – The Rest of the Story | Amazon Web Services</og:title>
<og:type>article</og:type>
<og:url>https://aws.amazon.com/blogs/aws/amazon-s3-path-deprecation-plan-the-rest-of-the-story/</og:url>
<og:description>Last week we made a fairly quiet (too quiet, in fact) announcement of our plan to slowly and carefully deprecate the path-based access model that is used to specify the address of an object in an S3 bucket. I spent some time talking to the S3 team in order to get a better understanding of […]</og:description>
<og:image>https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2019/05/09/ritchie_and_thompson_pdp11_1.jpeg</og:image>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://aws.amazon.com/blogs/aws/amazon-s3-path-deprecation-plan-the-rest-of-the-story/</dc:identifier>
</item>
<item>
<title>Denver decriminalizes psychedelic mushrooms</title>
<link>https://www.denverpost.com/2019/05/08/denver-psychedelic-magic-mushroom/</link>
<guid isPermaLink="true" >https://www.denverpost.com/2019/05/08/denver-psychedelic-magic-mushroom/</guid>
<description>&lt;img class=&quot; lazyautosizes lazyload&quot; src=&quot;https://i0.wp.com/www.denverpost.com/wp-content/uploads/2019/02/AP_070802036452.jpg?fit=620%2C9999px&amp;amp;ssl=1&quot; alt=&quot;Magic mushrooms are seen at the ...&quot; width=&quot;2312&quot; data-sizes=&quot;auto&quot; data-src=&quot;https://i0.wp.com/www.denverpost.com/wp-content/uploads/2019/02/AP_070802036452.jpg?fit=620%2C9999px&amp;amp;ssl=1&quot; data-srcset=&quot;https://i0.wp.com/www.denverpost.com/wp-content/uploads/2019/02/AP_070802036452.jpg?fit=620%2C9999px&amp;amp;ssl=1 620w,https://i0.wp.com/www.denverpost.com/wp-content/uploads/2019/02/AP_070802036452.jpg?fit=310%2C9999px&amp;amp;ssl=1 310w&quot;/&gt;&lt;p&gt;Peter Dejong, The Associated Press&lt;/p&gt;
Psychedelic mushrooms are seen at the Procare farm in Hazerswoude, central Netherlands, in this 2007 file photo.
&lt;p&gt;Denver is poised to become the first city in the nation to effectively decriminalize psychedelic mushrooms.&lt;/p&gt;&lt;p&gt;After &lt;a href=&quot;https://www.denverpost.com/2019/05/07/psychedelic-magic-mushrooms-denver-election/&quot;&gt;closing an early vote deficit Tuesday night&lt;/a&gt; and early Wednesday, final unofficial results &lt;a href=&quot;https://www.denvergov.org/electionresults#/results/20190507&quot;&gt;posted&lt;/a&gt; late in the afternoon showed a reversal of fortune — with Initiative 301 set to pass narrowly with 50.6 percent of the vote. The total stands at 89,320 votes in favor and 87,341 against, a margin of 1,979.&lt;/p&gt;
&lt;p&gt;The Denver Elections Division will continue accepting military and overseas ballots, but typically those numbers are small. Results will be certified May 16.&lt;/p&gt;
&lt;p&gt;“It’s been one hell of a 21 and a half hours,” Initiative 301 campaign manager Kevin Matthews said. “If these results hold, this is an example of the absurd comedy of the great metaphor. Against all odds, we prevailed. This is what happens when a small team of dedicated and passionate people unite under a single idea to create change.”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;RELATED:&lt;/strong&gt; &lt;a href=&quot;https://www.denverpost.com/2019/05/08/find-out-who-your-new-denver-city-council-member-is-or-if-you-have-to-vote-again/&quot;&gt;Find out who your new Denver City Council member is — or if you have to vote again&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Denver’s vote &lt;a href=&quot;https://www.washingtonpost.com/crime-law/2019/05/08/denver-voters-apparently-reject-decriminalization-magic-mushrooms/?utm_term=.16a348698b58&quot;&gt;has attracted national attention&lt;/a&gt;. While efforts are afoot to get psilocybin-related measures on the ballot in Oregon and California in 2020, Denver hosted the first-ever U.S. popular vote on the matter, according to organizers. An earlier effort in California last year failed to qualify for the ballot.&lt;/p&gt;
&lt;p&gt;Though Initiative 301 attracted no organized opposition, critics of Colorado’s legalization of marijuana lamented the prospect of Denver blazing yet another trail they see as misguided and potentially harmful.&lt;/p&gt;
&lt;p&gt;The measure essentially tells police to look the other way on adult psilocybin use.&lt;/p&gt;
&lt;p&gt;“We’ll see what the final numbers are, but we’re a little stunned to see a 7,000-vote flip overnight on that,” said Jeff Hunt, director of the Centennial Institute at Colorado Christian University, who &lt;a href=&quot;https://twitter.com/jeffhunt/status/1126259864978612225&quot;&gt;initially questioned on Twitter&lt;/a&gt; whether vote-tampering was involved. “We’ll continue to fight the growing drug culture. Denver’s becoming the illicit drug capital of the world. The larger issue here is not good for our city.”&lt;/p&gt;

&lt;p&gt;He added: “Marijuana has brought more problems than it’s solved to our city and our state, and if we continue to go down this track, we’re going to continue to see Colorado get in worse and worse shape.”&lt;/p&gt;
&lt;p&gt;Supporters extolled emerging research showing potential health benefits with psychedelic mushrooms. The measure likely was put over the top by younger voters, who tend to cast their ballots closer to or on Election Day, even though all registered voters receive their ballots in the mail about three weeks earlier.&lt;/p&gt;
&lt;p&gt;Last fall, the U.S. Food and Drug Administration &lt;a href=&quot;https://newatlas.com/psilocybin-magic-mushrooms-depression-fda-breakthrough-therapy/56928/&quot;&gt;granted psilocybin “breakthrough therapy” designation&lt;/a&gt; for its potential to help with treatment-resistant depression, a status that &lt;a href=&quot;https://reason.com/2018/10/25/fda-recognizes-psilocybin-as-breakthroug/&quot;&gt;speeds up the development and review process&lt;/a&gt; for a medicine containing the substance.&lt;/p&gt;
&lt;h3&gt;What Initiative 301 tells police to do&lt;/h3&gt;
&lt;p&gt;As written, I-301 &lt;a href=&quot;https://www.denverpost.com/2019/02/19/psychedelic-mushrooms-denver/&quot;&gt;directs police via ordinance&lt;/a&gt; to treat enforcement of laws against possession of psilocybin mushrooms as their lowest priority.&lt;/p&gt;
&lt;img class=&quot; lazyautosizes lazyload&quot; src=&quot;https://i0.wp.com/www.denverpost.com/wp-content/uploads/2019/02/magicmushrooms-021319-cha-050.jpg?fit=620%2C9999px&amp;amp;ssl=1&quot; alt=&quot;Kevin Matthews is leading the decriminalization ...&quot; width=&quot;8014&quot; data-sizes=&quot;auto&quot; data-src=&quot;https://i0.wp.com/www.denverpost.com/wp-content/uploads/2019/02/magicmushrooms-021319-cha-050.jpg?fit=620%2C9999px&amp;amp;ssl=1&quot; data-srcset=&quot;https://i0.wp.com/www.denverpost.com/wp-content/uploads/2019/02/magicmushrooms-021319-cha-050.jpg?fit=620%2C9999px&amp;amp;ssl=1 620w,https://i0.wp.com/www.denverpost.com/wp-content/uploads/2019/02/magicmushrooms-021319-cha-050.jpg?fit=310%2C9999px&amp;amp;ssl=1 310w&quot;/&gt;&lt;p&gt;Hyoung Chang, The Denver Post&lt;/p&gt;
Kevin Matthews led the decriminalization campaign for magic mushrooms in Denver. He was photographed on Feb. 12, 2019.
&lt;p&gt;It’s similar to decriminalization measures approved by Denver voters for marijuana years before Colorado’s Amendment 64 won statewide approval.&lt;/p&gt;
&lt;p&gt;“Our victory here is a clear signal to the rest of the country that we’re ready for a broader conversation around psilocybin and its potential benefits,” said Matthews, a 33-year-old stay-at-home dad.&lt;/p&gt;
&lt;p&gt;Psychedelic mushrooms still would remain illegal to buy, sell or possess, with the latter crime a felony that carries a potential punishment of up to a year in prison and a fine. But Initiative 301 backers hope to lower the risk users face of getting caught with mushrooms.&lt;/p&gt;
&lt;p&gt;Past marijuana efforts are instructive, though. Denver voters signed off on decriminalization measures in 2005 and 2007, but that didn’t stop police from enforcing the law — though drug law-liberalization advocates say the public discussion prompted by the ballot initiatives helped pave the way for statewide legalization in 2012.&lt;/p&gt;
&lt;p&gt;“I’ll say this: We’re looking forward to creating a positive relationship with city officials,” Matthews said. “We have the resources ready to make sure the Justice Department, the (district attorney’s) office and the Denver Police Department have the education they need to implement this in a way that’s fair.”&lt;/p&gt;
&lt;p&gt;Initiative 301 requires the city to create a panel to monitor the effects and implementation of the ordinance.&lt;/p&gt;
&lt;h3&gt;Tide turned Wednesday&lt;/h3&gt;
&lt;p&gt;Some national media outlets as well as the Centennial Institute wrongly called I-301 a bust late Tuesday, based on the early results.&lt;/p&gt;
&lt;aside class=&quot;related right&quot;&gt;
&lt;/aside&gt;&lt;p&gt;But the gap tightened throughout the night. By 1 a.m. Wednesday, when Denver Elections put out its last release before pausing counting for the night, the measure still was losing by 3.4 percentage points.&lt;/p&gt;
&lt;p&gt;It overcame that margin in the next — and final — round of results shortly after 4 p.m.&lt;/p&gt;


</description>
<pubDate>Wed, 08 May 2019 22:49:01 +0000</pubDate>
<dc:creator>tosh</dc:creator>
<og:type>article</og:type>
<og:title>Denver first in U.S. to decriminalize psychedelic mushrooms</og:title>
<og:url>https://www.denverpost.com/2019/05/08/denver-psychedelic-magic-mushroom/</og:url>
<og:description>Denver is poised to become the first city in the nation to effectively decriminalize psychedelic mushrooms after final ballot-counting flipped Initiative 301’s margin in favor of narrow passa…</og:description>
<og:image>https://www.denverpost.com/wp-content/uploads/2019/02/AP_070802036452.jpg?w=1024&amp;h=690</og:image>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.denverpost.com/2019/05/08/denver-psychedelic-magic-mushroom/</dc:identifier>
</item>
<item>
<title>“Users want control” is a shoulder shrug</title>
<link>https://www.ianbicking.org/blog/2019/04/users-want-control-is-a-shrug.html</link>
<guid isPermaLink="true" >https://www.ianbicking.org/blog/2019/04/users-want-control-is-a-shrug.html</guid>
<description>&lt;p&gt;Making the claim “users want control” is the same as saying you don’t know what users want, you don’t know what is good, and you don’t know what their goals are.&lt;/p&gt;
&lt;p&gt;I first started thinking about this during the debate over what would become the &lt;a href=&quot;https://en.wikipedia.org/wiki/Patient_Protection_and_Affordable_Care_Act&quot;&gt;&lt;span class=&quot;caps&quot;&gt;ACA&lt;/span&gt;&lt;/a&gt;. The rhetoric was filled with this idea that people want choice in their medical care: &lt;em&gt;people want control&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;No! People want &lt;strong&gt;good health care&lt;/strong&gt;. If they don’t trust systems to provide them good health care, if they don’t trust their providers to understand their priorities, then &lt;em&gt;choice&lt;/em&gt; is the fallback: it’s how you work the system when the system isn’t working for you. And it sucks! Here you are, in the middle of some health issue, with treatments and symptoms and the rest of your life duties, and now you have to become a researcher on top of it? But the politicians and the pundits could not stop talking about control.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Control&lt;/em&gt; is what you need when you want something and it won’t happen on its own. But (usually) it’s not control you want, it’s just a means.&lt;/p&gt;
&lt;p&gt;So when we say &lt;em&gt;users want control over X&lt;/em&gt; – their privacy, their security, their data, their history – we are first acknowledging that current systems act against users, but we aren’t proposing any real solution. We’re avoiding even talking about the problems.&lt;/p&gt;
&lt;p&gt;For instance, we say “users want control over their privacy,” but what people really want is some subset of:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;To avoid embarrassment&lt;/li&gt;
&lt;li&gt;To avoid persecution&lt;/li&gt;
&lt;li&gt;… sometimes for doing illegal and wrong things&lt;/li&gt;
&lt;li&gt;To keep from having the creeping sensation they left something sitting out that they didn’t want to&lt;/li&gt;
&lt;li&gt;They want to make some political statement against surveillance&lt;/li&gt;
&lt;li&gt;They want to keep things from the prying eyes of those close to them&lt;/li&gt;
&lt;li&gt;They want to avoid being manipulated by bad-faith messaging&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;There’s no easy answers, not everyone holds all these desires, but these are concrete ways of thinking about what people want. They don’t all point in the same direction. (And then consider the complex implications of someone else talking about you!)&lt;/p&gt;
&lt;p&gt;There are some cases when a person really does want control. If the person wants to determine their own path, if &lt;strong&gt;having choice is itself a personal goal&lt;/strong&gt;, then you need control. That’s a goal about &lt;em&gt;who you are&lt;/em&gt; not just &lt;em&gt;what you get&lt;/em&gt;. It’s worth identifying moments when this is important. But if a person does not pay attention to something then that person probably does not identify with the topic and is not seeking control over it. “Privacy advocates” pay attention to privacy, and attain a sense of identity from the very act of being mindful of their own privacy. Everyone else does not.&lt;/p&gt;
&lt;p&gt;Let’s think about another example: &lt;em&gt;users want control over their data&lt;/em&gt;. What are some things they want?&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;They don’t want to lose their data&lt;/li&gt;
&lt;li&gt;They don’t want their data used to hold them hostage (e.g., to a subscription service)&lt;/li&gt;
&lt;li&gt;They don’t want to delete data and have it still reappear&lt;/li&gt;
&lt;li&gt;They want to use their data however they want, but more likely they want their data available for use by some other service or tool&lt;/li&gt;
&lt;li&gt;They feel it’s unfair if their data is used for commercial purposes without any compensation&lt;/li&gt;
&lt;li&gt;They are offended if their data is used to manipulate themselves or others&lt;/li&gt;
&lt;li&gt;They don’t want their data used against them in manipulative ways&lt;/li&gt;
&lt;li&gt;They want to have shared ownership of data with other people&lt;/li&gt;
&lt;li&gt;They want to prevent unauthorized or malicious access to their data&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;Again these motivations are often against each other. A person wants to be able to copy their data between services, but also delete their data permanently and completely. People don’t want to lose their data, but having personal control over your data is a great way to lose it, or even to lose control over it. The professionalization and centralization of data management by services has mostly improved access control and reliability.&lt;/p&gt;
&lt;p&gt;When we simply say &lt;em&gt;users want control&lt;/em&gt; it’s giving up on understanding people’s specific desires. Still it’s not exactly wrong: it’s reasonable to assume people will use control to achieve their desires. But if, as technologists, we can’t map functionality to desire, it’s a bit of a stretch to imagine everyone else will figure it out on the fly.&lt;/p&gt;
</description>
<pubDate>Wed, 08 May 2019 21:02:31 +0000</pubDate>
<dc:creator>collinmanderson</dc:creator>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.ianbicking.org/blog/2019/04/users-want-control-is-a-shrug.html</dc:identifier>
</item>
<item>
<title>Show HN: 2D Graphics on Modern GPU</title>
<link>https://raphlinus.github.io/rust/graphics/gpu/2019/05/08/modern-2d.html</link>
<guid isPermaLink="true" >https://raphlinus.github.io/rust/graphics/gpu/2019/05/08/modern-2d.html</guid>
<description>&lt;p&gt;Is the traditional 2D imaging model nearing the end of its usefulness, or does it have a shiny future in the “modern graphics” world? I spent a week on a research retreat in a &lt;a href=&quot;https://www.stonesthrowfarmca.com/&quot;&gt;cottage in the woods&lt;/a&gt; to answer this question, as it shapes the future of UI toolkits. Performant UI &lt;em&gt;must&lt;/em&gt; use GPU effectively, and it’s increasingly common to write UI directly in terms of GPU rendering, without a 2D graphics API as in the intermediate layer. Is that the future, or perhaps a mistake?&lt;/p&gt;
&lt;p&gt;I have found that, if you can depend on modern compute capabilities, it seems quite viable to implement 2D rendering directly on GPU, with very promising quality and performance. The prototype I built strongly resembles a software renderer, just running on an outsized multicore GPU with wide SIMD vectors, much more so than rasterization-based pipelines.&lt;/p&gt;
&lt;p&gt;Writing a 2D renderer is a fairly ambitious project, doubly so to make it run efficiently on GPU. I deliberately reduced the scope of the project in a number of ways to make it viable. Most importantly, I targeted &lt;em&gt;only&lt;/em&gt; Metal 2.1, which is only a year old and only at &lt;a href=&quot;http://gs.statcounter.com/macos-version-market-share/desktop/worldwide&quot;&gt;42.5% share&lt;/a&gt; among worldwide macOS users. Thus, I am targeting the near future of GPU and ignoring the past. My faithful readers will no doubt be curious how much of this work can be adapted to older GPUs, but I believe that’s a much more complex question, and one I deliberately did not address. (Other work like &lt;a href=&quot;https://github.com/pcwalton/pathfinder&quot;&gt;PathFinder&lt;/a&gt; is more appropriate.)&lt;/p&gt;
&lt;p&gt;That said, I think the capabilities of Metal 2.1 are fairly mainstream and more so in coming years. From my perspective, it finally lets us program a GPU as if it were a big SIMD computer, which is basically what it’s been under the hood for a long time. Looking at newer features in, for example, &lt;a href=&quot;https://developer.nvidia.com/cuda-toolkit/whatsnew&quot;&gt;CUDA 10&lt;/a&gt;, I don’t see anything that would profoundly change the way I would approach this problem. I believe this is a very attractive target for research and practice in efficient GPU implementation of classical algorithms.&lt;/p&gt;
&lt;p&gt;It’s not surprising that 2D graphics can be efficiently implemented on GPU. The excellent 2014 &lt;a href=&quot;http://w3.impa.br/~diego/projects/GanEtAl14/&quot;&gt;Massively-Parallel Vector Graphics&lt;/a&gt; was a major inspiration to this work, and there have been follow-ups such as &lt;a href=&quot;http://kunzhou.net/zjugaps/pathrendering/&quot;&gt;Li 2016&lt;/a&gt; that promise even more performance. But both of these papers seemed very complex and focused narrowly on path rendering.&lt;/p&gt;
&lt;p&gt;I had great fun implementing my prototype and learned a lot. Along the way I kept a &lt;a href=&quot;https://docs.google.com/document/d/1LILagXyJgYtlm6y83x1Mc2VoNfOcvW_ZiCldZbs4yO8/edit?usp=sharing&quot;&gt;notes document&lt;/a&gt; that recounts some of my struggles and touches on some deeper topics that I will only briefly touch on in this blog post. The &lt;a href=&quot;https://github.com/linebender/piet-metal&quot;&gt;code&lt;/a&gt; is available and could be fun to play with or look at.&lt;/p&gt;
&lt;p&gt;I’ll stress again that this is a research prototype, not a finished product. The most promising use case for the work is likely CAD tools, where there might be quite complex scenes and it’s not necessarily practical to organize the UI drawing around GPU primitives (as opposed to 3D games, for example).&lt;/p&gt;
&lt;h2 id=&quot;the-architecture&quot;&gt;The architecture&lt;/h2&gt;
&lt;p&gt;Rendering starts with a “scene graph,” which is an on-GPU serialization of 2D drawing operations. It has a tree structure, in that operations like clipping are represented as a node with children; in the case of clipping, one child for the clip mask and another for the contents being clipped. It also has a graph structure, in that multiple instances can be shared by reference (with appropriate transform nodes to change their position). (Note: I didn’t get around to implementing much of the graph structure, but the prototype is designed to accommodate it without much trouble. I’m describing it anyway because it’s important to the motivation).&lt;/p&gt;
&lt;p&gt;The imaging model allows per-pixel operations only; operations like blur are purposefully excluded. Thus, a simplistic approach to parallel rendering would be for each pixel in the target framebuffer to traverse the scene graph, applying the computation at each node (each of which can be seen as a small functional program), and finally writing the pixel color computed at the root node. That approach is of course quite inefficient, but forms the basis of what the code actually does.&lt;/p&gt;
&lt;p&gt;To achieve performance, the code divides the target framebuffer into fixed size &lt;em&gt;tiles,&lt;/em&gt; currently 16x16 pixels each. There are two passes, a &lt;em&gt;tiling pass&lt;/em&gt; that creates a command list for each tile, and a &lt;em&gt;rendering pass&lt;/em&gt; that consumes the command list, evaluating all 256 pixels of the tile in parallel, each pixel sequentially evaluating the commands for the tile.&lt;/p&gt;
&lt;p&gt;Note that the approach to tiling is similar to &lt;a href=&quot;https://github.com/pcwalton/pathfinder&quot;&gt;PathFinder&lt;/a&gt;, but with important differences in the details. PathFinder renders intermediate alpha masks to a mask texture buffer, requiring a write and a read of global device memory, but I do all the blending in local memory in the rendering shader, as in &lt;a href=&quot;http://w3.impa.br/~diego/projects/GanEtAl14/&quot;&gt;MPVG&lt;/a&gt;. Minimizing global memory traffic is a major shared theme.&lt;/p&gt;
&lt;p&gt;A 16x16 tile should be close to the sweet spot. It results in 128x96 (12k total) tiles for a typical 2048x1536 window. It’s not a huge amount of work to generate the tiles, but with fewer tiles it would be harder to exploit parallelism in the tiling phase. Similarly, if graphic elements are much smaller than the tile size, there would be wasted work during rendering, as (for the most part) the entire tile needs to be rendered for any element that touches the tile. But again, 16x16 is a good size for a threadgroup dispatch, to exploit parallelism within the tile, and the savings from the leftover parts of a tile would be offset by per-tile overhead as tiles get smaller. It’s always possible to tune such things, but it’s not reasonable to expect any big wins. (I will note, though, that &lt;a href=&quot;http://w3.impa.br/~diego/projects/GanEtAl14/&quot;&gt;MPVG&lt;/a&gt; uses a quadtree structure, which basically amounts to adapting tile size to the workload. There are potential savings, but I also think it adds a lot to their overall complexity.)&lt;/p&gt;
&lt;p&gt;The rendering kernel (similar to a fragment shader) is fairly straightforward - it’s basically just computing signed area coverage for fills, distance fields for strokes, texture sampling for images and pre-rendered glyphs, and blends for clipping and compositing. The functional program represented by the scene graph is flattened into a linear sequence of operations, filtered of course to only those elements that touch the tile. For blend groups, nesting in the scene graph is represented by push/pop operations, with an explicit, local stack. (Again disclosure: I didn’t get too far into actually implementing blend groups, but it should be easy to see how they’d work).&lt;/p&gt;
&lt;p&gt;Thus, most of the interesting parts are in tiling. That’s all about efficiently traversing the scene graph, quickly skipping over parts of the graph that don’t touch the tile being generated.&lt;/p&gt;
&lt;p&gt;Similar to the simplistic rendering strategy above, a simple approach to tile generation would be to have a thread per tile (~12k threads), each of which sequentially traverses the scene graph. That’s a lot less work than doing a per-pixel traversal, but is still not great. As I’ll describe in the next section, the key to performance is a good serialization format for the scene graph, and SIMD techniques for extracting more parallelism from the traversal. The basic structure is there, though; the traversal of the scene graph and generation of tiles is at heart sequential, not relying on tricky GPU-compute techniques such as sorting.&lt;/p&gt;
&lt;h2 id=&quot;serialization&quot;&gt;Serialization&lt;/h2&gt;
&lt;p&gt;It’s often said that GPU is bad at data structures, but I’d turn that around. Most, but not all, data structures are bad at GPU. An extreme example is a linked list, which is still considered reasonable on CPU, and is the backbone of many popular data structures. Not only does it force sequential access, but it also doesn’t hide the latency of global memory access, which can be as high as 1029 cycles on a modern GPU such as &lt;a href=&quot;https://arxiv.org/pdf/1804.06826.pdf&quot;&gt;Volta&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Well known to game developers, what &lt;em&gt;is&lt;/em&gt; efficient on GPU is a structure-of-arrays approach. In particular, the tiling phase spends a lot of time looking at bounding boxes, to decide what belongs in each tile. Each group node in the graph has an array of bounding boxes of its children, 8 bytes each, and a separate array for the child contents. The core of the tiling pass is consuming those bounding box arrays, only dropping down to traverse the child when there’s an intersection.&lt;/p&gt;
&lt;p&gt;Other than that, the serialization format is not that exotic, broadly similar to &lt;a href=&quot;http://google.github.io/flatbuffers/&quot;&gt;FlatBuffers&lt;/a&gt; or &lt;a href=&quot;https://capnproto.org/&quot;&gt;Cap’n Proto&lt;/a&gt;. As a digression, I find it amusing that the word for packing a data structure into a byte buffer is “serialization” even when it’s designed to be accessed in parallel. Maybe we should come up with a better term, as “parallel-friendly serialization” is an oxymoron.&lt;/p&gt;
&lt;p&gt;While I mostly focused on parallel read access, I’m also intrigued by the possibility of &lt;em&gt;generating&lt;/em&gt; the scene graph in parallel, which obviously means doing allocations in a multithread-friendly way. Nical has a good &lt;a href=&quot;https://nical.github.io/posts/rust-2d-graphics-02.html&quot;&gt;blog post&lt;/a&gt; on some of the issues.&lt;/p&gt;
&lt;h2 id=&quot;exploiting-simd-for-bounding-box-culling&quot;&gt;Exploiting SIMD for bounding box culling&lt;/h2&gt;
&lt;p&gt;Now we get to the heart of the algorithm: going through an array of bounding boxes, looking for those that intersect a subset of tiles.&lt;/p&gt;
&lt;p&gt;The core computational model provided by shader languages is an independent thread per tiny grain of work (vertex, fragment, etc.), and the compiler and hardware conspire mightily in support of that illusion. You’ll hear numbers like 2560 cores, and it’s very difficult to wrap one’s mind around that. For workloads typical of &lt;a href=&quot;https://www.shadertoy.com/&quot;&gt;shadertoy&lt;/a&gt;, you don’t have to think too much about it, it magically gets through an impressive amount of computation per pixel.&lt;/p&gt;
&lt;p&gt;The reality is very different. It’s also useful to think of a GPU as a SIMD computer with dozens of cores, each of which has a SIMD width of hundreds of bits. If you write code optimized for, say, a 24 core computer with 512 bit SIMD, or 12 cores x 1024 bits wide, that’s likely to run well on an Intel Iris 640. That’s not actually what it is, but the details are shrouded in mystery, so I tell myself these simplified stories to keep myself comfortable. Note that these numbers aren’t that different than a high end desktop or server chip. (Also see the &lt;a href=&quot;https://docs.google.com/document/d/1LILagXyJgYtlm6y83x1Mc2VoNfOcvW_ZiCldZbs4yO8/edit?usp=sharing&quot;&gt;notes doc&lt;/a&gt; for why I have two different numbers here, kind of a fun story that kept me up a bit one night)&lt;/p&gt;
&lt;p&gt;In keeping with the 3D graphics tradition of clear and consistent naming, the SIMD concept is called SIMD groups on Metal, warps on Nvidia, wavefronts on AMD, and subgroups on Vulkan. (But note that there is an important distinction between pure SIMD and the “SIMT” concept in newer Nvidia models, see this presentation on &lt;a href=&quot;http://www.irisa.fr/alf/downloads/collange/talks/collange_warp_synchronous_gpu17.pdf&quot;&gt;cooperative groups&lt;/a&gt; for more detail.)&lt;/p&gt;
&lt;p&gt;So for running the tiling kernel, instead of having a few hundred or a couple thousand independent threads traversing the bounding box array, there are actually a few dozen “SIMD groups”, each of which is, say, 16 wide. In the simple version of the code, all the ALU’s in a SIMD group load the same bounding box, test against it, and go to the next iteration of the loop. We want to do better.&lt;/p&gt;
&lt;p&gt;The current code gives the 16-wide SIMD group responsibility for a block of tiles (16 wide, 1 tall, in a typical threadgroup geometry). On an iteration of the loop, each ALU loads a &lt;em&gt;different&lt;/em&gt; bounding box, then tests for intersection against a 256x16 region of the target frame buffer. It then shares the result of that test with the other ALU’s in the SIMD group (using the &lt;code class=&quot;highlighter-rouge&quot;&gt;simd_ballot&lt;/code&gt; intrinsic). There’s another pass with finer grained checking, but in the common case where no bounding boxes intersect the 256x16 region, it can immediately go to the next iteration. This is literally a 16x increase in theoretical bandwidth for consuming the bounding boxes, and I see that borne out by measurement.&lt;/p&gt;
&lt;p&gt;In similar fashion, the SIMD approach crunches through the segments of filled and stroked paths, quickly sifting to assign them to the relevant tiles. Inside the tiler are a number of other optimizations; for example tiles in the interior of a filled path just get a constant color. (This logic is similar to &lt;a href=&quot;https://github.com/pcwalton/pathfinder&quot;&gt;PathFinder&lt;/a&gt; and was inspired by it).&lt;/p&gt;
&lt;p&gt;The performance is impressive. I haven’t done careful benchmarking yet, but the &lt;a href=&quot;https://commons.wikimedia.org/wiki/File:Ghostscript_Tiger.svg&quot;&gt;Ghostscript tiger&lt;/a&gt;, the standard benchmark of 2D graphics renders in a 2048x1536 window in 2.8ms of GPU time on Intel Iris 640 integrated graphics. (A fun fact, this is a 500x speedup over results I got &lt;a href=&quot;https://levien.com/svg/&quot;&gt;20 years ago&lt;/a&gt;). More careful empirical evaluation is needed, especially as methodology of GPU performance can be quite tricky. Also, there are a bunch more things that can be done to improve performance further.&lt;/p&gt;
&lt;p&gt;Basically, I have confidence that it will render any reasonable UI scene, up to a high level of complexity, smoothly at 60 frames per second. It should be especially nice for data visualization, CAD, and of course tools for graphic artists. An especially nice feature is that the GPU does basically all the heavy lifting, freeing up the CPU for application logic.&lt;/p&gt;
&lt;h2 id=&quot;imaging-model&quot;&gt;Imaging model&lt;/h2&gt;
&lt;p&gt;The prototype mostly does just does fills and strokes of vector paths, but the &lt;em&gt;architecture&lt;/em&gt; of the renderer is designed to accommodate a full 2D graphics imaging model. Basically, it can handle any operation that works on a pixel at a time. Those include:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Soft masking and blending&lt;/li&gt;
&lt;li&gt;The PhotoShop &lt;a href=&quot;https://en.wikipedia.org/wiki/Blend_modes&quot;&gt;blend modes&lt;/a&gt; (also present in PDF and other imaging models)&lt;/li&gt;
&lt;li&gt;Tone mapping&lt;/li&gt;
&lt;li&gt;Color space conversions, including CMYK&lt;/li&gt;
&lt;li&gt;Halftone effects&lt;/li&gt;
&lt;li&gt;Gradients&lt;/li&gt;
&lt;li&gt;Images&lt;/li&gt;
&lt;li&gt;A wide variety of &lt;a href=&quot;https://www.ronja-tutorials.com/2018/11/10/2d-sdf-basics.html&quot;&gt;distance-field rendering techniques&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Probably the most important effect that is not included in this set is image-based blurring. That said, it is possible to get analytic or approximate blurring of many shapes, for example this &lt;a href=&quot;http://madebyevan.com/shaders/fast-rounded-rectangle-shadows/&quot;&gt;approximate blurred rounded rectangle&lt;/a&gt;, which can easily be adapted.&lt;/p&gt;
&lt;p&gt;I’m particularly interested in the rendering quality. All antialiasing and blending in the prototype is done in a &lt;a href=&quot;https://linebender.gitbook.io/linebender-graphics-wiki/&quot;&gt;linear sRGB&lt;/a&gt; colorspace, which makes for especially clear vector shapes without rope-like visual artifacts. In the notes document are more ideas about improving distance field rendering (hint: never use smoothstep).&lt;/p&gt;
&lt;p&gt;I’m mostly focused on making high resolution (4k and even higher) rendering fast, but an intriguing topic is to lavish compute power on making the finest possible images for lower resolution. One idea is to apply RGB &lt;a href=&quot;https://en.wikipedia.org/wiki/Subpixel_rendering&quot;&gt;subpixel rendering&lt;/a&gt; techniques (similar to ClearType), but for general vector graphics, not just fonts. There are more ideas (including a link to a code sketch) in the notes doc.&lt;/p&gt;
&lt;h2 id=&quot;implications&quot;&gt;Implications&lt;/h2&gt;
&lt;p&gt;The 2D rendering engine is a fairly central component of any graphics-intensive application. Its performance and quality characteristics can have profound implication for the rest of the system. As one example, if rendering is very slow, the system around it develops workarounds like rendering layers to textures and compositing them, which generally solves smooth scrolling but creates other problems. This work reopens the question: what should a system look like when rendering is really fast?&lt;/p&gt;
&lt;p&gt;One such related topic is immediate mode vs retained mode UI, a longstanding controversy, with passionate defenders on both sides. To be very clear, this renderer will work well with both. But I think there’s a special affinity for retained mode, as I hope to explain briefly.&lt;/p&gt;
&lt;p&gt;Very often in UI, the biggest challenge in performance is traversing the entire UI state in order to determine the new appearance. Immediate mode GUI solves this by writing the UI logic in a fast language, so that it reliably comes in under the time budget. But another approach is to minimize the work by only touching the parts of UI state that actually changed. In classical 2D, that often manifests as “damage regions,” so that only a subregion of the screen is repainted. That’s not very effective for scrolling or things like animation of layer opacity, and many people believe that damage regions are obsolete (I disagree, mostly for reasons of power consumption, but that’s a story for another day).&lt;/p&gt;
&lt;p&gt;A related approach is to retain parts of the scene graph (also commonly called “display list”), updating only those that have actually changed. Then the renderer redraws the screen based on the updated graph. Updated parameters can include translation (for scrolling) or alpha, so only a tiny amount of data need be uploaded to the GPU from frame to frame. &lt;a href=&quot;https://flutter.dev/&quot;&gt;Flutter&lt;/a&gt; is a good modern approach to this, and its “layers” are one of the keys to its performance.&lt;/p&gt;
&lt;p&gt;The piet-metal approach is designed to support this approach, by hosting the scene graph on the GPU, so that the process of painting a frame does &lt;em&gt;not&lt;/em&gt; rely on replaying the scene graph data structure resident on the CPU into GPU drawing commands. For simple scenes, this may not matter much, but for very complex visuals the difference might be significant.&lt;/p&gt;
&lt;h2 id=&quot;discussion&quot;&gt;Discussion&lt;/h2&gt;
&lt;p&gt;The week in the woods was extremely rewarding, and I recommend the format. Stones Throw Farm was a great setting for the research retreat.&lt;/p&gt;
&lt;p&gt;To be clear, what I have now is a research prototype. It only implements a subset of the imaging model, and only works on relatively recent GPU hardware. But I believe it has some very appealing properties, making it especially useful as the groundwork for next-generation UI.&lt;/p&gt;
&lt;p&gt;I believe the venerable 2D imaging model has lots of life left in it, as there is compelling evidence (not just my own work) that it can be implemented efficiently on GPU. I did the work largely to inform what to include and exclude in the &lt;a href=&quot;https://github.com/linebender/piet&quot;&gt;piet&lt;/a&gt; API - anything that &lt;em&gt;cannot&lt;/em&gt; efficiently be implemented on GPU is off the table. I plan to go forward on the existing piet/druid plans, confident that I can use existing platform-based drawing libraries like Direct2D for now, and that highly performant GPU-based implementations are at least possible.&lt;/p&gt;
&lt;p&gt;This work has benefitted from discussions with many, though of course the mistakes I’ve made are my own. In particular, thanks to Allan MacKinnon and his Spinel work for inspiring me to consider compute for rendering, Patrick Walton for many stimulating discussions, and Brian Merchant (our Google Summer of Code student on this project) for asking provoking questions.&lt;/p&gt;
</description>
<pubDate>Wed, 08 May 2019 20:47:07 +0000</pubDate>
<dc:creator>raphlinus</dc:creator>
<og:title>2D Graphics on Modern GPU</og:title>
<og:description>Is the traditional 2D imaging model nearing the end of its usefulness, or does it have a shiny future in the “modern graphics” world? I spent a week on a research retreat in a cottage in the woods to answer this question, as it shapes the future of UI toolkits. Performant UI must use GPU effectively, and it’s increasingly common to write UI directly in terms of GPU rendering, without a 2D graphics API as in the intermediate layer. Is that the future, or perhaps a mistake?</og:description>
<og:url>https://raphlinus.github.io/rust/graphics/gpu/2019/05/08/modern-2d.html</og:url>
<og:type>article</og:type>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://raphlinus.github.io/rust/graphics/gpu/2019/05/08/modern-2d.html</dc:identifier>
</item>
<item>
<title>We Need to Save What Made Linux and FOSS Possible</title>
<link>https://www.linuxjournal.com/content/we-need-save-what-made-linux-and-foss-possible</link>
<guid isPermaLink="true" >https://www.linuxjournal.com/content/we-need-save-what-made-linux-and-foss-possible</guid>
<description>&lt;p&gt;&lt;em&gt;If we take freedom and openness for granted, we'll lose both. That's already happening, and we need to fight back. The question is how.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;I am haunted by this passage in a letter we got from reader Alan E. Davis (the full text is in our Letters section):&lt;/p&gt;
&lt;blockquote readability=&quot;13&quot;&gt;
&lt;p&gt;...the real reason for this letter comes from my realization—in seeking online help—that the Linux Documentation Project is dead, and that the Linuxprinting.org project—now taken over by open printing, I think, is far from functioning well. Linux has been transformed into containers, and embedded systems. These and other such projects were the heart and soul of the Free Software movement, and I do not want for them to be gone!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is the kind of thing &lt;a href=&quot;https://en.wikipedia.org/wiki/Bradley_M._Kuhn&quot;&gt;Bradley Kuhn&lt;/a&gt; (of the &lt;a href=&quot;https://sfconservancy.org&quot;&gt;Software Freedom Conservancy&lt;/a&gt;) lamented in &lt;a href=&quot;https://www.youtube.com/watch?v=PLJjAupCMUg&amp;amp;index=10&amp;amp;list=PLsYAJYM22VA2NMo61bxIXowgXXHufwPm8&amp;amp;t=0s&quot;&gt;his talk&lt;/a&gt; at &lt;a href=&quot;https://freenode.live&quot;&gt;Freenode.live&lt;/a&gt; last year. So did &lt;a href=&quot;https://www.linuxjournal.com/users/kyle-rankin&quot;&gt;Kyle Rankin&lt;/a&gt; in his talk at the same event (&lt;a href=&quot;https://www.youtube.com/watch?v=17JowhH57kg&amp;amp;list=PLsYAJYM22VA2NMo61bxIXowgXXHufwPm8&amp;amp;index=15&quot;&gt;video&lt;/a&gt;, &lt;a href=&quot;https://kylerank.in/talks/misc/ljfoss.html&quot;&gt;slides&lt;/a&gt; and later, an &lt;em&gt;LJ&lt;/em&gt; &lt;a href=&quot;https://www.linuxjournal.com/content/what-linux-journals-resurrection-taught-me-about-foss-community&quot;&gt;article&lt;/a&gt;). In &lt;a href=&quot;https://www.youtube.com/watch?v=oOFuQLTVdZc&quot;&gt;an earlier conversation&lt;/a&gt; on the same stage (it was a helluva show), &lt;a href=&quot;https://webmink.com&quot;&gt;Simon Phipps&lt;/a&gt; (of the &lt;a href=&quot;https://opensource.org&quot;&gt;Open Source Initiative&lt;/a&gt;) and I had our own lamentations.&lt;/p&gt;
&lt;p&gt;We all said it has become too easy to take Linux and FOSS for granted, and the risks of doing that were dire. Some specifics:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;We collaborate inside proprietary environments&lt;/strong&gt;, such as Slack and Google Hangouts. Most of the chat and messaging systems in use today are also proprietary and closed. So are most video-conferencing systems and the codecs they use.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Many Linux and FOSS geeks today use Linux only professionally.&lt;/strong&gt; Most of their personal work is on proprietary Apple and Microsoft gear. Many use Windows or macOS boxes in presentations about FOSS topics.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;We're not modeling our values.&lt;/strong&gt; Bradley sourced this line from &lt;a href=&quot;https://mako.cc/writing/hill-free_tools.html&quot;&gt;Benjamin Mako Hill&lt;/a&gt;: &quot;The use of nonfree tools sends an unacceptable message...'Software freedom is important for you as users', developers seem to say, 'but not for us'. Such behavior undermines the basic effectiveness of the strong ethical commitment at the heart of the free software movement.&quot;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;We've allowed foundational ideas to collapse.&lt;/strong&gt; We've gone along with complicating the web, no longer respecting the simplicities in HTTP and HTML, which allowed the web to work in the first place. For example, we hardly still design for what Bradley calls &quot;progressive enhancement and graceful degradation&quot;. We see this failure in the web development world, which now depends almost utterly on JavaScript, most of which is proprietary and downloaded constantly on the fly to run in browsers.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;We are also forgetting (or perhaps never learned) how a reciprocal license, such as the GPL, can keep a project alive and a community together.&lt;/strong&gt; Simon blames SourceForge's failures on a decision to replace its original free (GPL-licensed) software base with a proprietary one. And now, even though we have Git, he says too many of us don't know the difference between Git and GitHub, or that GitHub runs proprietary JavaScript executed in our browsers.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;There were signs this was coming in 2002, when I wrote &lt;a href=&quot;https://www.linuxjournal.com/article/5912&quot;&gt;&quot;A Tale of Three Cultures&quot;&lt;/a&gt;. I'll unpack those a bit:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Geeks&lt;/strong&gt; at the time were busy inventing the world's basic software building materials. They operated in a culture that valued freedom, openness and maximized usefulness to everybody and everything. They also had a strong sense that they were winning the fight for freedom and openness in software development and product design. In geek slang, they said they were at &quot;&lt;a href=&quot;http://catb.org/jargon/html/G/GandhiCon.html&quot;&gt;GandhiCon&lt;/a&gt; 3&quot;. (The context is a Mohandas Gandhi one-liner: &quot;First they ignore you. Then they laugh at you. Then they fight you. Then you win.&quot;)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hollywood&lt;/strong&gt; as a label stood for all that is proprietary about business. I chose that label because the biggest public fight at the time was over copyright, and Hollywood was (and remains) the embodiment of copyright maximalism. &lt;a href=&quot;https://en.wikipedia.org/wiki/Lawrence_Lessig&quot;&gt;Larry Lessig&lt;/a&gt;, who with &lt;a href=&quot;https://en.wikipedia.org/wiki/Aaron_Swartz&quot;&gt;Aaron Swartz&lt;/a&gt; and others had recently minted &lt;a href=&quot;https://en.wikipedia.org/wiki/Creative_Commons&quot;&gt;Creative Commons&lt;/a&gt;, characterized the fight as Silicon Valley vs. Hollywood, and Northern vs. Southern California.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Embedded developers&lt;/strong&gt; were what I called &quot;purely technical...pre-Net, pre-UNIX and maybe even pre-cultural&quot;, with concerns that were &quot;utterly practical&quot;. In other words, &lt;em&gt;not&lt;/em&gt; about free software, open source or Linux—beyond its utilitarian value. I wrote that after attending the Embedded Systems Conference that Rich Lehrbaum wrote about for &lt;em&gt;Linux Journal&lt;/em&gt;, &lt;a href=&quot;https://www.linuxjournal.com/article/5969&quot;&gt;here&lt;/a&gt;. (That may be the only surviving record of the conference on the web.)&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;What I didn't see back then was that Hollywood andembedded would become pretty much the same thing: business as usual. That happened because it was too easy for too many developers to build proprietary and closed stuff, heads down, in utterly practical ways, usually for what amounted to embedded purposes, on top of Linux and FOSS foundations, with little respect for the virtues embodied in those foundations. And by now, we've built a lot of it. One might even argue that most of the Linux deployed in the world today is embedded inside proprietary and closed devices.&lt;/p&gt;
&lt;p&gt;So the question is &lt;em&gt;What should we do now?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;From my notes, here are some things Bradley, Kyle, Simon and others said at Freenode.live. It's not all verbatim, but close enough:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&quot;Having real-time chat is absolutely essential to the advancement of free software.&quot;&lt;/li&gt;
&lt;li&gt;&quot;We're the resistance now.&quot; &quot;We need to create mass movement.&quot;&lt;/li&gt;
&lt;li&gt;&quot;Volunteer to write free and open code, to participate in communities.&quot;&lt;/li&gt;
&lt;li&gt;&quot;If you didn't live the history, learn from those who did.&quot;&lt;/li&gt;
&lt;li&gt;&quot;If you did learn from history, teach those who need to know it. Respectfully.&quot;&lt;/li&gt;
&lt;li&gt;&quot;Be patient. Remember that the tortoise won not only because it was patient, but because it ignored insult, ridicule and dismissal.&quot;&lt;/li&gt;
&lt;li&gt;&quot;Model your values. Use free software and hardware.&quot;&lt;/li&gt;
&lt;li&gt;&quot;Remember always how 'the rights to copy, share, modify, redistribute and improve software' are fundamental rights that matter to people.&quot;&lt;/li&gt;
&lt;li&gt;&quot;Work to convince developers that their software freedom matters.&quot;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;That's all necessary, but not sufficient. We need something more. Something big.&lt;/p&gt;
&lt;p&gt;I suggest we pick a fight. Because fights raise emotions and have goals.&lt;/p&gt;
&lt;p&gt;I just ran a playoff between many different fights on many tabs in a browser. The winner—the last tab standing—is &lt;a href=&quot;https://www.nextplatform.com/2019/02/05/the-era-of-general-purpose-computers-is-ending&quot;&gt;&quot;The Era of General Purpose Computers Is Ending&quot;&lt;/a&gt;, by &lt;a href=&quot;https://www.nextplatform.com/author/michael&quot;&gt;Michael Feldman&lt;/a&gt; in &lt;a href=&quot;https://www.nextplatform.com&quot;&gt;The Next Platform website&lt;/a&gt;. It's a sad bookend to the history of a losing fight that &lt;a href=&quot;https://craphound.com&quot;&gt;Cory Doctorow&lt;/a&gt; forecast in 2011 with &lt;a href=&quot;https://boingboing.net/2012/01/10/lockdown.html&quot;&gt;&quot;Lockdown: the coming war on general-purpose computing&quot;&lt;/a&gt; and a year later in &lt;a href=&quot;https://boingboing.net/2012/08/23/civilwar.html&quot;&gt;&quot;The Coming Civil War over General Purpose Computing&quot;&lt;/a&gt;. Read all three.&lt;/p&gt;
&lt;p&gt;I chose general-purpose computing as the winning fight—the one most worth having—because we wouldn't have Linux, free software or open source today if there weren't general-purpose computers to develop and use them on. General-purpose computing is the goose that laid all our golden eggs. The fight is to keep it alive.&lt;/p&gt;
</description>
<pubDate>Wed, 08 May 2019 19:00:05 +0000</pubDate>
<dc:creator>brewski</dc:creator>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.linuxjournal.com/content/we-need-save-what-made-linux-and-foss-possible</dc:identifier>
</item>
<item>
<title>Alpine Linux Docker images have NULL for root password</title>
<link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-5021</link>
<guid isPermaLink="true" >https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-5021</guid>
<description>&lt;tr&gt;&lt;th colspan=&quot;2&quot;&gt;CVE-ID&lt;/th&gt;
&lt;/tr&gt;&lt;tr readability=&quot;3.232044198895&quot;&gt;&lt;td nowrap=&quot;nowrap&quot; align=&quot;center&quot; valign=&quot;top&quot;&gt;
&lt;h2&gt;CVE-2019-5021&lt;/h2&gt;
&lt;/td&gt;
&lt;td valign=&quot;top&quot; class=&quot;ltgreybackground&quot; readability=&quot;4.1676646706587&quot;&gt;

&lt;p&gt;• CVSS Severity Rating • Fix Information • Vulnerable Software Versions • SCAP Mappings • CPE Information&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;th colspan=&quot;2&quot;&gt;Description&lt;/th&gt;
&lt;/tr&gt;&lt;tr readability=&quot;8&quot;&gt;&lt;td colspan=&quot;2&quot;&gt;Versions of the Official Alpine Linux Docker images (since v3.3) contain a NULL password for the `root` user. This vulnerability appears to be the result of a regression introduced in December of 2015. Due to the nature of this issue, systems deployed using affected versions of the Alpine Linux container which utilize Linux PAM, or some other mechanism which uses the system shadow file as an authentication database, may accept a NULL password for the `root` user.&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;th colspan=&quot;2&quot;&gt;References&lt;/th&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2.7986577181208&quot;&gt;&lt;td colspan=&quot;2&quot; class=&quot;note&quot;&gt;&lt;strong&gt;Note:&lt;/strong&gt; &lt;a href=&quot;https://cve.mitre.org/data/refs/index.html&quot;&gt;References&lt;/a&gt; are provided for the convenience of the reader to help distinguish between vulnerabilities. The list is not intended to be complete.&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;0&quot;&gt;&lt;td colspan=&quot;2&quot;&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;th colspan=&quot;2&quot;&gt;Assigning CNA&lt;/th&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td colspan=&quot;2&quot;&gt;Talos&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;th colspan=&quot;2&quot;&gt;Date Entry Created&lt;/th&gt;
&lt;/tr&gt;&lt;tr readability=&quot;7.3795918367347&quot;&gt;&lt;td&gt;&lt;strong&gt;20190104&lt;/strong&gt;&lt;/td&gt;
&lt;td class=&quot;ltgreybackground&quot;&gt;Disclaimer: The &lt;a href=&quot;https://cve.mitre.org/about/faqs.html#date_entry_created_in_cve_entry&quot;&gt;entry creation date&lt;/a&gt; may reflect when the CVE ID was allocated or reserved, and does not necessarily indicate when this vulnerability was discovered, shared with the affected vendor, publicly disclosed, or updated in CVE.&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;th colspan=&quot;2&quot;&gt;Phase (Legacy)&lt;/th&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td colspan=&quot;2&quot;&gt;Assigned (20190104)&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;th colspan=&quot;2&quot;&gt;Votes (Legacy)&lt;/th&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td colspan=&quot;2&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;th colspan=&quot;2&quot;&gt;Comments (Legacy)&lt;/th&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td colspan=&quot;2&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;th colspan=&quot;2&quot;&gt;Proposed (Legacy)&lt;/th&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td colspan=&quot;2&quot;&gt;N/A&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;3.7264957264957&quot;&gt;&lt;td colspan=&quot;3&quot; class=&quot;note&quot;&gt;This is an entry on the &lt;a href=&quot;https://cve.mitre.org/cve/&quot;&gt;CVE List&lt;/a&gt;, which provides common identifiers for publicly known cybersecurity vulnerabilities.&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;1.6129032258065&quot;&gt;&lt;td colspan=&quot;2&quot; class=&quot;search&quot; readability=&quot;4.0322580645161&quot;&gt;


&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;1.3157894736842&quot;&gt;&lt;td colspan=&quot;2&quot; class=&quot;search&quot;&gt;&lt;span&gt;For More Information:&lt;/span&gt;  &lt;a href=&quot;mailto:cve@mitre.org&quot;&gt;cve@mitre.org&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;</description>
<pubDate>Wed, 08 May 2019 18:45:29 +0000</pubDate>
<dc:creator>alpb</dc:creator>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-5021</dc:identifier>
</item>
<item>
<title>Google Fights Back</title>
<link>https://stratechery.com/2019/google-fights-back/</link>
<guid isPermaLink="true" >https://stratechery.com/2019/google-fights-back/</guid>
<description>&lt;p&gt;For a company famed for its engineering culture, you wouldn’t expect a video at Google’s annual I/O developer conference to have such emotional resonance. And yet, just watch (I have included the context around the video in question, which starts at the 2:33 mark):&lt;/p&gt;

&lt;p&gt;“I liked that very much.”&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://stratechery.com/wp-content/uploads/2019/05/Screen-Shot-2019-05-08-at-9.45.21-PM.png&quot;&gt;&lt;img src=&quot;https://stratechery.com/wp-content/uploads/2019/05/Screen-Shot-2019-05-08-at-9.45.21-PM-1024x572.png&quot; alt=&quot;&amp;quot;I liked that very much&amp;quot;&quot; width=&quot;640&quot; height=&quot;358&quot; class=&quot;aligncenter size-large wp-image-4196&quot; srcset=&quot;https://stratechery.com/wp-content/uploads/2019/05/Screen-Shot-2019-05-08-at-9.45.21-PM-1024x572.png 1024w, https://stratechery.com/wp-content/uploads/2019/05/Screen-Shot-2019-05-08-at-9.45.21-PM-300x168.png 300w, https://stratechery.com/wp-content/uploads/2019/05/Screen-Shot-2019-05-08-at-9.45.21-PM-768x429.png 768w, https://stratechery.com/wp-content/uploads/2019/05/Screen-Shot-2019-05-08-at-9.45.21-PM-1128x630.png 1128w, https://stratechery.com/wp-content/uploads/2019/05/Screen-Shot-2019-05-08-at-9.45.21-PM.png 1300w&quot; sizes=&quot;(max-width: 640px) 100vw, 640px&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This was the most direct statement of what was a clear theme from Google’s entire keynote:&lt;br/&gt;“Technology, particularly Google’s technology, is a good thing, and we are going to remind you why you like it.”&lt;/p&gt;
&lt;h4&gt;Google’s Mission&lt;/h4&gt;
&lt;p&gt;As he opened &lt;a href=&quot;https://www.youtube.com/watch?v=lyRPyRKHO8M&amp;amp;feature=youtu.be&quot;&gt;the keynote&lt;/a&gt;, CEO Sundar Pichai, as he always does, repeated Google’s mission statements:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://stratechery.com/wp-content/uploads/2019/05/GoogleIO1.png&quot;&gt;&lt;img src=&quot;https://stratechery.com/wp-content/uploads/2019/05/GoogleIO1-1024x573.png&quot; alt=&quot;Google's Mission&quot; width=&quot;640&quot; height=&quot;358&quot; class=&quot;aligncenter size-large wp-image-4191&quot; srcset=&quot;https://stratechery.com/wp-content/uploads/2019/05/GoogleIO1-1024x573.png 1024w, https://stratechery.com/wp-content/uploads/2019/05/GoogleIO1-300x168.png 300w, https://stratechery.com/wp-content/uploads/2019/05/GoogleIO1-768x430.png 768w, https://stratechery.com/wp-content/uploads/2019/05/GoogleIO1-1125x630.png 1125w, https://stratechery.com/wp-content/uploads/2019/05/GoogleIO1.png 1300w&quot; sizes=&quot;(max-width: 640px) 100vw, 640px&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;It all begins with our mission to organize the world’s information and make it universally accessible and useful, and today, our mission feels as relevant as ever.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Pichai, though, quickly pivoted to something rather different than simply organizing and presenting information:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The way we approach it is constantly evolving. We are moving from a company that helps you find answers to a company that helps you get things done…We want our products to work harder for you in the context of your job, your home, and your life, and they all share a single goal: to be helpful, so we can be there for you in moments big and small over the course of your day.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In short, the mission statement may be the same, but what that means for Google and its products has shifted:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://stratechery.com/wp-content/uploads/2019/05/GoogleIO2.png&quot;&gt;&lt;img src=&quot;https://stratechery.com/wp-content/uploads/2019/05/GoogleIO2-1024x578.png&quot; alt=&quot;Google's goal&quot; width=&quot;640&quot; height=&quot;361&quot; class=&quot;aligncenter size-large wp-image-4192&quot; srcset=&quot;https://stratechery.com/wp-content/uploads/2019/05/GoogleIO2-1024x578.png 1024w, https://stratechery.com/wp-content/uploads/2019/05/GoogleIO2-300x169.png 300w, https://stratechery.com/wp-content/uploads/2019/05/GoogleIO2-768x434.png 768w, https://stratechery.com/wp-content/uploads/2019/05/GoogleIO2-1116x630.png 1116w, https://stratechery.com/wp-content/uploads/2019/05/GoogleIO2.png 1300w&quot; sizes=&quot;(max-width: 640px) 100vw, 640px&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Our goal is to build a more helpful Google for everyone. And when we say helpful, we mean giving you the tools to increase your knowledge, success, health, and happiness. We feel so privileged to be developing products for billions of users, and with that scale comes a deep sense of responsibility to create things that improve people’s lives. By focusing on these fundamental attributes, we can empower individuals and benefit society as a whole.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This set the stage for the rest of the keynote, including the video above: Google spent most of the keynote demonstrating — both with actual products, and whole bunch of vaporware — how Google could take a much more proactive role in its users’ lives in ways they ought appreciate.&lt;/p&gt;
&lt;h4&gt;Google’s Data Collection&lt;/h4&gt;
&lt;p&gt;To be sure, not all of the demos were of unassailably positive use cases like helping an illiterate person navigate the world; take, for example, this demonstration of Duplex for the Web:&lt;/p&gt;

&lt;p&gt;With the caveat that this is one of the pieces of vaporware I referenced earlier (Duplex, it should be noted, did finally launch several months after last year’s Google I/O), the demonstration is very impressive. What is worth noting, though, is the degree to which the demo relies on Google’s having access to your data; to that end, perhaps the most striking takeaway is that Google didn’t bother hiding this fact:&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://stratechery.com/wp-content/uploads/2019/05/GoogleIO4.png&quot;&gt;&lt;img src=&quot;https://stratechery.com/wp-content/uploads/2019/05/GoogleIO4-1024x577.png&quot; alt=&quot;Duplex on Web uses your data&quot; width=&quot;640&quot; height=&quot;361&quot; class=&quot;aligncenter size-large wp-image-4194&quot; srcset=&quot;https://stratechery.com/wp-content/uploads/2019/05/GoogleIO4-1024x577.png 1024w, https://stratechery.com/wp-content/uploads/2019/05/GoogleIO4-300x169.png 300w, https://stratechery.com/wp-content/uploads/2019/05/GoogleIO4-768x432.png 768w, https://stratechery.com/wp-content/uploads/2019/05/GoogleIO4-1119x630.png 1119w, https://stratechery.com/wp-content/uploads/2019/05/GoogleIO4.png 1300w&quot; sizes=&quot;(max-width: 640px) 100vw, 640px&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The implicit message was clear: “Yes, we have all of your data, but the fact we have all of your data is a good thing, because it allows us to make your life easier.”&lt;/p&gt;
&lt;p&gt;Notice that Aparna Chennapragada, the Vice President of Google’s AR, VR, and Vision-based Products whose video I opened with, makes the same point:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;What you are seeing here is text-to-speech, computer vision, the power of translate, and 20 years of language understanding from search, all coming together.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To put it more succinctly: “Yes, we collect a lot of data. But that data makes amazing things possible.”&lt;/p&gt;
&lt;h4&gt;Google’s Strategy Credits&lt;/h4&gt;
&lt;p&gt;There was one more thing Chennapragada said at the end of her presentation:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The power to read is the power to buy a train ticket, to shop in a store, to follow the news. It’s the power to get things done, so we want to make this feature accessible to as many people as possible.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is another feather in Google’s cap: it really does serve everyone in the way a company like Apple does not. Pichai made this point as well:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;So far, we have talked about building a more helpful Google. It is equally important to us it for everyone. “For everyone” is a core philosophy for us at Google. That’s why from the earliest days Search works the same whether you’re a professor at Stanford or a student in rural Indonesia. It’s why we build affordable laptops for classrooms everywhere. And it’s why we care about the experience on low-cost phones in countries where users are just starting to come on-line, with the same passion as we do with premium phones.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;What was unmentioned is that this is very much a &lt;a href=&quot;https://stratechery.com/2013/strategy-credit/&quot;&gt;Strategy Credit&lt;/a&gt;. Google spends billions of dollars on research and development and global-scaling infrastructure in order to deliver superior products to, first and foremost, users on premium phones (who have a huge amount of overlap with the set of customers most attractive to advertisers). That expenditure, though, is a fixed cost, while serving a marginal user is effectively free; it follows, then, that the best way to leverage those costs is to serve as many people as possible, even if the revenue from doing so is quite meager, at least for now.&lt;/p&gt;
&lt;p&gt;To be clear, to say that something is a Strategy Credit is not a bad thing: it is simply an observation that doing the “right thing” requires no trade-offs when it comes to a company’s core business model; I originally created the term to explain why Apple could commit to not collecting data in a way that a company like Google could not.&lt;/p&gt;
&lt;p&gt;Even so, it is striking how Google leaned into its core business model during the keynote: while Facebook likes to talk about connecting everyone, the company mostly tries to &lt;a href=&quot;https://stratechery.com/2019/facebooks-privacy-cake/&quot;&gt;have its privacy cake and eat it too&lt;/a&gt;, that is, talk a lot about privacy and major moves it claims it is making in that direction, while actually changing nothing about its core business (or acknowledging that those moves are for &lt;a href=&quot;https://stratechery.com/2019/microsoft-and-slack-follow-up-f8-facebook-versus-snapchat/&quot;&gt;competitive reasons&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Google, on the other hand, didn’t just admit it collects data, it highlighted how that collection makes Google more helpful. Google didn’t just admit that its goal is to be the Aggregator of information for every customer on earth, it bragged about that fact. And Google certainly didn’t engage in any self-effacing comments about how technology could be used for both good and bad: the entire keynote was arguing that technology is not only good, it is going to get better, and Google will lead the way.&lt;/p&gt;
&lt;h4&gt;Google’s Opportunities&lt;/h4&gt;
&lt;p&gt;There should be, to be sure, concerns about Google believing their own hype: many of &lt;a href=&quot;https://stratechery.com/2019/youtube-and-toxic-videos-youtubes-problematic-incentives-sins-of-omission-and-commission/&quot;&gt;the problems with YouTube&lt;/a&gt;, for example, stem from &lt;a href=&quot;https://stratechery.com/2017/the-pollyannish-assumption/&quot;&gt;The Pollyannish Assumption&lt;/a&gt; that treats technology as an inherent good instead of an &lt;a href=&quot;https://stratechery.com/2013/friction/&quot;&gt;amoral force&lt;/a&gt; that makes everything — both positive outcomes and negative ones — easier and more efficient to achieve.&lt;/p&gt;
&lt;p&gt;At the same time, from a purely strategic perspective, the positive message makes sense. Presuming that everything about technology is bad is just as mistaken as the opposite perspective, and the fact of the matter is that lots of people like Google products, and reminding them of that fact is to Google’s long-term benefit.&lt;/p&gt;
&lt;p&gt;Moreover, a world of assistants and machine-learning based products is very much to Google’s advantage: the argument to not simply tolerate Google’s collection of data, but to actually give them more, is less about some lame case about better-targeted ads but about making actually useful products better. The better-targeted ads are a Strategy Credit!&lt;/p&gt;
&lt;p&gt;It certainly appears that Google is pressing its advantage: after several years of including iPhones in Google I/O demos and/or alluding to products coming out on iOS — a welcome correction to &lt;a href=&quot;https://stratechery.com/2013/the-android-detour/&quot;&gt;The Android Detour&lt;/a&gt; — the only mention of iPhones was in a camera comparison to Google’s Pixel phone.&lt;a href=&quot;https://stratechery.com/2019/google-fights-back/#footnote_0_4189&quot; id=&quot;identifier_0_4189&quot; class=&quot;footnote-link footnote-identifier-link&quot; title=&quot;It was pretty lame that Google used an iPhone X instead of an iPhone XS for the comparison, though&quot;&gt;1&lt;/a&gt; Notably, Pixel’s headline feature — its camera — is very Google-like; Sabrina Ellis, Vice Product of Product Management, said while introducing the $399 Pixel 3a:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Delivering premium features with high performance on a phone at this price point has been a huge engineering challenge, and I’m really proud of what our team has been able to accomplish with Pixel 3a…What Pixel is really known for is its incredible camera. With software optimizations we found a way to bring our exclusive camera features and our industry-leading image quality into Pixel 3a. So photos look stunning in any light. What other smartphone cameras try to do with expensive hardware, we can deliver with software and AI, including high-end computational photography.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;While phones are certainly not a zero marginal cost item, the point is that Google applies overwhelming computer resources that can be leveraged through software instead of premium hardware, lowering the price of a phone, thus allowing it to be sold more broadly (better leveraging Google’s investment).&lt;/p&gt;
&lt;h4&gt;Google’s Challenges&lt;/h4&gt;
&lt;p&gt;At the same time, while many of today’s trends are in Google’s favor, the Pixel is a reminder that the company still has significant challenges: Google has struggled to sell Pixels not because it hasn’t invested in a quality phone, but because it hasn’t invested in marketing and distribution. To that end, what was even more notable than the Pixel 3a price point is the fact it will be available on more than one U.S. carrier for the first time; unfortunately for Google, that is only one country, and there remain the massive investments in marketing necessary to become a major smartphone player.&lt;/p&gt;
&lt;p&gt;More importantly, while Google Assistant continues to impress — putting everything on device promises a major breakthrough in speed, a major limiting factor for Assistants today — it is not at all clear what Google’s business model is. It is hard to imagine anything as profitable as search ads, which benefit not only from precise targeting — the user explicitly says what they want! — but also an auction format that leverages the user to pick winners, and incentivizes those winners to overpay for the chance of forming an ongoing relationship with that user.&lt;/p&gt;
&lt;p&gt;Indeed, this was both the promise and pitfall of Google’s overall presentation: organizing the world’s information was (relatively) easy when that information was widely available, and it was easy to monetize. Everything was aligned. The future, though, is a lot messier: getting information is more difficult, presenting that information is more challenging, and making money is very much an open question. Just because Google is better positioned in this race than anyone else doesn’t matter quite as much when the race is harder, even as the prize is less lucrative, while an increasing number of spectators are cheering for failure. Might as well bring cheerleaders!&lt;/p&gt;
&lt;ol class=&quot;footnotes&quot;&gt;&lt;li id=&quot;footnote_0_4189&quot; class=&quot;footnote&quot;&gt;It was pretty lame that Google used an iPhone X instead of an iPhone XS for the comparison, though [&lt;a href=&quot;https://stratechery.com/2019/google-fights-back/#identifier_0_4189&quot; class=&quot;footnote-link footnote-back-link&quot;&gt;↩&lt;/a&gt;]&lt;/li&gt;
&lt;/ol&gt;

</description>
<pubDate>Wed, 08 May 2019 15:57:35 +0000</pubDate>
<dc:creator>denzil_correa</dc:creator>
<og:type>article</og:type>
<og:title>Google Fights Back</og:title>
<og:url>https://stratechery.com/2019/google-fights-back/</og:url>
<og:description>At Google I/O, Google was the opposite of defensive: the company set out to make the case that its approach made for better products that makes people’s lives better</og:description>
<og:image>https://stratechery.com/wp-content/uploads/2019/05/Screen-Shot-2019-05-08-at-9.45.21-PM.png</og:image>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://stratechery.com/2019/google-fights-back/</dc:identifier>
</item>
<item>
<title>Estimating Number of Jupyter Notebooks on Github</title>
<link>https://kyso.io/KyleOS/nbestimate</link>
<guid isPermaLink="true" >https://kyso.io/KyleOS/nbestimate</guid>
<description>[unable to retrieve full-text content]
&lt;p&gt;Article URL: &lt;a href=&quot;https://kyso.io/KyleOS/nbestimate&quot;&gt;https://kyso.io/KyleOS/nbestimate&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Comments URL: &lt;a href=&quot;https://news.ycombinator.com/item?id=19859484&quot;&gt;https://news.ycombinator.com/item?id=19859484&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Points: 255&lt;/p&gt;
&lt;p&gt;# Comments: 122&lt;/p&gt;
</description>
<pubDate>Wed, 08 May 2019 15:04:06 +0000</pubDate>
<dc:creator>eoinmurray92</dc:creator>
<og:title>Estimating Number of Jupyter Notebooks on Github</og:title>
<og:image>https://d1kser01wv8mbw.cloudfront.net/390e08d1938fbff5ffc670d2cacae5c8_file-0N33S2ivMP-preview.jpg</og:image>
<og:description>Using fbprophet to predict the number of public Jupyter Notebooks on Github for the next 2 years.</og:description>
<og:url>https://kyso.io/KyleOS/nbestimate</og:url>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://kyso.io/KyleOS/nbestimate</dc:identifier>
</item>
<item>
<title>Britain passes one week without coal power for first time since 1882</title>
<link>https://www.theguardian.com/environment/2019/may/08/britain-passes-1-week-without-coal-power-for-first-time-since-1882</link>
<guid isPermaLink="true" >https://www.theguardian.com/environment/2019/may/08/britain-passes-1-week-without-coal-power-for-first-time-since-1882</guid>
<description>&lt;p&gt;Britain has gone a week without using coal to generate electricity for the first time since Queen Victoria was on the throne, in a landmark moment in the transition away from the heavily polluting fuel.&lt;/p&gt;
&lt;p&gt;The last coal generator came off the system at 1.24pm on 1 May, meaning the UK reached a week without coal at 1.24pm on Wednesday, according to the National Grid Electricity System Operator, which runs the network in England, Scotland and Wales.&lt;/p&gt;
&lt;p&gt;Coal-fired power stations still play a major part in the UK’s energy system as a backup during high demand but the increasing use of renewable energy sources such as wind power means it is required less. High international coal prices have also made the fuel a less attractive source of energy.&lt;/p&gt;
&lt;p&gt;The latest achievement – the first coal-free week since 1882, when a plant opened at Holborn in London – comes only two years after Britain’s &lt;a href=&quot;https://www.theguardian.com/environment/2017/apr/21/britain-set-for-first-coal-free-day-since-the-industrial-revolution&quot; data-link-name=&quot;in body link&quot; class=&quot;u-underline&quot;&gt;first coal-free day&lt;/a&gt; since the Industrial Revolution.&lt;/p&gt;
&lt;p&gt;Burning coal to generate electricity is thought to be incompatible with avoiding catastrophic climate change, and the UK government has committed to phasing out coal-fired power by 2025.&lt;/p&gt;
&lt;p&gt;Reductions in coal use in the UK have been responsible for halving electricity generation emissionssince 2013, according to the Committee on Climate Change (CCC), whose report last week called for the UK to pursue a &lt;a href=&quot;https://www.theguardian.com/environment/2019/may/02/do-it-now-uk-must-set-zero-carbon-target-for-2050-say-official-advisers&quot; data-link-name=&quot;in body link&quot; class=&quot;u-underline&quot;&gt;target of net-zero carbon emissions by 2050&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Fintan Slye, the director of National Grid ESO, said he believed Britain’s electricity system could be run with zero carbon as soon as 2025.&lt;/p&gt;
&lt;p&gt;He said: “Zero-carbon operation of the electricity system by 2025 means a fundamental change to how our system was designed to operate – integrating newer technologies right across the system – from large-scale offshore wind to domestic-scale solar panels to increased demand-side participation, using new smart digital systems to manage and control the system in real-time.”&lt;/p&gt;
&lt;p&gt;Greg Clark, the business secretary, hailed the achievement. He said the UK is “on a path to become the first major economy to legislate for net-zero emissions” in the wake of the report.&lt;/p&gt;
&lt;p&gt;However, the government has also faced criticism over some of its policies. The CCC’s chief executive, Chris Stark, said on Wednesday that proposals to impose higher VAT on solar panels and its failure to give its full backing to onshore wind generation would make meeting a net-zero emissions target more difficult.&lt;/p&gt;
&lt;p&gt;“We will need to throw everything at this challenge, including onshore wind and solar,” Stark told MPs on the business committee. “Anything that makes it harder is really not in line with the net-zero challenge overall.”&lt;/p&gt;


</description>
<pubDate>Wed, 08 May 2019 13:46:53 +0000</pubDate>
<dc:creator>andyjohnson0</dc:creator>
<og:url>http://www.theguardian.com/environment/2019/may/08/britain-passes-1-week-without-coal-power-for-first-time-since-1882</og:url>
<og:description>Landmark follows government pledge to phase out coal-fired electricity by 2025</og:description>
<og:image>https://i.guim.co.uk/img/media/33617f6dfd312c598e8ed693d573ad3607c7b63e/0_365_5472_3283/master/5472.jpg?width=1200&amp;height=630&amp;quality=85&amp;auto=format&amp;fit=crop&amp;overlay-align=bottom%2Cleft&amp;overlay-width=100p&amp;overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&amp;s=753ae17410d5f045d5a323d4edbf048d</og:image>
<og:type>article</og:type>
<og:title>Britain passes one week without coal power for first time since 1882</og:title>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.theguardian.com/environment/2019/may/08/britain-passes-1-week-without-coal-power-for-first-time-since-1882</dc:identifier>
</item>
</channel>
</rss>