<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=hnrss.org%2Fnewest%3Fpoints%3D200&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://hnrss.org/newest?points=200" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>Hacker News: Newest</title>
<link>https://news.ycombinator.com/newest</link>
<description>Hacker News RSS</description>
<item>
<title>Nvidia to Acquire Mellanox for $6.9B</title>
<link>https://nvidianews.nvidia.com/news/nvidia-to-acquire-mellanox-for-6-9-billion</link>
<guid isPermaLink="true" >https://nvidianews.nvidia.com/news/nvidia-to-acquire-mellanox-for-6-9-billion</guid>
<description>[unable to retrieve full-text content]
&lt;p&gt;Article URL: &lt;a href=&quot;https://nvidianews.nvidia.com/news/nvidia-to-acquire-mellanox-for-6-9-billion&quot;&gt;https://nvidianews.nvidia.com/news/nvidia-to-acquire-mellanox-for-6-9-billion&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Comments URL: &lt;a href=&quot;https://news.ycombinator.com/item?id=19358062&quot;&gt;https://news.ycombinator.com/item?id=19358062&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Points: 223&lt;/p&gt;
&lt;p&gt;# Comments: 117&lt;/p&gt;
</description>
<pubDate>Mon, 11 Mar 2019 11:15:05 +0000</pubDate>
<dc:creator>vostok4</dc:creator>
<og:title>IE 8 Below</og:title>
<og:type>website</og:type>
<og:url>http://nvidianews.nvidia.com/ie-8-below</og:url>
<og:description></og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://nvidianews.nvidia.com/ie-8-below</dc:identifier>
</item>
<item>
<title>Wipe and reinstall a running Linux system via SSH, without rebooting (2017)</title>
<link>https://github.com/marcan/takeover.sh</link>
<guid isPermaLink="true" >https://github.com/marcan/takeover.sh</guid>
<description>&lt;div class=&quot;Box-body p-6&quot;&gt;
&lt;article class=&quot;markdown-body entry-content&quot; itemprop=&quot;text&quot;&gt;
&lt;p&gt;A script to completely take over a running Linux system remotely, allowing you to log into an in-memory rescue environment, unmount the original root filesystem, and do anything you want, all without rebooting. Replace one distro with another without touching a physical console.&lt;/p&gt;
&lt;h2&gt;WARNING WARNING WARNING WARNING&lt;/h2&gt;
&lt;p&gt;This is experimental. Do not use this script if you don't understand exactly how it works. Do not use this script on any system you care about. Do not use this script on any system you expect to be up. Do not run this script unless you can afford to get physical access to fix a botched takeover. If anything goes wrong, your system will most likely panic.&lt;/p&gt;
&lt;p&gt;That said, this script will not (itself) make any permanent changes to your existing root filesystem (assuming you run it from a tmpfs), so as long as you can remotely reboot your box using an out-of-band mechanism, you &lt;em&gt;should&lt;/em&gt; be OK. But don't blame me if it eats your dog.&lt;/p&gt;
&lt;p&gt;This script does not have any provisions for exiting &lt;em&gt;out&lt;/em&gt; of the new environment back into something sane. You &lt;em&gt;will&lt;/em&gt; have to reboot when you're done. If you get anything wrong, your machine won't boot. Tough luck.&lt;/p&gt;
&lt;p&gt;This is not a guide for newbies. I'm deliberately not giving you commands you can copy and paste. If you can't figure out what to do exactly without handholding, this script is not for you.&lt;/p&gt;
&lt;h2&gt;Compatibility&lt;/h2&gt;
&lt;p&gt;This script is designed for init systems that support the &lt;code&gt;telinit u&lt;/code&gt; command to reload the init binary. This includes sysvinit and systemd. If your init system works a different way, you will have to adapt it, or this might not work at all. You're on your own here.&lt;/p&gt;
&lt;p&gt;You should always test this in a VM first. You can grab a tarball of your live root filesystem, extract it into a VM image, get your VM up and running (boot loader setup is left as an exercise for the reader), then try the process there and see if it works. Hint: &lt;code&gt;mount --bind / /mnt&lt;/code&gt; will get you a view of your root filesystem on &lt;code&gt;/mnt&lt;/code&gt; without any other filesystems that are mounted on top.&lt;/p&gt;
&lt;h2&gt;Usage&lt;/h2&gt;
&lt;p&gt;You need to decide on what rescue environment you want. I recommend &lt;a href=&quot;https://www.system-rescue-cd.org/&quot; rel=&quot;nofollow&quot;&gt;SystemRescueCD&lt;/a&gt;, which comes with many useful tools (you have to loopmount the ISO and then use &lt;code&gt;unsquashfs&lt;/code&gt;). Obviously, whatever you pick has to fit into free RAM, with room to spare. If your chosen rescue environment has &lt;code&gt;/lib/modules&lt;/code&gt;, you may want to get rid of it to save space, as its kernel modules won't be useful on the host kernel anyway.&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;Create a directory &lt;code&gt;/takeover&lt;/code&gt; on your target system and mount a tmpfs on it&lt;/li&gt;
&lt;li&gt;Extract your rescue environment there. Make sure it works by chrooting into it and running a few commands. Make sure you do not bork filesystem permissions. Exit the chroot.&lt;/li&gt;
&lt;li&gt;Grab a recent copy of &lt;code&gt;busybox&lt;/code&gt; (statically linked) and put it in &lt;code&gt;/takeover/busybox&lt;/code&gt;. You can find binaries &lt;a href=&quot;https://www.busybox.net/downloads/binaries/1.26.2-defconfig-multiarch/&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt;. Make sure it works by trying something like &lt;code&gt;/takeover/busybox sh&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Copy the contents of this repository into &lt;code&gt;/takeover&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Compile &lt;code&gt;fakeinit.c&lt;/code&gt;. It must be compiled such that it works inside the takeover environment. If your rescue environment has &lt;code&gt;gcc&lt;/code&gt;, you can just compile it inside the chroot: &lt;code&gt;chroot /takeover gcc /fakeinit.c -o /fakeinit&lt;/code&gt;. Otherwise, you might want to statically link it.&lt;/li&gt;
&lt;li&gt;Shut down as many services as you can on your host. &lt;code&gt;takeover.sh&lt;/code&gt; will by default set up an SSHd listening on port 80, though you may edit this in the script.&lt;/li&gt;
&lt;li&gt;Run &lt;code&gt;sh /takeover/takeover.sh&lt;/code&gt; and follow the prompts.&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;If everything worked, congratulations! You may now use your new SSH session to kill any remaining old daemons (&lt;code&gt;kill -9&lt;/code&gt; is recommended to make sure they don't try to do anything silly during shutdown), and then unmount all filesystems under &lt;code&gt;/old_root&lt;/code&gt;, including &lt;code&gt;/old_root&lt;/code&gt; itself. You may want to first copy &lt;code&gt;/old_root/lib/modules&lt;/code&gt; into your new tmpfs in case you need any old kernel modules.&lt;/p&gt;
&lt;p&gt;You are now running entirely from RAM and should be able to do as you please. Note that you may still have to clean up LVM volumes (&lt;code&gt;dmsetup&lt;/code&gt; is your friend) and similar before you can safely repartition your disk and install Gentoo Linux, which is of course the whole reason you're doing this crazy thing to begin with.&lt;/p&gt;
&lt;p&gt;When you're done, unmount all filesystems, &lt;code&gt;sync&lt;/code&gt;, then &lt;code&gt;reboot -f&lt;/code&gt; or &lt;code&gt;echo b &amp;gt; /proc/sysrq-trigger&lt;/code&gt; and cross your fingers.&lt;/p&gt;
&lt;h2&gt;Further reading&lt;/h2&gt;
&lt;p&gt;I've been pointed to &lt;a href=&quot;http://unix.stackexchange.com/questions/226872/how-to-shrink-root-filesystem-without-booting-a-livecd/227318#227318&quot; rel=&quot;nofollow&quot;&gt;this StackExchange answer&lt;/a&gt; which details how to manually perform a similar process, but using a subset of the existing root filesystem instead of a rescue filesystem. This allows you to keep (a new copy of) the existing init system running, as well as essential daemons, and then go back to the original root filesystem once you're done. This is a more useful version if, for example, you want to resize the original root filesystem or re-configure disk partitions, but not actually install a different distro, and you want to avoid rebooting at all.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;takeover.sh&lt;/code&gt; could be extended to support re-execing a new init once you're done. This could be used to switch to a &lt;em&gt;new&lt;/em&gt; distro entirely without rebooting, as long as you're happy using the old kernel. If you're interested, pull requests welcome :-).&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;
</description>
<pubDate>Mon, 11 Mar 2019 06:50:04 +0000</pubDate>
<dc:creator>1nvalid</dc:creator>
<og:image>https://avatars1.githubusercontent.com/u/98387?s=400&amp;v=4</og:image>
<og:type>object</og:type>
<og:title>marcan/takeover.sh</og:title>
<og:url>https://github.com/marcan/takeover.sh</og:url>
<og:description>Wipe and reinstall a running Linux system via SSH, without rebooting. You know you want to. - marcan/takeover.sh</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://github.com/marcan/takeover.sh</dc:identifier>
</item>
<item>
<title>How the Internet Travels Across Oceans</title>
<link>https://www.nytimes.com/interactive/2019/03/10/technology/internet-cables-oceans.html</link>
<guid isPermaLink="true" >https://www.nytimes.com/interactive/2019/03/10/technology/internet-cables-oceans.html</guid>
<description>&lt;div id=&quot;header-duplicate&quot;&gt;
&lt;div class=&quot;interactive-byline&quot; readability=&quot;9&quot;&gt;
&lt;p class=&quot;g-byline byline-dateline&quot;&gt;&lt;span class=&quot;byline last-byline&quot; itemprop=&quot;author creator&quot; itemscope=&quot;&quot; itemtype=&quot;http://schema.org/Person&quot;&gt;By ADAM SATARIANO&lt;br/&gt;Graphics by KARL RUSSELL, TROY GRIGGS and BLACKI MIGLIOZZI&lt;br/&gt;Photographs by CHANG W. LEE&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div data-preview-slug=&quot;2019-02-15-undersea-cables&quot; readability=&quot;104.7373358349&quot;&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;37&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;The internet consists of tiny bits of code that move around the world, traveling along wires as thin as a strand of hair strung across the ocean floor. The data zips from New York to Sydney, from Hong Kong to London, in the time it takes you to read this word.&lt;/p&gt;
&lt;/div&gt;

&lt;div class=&quot;g-item g-image&quot;&gt;
&lt;div class=&quot;g-item-image&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://static01.nyt.com/packages/flash/multimedia/ICONS/transparent.png&quot; class=&quot;g-freebird-lazy&quot; data-pattern=&quot;https://static01.nyt.com/newsgraphics/2019/02/15/undersea-cables/assets/images/cable-in-hand-{{size}}.jpg&quot; data-pattern-retina=&quot;https://static01.nyt.com/newsgraphics/2019/02/15/undersea-cables/assets/images/cable-in-hand-{{size}}_x2.jpg&quot; data-widths=&quot;[320,480,640,900,1050,1254,2000]&quot; data-ratio=&quot;0.7139457401237506&quot;/&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;36&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;Nearly 750,000 miles of cable already connect the continents to support our insatiable demand for communication and entertainment. Companies have typically pooled their resources to collaborate on undersea cable projects, like a freeway for them all to share.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;35&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;But now Google is going its own way, in a first-of-its-kind project connecting the United States to Chile, home to the company’s largest data center in Latin America.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;36&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;“People think that data is in the cloud, but it’s not,” said Jayne Stowell, who oversees construction of Google’s undersea cable projects. “It’s in the ocean.”&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;40&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;Getting it there is an exacting and time-intensive process. A 456-foot ship named Durable will eventually deliver the cable to sea. But first, the cable is assembled inside a sprawling factory a few hundred yards away, in Newington, N.H. The factory, owned by the company SubCom, is filled with specialized machinery used to maintain tension in the wire and encase it in protective skin.&lt;/p&gt;
&lt;/div&gt;

&lt;div class=&quot;g-item g-image&quot;&gt;
&lt;div class=&quot;g-item-image&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://static01.nyt.com/packages/flash/multimedia/ICONS/transparent.png&quot; class=&quot;g-freebird-lazy&quot; data-pattern=&quot;https://static01.nyt.com/newsgraphics/2019/02/15/undersea-cables/assets/images/spool-{{size}}.jpg&quot; data-pattern-retina=&quot;https://static01.nyt.com/newsgraphics/2019/02/15/undersea-cables/assets/images/spool-{{size}}_x2.jpg&quot; data-widths=&quot;[320,480,640,900,1050,1254,2000]&quot; data-ratio=&quot;0.6666666666666666&quot;/&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;37&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;The cables begin as a cluster of strands of tiny threads of glass fibers. Lasers propel data down the threads at nearly the speed of light, using fiber-optic technology. After reaching land and connecting with an existing network, the data needed to read an email or open a web page makes its way onto a person’s device.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;35&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;While most of us now largely experience the internet through Wi-Fi and phone data plans, those systems eventually link up with physical cables that swiftly carry the information across continents or across oceans.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;40&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;In the manufacturing process, the cables move through high-speed mills the size of jet engines, wrapping the wire in a copper casing that carries electricity across the line to keep the data moving. Depending on where the cable will be located, plastic, steel and tar are added later to help it withstand unpredictable ocean environments. When finished, the cables will end up the size of a thick garden hose.&lt;/p&gt;
&lt;/div&gt;

&lt;div class=&quot;g-item g-image&quot;&gt;
&lt;div class=&quot;g-item-image&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://static01.nyt.com/packages/flash/multimedia/ICONS/transparent.png&quot; class=&quot;g-freebird-lazy&quot; data-pattern=&quot;https://static01.nyt.com/newsgraphics/2019/02/15/undersea-cables/assets/images/men-at-track-{{size}}.jpg&quot; data-pattern-retina=&quot;https://static01.nyt.com/newsgraphics/2019/02/15/undersea-cables/assets/images/men-at-track-{{size}}_x2.jpg&quot; data-widths=&quot;[320,480,640,900,1050,1254,2000]&quot; data-ratio=&quot;0.6670023014959724&quot;/&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;37&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;A year of planning goes into charting a cable route that avoids underwater hazards, but the cables still have to withstand heavy currents, rock slides, earthquakes and interference from fishing trawlers. Each cable is expected to last up to 25 years.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;37&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;A conveyor that staff members call “the Cable Highway” moves the cable directly into Durable, docked in the Piscataqua River. The ship will carry over 4,000 miles of cable weighing about 3,500 metric tons when fully loaded.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;39&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;Inside the ship, workers spool the cable into cavernous tanks. One person walks the cable swiftly in a circle, as if laying out a massive garden hose, while others lie down to hold it in place to ensure it doesn’t snag or knot. Even with teams working around the clock, it takes about four weeks before the ship is loaded up with enough cable to hit the open sea.&lt;/p&gt;
&lt;/div&gt;

&lt;div class=&quot;g-item g-image&quot;&gt;
&lt;div class=&quot;g-item-image&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://static01.nyt.com/packages/flash/multimedia/ICONS/transparent.png&quot; class=&quot;g-freebird-lazy&quot; data-pattern=&quot;https://static01.nyt.com/newsgraphics/2019/02/15/undersea-cables/assets/images/lying-down-{{size}}.jpg&quot; data-pattern-retina=&quot;https://static01.nyt.com/newsgraphics/2019/02/15/undersea-cables/assets/images/lying-down-{{size}}_x2.jpg&quot; data-widths=&quot;[320,480,640,900,1050,1254,2000]&quot; data-ratio=&quot;0.75&quot;/&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;30.761904761905&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;The first trans-Atlantic cable was completed in 1858 to connect the United States and Britain. Queen Victoria commemorated the occasion with a message to President James Buchanan that took &lt;a href=&quot;https://archive.nytimes.com/www.nytimes.com/learning/general/onthisday/harp/0516.html&quot;&gt;16 hours to transmit&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;39&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;While new wireless and satellite technologies have been invented in the decades since, cables remain the fastest, most efficient and least expensive way to send information across the ocean. And it is still far from cheap: Google would not disclose the cost of its project to Chile, but experts say subsea projects cost up to $350 million, depending on the length of the cable.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;44&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;In the modern era, telecommunications companies laid most of the cable, but over the past decade American tech giants started taking more control. Google has backed at least 14 cables globally. Amazon, Facebook and Microsoft have invested in others, connecting data centers in North America, South America, Asia, Europe and Africa, according to TeleGeography, a research firm.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;37&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;Countries view the undersea cables as critical infrastructure and the projects have been flash points in geopolitical disputes. Last year, Australia stepped in to block the Chinese technology giant Huawei from building a cable connecting Australia to the Solomon Islands, for fear it would give the Chinese government an entry point into its networks.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-graphic g-inline-grx&quot; readability=&quot;7.5&quot;&gt;
&lt;div class=&quot;g-item-graphic&quot; readability=&quot;10&quot;&gt;
&lt;p class=&quot;g-asset-hed&quot;&gt;Content providers like &lt;strong&gt;Microsoft&lt;/strong&gt;, &lt;strong&gt;Google&lt;/strong&gt;, &lt;strong&gt;Facebook&lt;/strong&gt; and &lt;strong&gt;Amazon&lt;/strong&gt; now own or lease more than half of the undersea bandwidth&lt;/p&gt;
&lt;div id=&quot;g-undersea_cable-share-box&quot; class=&quot;ai2html ai2html-box-v5&quot;&gt;
&lt;div id=&quot;g-undersea_cable-share-300&quot; class=&quot;g-artboard&quot; data-aspect-ratio=&quot;0.929&quot; data-min-width=&quot;300&quot; data-max-width=&quot;539&quot; readability=&quot;6&quot;&gt;&lt;img id=&quot;g-undersea_cable-share-300-img&quot; class=&quot;g-aiImg g-aiAbs&quot; alt=&quot;&quot; data-src=&quot;https://static01.nyt.com/newsgraphics/2019/02/15/undersea-cables/fb3cf96f0a3ed634a251991b01220bb1374f1b85/undersea_cable-share-300.png&quot; src=&quot;data:image/gif;base64,R0lGODlhCgAKAIAAAB8fHwAAACH5BAEAAAAALAAAAAAKAAoAAAIIhI+py+0PYysAOw==&quot;/&gt;&lt;div id=&quot;g-ai0-1&quot; class=&quot;g-graphic g-aiAbs g-aiPointText&quot; readability=&quot;32&quot;&gt;
&lt;p class=&quot;g-pstyle0&quot;&gt;Share of used international&lt;/p&gt;
&lt;p class=&quot;g-pstyle0&quot;&gt;undersea cable bandwidth&lt;/p&gt;
&lt;/div&gt;



&lt;div id=&quot;g-ai0-5&quot; class=&quot;g-graphic g-aiAbs g-aiPointText&quot;&gt;
&lt;p class=&quot;g-pstyle3&quot;&gt;Internet&lt;/p&gt;
&lt;p class=&quot;g-pstyle3&quot;&gt;backbone&lt;/p&gt;
&lt;/div&gt;


&lt;div id=&quot;g-ai0-8&quot; class=&quot;g-graphic g-aiAbs g-aiPointText&quot;&gt;
&lt;p class=&quot;g-pstyle3&quot;&gt;Content&lt;/p&gt;
&lt;p class=&quot;g-pstyle3&quot;&gt;providers&lt;/p&gt;
&lt;/div&gt;






&lt;/div&gt;
&lt;div id=&quot;g-undersea_cable-share-540&quot; class=&quot;g-artboard&quot; data-aspect-ratio=&quot;1.86&quot; data-min-width=&quot;540&quot; readability=&quot;6&quot;&gt;&lt;img id=&quot;g-undersea_cable-share-540-img&quot; class=&quot;g-aiImg g-aiAbs&quot; alt=&quot;&quot; data-src=&quot;https://static01.nyt.com/newsgraphics/2019/02/15/undersea-cables/fb3cf96f0a3ed634a251991b01220bb1374f1b85/undersea_cable-share-540.png&quot; src=&quot;data:image/gif;base64,R0lGODlhCgAKAIAAAB8fHwAAACH5BAEAAAAALAAAAAAKAAoAAAIIhI+py+0PYysAOw==&quot;/&gt;


&lt;div id=&quot;g-ai1-4&quot; class=&quot;g-graphic g-aiAbs g-aiPointText&quot;&gt;
&lt;p class=&quot;g-pstyle2&quot;&gt;Internet&lt;/p&gt;
&lt;p class=&quot;g-pstyle2&quot;&gt;backbone&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;g-ai1-5&quot; class=&quot;g-graphic g-aiAbs g-aiPointText&quot; readability=&quot;32&quot;&gt;
&lt;p class=&quot;g-pstyle3&quot;&gt;Share of used international&lt;/p&gt;
&lt;p class=&quot;g-pstyle3&quot;&gt;undersea cable bandwidth&lt;/p&gt;
&lt;/div&gt;


&lt;div id=&quot;g-ai1-8&quot; class=&quot;g-graphic g-aiAbs g-aiPointText&quot;&gt;
&lt;p class=&quot;g-pstyle4&quot;&gt;Content&lt;/p&gt;
&lt;p class=&quot;g-pstyle4&quot;&gt;providers&lt;/p&gt;
&lt;/div&gt;






&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;span class=&quot;g-credit&quot;&gt;Source: TeleGeography&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;36&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;Yann Durieux, a ship captain, said one of his most important responsibilities was keeping morale up among his crew during the weeks at sea. Building the infrastructure of our digital world is a labor-intensive job.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;34&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;With 53 bedrooms and 60 bathrooms, the Durable can hold up to 80 crew members. The team splits into two 12-hour shifts. Signs warn to be quiet in the hallways because somebody is always sleeping.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;43&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;The ship will carry enough supplies to last at least 60 days: roughly 200 loaves of bread, 100 gallons of milk, 500 cartons of a dozen eggs, 800 pounds of beef, 1,200 pounds of chicken and 1,800 pounds of rice. There’s also 300 rolls of paper towels, 500 rolls of toilet paper, 700 bars of soap and almost 600 pounds of laundry detergent. No alcohol is allowed on board.&lt;/p&gt;
&lt;/div&gt;

&lt;div class=&quot;g-item g-image&quot;&gt;
&lt;div class=&quot;g-item-image&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://static01.nyt.com/packages/flash/multimedia/ICONS/transparent.png&quot; class=&quot;g-freebird-lazy&quot; data-pattern=&quot;https://static01.nyt.com/newsgraphics/2019/02/15/undersea-cables/assets/images/ship-tank-{{size}}.jpg&quot; data-pattern-retina=&quot;https://static01.nyt.com/newsgraphics/2019/02/15/undersea-cables/assets/images/ship-tank-{{size}}_x2.jpg&quot; data-widths=&quot;[320,480,640,900,1050,1254,2000]&quot; data-ratio=&quot;0.6774909797391063&quot;/&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;36&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;“I still get seasick,” said Walt Oswald, a technician who has been laying cables on ships for 20 years. He sticks a small patch behind his ear to hold back the nausea. “It’s not for everybody.”&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;39&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;Poor weather is inevitable. Swells reach up to 20 feet, occasionally requiring the ship captain to order the subsea cable to be cut so the ship can seek safer waters. When conditions improve, the ship returns, retrieving the cut cable that has been left attached to a floating buoy, then splicing it back together before continuing on.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;40&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;Work on board is slow and plodding. The ship, at sea for months at a time, moves about six miles per hour, as the cables are pulled from the giant basins out through openings at the back of the ship. Closer to shore, where there’s more risk of damage, an underwater plow is used to bury the cable in the sea floor.&lt;/p&gt;
&lt;/div&gt;


&lt;div class=&quot;g-item g-text&quot; readability=&quot;32&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;The Durable crew doesn’t expect the work to slow down anytime soon.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;38&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;After the Latin America project, Google plans to build a new cable running from Virginia to France, set to be done by 2020. The company has 13 data centers open around the world, with eight more under construction — all needed to power the trillions of Google searches made each year and the more than 400 hours of video uploaded to YouTube each minute.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;35&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;“It really is management of a very complex multidimensional chess board,” said Ms. Stowell of Google, who wears an undersea cable as a necklace.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;38&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;Demand for undersea cables will only grow as more businesses rely on cloud computing services. And technology expected around the corner, like more powerful artificial intelligence and driverless cars, will all require fast data speeds as well. Areas that didn’t have internet are now getting access, with the United Nations reporting that for the first time more than half the global population is now online.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;37&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;“This is a huge part of the infrastructure that’s making that happen,” said Debbie Brask, the vice president at SubCom, who is managing the Google project. “All of that data is going in the undersea cables.”&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-text g-footnote&quot; readability=&quot;14&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;Note: Cables shown in the map are ones that are currently in use, planned or being constructed. They do not show cables that were decommissioned. The content providers comprise cables publicly announced that Facebook, Google, Microsoft or Amazon partly own, solely own or are a major capacity buyer of a cable owned by another company. | Source: TeleGeography&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
<pubDate>Mon, 11 Mar 2019 02:47:56 +0000</pubDate>
<dc:creator>anuragsoni</dc:creator>
<og:url>https://www.nytimes.com/interactive/2019/03/10/technology/internet-cables-oceans.html</og:url>
<og:type>article</og:type>
<og:title>How the Internet Travels Across Oceans</og:title>
<og:image>https://static01.nyt.com/images/2019/03/07/technology/internet-cables-oceans-1552081048106/internet-cables-oceans-1552081048106-facebookJumbo-v5.png</og:image>
<og:description>Hundreds of thousands of miles of cable connect continents to support our insatiable demand for communication and entertainment. Companies have typically pooled their resources. Now Google is going its own way.</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.nytimes.com/interactive/2019/03/10/technology/internet-cables-oceans.html</dc:identifier>
</item>
<item>
<title>China orders its airlines to suspend use of Boeing 737 Max aircraft</title>
<link>https://www.reuters.com/article/us-ethiopia-airlines-china/china-orders-its-airlines-to-suspend-use-of-boeing-737-max-aircraft-media-idUSKBN1QS01Z</link>
<guid isPermaLink="true" >https://www.reuters.com/article/us-ethiopia-airlines-china/china-orders-its-airlines-to-suspend-use-of-boeing-737-max-aircraft-media-idUSKBN1QS01Z</guid>
<description>&lt;p&gt;BEIJING/SHANGHAI (Reuters) - China’s aviation regulator on Monday grounded nearly 100 Boeing Co 737 MAX 8 aircraft operated by its airlines, more than a quarter of the global fleet of the jets, after a deadly crash of one of the planes in Ethiopia.&lt;/p&gt;
&lt;p&gt;However, a U.S. official said it was unclear what information the Chinese regulator was acting on because the investigation of Sunday’s crash, the second involving the latest version of the narrowbody jet, was in the early stages.&lt;/p&gt;
&lt;p&gt;Speaking on condition of anonymity as the topic is sensitive, the U.S. official said there were no plans to follow suit, as the jet had a stellar safety record in the United States and there was a lack of information on what caused the Ethiopian crash.&lt;/p&gt;
&lt;p&gt;Boeing, whose shares dropped 9 percent in U.S. pre-market trade, said the investigation remained in its early stages and it had no basis to issue new guidance to operators.&lt;/p&gt;
&lt;p&gt;It was unusual to ground a plane type unless a specific mechanical issue or component failure had been identified and could be inspected, said Andrew Herdman, director general of the Association of Asia Pacific Airlines.&lt;/p&gt;
&lt;p&gt;“In this case it is not clear what the action item is, having done the suspension,” he said. “What is lacking now is what happened in this case.&lt;/p&gt;
&lt;p&gt;“That means finding the black boxes and piecing together other circumstantial evidence from air traffic control recordings and so on.”&lt;/p&gt;
&lt;p&gt;Most other Boeing 737 MAX operators globally told Reuters their planes would keep flying and they had no plans to cancel orders.&lt;/p&gt;
&lt;p&gt;Sunday’s crash, minutes after take-off, of an Ethiopian Airlines 737 MAX 8 bound for Nairobi, killed all 157 on board and prompted the carrier to ground the rest of its 737 MAX jets.&lt;/p&gt;
&lt;p&gt;In October, a 737 MAX 8 operated by Indonesian budget carrier Lion Air crashed 13 minutes after take-off from the Indonesian capital of Jakarta on a domestic flight, killing all 189 on board. The 737 MAX 8 first entered service in 2017.&lt;/p&gt;
&lt;p&gt;The Civil Aviation Administration of China (CAAC) said it would notify airlines when they could resume flying the jets, after contacting Boeing and the U.S. Federal Aviation Administration (FAA) to ensure flight safety.&lt;/p&gt;
&lt;p&gt;“Given that two accidents both involved newly delivered Boeing 737-8 planes and happened during take-off phase, they have some degree of similarity,” the CAAC said, adding the step was in line with its principle of zero tolerance of safety hazards. The 737 MAX 8 is sometimes referred to as the 737-8.&lt;/p&gt;
&lt;p&gt;The grounding was due to safety concerns and not related to trade friction between the United States and China, Li Jian, the deputy head of the Chinese regulator, told reporters, the Yangcheng Evening News said.&lt;/p&gt;
&lt;div class=&quot;Image_container&quot; tabindex=&quot;-1&quot;&gt;
&lt;div class=&quot;LazyImage_container LazyImage_dark&quot;&gt;&lt;img src=&quot;https://s2.reutersmedia.net/resources/r/?m=02&amp;amp;d=20190311&amp;amp;t=2&amp;amp;i=1365027562&amp;amp;r=LYNXMPEF2A0RC&amp;amp;w=20&quot; aria-label=&quot;Airplane engine parts are seen at the scene of the Ethiopian Airlines Flight ET 302 plane crash, near the town of Bishoftu, southeast of Addis Ababa, Ethiopia March 11, 2019. REUTERS/Tiksa Negeri&quot;/&gt;
&lt;/div&gt;

&lt;div class=&quot;Image_caption&quot;&gt;

&lt;span&gt;Airplane engine parts are seen at the scene of the Ethiopian Airlines Flight ET 302 plane crash, near the town of Bishoftu, southeast of Addis Ababa, Ethiopia March 11, 2019. REUTERS/Tiksa Negeri&lt;/span&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;“These are two separate issues,” the newspaper, which is backed by the government of the southern province of Guangdong, quoted Li as saying on the sidelines of a parliament meeting in Beijing.&lt;/p&gt;
&lt;h3&gt;CHINA’S FLEET&lt;/h3&gt;
&lt;p&gt;Chinese airlines have 96 737 MAX 8 jets in service, the state company regulator said on Twitter-like Weibo, including Air China, China Eastern Airlines, China Southern Airlines and Hainan Airlines.&lt;/p&gt;
&lt;p&gt;Chinese aviation data firm Variflight said at least 29 international and domestic flights on Monday had been canceled and that airlines had swapped out the plane on 256 other flights that had been scheduled to use it.&lt;/p&gt;
&lt;p&gt;China Eastern’s chairman, Liu Shaoyong, told financial publication Caixin on the sidelines of the Beijing meeting that it would only consider resuming 737 MAX 8 flights once Boeing issued a safety commitment for the jets and proved there was no aircraft design link between the two crashes.&lt;/p&gt;
&lt;p&gt;The cause of the Indonesian crash is still being investigated.&lt;/p&gt;
&lt;p&gt;A November preliminary report, before the retrieval of the cockpit voice recorder, focused on airline maintenance and training and the response of a Boeing anti-stall system to a recently replaced sensor but gave no reason for the crash.&lt;/p&gt;
&lt;p&gt;Ethiopian Airlines said it had grounded its 737 MAX 8 fleet until further notice as an “extra safety precaution” even though it did not know the cause of Sunday’s crash.&lt;/p&gt;
&lt;p&gt;The airline has a remaining fleet of four of the aircraft, flight tracking website FlightRadar24 says.&lt;/p&gt;
&lt;p&gt;Cayman Airways said it had grounded both of its new 737 MAX 8 jets until it got more information.&lt;/p&gt;
&lt;p&gt;But no other airlines with 737 MAX 8s in their fleets or on order, or their regulators, told Reuters they were grounding the aircraft or cancelling orders.&lt;/p&gt;
&lt;p&gt;By January-end, Boeing had delivered 350 of the 737 MAX family jets to customers, with 4,661 more on order.&lt;/p&gt;
&lt;p&gt;Western industry sources say China has been at pains in recent years to assert its independence as a safety regulator as it negotiates mutual safety standard recognition with regulators in the United States and Europe.&lt;/p&gt;
&lt;div class=&quot;Slideshow_container Slideshow_small Slideshow_standard&quot;&gt;
&lt;div class=&quot;Slideshow_preview-container&quot;&gt;
&lt;div class=&quot;LazyImage_container LazyImage_dark&quot;&gt;&lt;img src=&quot;https://s2.reutersmedia.net/resources/r/?m=02&amp;amp;d=20190311&amp;amp;t=2&amp;amp;i=1365027563&amp;amp;r=LYNXMPEF2A0RD&quot;/&gt;
&lt;/div&gt;

Slideshow &lt;span class=&quot;Slideshow_count&quot;&gt;(28 Images)&lt;/span&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;In 2017, it signed a mutual recognition deal with the FAA, but industry sources say it has struggled to gain approval from the FAA that would allow it to sell its self-developed C919 airliner to Western airlines.&lt;/p&gt;
&lt;p&gt;The grounding was “reasonable and justified”, said Chinese aviation expert Li Xiaojin but added that he did not anticipate a major problem, as Chinese airlines operated fewer than 100 of the aircraft, among a combined fleet of more than 2,000 planes.&lt;/p&gt;
&lt;div class=&quot;Attribution_container&quot; readability=&quot;11.5&quot;&gt;
&lt;div class=&quot;Attribution_attribution&quot; readability=&quot;18&quot;&gt;
&lt;p class=&quot;Attribution_content&quot;&gt;Reporting by Josh Horwitz and John Ruwitch; Additional reporting by Brenda Goh in Shanghai, Stella Qiu in Beijing, David Shepardson in Washington, Tom Westbrook in Sydney, Jamie Freed in Singapore, Cindy Silviana and Edward Davies in Jakarta, Heekyong Yang in Seoul, Tracy Rucinski in Chicago, Alexander Cornwell in Dubai and Tim Hepher in Paris; Writing by Brenda Goh and Jamie Freed; Editing by Robert Birsel and Clarence Fernandez&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;StandardArticleBody_trustBadgeContainer&quot;&gt;&lt;span class=&quot;StandardArticleBody_trustBadgeTitle&quot;&gt;Our Standards:&lt;/span&gt;&lt;span class=&quot;trustBadgeUrl&quot;&gt;&lt;a href=&quot;http://thomsonreuters.com/en/about-us/trust-principles.html&quot;&gt;The Thomson Reuters Trust Principles.&lt;/a&gt;&lt;/span&gt;&lt;/div&gt;
</description>
<pubDate>Mon, 11 Mar 2019 02:01:17 +0000</pubDate>
<dc:creator>Ultramanoid</dc:creator>
<og:title>Chinese carriers, Ethiopian Airlines halt use of Boeing 737 MAX 8...</og:title>
<og:url>https://www.reuters.com/article/us-ethiopia-airlines-china-idUSKBN1QS01Z</og:url>
<og:type>article</og:type>
<og:description>China's aviation regulator on Monday grounded nearly 100 Boeing Co 737 MAX ...</og:description>
<og:image>https://s2.reutersmedia.net/resources/r/?m=02&amp;d=20190311&amp;t=2&amp;i=1365027562&amp;w=1200&amp;r=LYNXMPEF2A0RC</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.reuters.com/article/us-ethiopia-airlines-china/china-orders-its-airlines-to-suspend-use-of-boeing-737-max-aircraft-media-idUSKBN1QS01Z</dc:identifier>
</item>
<item>
<title>Daydreaming about the future instead of doing work today</title>
<link>https://www.howitactuallyworks.com/archives/future_you_masturbation.html</link>
<guid isPermaLink="true" >https://www.howitactuallyworks.com/archives/future_you_masturbation.html</guid>
<description>&lt;h3&gt;Future You Masturbation&lt;/h3&gt;
&lt;p&gt;This was originally published in my free weekly newsletter, &lt;a href=&quot;https://howitactuallyworks.com&quot;&gt;&lt;em&gt;How It Actually Works&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I have a friend who’s creating an awesome side project: LED signs that you can control to let your coworkers know you’re busy.&lt;/p&gt;
&lt;img src=&quot;https://hiaw-images.s3.amazonaws.com/green-wired-in-1.jpg&quot;/&gt;&lt;p&gt;He has a bunch of fun features that he considers important to the type of business he “wants” to build in the future: integrating with Slack &amp;amp; other online tools, different colors, sync with a Mac &amp;amp; iPhone app, and too much more.&lt;/p&gt;
&lt;p&gt;But the reality is that even though he gets orders with zero marketing he’s still hand assembling the signs himself at his kitchen table.&lt;/p&gt;
&lt;p&gt;What’s the priority? Writing software for future use cases, or finding an assembler to build the signs for him?&lt;/p&gt;
&lt;p&gt;When presented like this you, dear reader, will think the choice is obvious.&lt;/p&gt;
&lt;p&gt;But to that I say: you make the same mistake every day.&lt;/p&gt;
&lt;p&gt;Where he gets stuck - where we all get stuck - is doing Future You Masturbation.&lt;/p&gt;
&lt;p&gt;The Big Vision with all the bells &amp;amp; whistles is fun to think about because it gives you all the benefits with none of the work.&lt;/p&gt;
&lt;p&gt;You can picture how you’ll look and feel, the money in your bank account, the respect of your friends and peers.&lt;/p&gt;
&lt;p&gt;At no cost you get to imagine a perfect future that has everything you want &amp;amp; nothing you don’t.&lt;/p&gt;
&lt;p&gt;Because all the bad stuff, all the unexpected twists &amp;amp; turns, the late nights &amp;amp; early mornings, the rejections &amp;amp; betrayals… even if you wanted to you couldn’t imagine them &lt;strong&gt;because you don’t yet know what they’re going to be.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Future You Masturbation gives you the pleasure of all your future accomplishments with none of the work. It’s your brain tricking you into something that feels good today in exchange for lost meaning and purpose and accomplishment in the future.&lt;/p&gt;
&lt;h6&gt;Do The Work&lt;/h6&gt;
&lt;p&gt;New projects are like being dropped in the middle of nowhere with 100 different paths in front of you. You have no clue where any of them will lead &amp;amp; can only see the first 3 steps in any direction.&lt;/p&gt;
&lt;p&gt;Most of us don’t choose at all &amp;amp; instead do more “research” and planning.&lt;/p&gt;
&lt;p&gt;To continue the metaphor: instead of choosing one of the 100 paths and beginning to walk we start building a tower that we believe will let us see higher to help us choose the “best” path.&lt;/p&gt;
&lt;p&gt;Of course we don’t know whether the extra vision from the tower will give us more useful information than walking a few steps down one of the paths, but we do it anyway because because it feels safer.&lt;/p&gt;
&lt;p&gt;You get to keep all the optionality and the Big Vision can’t be messed with. And the entire time you’re building your tower of research you’re Future You Masturbating so it &lt;em&gt;feels&lt;/em&gt; like you’re making progress.&lt;/p&gt;
&lt;p&gt;What we should all do is pick the path that has the best 3 feet. In my friend’s case: follow the money!&lt;/p&gt;
&lt;p&gt;People want the signs so find the cheapest and most reliable way to make them ASAP.&lt;/p&gt;
&lt;p&gt;That requires going outside his expertise though. And, more importantly, it might not work!&lt;/p&gt;
&lt;p&gt;The path he chooses might be a dead end and will likely have more bumps than other paths he could have chosen.&lt;/p&gt;
&lt;p&gt;Who wants to work on something that might not even work out? Yet another reason to daydream about the future instead of doing work today.&lt;/p&gt;
&lt;p&gt;You probably point at my friend &amp;amp; think “yeah but that’s so obvious you do the thing in front of you first”.&lt;/p&gt;
&lt;p&gt;OH REALLY?&lt;/p&gt;
&lt;p&gt;Have you ever…&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;been inspired to get in shape and instead of immediately running gone online to shop for workout clothes?&lt;/li&gt;
&lt;li&gt;Started a business by making a website instead of finding a customer?&lt;/li&gt;
&lt;li&gt;Complained about your dating prospects instead of making yourself more dateable?&lt;/li&gt;
&lt;li&gt;Emailed someone where a call would be better?&lt;/li&gt;
&lt;li&gt;Starting goal setting by buying a fancy journal instead of opening a Google Doc ?&lt;/li&gt;
&lt;li&gt;Put off the correct, hard work for the easier, less effective work?&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;We are all my friend.&lt;/p&gt;
&lt;p&gt;This was originally published in my weekly newsletter, &lt;a href=&quot;https://howitactuallyworks.com&quot;&gt;&lt;em&gt;How It Actually Works&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;h6&gt;Meaning Without Success&lt;/h6&gt;
&lt;p&gt;The hard work is the direction we need to go.&lt;/p&gt;
&lt;p&gt;Not only will it get us closer to the goals but it will add meaning to our lives even if we never accomplish them.&lt;/p&gt;
&lt;p&gt;Whether you have a Tesla in your brain or a Tesla in real life doesn’t make a difference in how happy you are.&lt;/p&gt;
&lt;h2&gt;The Links&lt;/h2&gt;
&lt;h6&gt;&lt;a href=&quot;https://www.cambus.net/oldest-domains-in-the-com-net-and-org-tlds/&quot;&gt;The Earliest Registered .com Domain Names&lt;/a&gt; (cambus.net, article)&lt;/h6&gt;
&lt;p&gt;Exactly what it says. Skip to the bottom for the list.&lt;/p&gt;
&lt;h6&gt;&lt;a href=&quot;https://www.inc.com/danielle-herzberg/how-to-build-a-network-from-scratch.html&quot;&gt;How to Build a Network from Scratch&lt;/a&gt; (inc.com, article)&lt;/h6&gt;
&lt;p&gt;Surprisingly effective advice for such a cliché topic. I like #4.&lt;/p&gt;
&lt;h6&gt;&lt;a href=&quot;https://www.theawl.com/2010/06/new-york-times-bans-the-word-tweet/&quot;&gt;The New York Times Banned the Word “Tweet”&lt;/a&gt; (theawl.com, article)&lt;/h6&gt;
&lt;p&gt;From 2010. Now “tweet” is in literally hundreds of their own headlines.&lt;/p&gt;
&lt;h6&gt;&lt;a href=&quot;https://amzn.to/2tLzOyV&quot;&gt;The American Spirit: Who We Are and What We Stand For&lt;/a&gt; (audible.com, audiobook)&lt;/h6&gt;
&lt;p&gt;Biographer David McCullough (1776, The Wright Brothers, Truman) released a book with some of his old speeches and essays. McCullough’s brand of American optimism in spite of whatever the current reality is my kind of American hope.&lt;/p&gt;
&lt;p&gt;This was originally published in my weekly newsletter, &lt;a href=&quot;https://howitactuallyworks.com&quot;&gt;&lt;em&gt;How It Actually Works&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;
</description>
<pubDate>Mon, 11 Mar 2019 01:36:27 +0000</pubDate>
<dc:creator>trevmckendrick</dc:creator>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.howitactuallyworks.com/archives/future_you_masturbation.html</dc:identifier>
</item>
<item>
<title>How Transformers Work – Model Used by Open AI and DeepMind</title>
<link>https://medium.com/@giacaglia/transformers-141e32e69591</link>
<guid isPermaLink="true" >https://medium.com/@giacaglia/transformers-141e32e69591</guid>
<description>&lt;div class=&quot;uiScale uiScale-ui--regular uiScale-caption--regular u-flexCenter u-marginVertical24 u-fontSize15 js-postMetaLockup&quot;&gt;
&lt;div class=&quot;u-flex0&quot;&gt;&lt;a class=&quot;link u-baseColor--link avatar&quot; href=&quot;https://medium.com/@giacaglia?source=post_header_lockup&quot; data-action=&quot;show-user-card&quot; data-action-source=&quot;post_header_lockup&quot; data-action-value=&quot;d0de4109e381&quot; data-action-type=&quot;hover&quot; data-user-id=&quot;d0de4109e381&quot; dir=&quot;auto&quot;&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/fit/c/100/100/1*cCB5c7J6eyvx_un7PEEwkg@2x.jpeg&quot; class=&quot;avatar-image u-size50x50&quot; alt=&quot;Go to the profile of Giuliano Giacaglia&quot;/&gt;&lt;/a&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;p name=&quot;f891&quot; id=&quot;f891&quot; class=&quot;graf graf--p graf-after--h3&quot;&gt;Transformers are a type of neural network architecture that have been gaining popularity. Transformers were recently used by OpenAI in their language &lt;a href=&quot;https://blog.openai.com/better-language-models/&quot; data-href=&quot;https://blog.openai.com/better-language-models/&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;models&lt;/a&gt;, and also used recently by DeepMind for &lt;a href=&quot;https://deepmind.com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii/&quot; data-href=&quot;https://deepmind.com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii/&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;AlphaStar&lt;/a&gt; — their program to defeat a top professional Starcraft player.&lt;/p&gt;
&lt;p name=&quot;90ad&quot; id=&quot;90ad&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Transformers were developed to solve the problem of &lt;a href=&quot;https://arxiv.org/abs/1211.3711&quot; data-href=&quot;https://arxiv.org/abs/1211.3711&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;&lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;sequence transduction&lt;/strong&gt;&lt;/a&gt;&lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;,&lt;/strong&gt; or &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;neural machine translation.&lt;/strong&gt; That means any task that transforms an input sequence to an output sequence. This includes speech recognition, text-to-speech transformation, etc..&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*mn3V4GHG9OABem9i26NVfg.gif&quot; data-width=&quot;600&quot; data-height=&quot;180&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*mn3V4GHG9OABem9i26NVfg.gif&quot;/&gt;&lt;/div&gt;
Sequence transduction. The input is represented in green, the model is represented in blue, and the output is represented in purple. GIF taken from &lt;a href=&quot;https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/&quot; data-href=&quot;https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/&quot; class=&quot;markup--anchor markup--figure-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;3&lt;/a&gt;
&lt;p name=&quot;5aac&quot; id=&quot;5aac&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;For models to perform &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;sequence transduction,&lt;/strong&gt; it is necessary some sort of memory. For example let’s say that we are translating the following sentence to another language (French):&lt;/p&gt;
&lt;blockquote name=&quot;5285&quot; id=&quot;5285&quot; class=&quot;graf graf--blockquote graf--startsWithDoubleQuote graf-after--p&quot; readability=&quot;7&quot;&gt;
&lt;p&gt;“The Transformers” are a Japanese [[hardcore punk]] band. The band was formed in 1968, during the height of Japanese music history”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p name=&quot;3c93&quot; id=&quot;3c93&quot; class=&quot;graf graf--p graf-after--blockquote&quot;&gt;In this example, the word “the band” in the second sentence refers to the band “The Transformers” introduced in the first sentence. When you read about the band in the second sentence, you know that it is referencing to the “The Transformers” band. That may be important for translation. There are many examples, where words in some sentences refer to words in previous sentences.&lt;/p&gt;
&lt;p name=&quot;10e9&quot; id=&quot;10e9&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;For translating sentences like that, a model needs to figure out these sort of dependencies and connections. Recurrent Neural Networks (RNNs) and Convolutional Neural Networks (CNNs) have been used to deal with this problem because of their properties. Let’s go over these two architectures and their drawbacks.&lt;/p&gt;
&lt;h3 name=&quot;10b9&quot; id=&quot;10b9&quot; class=&quot;graf graf--h3 graf-after--p&quot;&gt;&lt;strong class=&quot;markup--strong markup--h3-strong&quot;&gt;Recurrent Neural Networks&lt;/strong&gt;&lt;/h3&gt;
&lt;p name=&quot;7bfa&quot; id=&quot;7bfa&quot; class=&quot;graf graf--p graf-after--h3&quot;&gt;Recurrent Neural Networks have loops in them, allowing information to persist.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*L38xfe59H5tAgvuIjKoWPg.png&quot; data-width=&quot;200&quot; data-height=&quot;310&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*L38xfe59H5tAgvuIjKoWPg.png&quot;/&gt;&lt;/div&gt;
The input is represented as x_t
&lt;p name=&quot;0e89&quot; id=&quot;0e89&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;In the figure above, we see part of the neural network, &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;A,&lt;/strong&gt; processing some input x_t and outputs h_t. A loop allows information to be passed from one step to the next.&lt;/p&gt;
&lt;p name=&quot;78a5&quot; id=&quot;78a5&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;The loops can be thought in a different way. A Recurrent Neural Network can be thought of as multiple copies of the same network, &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;A&lt;/strong&gt;, each network passing a message to a successor. Consider what happens if we unroll the loop:&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*NKhwsOYNUT5xU7Pyf6Znhg.png&quot; data-width=&quot;2706&quot; data-height=&quot;711&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*NKhwsOYNUT5xU7Pyf6Znhg.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*NKhwsOYNUT5xU7Pyf6Znhg.png&quot;/&gt;&lt;/div&gt;
An unrolled recurrent neural network
&lt;p name=&quot;6abf&quot; id=&quot;6abf&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;This chain-like nature shows that recurrent neural networks are clearly related to sequences and lists. In that way, if we want to translate some text, we can set each input as the word in that text. The Recurrent Neural Network passes the information of the previous words to the next network that can use and process that information.&lt;/p&gt;
&lt;p name=&quot;a6d6&quot; id=&quot;a6d6&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;The following picture shows how usually a sequence to sequence model works using Recurrent Neural Networks. Each word is processed separately, and the resulting sentence is generated by passing a hidden state to the decoding stage that, then, generates the output.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*8GcdjBU5TAP36itWBcZ6iA.gif&quot; data-width=&quot;600&quot; data-height=&quot;265&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*8GcdjBU5TAP36itWBcZ6iA.gif&quot;/&gt;&lt;/div&gt;
GIF taken from &lt;a href=&quot;https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/&quot; data-href=&quot;https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/&quot; class=&quot;markup--anchor markup--figure-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;3&lt;/a&gt;
&lt;h4 name=&quot;3c47&quot; id=&quot;3c47&quot; class=&quot;graf graf--h4 graf-after--figure&quot;&gt;The problem of long-term dependencies&lt;/h4&gt;
&lt;p name=&quot;e0b6&quot; id=&quot;e0b6&quot; class=&quot;graf graf--p graf-after--h4&quot;&gt;Consider a language model that is trying to predict the next word based on the previous ones. If we are trying to predict the next word of the sentence &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;“the clouds in the sky”&lt;/strong&gt;, we don’t need further context. It’s pretty obvious that the next word is going to be &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;sky.&lt;/strong&gt;&lt;/p&gt;
&lt;p name=&quot;93fb&quot; id=&quot;93fb&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;In this case where the difference between the relevant information and the place that is needed is small, RNNs can learn to use past information and figure out what is the next word for this sentence.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*uQNyY58RRgRNQSnjuYKvkQ.png&quot; data-width=&quot;500&quot; data-height=&quot;231&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*uQNyY58RRgRNQSnjuYKvkQ.png&quot;/&gt;&lt;/div&gt;
Image taken from &lt;a href=&quot;http://colah.github.io/posts/2015-08-Understanding-LSTMs/&quot; data-href=&quot;http://colah.github.io/posts/2015-08-Understanding-LSTMs/&quot; class=&quot;markup--anchor markup--figure-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;6&lt;/a&gt;
&lt;p name=&quot;8f1f&quot; id=&quot;8f1f&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;But there are cases where we need more context. For example, let’s say that you are trying to predict the last word of the text: &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;“I grew up in France… I speak fluent &lt;em class=&quot;markup--em markup--p-em&quot;&gt;French&lt;/em&gt;”.&lt;/strong&gt; Recent information suggests that the next word is probably a language, but if we want to narrow down which language, we need context of France, that is further back in the text.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*a5EbLhyxbPR78PhiV5Esjg.png&quot; data-width=&quot;2523&quot; data-height=&quot;869&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*a5EbLhyxbPR78PhiV5Esjg.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1200/1*a5EbLhyxbPR78PhiV5Esjg.png&quot;/&gt;&lt;/div&gt;
Image taken from &lt;a href=&quot;http://colah.github.io/posts/2015-08-Understanding-LSTMs/&quot; data-href=&quot;http://colah.github.io/posts/2015-08-Understanding-LSTMs/&quot; class=&quot;markup--anchor markup--figure-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;6&lt;/a&gt;
&lt;p name=&quot;aef6&quot; id=&quot;aef6&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;RNNs become very ineffective when the gap between the relevant information and the point where it is needed become very large. That is due to the fact that the information is passed at each step and the longer the chain is, the more probable the information is lost along the chain.&lt;/p&gt;
&lt;p name=&quot;1389&quot; id=&quot;1389&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;In theory, RNNs could learn this long-term dependencies. In practice, they don’t seem to learn &lt;a href=&quot;http://ai.dinfo.unifi.it/paolo//ps/tnn-94-gradient.pdf&quot; data-href=&quot;http://ai.dinfo.unifi.it/paolo//ps/tnn-94-gradient.pdf&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;them&lt;/a&gt;. LSTM, a special type of RNN, tries to solve this kind of problem.&lt;/p&gt;
&lt;h3 name=&quot;9087&quot; id=&quot;9087&quot; class=&quot;graf graf--h3 graf-after--p&quot;&gt;Long-Short Term Memory (LSTM)&lt;/h3&gt;
&lt;p name=&quot;c054&quot; id=&quot;c054&quot; class=&quot;graf graf--p graf-after--h3&quot;&gt;When arranging one’s calendar for the day, we prioritize our appointments. If there is anything important, we can cancel some of the meetings and accommodate what is important.&lt;/p&gt;
&lt;p name=&quot;f14d&quot; id=&quot;f14d&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;RNNs don’t do that. Whenever it adds new information, it transforms existing information completely by applying a function. The entire information is modified, and there is no consideration of what is important and what is not.&lt;/p&gt;
&lt;p name=&quot;1045&quot; id=&quot;1045&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;LSTMs make small modifications to the information by multiplications and additions. With LSTMs, the information flows through a mechanism known as cell states. In this way, LSTMs can selectively remember or forget things that are important and not so important.&lt;/p&gt;
&lt;p name=&quot;a19d&quot; id=&quot;a19d&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Internally, a LSTM looks like the following:&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*J5W8FrASMi93Z81NlAui4w.png&quot; data-width=&quot;2233&quot; data-height=&quot;839&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*J5W8FrASMi93Z81NlAui4w.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*J5W8FrASMi93Z81NlAui4w.png&quot;/&gt;&lt;/div&gt;
Image taken from &lt;a href=&quot;http://colah.github.io/posts/2015-08-Understanding-LSTMs/&quot; data-href=&quot;http://colah.github.io/posts/2015-08-Understanding-LSTMs/&quot; class=&quot;markup--anchor markup--figure-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;6&lt;/a&gt;
&lt;p name=&quot;09fb&quot; id=&quot;09fb&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Each cell takes as inputs &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;x_t&lt;/strong&gt; (a word in the case of a sentence to sentence translation), the &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;previous cell state&lt;/strong&gt; and the &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;output&lt;/strong&gt; &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;of the previous cell&lt;/strong&gt;. It manipulates these inputs and based on them, it generates a new cell state, and an output. I won’t go into detail on the mechanics of each cell. If you want to understand how each cell works, I recommend Christopher’s blog post:&lt;/p&gt;

&lt;p name=&quot;5aee&quot; id=&quot;5aee&quot; class=&quot;graf graf--p graf-after--mixtapeEmbed&quot;&gt;With a cell state, the information in a sentence that is important for translating a word may be passed from one word to another, when translating.&lt;/p&gt;
&lt;h4 name=&quot;4d45&quot; id=&quot;4d45&quot; class=&quot;graf graf--h4 graf-after--p&quot;&gt;The problem with LSTMs&lt;/h4&gt;
&lt;p name=&quot;c005&quot; id=&quot;c005&quot; class=&quot;graf graf--p graf-after--h4&quot;&gt;The same problem that happens to RNNs generally, happen with LSTMs, i.e. when sentences are too long LSTMs still don’t do too well. The reason for that is that the probability of keeping the context from a word that is far away from the current word being processed decreases exponentially with the distance from it.&lt;/p&gt;
&lt;p name=&quot;4019&quot; id=&quot;4019&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;That means that when sentences are long, the model often forgets the content of distant positions in the sequence. Another problem with RNNs, and LSTMs, is that it’s hard to parallelize the work for processing sentences, since you are have to process word by word. Not only that but there is no model of long and short range dependencies. To summarize, LSTMs and RNNs present 3 problems:&lt;/p&gt;
&lt;ul class=&quot;postList&quot;&gt;&lt;li name=&quot;85e7&quot; id=&quot;85e7&quot; class=&quot;graf graf--li graf-after--p&quot;&gt;Sequential computation inhibits parallelization&lt;/li&gt;
&lt;li name=&quot;9204&quot; id=&quot;9204&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;No explicit modeling of long and short range dependencies&lt;/li&gt;
&lt;li name=&quot;9ec3&quot; id=&quot;9ec3&quot; class=&quot;graf graf--li graf--startsWithDoubleQuote graf-after--li&quot;&gt;“Distance” between positions is linear&lt;/li&gt;
&lt;/ul&gt;&lt;h3 name=&quot;423e&quot; id=&quot;423e&quot; class=&quot;graf graf--h3 graf-after--li&quot;&gt;Attention&lt;/h3&gt;
&lt;p name=&quot;92c8&quot; id=&quot;92c8&quot; class=&quot;graf graf--p graf-after--h3&quot;&gt;To solve some of these problems, researchers created a technique for paying attention to specific words.&lt;/p&gt;
&lt;p name=&quot;189a&quot; id=&quot;189a&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;When translating a sentence, I pay special attention to the word I’m presently translating. When I’m transcribing an audio recording, I listen carefully to the segment I’m actively writing down. And if you ask me to describe the room I’m sitting in, I’ll glance around at the objects I’m describing as I do so.&lt;/p&gt;
&lt;p name=&quot;c037&quot; id=&quot;c037&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Neural networks can achieve this same behavior using &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;&lt;em class=&quot;markup--em markup--p-em&quot;&gt;attention&lt;/em&gt;&lt;/strong&gt;, focusing on part of a subset of the information they are given. For example, an RNN can attend over the output of another RNN. At every time step, it focuses on different positions in the other RNN.&lt;/p&gt;
&lt;p name=&quot;8e1b&quot; id=&quot;8e1b&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;To solve these problems, &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;Attention&lt;/strong&gt; is a technique that is used in a neural network. For RNNs, instead of only encoding the whole sentence in a hidden state, each word has a corresponding hidden state that is passed all the way to the decoding stage. Then, the hidden states are used at each step of the RNN to decode. The following gif shows how that happens.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*JrxKsw2LYU9emkM-jR13uQ.gif&quot; data-width=&quot;600&quot; data-height=&quot;263&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*JrxKsw2LYU9emkM-jR13uQ.gif&quot;/&gt;&lt;/div&gt;
The &lt;strong class=&quot;markup--strong markup--figure-strong&quot;&gt;green&lt;/strong&gt; step is called the &lt;strong class=&quot;markup--strong markup--figure-strong&quot;&gt;encoding stage&lt;/strong&gt; and the purple step is the &lt;strong class=&quot;markup--strong markup--figure-strong&quot;&gt;decoding stage.&lt;/strong&gt; GIF taken from&lt;strong class=&quot;markup--strong markup--figure-strong&quot;&gt; &lt;/strong&gt;&lt;a href=&quot;http://3&quot; data-href=&quot;http://3&quot; class=&quot;markup--anchor markup--figure-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;3&lt;/a&gt;
&lt;p name=&quot;6531&quot; id=&quot;6531&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;The idea behind it is that there might be relevant information in every word in a sentence. So in order for the decoding to be precise, it needs to take into account every word of the input, using &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;attention.&lt;/strong&gt;&lt;/p&gt;
&lt;p name=&quot;b7cb&quot; id=&quot;b7cb&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;For attention to be brought to RNNs in sequence transduction, we divide the encoding and decoding into 2 main steps. One step is represented in &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;green&lt;/strong&gt; and the other in &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;purple.&lt;/strong&gt; The &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;green&lt;/strong&gt; step is called the &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;encoding stage&lt;/strong&gt; and the purple step is the &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;decoding stage.&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*KD1xANybFo4EC2V2unn3RQ.gif&quot; data-width=&quot;600&quot; data-height=&quot;327&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*KD1xANybFo4EC2V2unn3RQ.gif&quot;/&gt;&lt;/div&gt;
GIF taken from &lt;a href=&quot;https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/&quot; data-href=&quot;https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/&quot; class=&quot;markup--anchor markup--figure-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;3&lt;/a&gt;
&lt;p name=&quot;e31e&quot; id=&quot;e31e&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;The step in green in charge of creating the hidden states from the input. Instead of passing only one hidden state to the decoders as we did before using &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;attention&lt;/strong&gt;, we pass all the hidden states generated by every “word” of the sentence to the decoding stage. Each hidden state is used in the decoding &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;stage&lt;/strong&gt;, to figure out where the network should pay &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;attention&lt;/strong&gt; to.&lt;/p&gt;
&lt;p name=&quot;55ab&quot; id=&quot;55ab&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;For example, when translating the sentence “&lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;Je suis étudiant”&lt;/strong&gt; to English, requires that the decoding step looks at different words when translating it.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*X5xkbiH-6N-VGeucGK6R5Q.gif&quot; data-width=&quot;600&quot; data-height=&quot;261&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*X5xkbiH-6N-VGeucGK6R5Q.gif&quot;/&gt;&lt;/div&gt;
This gif shows how the weight that is given to each hidden state when translating the sentence “Je suis étudiant” to English. The darker the color is, the more weight is associated to each word. GIF taken from &lt;a href=&quot;https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/&quot; data-href=&quot;https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/&quot; class=&quot;markup--anchor markup--figure-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;3&lt;/a&gt;
&lt;p name=&quot;3a93&quot; id=&quot;3a93&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Or for example, when you translate the sentence “L’accord sur la zone économique européenne a été signé en août 1992.” from French to English, and how much attention it is paid to each input.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*Bq8Dll0nAlzIEWwiS627Ew.png&quot; data-width=&quot;634&quot; data-height=&quot;647&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*Bq8Dll0nAlzIEWwiS627Ew.png&quot;/&gt;&lt;/div&gt;
Translating the sentence “L’accord sur la zone économique européenne a été signé en août 1992.” to English. Image taken from &lt;a href=&quot;https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/&quot; data-href=&quot;https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/&quot; class=&quot;markup--anchor markup--figure-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;3&lt;/a&gt;
&lt;p name=&quot;91a0&quot; id=&quot;91a0&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;But some of the problems that we discussed, still are not solved with RNNs using &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;attention.&lt;/strong&gt; For example, processing inputs (words) in parallel is not possible. For a large corpus of text, this increases the time spent translating the text.&lt;/p&gt;
&lt;h3 name=&quot;8d5d&quot; id=&quot;8d5d&quot; class=&quot;graf graf--h3 graf-after--p&quot;&gt;Convolutional Neural Networks&lt;/h3&gt;
&lt;p name=&quot;8bf9&quot; id=&quot;8bf9&quot; class=&quot;graf graf--p graf-after--h3&quot;&gt;Convolutional Neural Networks help solve these problems. With them we can&lt;/p&gt;
&lt;ul class=&quot;postList&quot;&gt;&lt;li name=&quot;2897&quot; id=&quot;2897&quot; class=&quot;graf graf--li graf-after--p&quot;&gt;Trivial to parallelize (per layer)&lt;/li&gt;
&lt;li name=&quot;8387&quot; id=&quot;8387&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;Exploits local dependencies&lt;/li&gt;
&lt;li name=&quot;3b11&quot; id=&quot;3b11&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;Distance between positions is logarithmic&lt;/li&gt;
&lt;/ul&gt;&lt;p name=&quot;6df9&quot; id=&quot;6df9&quot; class=&quot;graf graf--p graf-after--li&quot;&gt;Some of the most popular neural networks for sequence transduction, Wavenet and Bytenet, are Convolutional Neural Networks.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*www46FWqJCc3OZQKP_QRoQ.gif&quot; data-width=&quot;570&quot; data-height=&quot;262&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*www46FWqJCc3OZQKP_QRoQ.gif&quot;/&gt;&lt;/div&gt;
Wavenet, model is a Convolutional Neural Network (CNN). Image taken from &lt;a href=&quot;https://deepmind.com/blog/wavenet-generative-model-raw-audio/&quot; data-href=&quot;https://deepmind.com/blog/wavenet-generative-model-raw-audio/&quot; class=&quot;markup--anchor markup--figure-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;10&lt;/a&gt;
&lt;p name=&quot;8880&quot; id=&quot;8880&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;The reason why Convolutional Neural Networks can work in parallel, is that each word on the input can be processed at the same time and does not necessarily depend on the previous words to be translated. Not only that, but the “distance” between the output word and any input for a CNN is in the order of &lt;a href=&quot;https://www.youtube.com/watch?v=rBCqOTEfxvg&amp;amp;t=8m21s&quot; data-href=&quot;https://www.youtube.com/watch?v=rBCqOTEfxvg&amp;amp;t=8m21s&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener nofollow&quot; target=&quot;_blank&quot;&gt;&lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;log(N)&lt;/strong&gt;&lt;/a&gt; — that is the size of the height of the tree generated from the output to the input (you can see it on the GIF above. That is much better than the distance of the output of a RNN and an input, which is on the order of &lt;a href=&quot;https://www.youtube.com/watch?v=rBCqOTEfxvg&amp;amp;t=8m21s&quot; data-href=&quot;https://www.youtube.com/watch?v=rBCqOTEfxvg&amp;amp;t=8m21s&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener nofollow&quot; target=&quot;_blank&quot;&gt;&lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;N&lt;/strong&gt;&lt;/a&gt;&lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;.&lt;/strong&gt;&lt;/p&gt;
&lt;p name=&quot;fdc4&quot; id=&quot;fdc4&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;The problem is that Convolutional Neural Networks do not necessarily help with the problem of figuring out the problem of dependencies when translating sentences. That’s why &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;Transformers&lt;/strong&gt; were created, they are a combination of both CNNs with attention.&lt;/p&gt;
&lt;h3 name=&quot;1d7e&quot; id=&quot;1d7e&quot; class=&quot;graf graf--h3 graf-after--p&quot;&gt;Transformers&lt;/h3&gt;
&lt;p name=&quot;3df5&quot; id=&quot;3df5&quot; class=&quot;graf graf--p graf-after--h3&quot;&gt;To solve the problem of parallelization, Transformers try to solve the problem by using Convolutional Neural Networks together with &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;attention models.&lt;/strong&gt; Attention boosts the speed of how fast the model can translate from one sequence to another.&lt;/p&gt;
&lt;p name=&quot;c3cd&quot; id=&quot;c3cd&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Let’s take a look at how &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;Transformer&lt;/strong&gt; works. Transformer is a model that uses &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;attention&lt;/strong&gt; to boost the speed. More specifically, it uses &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;self-attention.&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*Aqcm4iX3AQNWx9Zb-z7o1Q.png&quot; data-width=&quot;1127&quot; data-height=&quot;294&quot; data-is-featured=&quot;true&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*Aqcm4iX3AQNWx9Zb-z7o1Q.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*Aqcm4iX3AQNWx9Zb-z7o1Q.png&quot;/&gt;&lt;/div&gt;
The Transformer. Image taken from &lt;a href=&quot;http://jalammar.github.io/illustrated-transformer/&quot; data-href=&quot;http://jalammar.github.io/illustrated-transformer/&quot; class=&quot;markup--anchor markup--figure-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;4&lt;/a&gt;
&lt;p name=&quot;90a2&quot; id=&quot;90a2&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Internally, the Transformer has a similar kind of architecture as the previous models above. But the Transformer consists of six encoders and six decoders.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*V2435M1u0tiSOz4nRBfl4g.png&quot; data-width=&quot;1218&quot; data-height=&quot;793&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*V2435M1u0tiSOz4nRBfl4g.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*V2435M1u0tiSOz4nRBfl4g.png&quot;/&gt;&lt;/div&gt;
Image taken from &lt;a href=&quot;http://jalammar.github.io/illustrated-transformer/&quot; data-href=&quot;http://jalammar.github.io/illustrated-transformer/&quot; class=&quot;markup--anchor markup--figure-anchor&quot; rel=&quot;noopener nofollow&quot; target=&quot;_blank&quot;&gt;4&lt;/a&gt;
&lt;p name=&quot;796c&quot; id=&quot;796c&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Each encoder is very similar to each other. All encoders have the same architecture. Decoders share the same property, i.e. they are also very similar to each other. Each encoder consists of two layers: &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;Self-attention&lt;/strong&gt; and a feed Forward Neural Network.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*HaGTuYfNHWg45GZbTBnVSA.png&quot; data-width=&quot;792&quot; data-height=&quot;411&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*HaGTuYfNHWg45GZbTBnVSA.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*HaGTuYfNHWg45GZbTBnVSA.png&quot;/&gt;&lt;/div&gt;
Image taken from &lt;a href=&quot;http://jalammar.github.io/illustrated-transformer/&quot; data-href=&quot;http://jalammar.github.io/illustrated-transformer/&quot; class=&quot;markup--anchor markup--figure-anchor&quot; rel=&quot;noopener nofollow&quot; target=&quot;_blank&quot;&gt;4&lt;/a&gt;
&lt;p name=&quot;b86f&quot; id=&quot;b86f&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;The encoder’s inputs first flow through a &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;self-attention&lt;/strong&gt; layer. It helps the encoder look at other words in the input sentence as it encodes a specific word. The decoder has both those layers, but between them is an attention layer that helps the decoder focus on relevant parts of the input sentence.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*QcTbVCVPj4WFnqvvWU5-hQ.png&quot; data-width=&quot;407&quot; data-height=&quot;264&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*QcTbVCVPj4WFnqvvWU5-hQ.png&quot;/&gt;&lt;/div&gt;
Image taken from &lt;a href=&quot;http://jalammar.github.io/illustrated-transformer/&quot; data-href=&quot;http://jalammar.github.io/illustrated-transformer/&quot; class=&quot;markup--anchor markup--figure-anchor&quot; rel=&quot;noopener nofollow&quot; target=&quot;_blank&quot;&gt;4&lt;/a&gt;
&lt;h3 name=&quot;44a9&quot; id=&quot;44a9&quot; class=&quot;graf graf--h3 graf-after--figure&quot;&gt;Self-Attention&lt;/h3&gt;
&lt;p name=&quot;3210&quot; id=&quot;3210&quot; class=&quot;graf graf--p graf-after--h3&quot;&gt;&lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;Note:&lt;/strong&gt; This section comes from Jay Allamar &lt;a href=&quot;http://jalammar.github.io/illustrated-transformer/&quot; data-href=&quot;http://jalammar.github.io/illustrated-transformer/&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;blog post&lt;/a&gt;&lt;/p&gt;
&lt;p name=&quot;b597&quot; id=&quot;b597&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Let’s start to look at the various vectors/tensors and how they flow between these components to turn the input of a trained model into an output. As is the case in NLP applications in general, we begin by turning each input word into a vector using an &lt;a href=&quot;https://medium.com/deeper-learning/glossary-of-deep-learning-word-embedding-f90c3cec34ca&quot; data-href=&quot;https://medium.com/deeper-learning/glossary-of-deep-learning-word-embedding-f90c3cec34ca&quot; class=&quot;markup--anchor markup--p-anchor&quot; target=&quot;_blank&quot;&gt;embedding algorithm&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;0*0oTRj6MKAYEs_cT1.png&quot; data-width=&quot;824&quot; data-height=&quot;99&quot; data-action=&quot;zoom&quot; data-action-value=&quot;0*0oTRj6MKAYEs_cT1.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/0*0oTRj6MKAYEs_cT1.png&quot;/&gt;&lt;/div&gt;
Image taken from &lt;a href=&quot;http://jalammar.github.io/illustrated-transformer/&quot; data-href=&quot;http://jalammar.github.io/illustrated-transformer/&quot; class=&quot;markup--anchor markup--figure-anchor&quot; rel=&quot;noopener nofollow&quot; target=&quot;_blank&quot;&gt;4&lt;/a&gt;
&lt;p name=&quot;5082&quot; id=&quot;5082&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Each word is embedded into a vector of size 512. We’ll represent those vectors with these simple boxes.&lt;/p&gt;
&lt;p name=&quot;3223&quot; id=&quot;3223&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;The embedding only happens in the bottom-most encoder. The abstraction that is common to all the encoders is that they receive a list of vectors each of the size 512.&lt;/p&gt;
&lt;p name=&quot;196b&quot; id=&quot;196b&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;In the bottom encoder that would be the word embeddings, but in other encoders, it would be the output of the encoder that’s directly below. After embedding the words in our input sequence, each of them flows through each of the two layers of the encoder.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;0*FVCP6TqLPQeWPZqt.png&quot; data-width=&quot;1082&quot; data-height=&quot;694&quot; data-action=&quot;zoom&quot; data-action-value=&quot;0*FVCP6TqLPQeWPZqt.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/0*FVCP6TqLPQeWPZqt.png&quot;/&gt;&lt;/div&gt;
Image taken from &lt;a href=&quot;http://jalammar.github.io/illustrated-transformer/&quot; data-href=&quot;http://jalammar.github.io/illustrated-transformer/&quot; class=&quot;markup--anchor markup--figure-anchor&quot; rel=&quot;noopener nofollow&quot; target=&quot;_blank&quot;&gt;4&lt;/a&gt;
&lt;p name=&quot;a758&quot; id=&quot;a758&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Here we begin to see one key property of the Transformer, which is that the word in each position flows through its own path in the encoder. There are dependencies between these paths in the self-attention layer. The feed-forward layer does not have those dependencies, however, and thus the various paths can be executed in parallel while flowing through the feed-forward layer.&lt;/p&gt;
&lt;p name=&quot;5315&quot; id=&quot;5315&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Next, we’ll switch up the example to a shorter sentence and we’ll look at what happens in each sub-layer of the encoder.&lt;/p&gt;
&lt;h4 name=&quot;b511&quot; id=&quot;b511&quot; class=&quot;graf graf--h4 graf-after--p&quot;&gt;Self-Attention&lt;/h4&gt;
&lt;p name=&quot;560d&quot; id=&quot;560d&quot; class=&quot;graf graf--p graf-after--h4&quot;&gt;Let’s first look at how to calculate self-attention using vectors, then proceed to look at how it’s actually implemented — using matrices.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*GQzYZuAMWr3lN_IACBfvAA.png&quot; data-width=&quot;1264&quot; data-height=&quot;884&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*GQzYZuAMWr3lN_IACBfvAA.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*GQzYZuAMWr3lN_IACBfvAA.png&quot;/&gt;&lt;/div&gt;
Figuring out relation of words within a sentence and giving the right &lt;strong class=&quot;markup--strong markup--figure-strong&quot;&gt;attention&lt;/strong&gt; to it. Image taken from &lt;a href=&quot;http://web.stanford.edu/class/cs224n/slides/cs224n-2019-lecture14-transformers.pdf&quot; data-href=&quot;http://web.stanford.edu/class/cs224n/slides/cs224n-2019-lecture14-transformers.pdf&quot; class=&quot;markup--anchor markup--figure-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;8&lt;/a&gt;
&lt;p name=&quot;9c0a&quot; id=&quot;9c0a&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;The &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;first step&lt;/strong&gt; in calculating self-attention is to create three vectors from each of the encoder’s input vectors (in this case, the embedding of each word). So for each word, we create a Query vector, a Key vector, and a Value vector. These vectors are created by multiplying the embedding by three matrices that we trained during the training process.&lt;/p&gt;
&lt;p name=&quot;6236&quot; id=&quot;6236&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Notice that these new vectors are smaller in dimension than the embedding vector. Their dimensionality is 64, while the embedding and encoder input/output vectors have dimensionality of 512. They don’t HAVE to be smaller, this is an architecture choice to make the computation of multiheaded attention (mostly) constant.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;0*-P9BdUe2FCSAIpxC.png&quot; data-width=&quot;875&quot; data-height=&quot;552&quot; data-action=&quot;zoom&quot; data-action-value=&quot;0*-P9BdUe2FCSAIpxC.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/0*-P9BdUe2FCSAIpxC.png&quot;/&gt;&lt;/div&gt;
Image taken from &lt;a href=&quot;http://jalammar.github.io/illustrated-transformer/&quot; data-href=&quot;http://jalammar.github.io/illustrated-transformer/&quot; class=&quot;markup--anchor markup--figure-anchor&quot; rel=&quot;noopener nofollow&quot; target=&quot;_blank&quot;&gt;4&lt;/a&gt;
&lt;p name=&quot;3ac0&quot; id=&quot;3ac0&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Multiplying x1 by the WQ weight matrix produces q1, the “query” vector associated with that word. We end up creating a “query”, a “key”, and a “value” projection of each word in the input sentence.&lt;/p&gt;
&lt;p name=&quot;59e3&quot; id=&quot;59e3&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;What are the “query”, “key”, and “value” vectors?&lt;/p&gt;
&lt;p name=&quot;0883&quot; id=&quot;0883&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;They’re abstractions that are useful for calculating and thinking about attention. Once you proceed with reading how attention is calculated below, you’ll know pretty much all you need to know about the role each of these vectors plays.&lt;/p&gt;
&lt;p name=&quot;7c78&quot; id=&quot;7c78&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;The &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;second step&lt;/strong&gt; in calculating self-attention is to calculate a score. Say we’re calculating the self-attention for the first word in this example, “Thinking”. We need to score each word of the input sentence against this word. The score determines how much focus to place on other parts of the input sentence as we encode a word at a certain position.&lt;/p&gt;
&lt;p name=&quot;4ab5&quot; id=&quot;4ab5&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;The score is calculated by taking the dot product of the query vector with the key vector of the respective word we’re scoring. So if we’re processing the self-attention for the word in position #1, the first score would be the dot product of q1 and k1. The second score would be the dot product of q1 and k2.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;0*KlFsyIDK3O54l14X.png&quot; data-width=&quot;685&quot; data-height=&quot;358&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/0*KlFsyIDK3O54l14X.png&quot;/&gt;&lt;/div&gt;
Image taken from &lt;a href=&quot;http://jalammar.github.io/illustrated-transformer/&quot; data-href=&quot;http://jalammar.github.io/illustrated-transformer/&quot; class=&quot;markup--anchor markup--figure-anchor&quot; rel=&quot;noopener nofollow&quot; target=&quot;_blank&quot;&gt;4&lt;/a&gt;
&lt;p name=&quot;7562&quot; id=&quot;7562&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;The &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;third and forth steps&lt;/strong&gt; are to divide the scores by 8 (the square root of the dimension of the key vectors used in the paper — 64. This leads to having more stable gradients. There could be other possible values here, but this is the default), then pass the result through a softmax operation. Softmax normalizes the scores so they’re all positive and add up to 1.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;0*rqWSBLDcJcbMmGs2.png&quot; data-width=&quot;867&quot; data-height=&quot;546&quot; data-action=&quot;zoom&quot; data-action-value=&quot;0*rqWSBLDcJcbMmGs2.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/0*rqWSBLDcJcbMmGs2.png&quot;/&gt;&lt;/div&gt;
Image taken from &lt;a href=&quot;http://jalammar.github.io/illustrated-transformer/&quot; data-href=&quot;http://jalammar.github.io/illustrated-transformer/&quot; class=&quot;markup--anchor markup--figure-anchor&quot; rel=&quot;noopener nofollow&quot; target=&quot;_blank&quot;&gt;4&lt;/a&gt;
&lt;p name=&quot;a103&quot; id=&quot;a103&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;This softmax score determines how much how much each word will be expressed at this position. Clearly the word at this position will have the highest softmax score, but sometimes it’s useful to attend to another word that is relevant to the current word.&lt;/p&gt;
&lt;p name=&quot;5fd1&quot; id=&quot;5fd1&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;The &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;fifth step&lt;/strong&gt; is to multiply each value vector by the softmax score (in preparation to sum them up). The intuition here is to keep intact the values of the word(s) we want to focus on, and drown-out irrelevant words (by multiplying them by tiny numbers like 0.001, for example).&lt;/p&gt;
&lt;p name=&quot;5ec2&quot; id=&quot;5ec2&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;The &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;sixth step&lt;/strong&gt; is to sum up the weighted value vectors. This produces the output of the self-attention layer at this position (for the first word).&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;0*ih2c_llIiOD1-aJN.png&quot; data-width=&quot;786&quot; data-height=&quot;747&quot; data-action=&quot;zoom&quot; data-action-value=&quot;0*ih2c_llIiOD1-aJN.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/0*ih2c_llIiOD1-aJN.png&quot;/&gt;&lt;/div&gt;
Image taken from &lt;a href=&quot;http://jalammar.github.io/illustrated-transformer/&quot; data-href=&quot;http://jalammar.github.io/illustrated-transformer/&quot; class=&quot;markup--anchor markup--figure-anchor&quot; rel=&quot;noopener nofollow&quot; target=&quot;_blank&quot;&gt;4&lt;/a&gt;
&lt;p name=&quot;bfc4&quot; id=&quot;bfc4&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;That concludes the self-attention calculation. The resulting vector is one we can send along to the feed-forward neural network. In the actual implementation, however, this calculation is done in matrix form for faster processing. So let’s look at that now that we’ve seen the intuition of the calculation on the word level.&lt;/p&gt;
&lt;h4 name=&quot;929d&quot; id=&quot;929d&quot; class=&quot;graf graf--h4 graf-after--p&quot;&gt;Multihead attention&lt;/h4&gt;
&lt;p name=&quot;626a&quot; id=&quot;626a&quot; class=&quot;graf graf--p graf-after--h4&quot;&gt;Transformers basically work like that. There are a few other details that make them work better. For example, instead of only paying attention to each other in one dimension, Transformers use the concept of Multihead attention.&lt;/p&gt;
&lt;p name=&quot;972f&quot; id=&quot;972f&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;The idea behind it is that whenever you are translating a word, you may pay different attention to each word based on the type of question that you are asking. The images below show what that means. For example, whenever you are translating “kicked” in the sentence “I kicked the ball”, you may ask “Who kicked”. Depending on the answer, the translation of the word to another language can change. Or ask other questions, like “Did what?”, etc…&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*8H6TqcfHrtNCc9_Qva7xog.png&quot; data-width=&quot;1232&quot; data-height=&quot;682&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*8H6TqcfHrtNCc9_Qva7xog.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*8H6TqcfHrtNCc9_Qva7xog.png&quot;/&gt;&lt;/div&gt;
</description>
<pubDate>Mon, 11 Mar 2019 00:17:41 +0000</pubDate>
<dc:creator>giacaglia</dc:creator>
<og:title>Transformers</og:title>
<og:url>https://medium.com/@giacaglia/transformers-141e32e69591</og:url>
<og:image>https://cdn-images-1.medium.com/max/1200/1*Aqcm4iX3AQNWx9Zb-z7o1Q.png</og:image>
<og:description>Transformers are a type of neural network architecture that have been gaining popularity. Transformers were recently used by OpenAI in…</og:description>
<og:type>article</og:type>
<dc:format>text/html</dc:format>
<dc:identifier>https://medium.com/@giacaglia/transformers-141e32e69591</dc:identifier>
</item>
<item>
<title>Apple Maps Flyover Reverse Engineering</title>
<link>https://github.com/retroplasma/flyover-reverse-engineering</link>
<guid isPermaLink="true" >https://github.com/retroplasma/flyover-reverse-engineering</guid>
<description>&lt;div class=&quot;Box-body p-6&quot;&gt;
&lt;article class=&quot;markdown-body entry-content&quot; itemprop=&quot;text&quot;&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; href=&quot;https://user-images.githubusercontent.com/46618410/53480398-0a4d5100-3a73-11e9-983e-99f24ebdf674.png&quot;&gt;&lt;img width=&quot;100%&quot; alt=&quot;Santa Monica Pier&quot; title=&quot;Santa Monica Pier&quot; src=&quot;https://user-images.githubusercontent.com/46618410/53480398-0a4d5100-3a73-11e9-983e-99f24ebdf674.png&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This is an attempt to reverse-engineer &lt;em&gt;Flyover&lt;/em&gt; (= 3D satellite mode) from Apple Maps. Main goal is to document the results and to provide code that emerges.&lt;/p&gt;
&lt;h4&gt;Motivation&lt;/h4&gt;
&lt;p&gt;Noticed differences between Google Earth and Apple Flyover during &lt;a href=&quot;https://github.com/retroplasma/earth-reverse-engineering&quot;&gt;previous project&lt;/a&gt;. Extreme example:&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Google Earth&lt;/th&gt;
&lt;th&gt;Apple Flyover&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;a target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; href=&quot;https://user-images.githubusercontent.com/46618410/52183147-db89e500-27fc-11e9-9c75-fc78ff6cda58.jpg&quot;&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46618410/52183147-db89e500-27fc-11e9-9c75-fc78ff6cda58.jpg&quot; alt=&quot;Google&quot; title=&quot;Google&quot; width=&quot;100%&quot;/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; href=&quot;https://user-images.githubusercontent.com/46618410/52183145-d62c9a80-27fc-11e9-9396-2d0acb34ec03.jpg&quot;&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/46618410/52183145-d62c9a80-27fc-11e9-9396-2d0acb34ec03.jpg&quot; alt=&quot;Apple&quot; title=&quot;Apple&quot; width=&quot;100%&quot;/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h4&gt;General&lt;/h4&gt;
&lt;p&gt;Data is stored in map tiles. These five tile styles are used for Flyover:&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Type&lt;/th&gt;
&lt;th&gt;Purpose&lt;/th&gt;
&lt;th&gt;URL structure&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;C3M&lt;/td&gt;
&lt;td&gt;Texture, Mesh, Transformation(, Animation)&lt;/td&gt;
&lt;td&gt;🅐(?|&amp;amp;)style=15&amp;amp;v=⓿&amp;amp;region=❶&amp;amp;x=❷&amp;amp;y=❸&amp;amp;z=❹&amp;amp;h=❺&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;C3MM 1&lt;/td&gt;
&lt;td&gt;Metadata&lt;/td&gt;
&lt;td&gt;🅐(?|&amp;amp;)style=14&amp;amp;v=⓿&amp;amp;part=❻&amp;amp;region=❶&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;C3MM 2&lt;/td&gt;
&lt;td&gt;Metadata&lt;/td&gt;
&lt;td&gt;🅐(?|&amp;amp;)style=52&amp;amp;v=⓿&amp;amp;region=❶&amp;amp;x=❷&amp;amp;y=❸&amp;amp;z=❹&amp;amp;h=❺&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;DTM 1&lt;/td&gt;
&lt;td&gt;Terrain/Surface/Elevation&lt;/td&gt;
&lt;td&gt;🅐(?|&amp;amp;)style=16&amp;amp;v=⓿&amp;amp;region=❶&amp;amp;x=❷&amp;amp;y=❸&amp;amp;z=❹&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;DTM 2&lt;/td&gt;
&lt;td&gt;Terrain/Surface/Elevation&lt;/td&gt;
&lt;td&gt;🅐(?|&amp;amp;)style=17&amp;amp;v=⓿&amp;amp;size=❼&amp;amp;scale=❽&amp;amp;x=❷&amp;amp;y=❸&amp;amp;z=❹&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;ul&gt;&lt;li&gt;🅐: URL prefix from resource manifest&lt;/li&gt;
&lt;li&gt;⓿: Version from resource manifest or altitude manifest using region&lt;/li&gt;
&lt;li&gt;❶: Region ID from altitude manifest&lt;/li&gt;
&lt;li&gt;❷❸❹: Map tile numbers (&lt;a href=&quot;https://en.wikipedia.org/wiki/Tiled_web_map&quot; rel=&quot;nofollow&quot;&gt;tiled web map&lt;/a&gt; scheme)&lt;/li&gt;
&lt;li&gt;❺: Height/altitude index. Probably from C3MM&lt;/li&gt;
&lt;li&gt;❻: Incremental part number&lt;/li&gt;
&lt;li&gt;❼❽: Size/scale. Not sure where its values come from&lt;/li&gt;
&lt;/ul&gt;&lt;h4&gt;Resource hierarchy&lt;/h4&gt;
&lt;pre&gt;
&lt;code&gt;ResourceManifest
└─ AltitudeManifest
   ├─ C3MM
   │  └─ C3M
   └─ DTM?
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Focusing on C3M(M) for now. DTMs are just images with a footer; they're probably used for the &lt;a href=&quot;https://user-images.githubusercontent.com/46618410/53483243-fdcbf700-3a78-11e9-8fc0-ad6cfa8c57cd.png&quot; rel=&quot;nofollow&quot;&gt;grid&lt;/a&gt; that is displayed when Maps is loading.&lt;/p&gt;
&lt;h4&gt;Status&lt;/h4&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/retroplasma/flyover-reverse-engineering/projects/1&quot;&gt;Here&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;Code&lt;/h4&gt;
&lt;p&gt;This repository is structured as follows:&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Directory&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://github.com/retroplasma/flyover-reverse-engineering/blob/master/cmd&quot;&gt;cmd&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;command line programs&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://github.com/retroplasma/flyover-reverse-engineering/blob/master/pkg&quot;&gt;pkg&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;most of the actual code&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://github.com/retroplasma/flyover-reverse-engineering/blob/master/proto&quot;&gt;proto&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;protobuf files&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://github.com/retroplasma/flyover-reverse-engineering/blob/master/scripts&quot;&gt;scripts&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;additional scripts&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://github.com/retroplasma/flyover-reverse-engineering/blob/master/vendor&quot;&gt;vendor&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;dependencies&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h5&gt;Install&lt;/h5&gt;
&lt;p&gt;Clone repo including submodules and install &lt;a href=&quot;https://golang.org/&quot; rel=&quot;nofollow&quot;&gt;Go&lt;/a&gt;. Then edit &lt;a href=&quot;https://github.com/retroplasma/flyover-reverse-engineering/blob/master/config.json&quot;&gt;config.json&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;automatically on macOS:
&lt;ul&gt;&lt;li&gt;&lt;code&gt;./scripts/get_config_macos.sh &amp;gt; config.json&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;or manually:
&lt;/li&gt;
&lt;/ul&gt;&lt;h5&gt;Command line programs&lt;/h5&gt;
&lt;p&gt;Here are some independent command line programs that use code from &lt;a href=&quot;https://github.com/retroplasma/flyover-reverse-engineering/blob/master/pkg&quot;&gt;pkg&lt;/a&gt;:&lt;/p&gt;
&lt;h6&gt;Export OBJ (proof of concept, inefficient)&lt;/h6&gt;
&lt;p&gt;This exports Santa Monica Pier to &lt;code&gt;./export&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;go run cmd/poc-export-obj/main.go
&lt;/code&gt;
&lt;/pre&gt;
&lt;h6&gt;Authenticate URLs&lt;/h6&gt;
&lt;p&gt;This authenticates a URL using parameters from &lt;code&gt;config.json&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;go run cmd/auth/main.go [url]
&lt;/code&gt;
&lt;/pre&gt;
&lt;h6&gt;Parse C3M file&lt;/h6&gt;
&lt;p&gt;This parses a C3M v3 file, decompresses meshes, reads JPEG textures and produces a struct that contains a textured 3d model:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;go run cmd/parse-c3m/main.go [file]
&lt;/code&gt;
&lt;/pre&gt;
&lt;h6&gt;Parse C3MM file (work in progress)&lt;/h6&gt;
&lt;pre&gt;
&lt;code&gt;go run cmd/parse-c3mm/main.go [file]
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4&gt;Files on macOS&lt;/h4&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;~/Library/Preferences/com.apple.GEO.plist&lt;/code&gt;
&lt;ul&gt;&lt;li&gt;last resource manifest url&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;~/Library/Caches/GeoServices/Resources/altitude-*.xml&lt;/code&gt;
&lt;ul&gt;&lt;li&gt;defines regions for c3m urls&lt;/li&gt;
&lt;li&gt;&lt;code&gt;altitude-*.xml&lt;/code&gt; url in resource manifest&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;~/Library/Containers/com.apple.geod/Data/Library/Caches/com.apple.geod/MapTiles/MapTiles.sqlitedb&lt;/code&gt;
&lt;ul&gt;&lt;li&gt;local map tile cache&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/System/Library/PrivateFrameworks/GeoServices.framework/GeoServices&lt;/code&gt;
&lt;ul&gt;&lt;li&gt;resource manifest base url, networking, caching, authentication&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/System/Library/PrivateFrameworks/VectorKit.framework/VectorKit&lt;/code&gt;
&lt;ul&gt;&lt;li&gt;parsers, decoders&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/System/Library/PrivateFrameworks/GeoServices.framework/XPCServices/com.apple.geod.xpc&lt;/code&gt;
&lt;ul&gt;&lt;li&gt;loads &lt;code&gt;GeoServices&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/Applications/Maps.app/Contents/MacOS/Maps&lt;/code&gt;
&lt;ul&gt;&lt;li&gt;loads &lt;code&gt;VectorKit&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h4&gt;Important&lt;/h4&gt;
&lt;p&gt;THE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;
</description>
<pubDate>Mon, 11 Mar 2019 00:10:17 +0000</pubDate>
<dc:creator>benzinschleuder</dc:creator>
<og:image>https://avatars3.githubusercontent.com/u/46618410?s=400&amp;v=4</og:image>
<og:type>object</og:type>
<og:title>retroplasma/flyover-reverse-engineering</og:title>
<og:url>https://github.com/retroplasma/flyover-reverse-engineering</og:url>
<og:description>Reversing Apple's 3D satellite mode. Contribute to retroplasma/flyover-reverse-engineering development by creating an account on GitHub.</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://github.com/retroplasma/flyover-reverse-engineering</dc:identifier>
</item>
<item>
<title>Melatonin&amp;#039;s Effect on Skin and Hair</title>
<link>https://thelri.org/blog-and-news/melatonin-s-effect-on-skin-and-hair/</link>
<guid isPermaLink="true" >https://thelri.org/blog-and-news/melatonin-s-effect-on-skin-and-hair/</guid>
<description>&lt;p&gt;&lt;strong&gt;Melatonin and General Aging&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Melatonin, a hormone primarily secreted by the pineal gland in the brain, is also produced in skin and hair cells.  Melatonin is more than just the “sleep hormone” -- it regulates the circadian rhythm, which affects many metabolic and endocrine processes.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Melatonin, and the circadian rhythm more generally, plays a role in staving off aging. Melatonin levels decline as we age, and correspondingly circadian rhythms become less regular.[1][2][3]  Mice with mutations damaging their circadian rhythm have accelerated-aging syndromes, with obesity, diabetes, muscle loss, and shortened lifespans.[4][5][6] Supplementing melatonin in rodents (or administering extracts from the pineal gland[7], or grafts from fetal pineal glands[8]) has been found to extend lifespan[9][10], prolong fertility[11], reduce cancer incidence[12], reduce obesity and insulin resistance[13], and improve neurological recovery from brain injury.[14]  Melatonin and compounds that act along the same pathway have potential as aging-preventative drugs.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Melatonin administration also improves skin resistance to damage (such as from UV rays) and increases hair growth.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Melatonin and Skin&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;In both in-vitro skin culture experiments and human studies, administering melatonin prior to exposure to UV radiation increases cell survival and reduces oxidative damage.[15] Topical melatonin applied to skin 15 minutes prior to exposure to UV radiation completely prevented skin redness (erythema) in a small randomized double-blind study of human subjects.[16][17]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Melatonin and Hair: Animal and Human Studies&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Melatonin also affects hair growth, as the hair growth cycle in mammals is under circadian control. As with other circadian cycles, the hair growth cycle becomes dysregulated and lower in amplitude with age.  Mice whose circadian rhythms are damaged (via removal of the pineal gland or knockout of a circadian clock gene) show impaired hair growth as part of an accelerated aging syndrome.[17][18] When pinealectomized rats are given injections of melatonin, their hair growth recovers to that of healthy rats.[19] Melatonin administration has been found to increase hair growth in a variety of mammals: weasels[20], ewes [21], dogs[22], minks[23], goats[24], rabbits[25],  raccoon dogs[26], and foxes [27], administered either orally or via subcutaneous implants.  There’s a good evolutionary rationale for this effect: melatonin is the hormone that signals the onset of darkness, which triggers many mammals to grow thick winter coats as days grow shorter. In animals which grow white coats in winter and brown coats in summer, experimenters can trigger the growth of the white winter coat by administering melatonin.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;There’s even evidence that topical melatonin can reverse hair loss in humans.  In a randomized double-blind study of 40 women with hair loss, melatonin solution applied to the scalp increased hair growth significantly relative to placebo.[28]  In an open-label, uncontrolled study of topical melatonin involving 1891 male and female patients with androgenic alopecia, at 3 months 61% of patients had no hair loss, compared to 12.2% at the start; 22% had new hair growth at 3 months compared to 4% at baseline.  The incidence of seborrheic dermatitis also declined, from 34.5% at baseline to 9.9% at 3 months.[29]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;[1]Waldhauser, F., J. Ková, and E. Reiter. &quot;Age-related changes in melatonin levels in humans and its potential consequences for sleep disorders.&quot;&lt;/span&gt; &lt;em&gt;&lt;span&gt;Experimental gerontology&lt;/span&gt;&lt;/em&gt; &lt;span&gt;33.7-8 (1998): 759-772.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;[2]REITER, RUSSEL J., et al. &quot;Age-associated reduction in nocturnal pineal melatonin levels in female rats.&quot;&lt;/span&gt; &lt;em&gt;&lt;span&gt;Endocrinology&lt;/span&gt;&lt;/em&gt; &lt;span&gt;109.4 (1981): 1295-1297.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;[3]Mattis, Joanna, and Amita Sehgal. &quot;Circadian rhythms, sleep, and disorders of aging.&quot;&lt;/span&gt; &lt;em&gt;&lt;span&gt;Trends in Endocrinology &amp;amp; Metabolism&lt;/span&gt;&lt;/em&gt; &lt;span&gt;27.4 (2016): 192-203.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;[4]Marcheva, Biliana, et al. &quot;Disruption of the clock components CLOCK and BMAL1 leads to hypoinsulinaemia and diabetes.&quot;&lt;/span&gt; &lt;em&gt;&lt;span&gt;Nature&lt;/span&gt;&lt;/em&gt; &lt;span&gt;466.7306 (2010): 627.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;[5]Kondratov, Roman V., et al. &quot;Early aging and age-related pathologies in mice deficient in BMAL1, the core component of the circadian clock.&quot;&lt;/span&gt; &lt;em&gt;&lt;span&gt;Genes &amp;amp; development&lt;/span&gt;&lt;/em&gt; &lt;span&gt;20.14 (2006): 1868-1873.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;[6]Turek, Fred W., et al. &quot;Obesity and metabolic syndrome in circadian Clock mutant mice.&quot;&lt;/span&gt; &lt;em&gt;&lt;span&gt;Science&lt;/span&gt;&lt;/em&gt; &lt;span&gt;308.5724 (2005): 1043-1045.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;[7]Dilman, V. M., et al. &quot;Increase in lifespan of rats following polypeptide pineal extract treatment.&quot;&lt;/span&gt; &lt;em&gt;&lt;span&gt;Experimentelle Pathologie&lt;/span&gt;&lt;/em&gt; &lt;span&gt;17.9 (1979): 539-545.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;[8]Hurd, Mark W., and Martin R. Ralph. &quot;The significance of circadian organization for longevity in the golden hamster.&quot;&lt;/span&gt; &lt;em&gt;&lt;span&gt;Journal of biological rhythms&lt;/span&gt;&lt;/em&gt; &lt;span&gt;13.5 (1998): 430-436.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;[9]Oxenkrug, G., P. Requintina, and S. Bachurin. &quot;Antioxidant and antiaging activity of N‐acetylserotonin and melatonin in the in vivo models.&quot;&lt;/span&gt; &lt;em&gt;&lt;span&gt;Annals of the New York Academy of Sciences&lt;/span&gt;&lt;/em&gt; &lt;span&gt;939.1 (2001): 190-199.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;[10]Anisimov, Vladimir N., et al. &quot;Melatonin increases both life span and tumor incidence in female CBA mice.&quot;&lt;/span&gt; &lt;em&gt;&lt;span&gt;The Journals of Gerontology Series A: Biological Sciences and Medical Sciences&lt;/span&gt;&lt;/em&gt; &lt;span&gt;56.7 (2001): B311-B323.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;[11]Meredith, S., et al. &quot;Long-term supplementation with melatonin delays reproductive senescence in rats, without an effect on number of primordial follicles☆.&quot; Experimental gerontology 35.3 (2000): 343-352.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;[12]El-Domeiri, Ali AH, and Tapas K. Das Gupta. &quot;Reversal by melatonin of the effect of pinealectomy on tumor growth.&quot;&lt;/span&gt; &lt;em&gt;&lt;span&gt;Cancer research&lt;/span&gt;&lt;/em&gt; &lt;span&gt;33.11 (1973): 2830-2833.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;[13]Wolden-Hanson, T., et al. &quot;Daily melatonin administration to middle-aged male rats suppresses body weight, intraabdominal adiposity, and plasma leptin and insulin independent of food intake and total body fat.&quot;&lt;/span&gt; &lt;em&gt;&lt;span&gt;Endocrinology&lt;/span&gt;&lt;/em&gt;&lt;span&gt;141.2 (2000): 487-497.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;[14]Kilic, Ertugrul, et al. &quot;Pinealectomy aggravates and melatonin administration attenuates brain damage in focal ischemia.&quot;&lt;/span&gt; &lt;em&gt;&lt;span&gt;Journal of Cerebral Blood Flow &amp;amp; Metabolism&lt;/span&gt;&lt;/em&gt; &lt;span&gt;19.5 (1999): 511-516.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;[15]&lt;/span&gt;&lt;span&gt;Kleszczynski, Konrad, and Tobias W. Fischer. &quot;Melatonin and human skin aging.&quot; Dermato-endocrinology 4.3 (2012): 245-252.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;[16]&lt;/span&gt;&lt;span&gt;Fischer, Tobias W., et al. &quot;Melatonin as a major skin protectant: from free radical scavenging to DNA damage repair.&quot;&lt;/span&gt; &lt;em&gt;&lt;span&gt;Experimental dermatology&lt;/span&gt;&lt;/em&gt; &lt;span&gt;17.9 (2008): 713-730.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;[17]Geyfman, Mikhail, and Bogi Andersen. &quot;Clock genes, hair growth and aging.&quot;&lt;/span&gt; &lt;em&gt;&lt;span&gt;Aging (Albany NY)&lt;/span&gt;&lt;/em&gt; &lt;span&gt;2.3 (2010): 122.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;[18]Kondratov, Roman V., et al. &quot;Early aging and age-related pathologies in mice deficient in BMAL1, the core componentof the circadian clock.&quot;&lt;/span&gt; &lt;em&gt;&lt;span&gt;Genes &amp;amp; development&lt;/span&gt;&lt;/em&gt; &lt;span&gt;20.14 (2006): 1868-1873.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;[19]Eşrefoğlu, Mukaddes, et al. &quot;Potent therapeutic effect of melatonin on aging skin in pinealectomized rats.&quot;&lt;/span&gt; &lt;em&gt;&lt;span&gt;Journal of pineal research&lt;/span&gt;&lt;/em&gt; &lt;span&gt;39.3 (2005): 231-237.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;[20]Rust, Charles C., and Roland K. Meyer. &quot;Hair color, molt, and testis size in male, short-tailed weasels treated with melatonin.&quot;&lt;/span&gt; &lt;em&gt;&lt;span&gt;Science&lt;/span&gt;&lt;/em&gt; &lt;span&gt;165.3896 (1969): 921-922.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;[21]Santiago-Moreno, J., et al. &quot;Effect of constant-release melatonin implants and prolonged exposure to a long day photoperiod on prolactin secretion and hair growth in mouflon (Ovis gmelini musimon).&quot;&lt;/span&gt; &lt;em&gt;&lt;span&gt;Domestic animal endocrinology&lt;/span&gt;&lt;/em&gt; &lt;span&gt;26.4 (2004): 303-314.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;[22]FRANK, LINDA A., KEITH A. HNILICA, and JACK W. OLIVER. &quot;Adrenal steroid hormone concentrations in dogs with hair cycle arrest (Alopecia X) before and during treatment with melatonin and mitotane.&quot;&lt;/span&gt; &lt;em&gt;&lt;span&gt;Veterinary dermatology&lt;/span&gt;&lt;/em&gt; &lt;span&gt;15.5 (2004): 278-284.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;[23]Allain, D., and J. Rougeot. &quot;Induction of autumn moult in mink (Mustela vison Peale and Beauvois) with melatonin.&quot;&lt;/span&gt; &lt;em&gt;&lt;span&gt;Reproduction Nutrition Développement&lt;/span&gt;&lt;/em&gt; &lt;span&gt;20.1A (1980): 197-201.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;[24]Dicks, P., A. J. F. Russel, and G. A. Lincoln. &quot;The effect of melatonin implants administered from December until April, on plasma prolactin, triiodothyronine and thyroxine concentrations and on the timing of the spring moult in cashmere goats.&quot;&lt;/span&gt; &lt;em&gt;&lt;span&gt;Animal Science&lt;/span&gt;&lt;/em&gt; &lt;span&gt;60.2 (1995): 239-247.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;[25]Lanszki, József, et al. &quot;The effects of melatonin treatment on wool production and hair follicle cycle in angora rabbits.&quot;&lt;/span&gt; &lt;em&gt;&lt;span&gt;Animal Research&lt;/span&gt;&lt;/em&gt; &lt;span&gt;50.1 (2001): 79-89.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;[26]Xiao, Yongjun, et al. &quot;Effects of melatonin implants on winter fur growth and testicular recrudescence in adult male raccoon dogs (Nyctereutes procyonoides).&quot;&lt;/span&gt; &lt;em&gt;&lt;span&gt;Journal of pineal research&lt;/span&gt;&lt;/em&gt;&lt;span&gt;20.3 (1996): 148-156.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;[27]&lt;span&gt;Smith, A. J., et al. &quot;Effects of melatonin implantation on spermatogenesis, the moulting cycle and plasma concentrations of melatonin, LH, prolactin and testosterone in the male blue fox (Alopex lagopus).&quot; &lt;/span&gt;&lt;em&gt;Journal of reproduction and fertility&lt;/em&gt;&lt;span&gt; 79.2 (1987): 379-390.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;[28]Fischer, T. W., et al. &quot;Melatonin increases anagen hair rate in women with androgenetic alopecia or diffuse alopecia: results of a pilot randomized controlled trial.&quot;&lt;/span&gt; &lt;em&gt;&lt;span&gt;British Journal of Dermatology&lt;/span&gt;&lt;/em&gt; &lt;span&gt;150.2 (2004): 341-345.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;[29]Fischer, Tobias W., et al. &quot;Topical melatonin for treatment of androgenetic alopecia.&quot; &lt;em&gt;International journal of trichology&lt;/em&gt; 4.4 (2012): 236.&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Sun, 10 Mar 2019 23:59:40 +0000</pubDate>
<dc:creator>apsec112</dc:creator>
<og:image>images/thelri-social.jpg</og:image>
<dc:format>text/html</dc:format>
<dc:identifier>https://thelri.org/blog-and-news/melatonin-s-effect-on-skin-and-hair/</dc:identifier>
</item>
<item>
<title>India Imposes Complete Ban on Solid Plastic Waste Imports</title>
<link>https://thewire.in/environment/india-solid-plastic-import-banned</link>
<guid isPermaLink="true" >https://thewire.in/environment/india-solid-plastic-import-banned</guid>
<description>&lt;p&gt;&lt;strong&gt;New Delhi:&lt;/strong&gt; A loophole that was apparently responsible for India’s imports of solid plastic waste quadrupling in the last fiscal year (FY) has been closed after the government amended the rules. Though solid plastic waste imports were banned in 2015, the Centre allowed agencies in special economic zones (SEZ) to import them in 2016.&lt;/p&gt;
&lt;p&gt;According to reports, the Hazardous and Other Wastes (Management and Transboundary Movement) Rules, 2016 was amended to the effect that units in SEZs or export oriented units were also banned from importing solid plastic ways.&lt;/p&gt;
&lt;p&gt;In January, it was reported that &lt;a href=&quot;https://thewire.in/environment/plastic-import-india-pet-bottles-ban-increase&quot;&gt;India’s plastic imports had increased from 12,000 tonnes in 2016-17 FY to 48,000 in the 2017-18 FY&lt;/a&gt;. While India has recycles a higher percentage of its plastic waste than most countries, 44% of its plastic waste is still not recycled. The rising imports only made matters worse.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://timesofindia.indiatimes.com/home/environment/pollution/india-bans-import-of-plastic-waste/articleshow/68293186.cms&quot;&gt;The environment ministry&lt;/a&gt; admitted as much, when the “huge gap between waste generation and recycling capacity” in the country was attributed as one reason for the complete ban. Officials said India’s “commitment to completely phase out single-use plastic by 2022” was another reason for the new amendments.&lt;/p&gt;
&lt;p&gt;The increased imports of solid plastic waste to India was a result of China’s complete ban on importing such waste. China was the largest importer previously and the vacuum left by it was occupied by countries such as Malaysia and India.&lt;/p&gt;
&lt;p&gt;&lt;ins&gt;Also Read: &lt;a href=&quot;https://thewire.in/environment/plastic-import-india-pet-bottles-ban-increase&quot;&gt;How Are India’s Plastic Waste Imports Increasing?&lt;/a&gt;&lt;/ins&gt;&lt;/p&gt;
&lt;p&gt;The &lt;a href=&quot;http://www.pib.nic.in/Pressreleaseshare.aspx?PRID=1567682&quot;&gt;amendments announced on Wednesday&lt;/a&gt; also exempted exporters of silk from requiring permission from the Ministry of Environment, Forest and Climate Change.&lt;/p&gt;
&lt;p&gt;“Electrical and electronic assemblies and components manufactured in and exported from India, if found defective can now be imported back into the country, within a year of export, without obtaining permission from the Ministry of Environment, Forest and Climate Change,” the ministry said in a release.&lt;/p&gt;
&lt;p&gt;Additionally, industries that do not require consent under Water (Prevention and Control of Pollution) Act 1974 and Air (Prevention and Control of Pollution) Act 1981 were exempted from requiring authorisation also under the Hazardous and Other Wastes (Management &amp;amp; Transboundary Movement) Rules, 2016. This exemption would be on the condition that hazardous and other wastes generated by the industries are handed over to the authorised actual users, waste collectors or disposal facilities.&lt;/p&gt;
</description>
<pubDate>Sun, 10 Mar 2019 20:48:18 +0000</pubDate>
<dc:creator>howard941</dc:creator>
<og:title>India Imposes Complete Ban on Solid Plastic Waste Imports</og:title>
<og:url>https://thewire.in/environment/india-solid-plastic-import-banned</og:url>
<og:image>https://cdn.thewire.in/wp-content/uploads/2019/03/07160549/plastic-bottles-115071_1920-800x400.jpg</og:image>
<og:description>A loophole that was apparently responsible for plastic waste imports quadrupling was closed, the environment ministry said.</og:description>
<dc:format>text/html</dc:format>
<dc:identifier>https://thewire.in/environment/india-solid-plastic-import-banned</dc:identifier>
</item>
<item>
<title>Peak California</title>
<link>https://medium.com/@byrnehobart/peak-california-7cf97baecaf0</link>
<guid isPermaLink="true" >https://medium.com/@byrnehobart/peak-california-7cf97baecaf0</guid>
<description>&lt;div class=&quot;uiScale uiScale-ui--regular uiScale-caption--regular u-flexCenter u-marginVertical24 u-fontSize15 js-postMetaLockup&quot;&gt;
&lt;div class=&quot;u-flex0&quot;&gt;&lt;a class=&quot;link u-baseColor--link avatar&quot; href=&quot;https://medium.com/@byrnehobart?source=post_header_lockup&quot; data-action=&quot;show-user-card&quot; data-action-source=&quot;post_header_lockup&quot; data-action-value=&quot;94cdf41ea82&quot; data-action-type=&quot;hover&quot; data-user-id=&quot;94cdf41ea82&quot; dir=&quot;auto&quot;&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/fit/c/100/100/0*cc_cKcl1cnKw7cGK.&quot; class=&quot;avatar-image u-size50x50&quot; alt=&quot;Go to the profile of Byrne Hobart&quot;/&gt;&lt;/a&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;p name=&quot;e210&quot; id=&quot;e210&quot; class=&quot;graf graf--p graf-after--h3&quot;&gt;California is hard to beat. There are richer places with worse weather, there are (a few) nicer climates with worse economies, but it’s really hard to find any place on planet earth that’s nicer to live in &lt;em class=&quot;markup--em markup--p-em&quot;&gt;and&lt;/em&gt; to work in. There’s a consensus among smart people that the Bay Area is the place to be, and they relocate accordingly.&lt;/p&gt;
&lt;p name=&quot;9d58&quot; id=&quot;9d58&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Smart people are generally right on average. But whenever the consensus among smart people is that you can make a given decision without thinking too hard, beware: the flip side of intelligence is the ability to rationalize bad decisions rather than admit your mistakes. It took a lot of intellectual horsepower to rationalize Superbowl ads and &lt;a href=&quot;https://en.wikipedia.org/wiki/Pets.com&quot; data-href=&quot;https://en.wikipedia.org/wiki/Pets.com&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;free shipping for cat litter&lt;/a&gt; in 2000; it took a similar amount of braininess to believe that subprime mortgages could be aggregated into securities that were as safe as treasuries.&lt;/p&gt;
&lt;p name=&quot;b3f1&quot; id=&quot;b3f1&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;There are three related problems that make California economically tenuous, and a fourth that makes the situation worse:&lt;/p&gt;
&lt;ol class=&quot;postList&quot;&gt;&lt;li name=&quot;a959&quot; id=&quot;a959&quot; class=&quot;graf graf--li graf-after--p&quot;&gt;It’s no longer the best place in the world to start a startup.&lt;/li&gt;
&lt;li name=&quot;1373&quot; id=&quot;1373&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;The gains from the existing tech industry increasingly accrue to a) passive investors, and b) lucky landlords.&lt;/li&gt;
&lt;li name=&quot;de5c&quot; id=&quot;de5c&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;The state government is a levered bet on tech compensation.&lt;/li&gt;
&lt;li name=&quot;e0bb&quot; id=&quot;e0bb&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;These three problems, which are interrelated, won’t show visible symptoms until well after they’re terminally un-fixable.&lt;/li&gt;
&lt;/ol&gt;&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*VzpfniCc8S1ygMj2Z8CaUA.png&quot; data-width=&quot;960&quot; data-height=&quot;472&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*VzpfniCc8S1ygMj2Z8CaUA.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*VzpfniCc8S1ygMj2Z8CaUA.png&quot;/&gt;&lt;/div&gt;
Here in New York we prize elegant design and high production values.
&lt;p name=&quot;9385&quot; id=&quot;9385&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;The good news, such as it is: part of my bear case on the Bear Republic is that its most valuable assets can just pick up and leave, so it’s not a bad place to be right now. If you get a nice offer from a big tech company, by all means, go to Mountain View or Los Gatos or even San Francisco. (If you can afford Pacific Heights rents and ride-sharing everywhere, you can pretend you don’t live in SF at all.)&lt;/p&gt;
&lt;p name=&quot;e33f&quot; id=&quot;e33f&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;But if you’re considering starting a company, maybe take a look at Austin, Brooklyn, Denver, or Seattle.[1] All of these places have some of the same problems as California, but at a smaller scale.&lt;/p&gt;
&lt;h3 name=&quot;0f1f&quot; id=&quot;0f1f&quot; class=&quot;graf graf--h3 graf-after--p&quot;&gt;The California Cycle&lt;/h3&gt;
&lt;p name=&quot;434d&quot; id=&quot;434d&quot; class=&quot;graf graf--p graf-after--h3&quot;&gt;Since the late 1970s, California has benefited from a virtuous cycle that goes like this:&lt;/p&gt;
&lt;ol class=&quot;postList&quot;&gt;&lt;li name=&quot;a4ec&quot; id=&quot;a4ec&quot; class=&quot;graf graf--li graf-after--p&quot;&gt;A group of smart people decide to solve a challenging technical and business problem.&lt;/li&gt;
&lt;li name=&quot;86e1&quot; id=&quot;86e1&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;They raise some money, form a company, and dole out stock options to early employees.&lt;/li&gt;
&lt;li name=&quot;597b&quot; id=&quot;597b&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;The company grows, and either sells or goes public.&lt;/li&gt;
&lt;li name=&quot;5bab&quot; id=&quot;5bab&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;The founders retire, get bored after a couple days, and return to step two, except this time they’re the ones writing checks.&lt;/li&gt;
&lt;/ol&gt;&lt;p name=&quot;6b4a&quot; id=&quot;6b4a&quot; class=&quot;graf graf--p graf-after--li&quot;&gt;Every generation of technology has been disproportionately funded by the founders of companies in the previous generation. Kleiner and Perkins of Kleiner Perkins were early employees at Fairchild and Hewlett-Packard. Fairchild and Intel begot Mike Markkula, who retired from his options at 32 and then un-retired after he met Jobs and Wozniak. Sun Microsystems begat Khosla Ventures and Andy Bechtolsheim, an angel investor so aggressive he once wrote a check to &lt;a href=&quot;https://en.wikipedia.org/wiki/Andy_Bechtolsheim#Investments&quot; data-href=&quot;https://en.wikipedia.org/wiki/Andy_Bechtolsheim#Investments&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;a company that didn’t exist yet&lt;/a&gt;. (It worked out.)&lt;/p&gt;
&lt;p name=&quot;9579&quot; id=&quot;9579&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;For this cycle to work, your ecosystem needs three things: big companies that can buy out small companies and produce a cash windfall; rich people who are still hungry to get richer but don’t want to be CEOs any more; and new companies that can survive long enough to raise funding in order to join the other two categories. The cycle further benefits from the &lt;a href=&quot;https://medium.com/@byrnehobart/alchian-allen-and-agglomeration-explaining-economic-inequality-and-nice-golf-courses-in-vegas-379eae5ddc5&quot; data-href=&quot;https://medium.com/@byrnehobart/alchian-allen-and-agglomeration-explaining-economic-inequality-and-nice-golf-courses-in-vegas-379eae5ddc5&quot; class=&quot;markup--anchor markup--p-anchor&quot; target=&quot;_blank&quot;&gt;Alchian-Allen effect&lt;/a&gt;: agglomerating industries have higher productivity, which raises the cost of living and prices out other industries, raising concentration over time.&lt;/p&gt;
&lt;p name=&quot;0eb9&quot; id=&quot;0eb9&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;New, small companies are the most fragile and least visible part of this ecosystem. They’re hard to see because the best companies keep a low profile (a CEO with time to cultivate an image is not a CEO busy writing code or talking to customers), and because reporters are always willing to talk about a company filling the role of Hot New Startup. When Genentech is a startup, they’ll write about Genentech; when there aren’t any new Genentechs, they’ll write about Theranos instead.&lt;/p&gt;
&lt;p name=&quot;3be6&quot; id=&quot;3be6&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;New companies are essential because whenever there’s a new technology or a new way of organizing a business, it’s unclear whether the result will be a bigger industry or a smaller one. When Uber first came out, you could debate whether it would 10x the size of the car-hire market, or just reduce ROI to below the cost of capital by creating an unlimited supply of drivers. (You can still have this debate, but it’s harder to deny the upside opportunity.)&lt;/p&gt;
&lt;p name=&quot;62fa&quot; id=&quot;62fa&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Since startups raise the variance within whatever industry they’re started in, the natural constituency for them is someone who doesn’t have capital deployed in the industry. If you’re an asset owner, you want low volatility. Since a startup is a call option on whatever business it will turn into, it benefits from higher volatility.&lt;/p&gt;
&lt;p name=&quot;c508&quot; id=&quot;c508&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Historically, startups have created a constant supply of volatility for tech companies; the next generation is always cannibalizing the previous one. So chip companies in the 1970s created the PC companies of the 80s, but PC companies sourced cheaper and cheaper chips, commoditizing the product until Intel managed to fight back. Meanwhile, the OS turned PCs into a commodity, then search engines and social media turned the &lt;em class=&quot;markup--em markup--p-em&quot;&gt;OS&lt;/em&gt; into a commodity, and presumably this process will continue indefinitely.&lt;/p&gt;
&lt;p name=&quot;6a8b&quot; id=&quot;6a8b&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;What that looks like from a financial markets perspective is that tech companies go through a golden age where they’re growing fast and trading at a sky-high multiple, then suddenly they’re trading at a below-market multiple because their revenue growth is flat at best and unstable at worst. What’s worrisome is that, if we have fewer startups, this valuation compression will start to happen later, or not at all. If you’re just looking at public markets, all you’ll see is that the numbers have never been better, and if you’re looking at private markets, you’ll see that the bubble you were worried about has gotten less frothy.&lt;/p&gt;
&lt;h3 name=&quot;2726&quot; id=&quot;2726&quot; class=&quot;graf graf--h3 graf-after--p&quot;&gt;Land and Burn Rates&lt;/h3&gt;
&lt;p name=&quot;03ce&quot; id=&quot;03ce&quot; class=&quot;graf graf--p graf-after--h3&quot;&gt;The key reason that startups are getting harder to start in California is that the incremental cost of existing and growing has gotten higher. There are two monopolists to blame: landlords, and platform companies.&lt;/p&gt;
&lt;p name=&quot;57ec&quot; id=&quot;57ec&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Landlords are the most annoying. A California landlord is generally not much more skilled or talented than other landlords; they just happened to own property in a place with a high concentration of engineers (thanks to good schools) and hippies (thanks to those schools’ liberal arts programs, as well as the fact that you can sleep outdoors in SF year-round). The engineers ensure that there’s growing demand for property; the hippies conspire with landlords to limit supply. Perhaps the funniest case study was that it took four months for San Francisco to determine that &lt;a href=&quot;https://sf.curbed.com/2018/6/11/17451078/historic-mission-laundromat-2918-mission-review&quot; data-href=&quot;https://sf.curbed.com/2018/6/11/17451078/historic-mission-laundromat-2918-mission-review&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;a laundromat&lt;/a&gt; was not an historic site that the city could not allow to be demolished.[2]&lt;/p&gt;
&lt;p name=&quot;d394&quot; id=&quot;d394&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;I’ve lived in the Midwest, on the Texas/Mexico border, and in New York, and when I moved to San Francisco I was surprised to see that anti-immigrant sentiment was quite socially-acceptable there. Literally, on my way to work, I’d see propaganda posters about how people like me who’d moved to San Francisco had better pack up and leave — or else. I can understand some level of discomfort with changes in one’s community brought about by immigration, whether it’s smart people from foreign countries or just people from other cities. But the policies SF has chosen are just plain pathological: the city reduces the supply of housing to discourage gentrifiers from moving in, so gentrifiers bid against natives. The rising cost-of-living prices more industries out, making tech companies more dominant, and the rising share of tech company residents means that tech comp increasingly sets the market price for housing. If San Francisco wants to eliminate gentrification, they’re going to have to accept becoming very poor. If they want to mitigate the impact of gentrification, they should start building some big &lt;a href=&quot;https://en.wikipedia.org/wiki/Stuyvesant_Town%E2%80%93Peter_Cooper_Village&quot; data-href=&quot;https://en.wikipedia.org/wiki/Stuyvesant_Town%E2%80%93Peter_Cooper_Village&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;Stuy Town&lt;/a&gt;-style high-density apartment blocks.&lt;/p&gt;
&lt;p name=&quot;74fe&quot; id=&quot;74fe&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Real estate supply restrictions have a perverse effect. Per the law of supply and demand, they mean that demand is immediately and indefinitely reflected in price. Since demand is set by the incomes of people who think they’ll be earning that amount of money for the next year, the cash flow characteristics of a city’s businesses determine what effect high real estate prices have. In New York, finance and law start paying you well right away. It’s rare for a startup financial company to produce negative cash flow for owners after the first year. Other industries in New York have worse immediate cash flow prospects — media, fashion, and music, for example.&lt;/p&gt;
&lt;p name=&quot;80b2&quot; id=&quot;80b2&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;For a city to have a thriving arts scene, you need some combination of:&lt;/p&gt;
&lt;ol class=&quot;postList&quot;&gt;&lt;li name=&quot;09b9&quot; id=&quot;09b9&quot; class=&quot;graf graf--li graf-after--p&quot;&gt;Families or nightlife, both of which produce demand for reasonably educated workers who work non-traditional or variable-schedule jobs, either as babysitters or bartenders.&lt;/li&gt;
&lt;li name=&quot;d46c&quot; id=&quot;d46c&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;Cheap neighborhoods that aren’t unsafe. My current neighborhood, Williamsburg, fit this role ten years ago.&lt;/li&gt;
&lt;li name=&quot;4a41&quot; id=&quot;4a41&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;Upside, either in the form of selling out or marrying someone with a boring but lucrative job.&lt;/li&gt;
&lt;/ol&gt;&lt;p name=&quot;c0a7&quot; id=&quot;c0a7&quot; class=&quot;graf graf--p graf-after--li&quot;&gt;New York manages to combine all of these in clever ways. For example, the New York restaurant industry benefits from two dinner shifts, because finance and media/fashion are basically in two different time zones. Traders leave work at 5 and have expense-account dinners at 5:30; by the time the table’s cleared at 8 it’s time for the ad agency and fashion people to show up for &lt;em class=&quot;markup--em markup--p-em&quot;&gt;their&lt;/em&gt; expense-account dinner. New York’s nightlife feeds into family formation, maintaining a balance between demand for babysitters and bartenders, while also keeping wages up by reducing the supply.[3] And in a broader sense, status in New York is a progressive tax on wealth because the city is full of opportunities for conspicuous consumption. You can earn below the poverty line and save money, at least if you’re healthy and able-bodied; but as Tom Wolfe pointed out back in the 80s, you can also slowly go broke earning a million dollars a year.&lt;/p&gt;
&lt;p name=&quot;27e7&quot; id=&quot;27e7&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Startups are not like New York’s low-paying jobs; there is a “marriage” market, in the sense that one exit opportunity is to meet a Corp Dev matchmaker and decide where you want to settle down. But that takes a while, and unlike in New York, the economically disadvantaged party is the one paying for the dates, at least in terms of opportunity cost.&lt;/p&gt;
&lt;p name=&quot;ef23&quot; id=&quot;ef23&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;There’s anecdotal evidence of this. When Airbnb was just starting out, the founders spent years being nearly broke. It’s hard to imagine someone living in the Bay Area spending a long time “nearly broke” today; they’d spend too much on rent and have to move back home or get a BigCo job. Y Combinator has implicitly acknowledged this. When the program started in 2005, they’d offer founders a maximum of $20,000 to spend the summer running a startup. Now it’s $120,000. That’s a 14% compounded growth rate in the minimum amount of cash on hand needed to start a company. YC has also grown, but it’s hard to count on one organization to hold back the tide here. &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;As long as higher rents raise the cost of starting a pre-revenue company, fewer people will join them, so more people will join established companies, where they’ll earn market salaries and continue to push up rents.&lt;/strong&gt;&lt;/p&gt;
&lt;p name=&quot;7387&quot; id=&quot;7387&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;And one of the things they’ll do there is optimize ad loads, which places another tax on startups. More dangerously, this is an incremental tax on growth rather than a fixed tax on headcount, so it puts pressure on out-year valuations, not just upfront cash flow. According to Social Capital’s &lt;a href=&quot;https://s3-us-west-2.amazonaws.com/socialcapital-annual-letters/Social+Capital+Interim+Annual+Letter,+2018.pdf&quot; data-href=&quot;https://s3-us-west-2.amazonaws.com/socialcapital-annual-letters/Social+Capital+Interim+Annual+Letter,+2018.pdf&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;2018 letter&lt;/a&gt;, almost 40% of VC money goes to advertising on the largest search, social, and e-commerce channels. Those channels have adapted to a world where they’re the best place to scale because they have the biggest audience, which means there’s more money for them in optimizing their revenue capture. Thus, ads get better-targeted, ad loads rise over time, more content moves into the walled garden, and it becomes progressively harder not to pay an economically efficient (read: very high) ad price.&lt;/p&gt;
&lt;p name=&quot;1af2&quot; id=&quot;1af2&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Digital landlords at least homesteaded their land and made it worth renting on. Unfortunately, they’re a lot better at charging the Laffer optimal tax rate on their tenants’ profits.&lt;/p&gt;
&lt;h3 name=&quot;d9a3&quot; id=&quot;d9a3&quot; class=&quot;graf graf--h3 graf-after--p&quot;&gt;Public Pension Funds: A Slow-Motion Run on the Bank&lt;/h3&gt;
&lt;p name=&quot;3640&quot; id=&quot;3640&quot; class=&quot;graf graf--p graf-after--h3&quot;&gt;You may notice that my thesis is about “California,” but my comments have been restricted to the Bay Area. There’s a reason for this: the Bay has provided vast income and capital gains tax upside for California in the last few decades, which the state has habitually spent as quickly as it can. Government spending tends to be sticky, especially because one of the easiest ways for governments to give away money is to get higher cash flow today in exchange for taking on higher future liabilities.&lt;/p&gt;
&lt;p name=&quot;384c&quot; id=&quot;384c&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;The final piece of the California puzzle — after the real estate tax on low-cash flow startups and the platform tax on growth-stage startups — is the literal taxes on everybody.&lt;/p&gt;
&lt;p name=&quot;131b&quot; id=&quot;131b&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;There are two key points to understand about California’s fiscal situation:&lt;/p&gt;
&lt;ol class=&quot;postList&quot;&gt;&lt;li name=&quot;e1c2&quot; id=&quot;e1c2&quot; class=&quot;graf graf--li graf-after--p&quot;&gt;Income taxes, which are &lt;a href=&quot;https://lao.ca.gov/reports/2018/3805/ca-tax-system-041218.pdf#page=12&quot; data-href=&quot;https://lao.ca.gov/reports/2018/3805/ca-tax-system-041218.pdf#page=12&quot; class=&quot;markup--anchor markup--li-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;volatile&lt;/a&gt;, are a large proportion of state revenue. And capital gains taxes are in the high-single digits. Since capital gains are the integral of income over time (they’re a change in the market’s estimation of the net present value of all future income from a company), they’re particularly cyclical.&lt;/li&gt;
&lt;li name=&quot;0df5&quot; id=&quot;0df5&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;California’s public pensions are &lt;a href=&quot;https://www.hoover.org/research/californias-pension-indigestion-appetite-fine-dining-while-stuck-fast-food-budget&quot; data-href=&quot;https://www.hoover.org/research/californias-pension-indigestion-appetite-fine-dining-while-stuck-fast-food-budget&quot; class=&quot;markup--anchor markup--li-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;massively underfunded&lt;/a&gt; (the $769bn in that article is an overestimate, but it’s directionally right).&lt;/li&gt;
&lt;/ol&gt;&lt;p name=&quot;fc25&quot; id=&quot;fc25&quot; class=&quot;graf graf--p graf-after--li&quot;&gt;Now, consider the incentives for someone living in California during a recession. Budgets are getting cut, but state worker headcount and compensation are sticky due to heavy unionization, so the net result is that there’s a reduction in new services offered. At best, this means the state government is stuck solving whatever problems were most pressing back when their budget was growing; at worst, it means that the state is just a jobs program. While there’s pressure to lay off employees, there’s heightened pressure from those employees not to do so — the stability of a government job is particularly desirable when unemployment is high.&lt;/p&gt;
&lt;p name=&quot;20ce&quot; id=&quot;20ce&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;So something has to give: taxes have to rise. As taxes go up, people start to consider living elsewhere. (We already see this with people who run mature companies; they like to retire to Florida or something for a year before they close a sale, so they avoid the capital gains tax.) Every time the tax base diminishes, the tax burden on the people who stay behind goes up.&lt;/p&gt;
&lt;p name=&quot;5ee3&quot; id=&quot;5ee3&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Big companies won’t leave right away. The network effects of the Bay are too strong. They may grow other offices, and employees will transfer, but the Stanford/Berkeley/Caltech-to-Big Tech Company pipeline will persist. However, the current crop of big companies will still be the big tech companies in 2030 and 2040.&lt;/p&gt;
&lt;p name=&quot;4214&quot; id=&quot;4214&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Over the long term, California’s future looks like New York excluding New York City, albeit with nicer weather. There will be big companies that slowly decline, the tax base will deplete, and politicians will have to find ways to raise taxes on the remaining citizens while getting them to tolerate the same or diminished levels of government services.[4] Eventually, this will reduce the price of housing, but not in a way that revitalizes startups. Instead, we’ll have a dynamic where a house that used to be 50% too expensive at a million dollars will still be 50% too expensive at $750,000.&lt;/p&gt;
&lt;h3 name=&quot;4e18&quot; id=&quot;4e18&quot; class=&quot;graf graf--h3 graf-after--p&quot;&gt;Conclusions&lt;/h3&gt;
&lt;p name=&quot;5120&quot; id=&quot;5120&quot; class=&quot;graf graf--p graf-after--h3&quot;&gt;Once upon a time, California was cheap. In the 50s and 60s, it was a place where you could work part-time to fund your &lt;a href=&quot;https://www.amazon.com/dp/B008IU9IVG/ref=dp-kindle-redirect?_encoding=UTF8&amp;amp;btkr=1&quot; data-href=&quot;https://www.amazon.com/dp/B008IU9IVG/ref=dp-kindle-redirect?_encoding=UTF8&amp;amp;btkr=1&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;biker gang&lt;/a&gt;. In the 70s, you could work part-time to fund your &lt;a href=&quot;https://www.amazon.com/dp/B00LFZ84PC/ref=dp-kindle-redirect?_encoding=UTF8&amp;amp;btkr=1&quot; data-href=&quot;https://www.amazon.com/dp/B00LFZ84PC/ref=dp-kindle-redirect?_encoding=UTF8&amp;amp;btkr=1&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;revolutionary terrorist cell&lt;/a&gt;. Such side projects are infeasible today. If you’re going to run a massive bombing campaign out of a house in San Francisco, you’ll need to raise at least a mid-six figure seed round.&lt;/p&gt;
&lt;p name=&quot;8f64&quot; id=&quot;8f64&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;You can see the decline over time:&lt;/p&gt;
&lt;ul class=&quot;postList&quot;&gt;&lt;li name=&quot;c783&quot; id=&quot;c783&quot; class=&quot;graf graf--li graf-after--p&quot;&gt;Semiconductor startups, which are capital-intensive once they start manufacturing, were mostly founded by people leaving other hardware companies.&lt;/li&gt;
&lt;li name=&quot;eb73&quot; id=&quot;eb73&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;PC companies got founded in garages.&lt;/li&gt;
&lt;li name=&quot;298c&quot; id=&quot;298c&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;The biggest of the Internet companies got founded in garages and trailers, yes — by procrastinating grad students who had stipends and university-provided computers.&lt;/li&gt;
&lt;li name=&quot;6634&quot; id=&quot;6634&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;Mid-2000s consumer web companies economized on labor by hiring friends, and raised small seed rounds. When Y Combinator started, funding was explicitly modeled on grad student stipends.&lt;/li&gt;
&lt;li name=&quot;91e2&quot; id=&quot;91e2&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;Today, YC thinks it takes $150k to fund a startup through Demo Day and beyond.&lt;/li&gt;
&lt;/ul&gt;&lt;p name=&quot;d2f1&quot; id=&quot;d2f1&quot; class=&quot;graf graf--p graf-after--li&quot;&gt;As the market for talent gets more efficient and the supply of housing remains constrained, the required burn rate for startups will rise, making them an increasingly expensive indulgence. Rewind the Airbnb story but with higher rents and it’s a story about three guys who ran a novelty website for a while before they all got jobs designing marketing microsites for Oracle.&lt;/p&gt;
&lt;p name=&quot;feb4&quot; id=&quot;feb4&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;California’s politicians will always be able to say “We’re so happy to be the home of companies like X, Y, and Z.” It will take them a long, long time to notice that “X, Y, and Z” used to change every five years, then it was every ten, then it was the same companies for a generation. By the time they figure out that the big new companies aren’t being founded nearby, the next big startup cluster will already have had its first round of exits, and Austin or Portland or Raleigh will be full of angel investors and small VC shops itching to perpetuate the local startup cycle.&lt;/p&gt;
&lt;p name=&quot;fd55&quot; id=&quot;fd55&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Californians will end up like the landed gentry in interwar England. Lovely houses, illustrious history, and no conceivable way to pay their bills.&lt;/p&gt;
&lt;p name=&quot;ce2c&quot; id=&quot;ce2c&quot; class=&quot;graf graf--p graf-after--p graf--trailing&quot;&gt;&lt;em class=&quot;markup--em markup--p-em&quot;&gt;Don’t miss the next story.&lt;/em&gt; &lt;a href=&quot;https://us15.list-manage.com/subscribe?u=ebcca019646af0aef311450c7&amp;amp;id=074da9dcef&quot; data-href=&quot;https://us15.list-manage.com/subscribe?u=ebcca019646af0aef311450c7&amp;amp;id=074da9dcef&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;nofollow noopener nofollow noopener&quot; target=&quot;_blank&quot;&gt;&lt;em class=&quot;markup--em markup--p-em&quot;&gt;Sign up&lt;/em&gt;&lt;/a&gt; &lt;em class=&quot;markup--em markup--p-em&quot;&gt;for my occasional email newsletter.&lt;/em&gt;&lt;/p&gt;
</description>
<pubDate>Sun, 10 Mar 2019 18:35:14 +0000</pubDate>
<dc:creator>cobbzilla</dc:creator>
<og:title>Peak California</og:title>
<og:url>https://medium.com/@byrnehobart/peak-california-7cf97baecaf0</og:url>
<og:image>https://cdn-images-1.medium.com/max/1200/1*VzpfniCc8S1ygMj2Z8CaUA.png</og:image>
<og:description>California is hard to beat. There are richer places with worse weather, there are (a few) nicer climates with worse economies, but it’s…</og:description>
<og:type>article</og:type>
<dc:format>text/html</dc:format>
<dc:identifier>https://medium.com/@byrnehobart/peak-california-7cf97baecaf0</dc:identifier>
</item>
</channel>
</rss>