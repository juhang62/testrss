<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=hnrss.org%2Fnewest%3Fpoints%3D200&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://hnrss.org/newest?points=200" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>Hacker News: Newest</title>
<link>https://news.ycombinator.com/newest</link>
<description>Hacker News RSS</description>
<item>
<title>Stop Learning Frameworks</title>
<link>https://sizovs.net/2018/12/17/stop-learning-frameworks/</link>
<guid isPermaLink="true" >https://sizovs.net/2018/12/17/stop-learning-frameworks/</guid>
<description>&lt;p&gt;We are developers. We need to stay up to date with technology. Every day, we learn programming languages, frameworks, and libraries. The more modern tools we know — the better.&lt;/p&gt;
&lt;p&gt;Keeping up to date with Angular, React, Vue, Riot, Ember, Knockout is fun.&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;But we are wasting our time.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr/&gt;&lt;p&gt;Time is the most precious resource we have. Time is limited, nonrenewable and you cannot buy more of it.&lt;/p&gt;
&lt;p&gt;Technology, like fashion, is changing at the speed of light. To catch up, we need to run very fast. This race has no winners because it has no end.&lt;/p&gt;
&lt;img src=&quot;https://sizovs.net/images/wolf.jpg&quot;/&gt; © The Wolf of Wall Street (2013) by Martin Scorsese
&lt;p&gt;&lt;strong&gt;My mentor once taught me a lesson:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Mentor: “Ed, what are you doing?”&lt;/p&gt;
&lt;p&gt;Me (proud): “I am reading a book about building modern Java apps with GWT.”&lt;/p&gt;
&lt;p&gt;Mentor: “What for?”&lt;/p&gt;
&lt;p&gt;Me: “As a Java developer, I need to keep up with trends. GWT is a thing.”&lt;/p&gt;
&lt;p&gt;Mentor: “What technology book did you read before GWT?”&lt;/p&gt;
&lt;p&gt;Me: “It’s a 500-page-long Apache Tapestry book. Tapestry was a thing.”&lt;/p&gt;
&lt;p&gt;Mentor: “Is Tapestry still a thing?”&lt;/p&gt;
&lt;p&gt;Me: “Not anymore. GWT is a thing.”&lt;/p&gt;
&lt;p&gt;Mentor: “Can you re-use Tapestry skills to solve current problems?”&lt;/p&gt;
&lt;p&gt;Me: “No, no one is using it today.”&lt;/p&gt;
&lt;p&gt;Mentor: “Does Tapestry knowledge help you understand GWT better?”&lt;/p&gt;
&lt;p&gt;Me: “No, it doesn’t. But I see some overlapping patterns.”&lt;/p&gt;
&lt;p&gt;Mentor: “It’s Design Patterns. Do they help you solve current problems?”&lt;/p&gt;
&lt;p&gt;Me: “Yes. Many of them.”&lt;/p&gt;
&lt;p&gt;Mentor: “Technology come and go, but it has a lot in common. Set priorities right. Invest 80% of your learning time in fundamentals. Leave 20% for frameworks, libraries and tools.”&lt;/p&gt;
&lt;p&gt;Me: “Hmm… Only 20% for frameworks, libraries, and tools?”&lt;/p&gt;
&lt;p&gt;Mentor: “Yes. You’ll learn them at work anyway while solving problems.”&lt;/p&gt;
&lt;p&gt;Me: “Thanks.”&lt;/p&gt;
&lt;p&gt;Mentor: “You’ll thank me later.”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This advice has changed my life&lt;/strong&gt;. I removed all framework books from &lt;a href=&quot;https://www.goodreads.com/eduardsi&quot;&gt;my bookshelf&lt;/a&gt;. The guilt pile shrank from 50 to 0 books. What a relief!&lt;/p&gt;
&lt;p&gt;I bought a set of evergreen books. These books took 80% of my learning time:&lt;/p&gt;
&lt;p&gt;I also bought a single book on the current technology. &lt;strong&gt;The Lindy effect&lt;/strong&gt; suggested that Spring Framework must be a good investment:&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;The future life expectancy of technology is proportional to its current age. Every extra period of survival implies a longer remaining life expectancy.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The longer a technology is on the market, the safer investment it is.&lt;/p&gt;
&lt;p&gt;Don’t rush to learn new technology – it has a high probability of dying.&lt;/p&gt;
&lt;p&gt;Time will show which technology is worth investing. Time is your best advisor. Learn to wait.&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;Ten years have passed since then. I helped 50 different software projects. Thanks to the advice, everything I learn is portable across companies, teams, domains. My knowledge is still relevant today. &lt;strong&gt;I did not waste my time&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;All projects seem different unless you look under the surface:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Programming languages are different, but design smells are alike.&lt;/li&gt;
&lt;li&gt;Frameworks are different, but the same design patterns shine through.&lt;/li&gt;
&lt;li&gt;Developers are different, but rules of dealing with people are uniform.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Remember – frameworks, libraries and tools come and go. Time is precious.&lt;/p&gt;
&lt;img src=&quot;https://sizovs.net/images/intime.png&quot;/&gt; © In Time (2011) by Andrew Niccol
&lt;p&gt;&lt;strong&gt;Invest your golden time in transferable skills. Skills that will always be relevant.&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;del&gt;Microservices frameworks&lt;/del&gt; Evolutionary Architecture&lt;/li&gt;
&lt;li&gt;&lt;del&gt;New programming language&lt;/del&gt; Clean Code, Design Patterns, DDD&lt;/li&gt;
&lt;li&gt;&lt;del&gt;LeSS, SAFe&lt;/del&gt; Lean manufacturing principles&lt;/li&gt;
&lt;li&gt;&lt;del&gt;Hystrix&lt;/del&gt; Fault Tolerance Patterns&lt;/li&gt;
&lt;li&gt;&lt;del&gt;Docker&lt;/del&gt; Continuous Delivery&lt;/li&gt;
&lt;li&gt;&lt;del&gt;Angular&lt;/del&gt; Web, HTTP and REST&lt;/li&gt;
&lt;/ul&gt;</description>
<pubDate>Tue, 18 Dec 2018 14:58:16 +0000</pubDate>
<dc:creator>ingve</dc:creator>
<og:description>We are developers. We need to stay up to date with technology. Every day, we learn programming languages, frameworks, and libraries. The more modern tools we know — the better.</og:description>
<og:title>Stop Learning Frameworks</og:title>
<og:url>http://sizovs.net/2018/12/17/stop-learning-frameworks/</og:url>
<og:type>website</og:type>
<og:image>http://sizovs.net/images/me.png</og:image>
<dc:format>text/html</dc:format>
<dc:identifier>https://sizovs.net/2018/12/17/stop-learning-frameworks/</dc:identifier>
</item>
<item>
<title>SpaceX Is Raising $500M at a $30.5B Valuation</title>
<link>https://www.wsj.com/articles/elon-musks-spacex-is-raising-500-million-in-funding-11545142054</link>
<guid isPermaLink="true" >https://www.wsj.com/articles/elon-musks-spacex-is-raising-500-million-in-funding-11545142054</guid>
<description>&lt;p&gt; Elon Musk’s rocket company, Space Exploration Technologies Corp., is set to raise $500 million at a $30.5 billion valuation, in a bid to help get its internet-service business off the ground, according to people familiar with the fundraising.&lt;/p&gt; &lt;p&gt;The Hawthorne, Calif., company, known as SpaceX, is raising the capital from existing shareholders and new investor Baillie Gifford &amp;amp; Co., one of the people said. The Scottish money-management firm is one of the largest investors in another Musk-led company, Tesla Inc., with about...
  &lt;/p&gt;</description>
<pubDate>Tue, 18 Dec 2018 14:17:52 +0000</pubDate>
<dc:creator>dcgudeman</dc:creator>
<og:title>Elon Musk’s SpaceX Is Raising $500 Million in Funding</og:title>
<og:description>Elon Musk’s rocket company, Space Exploration Technologies, is set to raise $500 million at a $30.5 billion valuation, in a bid to help get a satellite-internet service off the ground.</og:description>
<og:url>https://www.wsj.com/articles/elon-musks-spacex-is-raising-500-million-in-funding-11545142054</og:url>
<og:image>https://si.wsj.net/public/resources/images/B3-CR487_spacex_SOC_20181217235123.jpg</og:image>
<og:type>article</og:type>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.wsj.com/articles/elon-musks-spacex-is-raising-500-million-in-funding-11545142054</dc:identifier>
</item>
<item>
<title>Glitter bomb tricks parcel thieves</title>
<link>https://www.bbc.com/news/technology-46604625</link>
<guid isPermaLink="true" >https://www.bbc.com/news/technology-46604625</guid>
<description>&lt;figure class=&quot;media-landscape has-caption full-width lead&quot;&gt;&lt;span class=&quot;image-and-copyright-container&quot;&gt;
                
                &lt;img class=&quot;js-image-replace&quot; alt=&quot;Mark Rober youtube&quot; src=&quot;https://ichef.bbci.co.uk/news/320/cpsprodpb/160A3/production/_104857209_mediaitem104857208.jpg&quot; width=&quot;976&quot; height=&quot;549&quot;/&gt;&lt;span class=&quot;off-screen&quot;&gt;Image copyright&lt;/span&gt;
                 &lt;span class=&quot;story-image-copyright&quot;&gt;Mark Rober&lt;/span&gt;
                
            &lt;/span&gt;
            
            &lt;figcaption class=&quot;media-caption&quot;&gt;&lt;span class=&quot;off-screen&quot;&gt;Image caption&lt;/span&gt;
                &lt;span class=&quot;media-caption__text&quot;&gt;
                    Mark Rober worked on the Mars Curiosity Rover at Nasa
                &lt;/span&gt;
            &lt;/figcaption&gt;&lt;/figure&gt;&lt;p class=&quot;story-body__introduction&quot;&gt;A former Nasa engineer spent six months building a glitter bomb trap to trick thieves after some parcels were stolen from his doorstep.&lt;/p&gt;&lt;p&gt;The device, hidden in an Apple Homepod box, used four smartphones, a circuit board and 1lb (453g) of glitter.&lt;/p&gt;&lt;p&gt;Mark Rober, who is now a YouTuber, caught the original thieves on his home security camera.&lt;/p&gt;&lt;p&gt;He decided to take action after the police said they were unable to investigate the case.&lt;/p&gt;&lt;h2 class=&quot;story-body__crosshead&quot;&gt;Smelly surprise&lt;/h2&gt;&lt;p&gt;He designed the elaborate bomb so that it would be activated when the package in which it was hidden was opened by thieves. The phone cameras and microphones would record the moment. &lt;/p&gt;&lt;p&gt;The device contained an accelerometer to detect motion.&lt;/p&gt;&lt;p&gt;When the parcel was jostled, the device would check the GPS signal to see if it had been moved from its spot.&lt;/p&gt;&lt;p&gt;If it had, then it would send a signal to activate the phones and start recording.&lt;/p&gt;&lt;p&gt;The glitter was in a cup that spun round on a motor when released as the box was opened.&lt;/p&gt;&lt;p&gt;The device was also engineered to squirt a tube of strong-smelling fart spray every 30 seconds.&lt;/p&gt;&lt;p&gt;The package was left on Mr Rober's porch with a label saying it had been sent by &quot;Kevin McCallister&quot; - the boy played by Macaulay Culkin in the 1990 movie Home Alone.&lt;/p&gt;&lt;p&gt;It was stolen on several occasions and re-set to explode and capture the footage every time. On every occasion, the thieves abandoned the package once it had been triggered and they or their property had been doused in glitter.&lt;/p&gt;&lt;p&gt;Mr Rober's YouTube video has so far had more than six million views.&lt;/p&gt;&lt;p&gt;The former Nasa engineer said: &quot;If anyone was going to make a revenge bait package and over-engineer the crap out of it, it was going to be me.&quot;&lt;/p&gt;&lt;p&gt;Last week, Amazon announced that it is &lt;a href=&quot;https://www.bbc.co.uk/news/technology-46552611&quot; class=&quot;story-body__link&quot;&gt;working with police in New Jersey to combat parcel theft crime&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Officers are planting dummy boxes fitted with GPS trackers, and hidden doorbell cameras outside homes in areas identified by mapping data of theft locations supplied by Amazon as well as local crime data.&lt;/p&gt;&lt;p&gt;One of the parcels was stolen within three minutes.&lt;/p&gt;
            </description>
<pubDate>Tue, 18 Dec 2018 13:16:46 +0000</pubDate>
<dc:creator>tartoran</dc:creator>
<og:title>Glitter bomb tricks parcel thieves</og:title>
<og:type>article</og:type>
<og:description>A former Nasa engineer spent six months building a disguised glitter bomb to surprise thieves stealing parcels from his doorstep.</og:description>
<og:url>https://www.bbc.com/news/technology-46604625</og:url>
<og:image>https://ichef.bbci.co.uk/news/1024/branded_news/160A3/production/_104857209_mediaitem104857208.jpg</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.bbc.com/news/technology-46604625</dc:identifier>
</item>
<item>
<title>Reasons Python Sucks</title>
<link>https://www.hackerfactor.com/blog/index.php?/archives/825-8-Reasons-Python-Sucks.html</link>
<guid isPermaLink="true" >https://www.hackerfactor.com/blog/index.php?/archives/825-8-Reasons-Python-Sucks.html</guid>
<description>Occasionally I go out to lunch with some of my techie friends and we have a great time geeking together. We talk about projects, current events, and various tech-related issues. Inevitably, the discussion will turn to programming languages. One might lament &quot;I have to modify some Java code. I hate Java. (Oh, sorry, Kyle.)&quot; (It probably doesn't help that we gave Kyle the nickname &quot;Java-boy&quot; over a decade ago.) Another will gripe about some old monolithic shell code that nobody wants to rewrite.&lt;p&gt;And me, well... I just blurted it out: I hate Python. I hate it with a passion. If I have the choice between using some pre-existing Python code or rewriting it in C, I'd rather rewrite it in C.&lt;/p&gt;&lt;p&gt;When I finished shouting, Bill humorously added, &quot;But what do you &lt;em&gt;really&lt;/em&gt; think about Python, Neal?&quot; So I'm dedicating this blog entry to Bill.&lt;/p&gt;&lt;p&gt;Here's my list of &quot;8 reasons Python sucks&quot;.&lt;/p&gt;&lt;h3&gt;Reason 1: Versions&lt;/h3&gt;
If you install a default Linux operating system, there's a really good chance that it will install multiple versions of Python. It will probably have Python2 and Python3, and maybe even some fractional versions like 3.5 or 3.7. There's a reason for this: Python3 is not fully compatible with Python2. Even some of the fractional versions are distinct enough to lack backwards compatibility.&lt;p&gt;I'm all for adding new functionality to languages. I don't even mind if some old version becomes obsolete. However, Python installs in separate installations. My code for Python 3.5 won't work with the Python 3.7 installation unless I intentionally port it to 3.7. Enough Linux developers have decided that porting isn't worth the effort, so Ubuntu installs with both Python2 and Python3 -- because they are needed by different core functions.&lt;/p&gt;&lt;p&gt;This lack of backwards compatibility and split versions is usually a death knell. Commodore created one of the first home computers (long before the IBM PC or Apple). But the Commodore PET wasn't compatible with the subsequent Commodore CBM computer. And the CBM wasn't compatible with the VIC-20, Commodore-64, Amiga, etc. So either you spent a lot of time porting code from one platform to another, or you abandoned the platform. (Where's Commodore today? It died out as users abandoned the platform.)&lt;/p&gt;&lt;p&gt;Similarly, Perl used to be very popular. But when Perl3 came out, it wasn't fully backwards compatible with a lot of Perl2 code. The community griped, good code was ported, and the rest was abandoned. Then came Perl4 and the same thing happened. When Perl5 came out, a lot of people just switched to a different programming language that was more stable. Today, there's only a small community of people actively using Perl to maintain existing Perl projects. I haven't seen any major new projects based on Perl.&lt;/p&gt;&lt;p&gt;By the same means, Python has distinct silos of code for each version. And the community keeps dragging along the old versions. So you end up with a lot of old, dead Python code that keeps getting dragged along because nobody wants to spend the time porting it to the latest version. As far as I can tell, nobody creates new code for Python2, but we drag it along because nobody's ported the needed code to Python3.x. At the official &lt;a href=&quot;https://docs.python.org/3/&quot;&gt;Python web site&lt;/a&gt;, their documentation is actively maintained and available for Python 2.7, 3.5, 3.6, and 3.7 -- because they can't decide to give up on the old code. Python is like the zombie of programming languages -- the dead just keep walking on.&lt;/p&gt;&lt;h3&gt;Reason 2: Installation&lt;/h3&gt;
With most software packages, you can easily run apt, yum, rpm, or some other install base and get the most recent code. That isn't the case with Python. If you install using 'apt-get install python', you don't know what version you're actually installing, and it may not be compatible with all of the code you need.&lt;p&gt;So instead, you install the version of Python you need. For one of the projects I was on, we used Python. But we had to use Python3.5 (the latest at that time). My computer ended up with Python2, Python2.6, Python3, and Python3.5 installed. Two were from the operating system, one was for the project, and one came in because of some unrelated software I installed for some other reason. Even though they are all &quot;Python&quot;, they are not all the same.&lt;/p&gt;&lt;p&gt;If you want to install packages for Python, you're supposed to use &quot;pip&quot;. (Pip stands for &quot;Pip Installs Packages&quot;, because someone thinks recursive acronyms are still funny.) But since there's a bunch of versions of Python on the system, you have to remember to use the correct version of pip. Otherwise, 'pip' might run 'pip2' and not the 'pip3.7' that you need. (And you need to specify the actual path for pip3.7 if the name doesn't exist.)&lt;/p&gt;&lt;p&gt;I was advised by one teammate that I needed to &lt;a href=&quot;https://docs.python-guide.org/dev/virtualenvs/&quot;&gt;configure my environment&lt;/a&gt; so that everything uses the Python 3.5 base. This worked great until I started on a second project that needed Python 3.6. Two concurrent projects with two different versions of Python -- no, that wasn't confusing. (What's the emoticon for sarcasm?)&lt;/p&gt;&lt;p&gt;The pip installer places files in the user's local directory. You don't use pip to install system-wide libraries. And Gawd forbid you make the mistake of running 'sudo pip', because that can screw up your entire computer! Running sudo might make some packages install at the system level, some install for the wrong version of Python, and some files in your home directory might end up being owned by root, so future non-sudo pip installs may fail due to permissions. Just don't do it.&lt;/p&gt;&lt;p&gt;By the way, who maintains these pip modules? The community. That is, no clear owner and no enforced chain of provenance or accountability. Earlier this year, a version of PyPI was found to have a &lt;a href=&quot;https://www.bleepingcomputer.com/news/security/backdoored-python-library-caught-stealing-ssh-credentials/&quot;&gt;backdoor&lt;/a&gt; that stole SSH credentials. This doesn't surprise me at all. (I don't use Node.js and npm for the same reason; I don't trust their &lt;a href=&quot;https://www.infoq.com/news/2018/05/npm-getcookies-backdoor&quot;&gt;community repositories&lt;/a&gt;.)&lt;/p&gt;&lt;h3&gt;Reason 3: Syntax&lt;/h3&gt;
I'm a strong believer in readable code. And at first glance, Python seems very readable. That is, until you start making large code bases.&lt;p&gt;Most programming languages use some kind of notation to identify scope -- where a function begins and ends, actions contained in a conditional statement, range of a variable's definition, etc. With C, Java, JavaScript, Perl, and PHP, braces {...} define the scope. Lisp uses parenthesis (...). And Python? It uses spaces. If you need to define a scope for complex code, then you indent the next few lines. The scope ends when the indent ends.&lt;/p&gt;&lt;p&gt;The Python manual says that you can use any number of &lt;a href=&quot;https://docs.python.org/3/reference/lexical_analysis.html#indentation&quot;&gt;spaces or tabs&lt;/a&gt; for defining the scope. However, ALWAYS USE FOUR SPACES PER INDENT! If you want to indent twice for nesting, use eight spaces! The Python community has standardized on this nomenclature, even though it isn't in the Python manual. Forget the fact that the examples in the documentation use tabs, tabs + 1 space, and other indents. The community is rabid about using four spaces. So unless you plan to never show your code to anyone else, always use four spaces for each indent.&lt;/p&gt;&lt;p&gt;When I first saw Python code, I thought that using indents to define the scope seemed like a good idea. However, there's a huge downside. Deep nesting is permitted, but lines can get so wide that they wrap lines in the text editor. Long functions and long conditional actions may make it hard to match the start to the end. And I pity anyone who miscounts spaces and accidentally puts in three spaces instead of four somewhere -- this can take hours to debug and track down.&lt;/p&gt;&lt;p&gt;For other languages, I've picked up the habit of putting debug code without any indents. This way, I can quickly browse the code and easily identify and remove debugging code when I'm done. But with Python? Anything not indented properly generates an indention error. This means debugging code must blend in to the active code.&lt;/p&gt;&lt;h3&gt;Reason 4: Includes&lt;/h3&gt;
Most programming languages have some way to include other chunks of code. For C, it's &quot;#include&quot;. For PHP, there's 'include', 'include_once', 'require', and 'require_once'. And for Python, there's &quot;import&quot;.&lt;p&gt;Python's import permits including an entire module, part of a module, or a specific function from a module. Finding a list of what can be imported is non-intuitive. With C, you can just look in /usr/include/*.h. But with Python? It's best to use 'python -v' to list all of the places it looks, and then search every file in every directory and subdirectory from that list. I have friends who love Python and I've seen them grep through standard modules as they look for the thing they want to import. Seriously.&lt;/p&gt;&lt;p&gt;The import function also allows users to rename the imported code. They basically define a custom namespace. At first glance, this might seem nice, but it ends up impacting readability and long-term support. Renaming modules is great for small scripts, but really bad for long programs. People who use 1-2 letter namespaces, like &quot;import numpy as n&quot; should be shot (or forced to convert all of their code to Perl5).&lt;/p&gt;&lt;p&gt;But that's not the worst part. With most languages, including code just includes the code. A few languages, like object-oriented C++, may execute code if there's a global object with a constructor. Similarly, some PHP code may define global variables, so an import could run code -- but that's typically considered a bad practice. In contrast, many Python modules include initialization functions that run during the import. You don't know what's running, you don't know what it does, and you might not notice. Unless there's a namespace conflict, in which case you get to spend many fun hours tracking down the cause.&lt;/p&gt;&lt;h3&gt;Reason 5: Nomenclature&lt;/h3&gt;
In every other language, arrays are called 'arrays'. In Python, they are called 'lists'. And an associative array is sometimes called a 'hash' (Perl), but Python calls it a 'dictionary'. Python seems to go out of it's way to not use the common terms found throughout the computer and information science field.&lt;p&gt;And then there are the names of libraries. PyPy, PyPi, NumPy, SciPy, SymPy, PyGtk, Pyglet, PyGame... (Yes, those first two are pronounced the same way, but they do very different things.) I understand that the 'py' is for Python. But couldn't they be consistent about whether it comes first or second?&lt;/p&gt;&lt;p&gt;Some common libraries just gave up on the pun-like &quot;Py&quot; naming convention. This includes, matplotlib, nose, Pillow, and SQLAlchemy. And while some of the names may give you a hint to the purpose (e.g., &quot;SQLAlchemy&quot; contains SQL, so it's probably an SQL interface), others are just random words. If you didn't know what &quot;BeautifulSoup&quot; did, could you tell from the name that it's an HTML/XML parser? (As an aside, BeautifulSoup is well documented and easy to use. If every Python module was like this, I wouldn't be complaining so much. Unfortunately, this is the exception and not the norm. Most Python libraries seriously suck at documentation.)&lt;/p&gt;&lt;p&gt;Overall, I view Python as a collection of libraries with horrible and inconsistent naming conventions. I have a &lt;a href=&quot;https://www.hackerfactor.com/blog/index.php?/archives/415-Open-Source-Sucks.html&quot;&gt;standing gripe&lt;/a&gt; that open source projects typically have horrible names. Unless you know the project, you'll never figure out what it does by the name. And unless you know what to look for, you'll probably only find it by accidentally stumbling across someone who mentions it in passing. Most of Python's libraries reinforce this negative criticism.&lt;/p&gt;&lt;h3&gt;Reason 6: Quirks&lt;/h3&gt;
Every language has its quirks. With C, there's the weird nomenclature of using &amp;amp; and * for accessing address space and values. C also has that increment/decrement shortcut using ++ and --. With Bash, there's the whole &quot;when to use a backslash&quot; when quoting special characters like parenthesis and periods for regular expressions. And JavaScript has issues around compatibility (not every browser supports every useful function). However, Python has more quirks than any other language I've ever seen. Consider strings:&lt;br /&gt;&lt;ul&gt;&lt;li&gt;In C, double quotes enclose strings. Single quotes enclose characters.&lt;/li&gt;
&lt;li&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;In PHP and Bash, both types of quotes can enclose strings. However, a double quote can have variables embedded in the string. In contrast, single quoted strings are literals; any embedded variable-like names are not expanded.&lt;/li&gt;
&lt;li&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;In JavaScript, there's really no difference between single quotes and double quotes.&lt;/li&gt;
&lt;li&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;In Python, there's no difference between single quotes and double quotes. However, if you want your string to span lines, then you need to use triple quotes &quot;&quot;&quot;string&quot;&quot;&quot; or '''string'''. And if you want to use binary, then you need to preference the string with b (b'binary') or r (r'raw'). And sometimes you need to cast your strings as strings using str(string), or convert it to utf8 using string.encode('utf-8').&lt;/li&gt;
&lt;/ul&gt;
If you thought that =, ==, and === was initially a little weird in PHP and JavaScript, wait until you play with quotes in Python.&lt;h3&gt;Reason 7: Pass By Object Reference&lt;/h3&gt;
Most programming languages pass function parameters by value. If the function alters the value, the results are not passed back to the calling code. But as I've already explained, Python goes out of its way to be different. Python defaults to doing functions with &lt;a href=&quot;https://robertheaton.com/2014/02/09/pythons-pass-by-object-reference-as-explained-by-philip-k-dick/&quot;&gt;pass-by-object-reference&lt;/a&gt; parameters. This means that changing the source variable may end up changing the value.&lt;p&gt;This is one of the big differences between procedural, functional, and object-oriented programming languages. If every variable is passed by object reference, and any change to the variable changes the reference everywhere, then you might as well use globals for everything. Calling the same object by different names doesn't change the object, so it is effectively global. And as C programmers learned long ago, &lt;a href=&quot;https://www.learncpp.com/cpp-tutorial/4-2a-why-global-variables-are-evil/&quot;&gt;global variables are evil&lt;/a&gt; and &lt;a href=&quot;https://www.quora.com/Is-it-a-bad-practice-to-use-global-variables-in-any-programming-language&quot;&gt;should not be used&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;In Python, you have to work to pass variables by value. Saying &quot;a=b&quot; just assigns another name to the same object space; this doesn't copy the value of b into a. If you actually meant to copy the value, then you need to use a copy function. Usually this is &quot;a=b.copy()&quot;. However, notice that I said &quot;usually&quot;. Not all data types have a 'copy' prototype. Or maybe the copy function is incomplete. In those cases, there is a separate library called 'copy' that you can use: &quot;a=copy.deepcopy(b)&quot;.&lt;/p&gt;&lt;h3&gt;Reason 8: Local Names&lt;/h3&gt;
It's a common programming technique to name the program after the library or function being used. For example, if I'm testing a screen capture program with a C library called &quot;libscreencapture.so&quot;, I would call my program &quot;screencapture.c&quot; and compile into &quot;screencapture.exe&quot;.&lt;p&gt;&lt;code&gt;gcc -o screencapture.exe screencapture.c -lscreencapture&lt;/code&gt;&lt;/p&gt;&lt;p&gt;With C, Java, JavaScript, Perl, PHP, etc., this works fine because the language can easily distinguish resource libraries from the local program; they have different paths. But with Python? Don't do this. Never do this. Why? Python assumes you want to import the local code first. If I have a program called &quot;screencapture.py&quot; that uses &quot;import screencapture&quot;, then it will import itself rather than the system library. At minimum, you should call your local program &quot;myscreencapture.py&quot; instead.&lt;/p&gt;&lt;h3&gt;Not All Bad&lt;/h3&gt;
Python is a very popular language and has a huge following. I even have a handful of friends who really like Python -- it's their preferred programming language. Over the years, I've discussed these issues with them, and each time they nod their heads and agree. They don't disagree that these are problems with Python; they just think it's not bad enough for them to stop loving the language.&lt;p&gt;My friends often cite all of the really cool Python libraries that exist. And I agree that some of the libraries are really useful. For example, BeautifulSoup is one of the best HTML parsers I've ever used, NumPy makes multidimensional arrays and complex mathematics easier to implement, and TensorFlow is very useful for machine learning. However, I'm not going to make a monolithic program in Python just because I like TensorFlow or SciPy. I'm not going to give up readability and maintainability for a &lt;a href=&quot;https://www.urbandictionary.com/define.php?term=Free%20Pony&quot;&gt;free pony&lt;/a&gt;; it's not worth the effort.&lt;/p&gt;&lt;p&gt;Usually when I write negative criticisms about a topic, I also try to write something positive. I followed my blog entry on &quot;&lt;a href=&quot;https://www.hackerfactor.com/blog/index.php?/archives/415-Open-Source-Sucks.html&quot;&gt;Open Source Sucks&lt;/a&gt;&quot; with &quot;&lt;a href=&quot;https://www.hackerfactor.com/blog/index.php?/archives/416-Open-Source-Rocks.html&quot;&gt;Open Source Rocks&lt;/a&gt;&quot;. And when I wrote about limitations with &lt;a href=&quot;https://www.hackerfactor.com/blog/index.php?/archives/300-Ten-Little-Endians.html&quot;&gt;FFmpeg&lt;/a&gt;, I explicitly mentioned how it's the best video processing library out there. But I can't make a list of good things about Python because I really think that Python sucks.&lt;/p&gt;&lt;p&gt;(Hey Bill, does this answer your question?)&lt;/p&gt;</description>
<pubDate>Tue, 18 Dec 2018 13:11:30 +0000</pubDate>
<dc:creator>BerislavLopac</dc:creator>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.hackerfactor.com/blog/index.php?/archives/825-8-Reasons-Python-Sucks.html</dc:identifier>
</item>
<item>
<title>Why we should care about the Nate Silver vs. Nassim Taleb Twitter war</title>
<link>https://towardsdatascience.com/why-you-should-care-about-the-nate-silver-vs-nassim-taleb-twitter-war-a581dce1f5fc</link>
<guid isPermaLink="true" >https://towardsdatascience.com/why-you-should-care-about-the-nate-silver-vs-nassim-taleb-twitter-war-a581dce1f5fc</guid>
<description>&lt;h2 name=&quot;aece&quot; id=&quot;aece&quot; class=&quot;graf graf--h4 graf-after--h3 graf--subtitle&quot;&gt;How can two data experts disagree so much?&lt;/h2&gt;
&lt;div class=&quot;uiScale uiScale-ui--regular uiScale-caption--regular u-flexCenter u-marginVertical24 u-fontSize15 js-postMetaLockup&quot;&gt;
&lt;div class=&quot;u-flex0&quot;&gt;&lt;a class=&quot;link u-baseColor--link avatar&quot; href=&quot;https://towardsdatascience.com/@isaacfaber?source=post_header_lockup&quot; data-action=&quot;show-user-card&quot; data-action-source=&quot;post_header_lockup&quot; data-action-value=&quot;81d6b9acba62&quot; data-action-type=&quot;hover&quot; data-user-id=&quot;81d6b9acba62&quot; data-collection-slug=&quot;towards-data-science&quot; dir=&quot;auto&quot;&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/fit/c/100/100/1*oQEv0ES7AUPNp-zPsIOKkw.jpeg&quot; class=&quot;avatar-image u-size50x50&quot; alt=&quot;Go to the profile of Isaac Faber&quot;/&gt;&lt;/a&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;p name=&quot;1bb2&quot; id=&quot;1bb2&quot; class=&quot;graf graf--p graf-after--h4&quot;&gt;An obscure controversy has reared its ugly head again this past month. Two icons of the quantitative analysis community have locked horns on the greatest of public stages, Twitter. You may be forgiven for not following the controversy: I’ll do a quick review for the uninitiated. &lt;a href=&quot;https://community.platform.matrixds.com/community/project/5c09a98a5fd07d6fa67f645d/files&quot; data-href=&quot;https://community.platform.matrixds.com/community/project/5c09a98a5fd07d6fa67f645d/files&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;All code and data used to create this article can be forklifted from this MatrixDS project.&lt;/a&gt;&lt;/p&gt;
&lt;p name=&quot;0fb3&quot; id=&quot;0fb3&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Nate Silver is the co-founder of &lt;a href=&quot;https://fivethirtyeight.com/&quot; data-href=&quot;https://fivethirtyeight.com/&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;FiveThirtyEight&lt;/a&gt;. A massively popular data focused blog that gained fame for its accuracy predicting the outcomes for the U.S. elections in 2008. Silver generates predictions using a clever poll aggregating technique which accounts for biases, such as pollsters who only call people with landlines.&lt;/p&gt;
&lt;p name=&quot;f27e&quot; id=&quot;f27e&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;A trained statistician, via economics, he directed his passion for baseball (sabermetrics) and poker analytics into the arena of politics. In fact, the name FiveThirtyEight is a nod to the number of U.S. electoral votes (538 of them). However, the blog also covers other interest areas like sports. Nate sold his blog to ESPN and took the job of Editor in Chief. They (ESPN) used it as a platform to feed their audience with forecasts of sporting events, FiveThirtyEight has since moved to ABC. A routine visit to their website is greeted with a mix of political and sports articles with detailed predictions and data visualizations.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*9FfCONibVqj8F1XIR-aDkw.jpeg&quot; data-width=&quot;512&quot; data-height=&quot;341&quot; src=&quot;https://cdn-images-1.medium.com/max/1200/1*9FfCONibVqj8F1XIR-aDkw.jpeg&quot;/&gt;&lt;/div&gt;
&lt;a href=&quot;https://commons.wikimedia.org/wiki/File:Nate_Silver_in_Conversation_with_NY1%27s_Pat_Kiernan.jpg&quot; data-href=&quot;https://commons.wikimedia.org/wiki/File:Nate_Silver_in_Conversation_with_NY1%27s_Pat_Kiernan.jpg&quot; class=&quot;markup--anchor markup--figure-anchor&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;Silver (left) in conversation with NY1’s Pat Kiernan&lt;/a&gt;
&lt;p name=&quot;7e2b&quot; id=&quot;7e2b&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Nate’s forecasting prowess has become accepted as canon in the popular media. He is a routine guest on many nationally televised shows to discuss his predictions during every national election cycle. So it came as quite a shock when Nassim Taleb, a best-selling author, and quantitative risk expert, publicly announced that FiveThirtyEight does not know how to forecast elections properly!&lt;/p&gt;
&lt;p name=&quot;72f7&quot; id=&quot;72f7&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;For his part, Taleb has become extremely successful due to his shrewd understanding of probability in the real world. His books are both philosophical and technical, with a focus on uncertainty and risk. Specifically, he believes that the vast majority of quantitative models used in practice do not sufficiently account for real-world risk. Instead, they give the illusion of short-term value (like being accurate in some well-understood situations) but expose the unknowing users to enormous systemic risk when they experience situations the models are not designed to understand.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*oliaBOQkldY-2V4l1KYMcg.jpeg&quot; data-width=&quot;256&quot; data-height=&quot;250&quot; src=&quot;https://cdn-images-1.medium.com/max/1200/1*oliaBOQkldY-2V4l1KYMcg.jpeg&quot;/&gt;&lt;/div&gt;
Nassim Taleb
&lt;p name=&quot;31d4&quot; id=&quot;31d4&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Taleb gained fame, in part, because he puts his philosophy into action by exposing his wealth. &lt;a href=&quot;http://faculty.sites.uci.edu/pjorion/files/2018/03/NYorker2002-blowingup.pdf&quot; data-href=&quot;http://faculty.sites.uci.edu/pjorion/files/2018/03/NYorker2002-blowingup.pdf&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;Malcolm Gladwell wrote an article in the New Yorker on how Taleb turned his philosophy on risk into an incredibly successful investment strategy.&lt;/a&gt; He has since gained significant wealth during unforeseen market events such as the Russian debt default, 9/11, and the financial crisis of 2008. Taleb now spends much of his time writing and deadlifting (I’m jealous of this bit). He is not shy about telling someone publicly that he disagrees with them: One of those people is Nate Silver.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*9KxNUeOd9CZF1xiVKBei3Q.png&quot; data-width=&quot;1252&quot; data-height=&quot;1606&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*9KxNUeOd9CZF1xiVKBei3Q.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*9KxNUeOd9CZF1xiVKBei3Q.png&quot;/&gt;&lt;/div&gt;
Taleb’s Tweets directed at Silver November 2018
&lt;p name=&quot;238a&quot; id=&quot;238a&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;However, Silver isn’t taking the insults lying down!&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*_g_Z_-yZr1Evt27FuWPeHg.png&quot; data-width=&quot;1204&quot; data-height=&quot;1060&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*_g_Z_-yZr1Evt27FuWPeHg.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*_g_Z_-yZr1Evt27FuWPeHg.png&quot;/&gt;&lt;/div&gt;
&lt;p name=&quot;c85a&quot; id=&quot;c85a&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Silver and Taleb, with three million and 300k followers respectively, create an enormous buzz with these exchanges (starting back in 2016). However, a quick read through the comment threads and you will realize that few people understand the arguments. Even Silver himself seems taken off guard by Taleb’s attack.&lt;/p&gt;
&lt;p name=&quot;35b1&quot; id=&quot;35b1&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;I think, however, this is a great opportunity for a data science professional (or aspiring professional) to dig deeper into what is being said. There are implications on how we choose to model and present our work in a reliable and verifiable way. You must decide for yourself if Taleb has a point or is a just another crazy rich person with too much time on his hands.&lt;/p&gt;
&lt;h4 name=&quot;9e6e&quot; id=&quot;9e6e&quot; class=&quot;graf graf--h4 graf-after--p&quot;&gt;Not all real numbers between 0 and 1 are probabilities&lt;/h4&gt;
&lt;p name=&quot;f48e&quot; id=&quot;f48e&quot; class=&quot;graf graf--p graf-after--h4&quot;&gt;The primary source of controversy and confusion surrounding FiveThirtyEight’s predictions is that they are ‘probabilistic.’ Practically what this means is that they do not predict a winner or looser but instead report a likelihood. Further complicating the issue, these predictions are reported as point estimates (sometimes with model implied error), well in advance of the event. For example, six months before polls open, this was their forecast of the 2016 presidential election.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*KMG4rwNgtELoFVMg_aNtkQ.png&quot; data-width=&quot;743&quot; data-height=&quot;453&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*KMG4rwNgtELoFVMg_aNtkQ.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*KMG4rwNgtELoFVMg_aNtkQ.png&quot;/&gt;&lt;/div&gt;
FiveThirtyEight Running Forecast of the 2016 Presidential Election
&lt;p name=&quot;880a&quot; id=&quot;880a&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Their forecast process is to build a quantitative replica of a system with expert knowledge (elections, sporting events, etc.) then run a &lt;a href=&quot;https://en.wikipedia.org/wiki/Monte_Carlo_method&quot; data-href=&quot;https://en.wikipedia.org/wiki/Monte_Carlo_method&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;Monte Carlo simulation&lt;/a&gt;. If the model closely represents the real-world, the simulation averages can be reliably used for probabilistic statements. So what FiveThirtyEight is actually saying is:&lt;/p&gt;
&lt;blockquote name=&quot;494c&quot; id=&quot;494c&quot; class=&quot;graf graf--blockquote graf-after--p&quot; readability=&quot;5&quot;&gt;
&lt;p&gt;x% of the time our Monte Carlo simulation resulted in this particular outcome&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p name=&quot;21c7&quot; id=&quot;21c7&quot; class=&quot;graf graf--p graf-after--blockquote&quot;&gt;The problem is that models are not perfect replicas of the real world and are, as a matter of fact, always wrong in some way. This type of model building allows for some amount of subjectivity in construction. &lt;a href=&quot;https://fivethirtyeight.com/features/the-media-has-a-probability-problem/&quot; data-href=&quot;https://fivethirtyeight.com/features/the-media-has-a-probability-problem/&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;For example, Silver has said on numerous occasions that other competitive models do not correctly incorporate correlation.&lt;/a&gt; When describing modeling approaches, he also makes clear that they tune outcomes &lt;a href=&quot;https://fivethirtyeight.com/features/how-the-fivethirtyeight-senate-forecast-model-works/&quot; data-href=&quot;https://fivethirtyeight.com/features/how-the-fivethirtyeight-senate-forecast-model-works/&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;(like artificially increasing variance based on the time until an event or similar adjustments)&lt;/a&gt;. This creates an infinitely recursive debate as to whose model is the ‘best’ or most like the real world. Of course, to judge this, you could look at who performed better in the long run. This is where things go off the rails a bit.&lt;/p&gt;
&lt;p name=&quot;e736&quot; id=&quot;e736&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Because FiveThirtyEight only predicts probabilities, they do not ever take an absolute stand on an outcome: No ‘skin in the game’ as Taleb would say. This is not, however, something their readers follow suit on. In the public eye, they (FiveThirtyEight) are judged on how many events with forecasted probabilities above and below 50% happened or didn’t respectively (in a binary setting). Or, they (the readers) just pick the highest reported probability as the intended forecast. For example, they were showered with accolades when after, ‘calling 49 of 50 states in the 2008 presidential race correctly’ &lt;a href=&quot;http://content.time.com/time/specials/packages/article/0,28804,1894410_1893209_1893477,00.html&quot; data-href=&quot;http://content.time.com/time/specials/packages/article/0,28804,1894410_1893209_1893477,00.html&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;Nate Silver was placed on Times 100 most influential people lis&lt;/a&gt;t. He should not have accepted the honor if he didn’t call a winner in any of the states!&lt;/p&gt;
&lt;p name=&quot;bc91&quot; id=&quot;bc91&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;The public can be excused for using the 50% rule without asking. For example, in supervised machine learning, a classification model must have a characteristic called a ‘decision boundary.’ This is often decided a priori and is a fundamental part of understanding the quality of the model after it is trained. Above this boundary, the machine believes one thing and below it the opposite (in the binary case).&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*EOVG2D1GD8kLz56sb_NKsA.png&quot; data-width=&quot;256&quot; data-height=&quot;116&quot; src=&quot;https://cdn-images-1.medium.com/max/1200/1*EOVG2D1GD8kLz56sb_NKsA.png&quot;/&gt;&lt;/div&gt;
Example Decision Boundary in Classification Problems
&lt;p name=&quot;d1e3&quot; id=&quot;d1e3&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;For standard models, like logistic regression, the default decision boundary is assumed to be 50% (or 0.5 on a 0 to 1 scale) or the alternative with the highest value. Classical neural networks designed for classification often use softmax functions which are interpreted in just this way. Here is an example Convolutional Neural Network performing an image classification using computer vision. Even this basic Artifical Intelligence model manages to make a decision.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*hkXhAIqR-1IB78_35DMDeg.gif&quot; data-width=&quot;480&quot; data-height=&quot;200&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*hkXhAIqR-1IB78_35DMDeg.gif&quot;/&gt;&lt;/div&gt;
&lt;a href=&quot;http://cs231n.stanford.edu/&quot; data-href=&quot;http://cs231n.stanford.edu/&quot; class=&quot;markup--anchor markup--figure-anchor&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;Convolutional Neural Network with Decision Boundary Prediction&lt;/a&gt;
&lt;p name=&quot;209a&quot; id=&quot;209a&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;If FiveThirtyEight has no stated decision boundary, it can be difficult to know how good their model actually is. The confusion is compounded when they are crowned, and gladly accept it, with platitudes of crystal ball-like precision in 2008 and 2012, due to the implied decision boundary. However, when they are accused of being wrong they fall back to a simple quip:&lt;/p&gt;
&lt;blockquote name=&quot;54bf&quot; id=&quot;54bf&quot; class=&quot;graf graf--blockquote graf-after--p&quot; readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://twitter.com/NateSilver538/status/1059149034693316608&quot; data-href=&quot;https://twitter.com/NateSilver538/status/1059149034693316608&quot; class=&quot;markup--anchor markup--blockquote-anchor&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;You just don’t understand math and probability.&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p name=&quot;4c86&quot; id=&quot;4c86&quot; class=&quot;graf graf--p graf-after--blockquote&quot;&gt;Often this is f&lt;a href=&quot;https://fivethirtyeight.com/features/the-media-has-a-probability-problem/&quot; data-href=&quot;https://fivethirtyeight.com/features/the-media-has-a-probability-problem/&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;ollowed up with an exposé about how they only reported x%, so that means that (1-x)% can also happen&lt;/a&gt;. It’s a perfect scenario; they can never be wrong! We should all be so lucky. Of course, this probabilistic argument may be valid, but it can cause some angst if it seems disingenuous. &lt;a href=&quot;https://www.washingtonpost.com/opinions/no-matter-who-wins-the-presidential-election-nate-silver-was-right/2016/11/08/540825dc-a5eb-11e6-ba59-a7d93165c6d4_story.html?noredirect=on&amp;amp;utm_term=.47a35c316189&quot; data-href=&quot;https://www.washingtonpost.com/opinions/no-matter-who-wins-the-presidential-election-nate-silver-was-right/2016/11/08/540825dc-a5eb-11e6-ba59-a7d93165c6d4_story.html?noredirect=on&amp;amp;utm_term=.47a35c316189&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;Even the Washington Post had an opinion piece which opined as much during the 2016 election.&lt;/a&gt;&lt;/p&gt;
&lt;p name=&quot;b172&quot; id=&quot;b172&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;What is not clear is that there is a factor hidden from the FiveThirtyEight reader. &lt;a href=&quot;https://en.wikipedia.org/wiki/Uncertainty_quantification#Aleatoric_and_epistemic_uncertainty&quot; data-href=&quot;https://en.wikipedia.org/wiki/Uncertainty_quantification#Aleatoric_and_epistemic_uncertainty&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;Predictions have two types of uncertainty; &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;aleatory&lt;/strong&gt; and &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;epistemic&lt;/strong&gt;.&lt;/a&gt; Aleatory uncertainty is concerned with the fundamental system (probability of rolling a six on a standard die). Epistemic uncertainty is concerned with the uncertainty of the system (how many sides does a die have? And what is the probability of rolling a six?). With the later, you have to guess the game and the outcome; like an election!&lt;/p&gt;
&lt;p name=&quot;145a&quot; id=&quot;145a&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Bespoke models, like FiveThirtyEight’s, only report to the public aleatory uncertainty as it concerns their statistical outputs (inference by Monte Carlo in this case). The trouble is that epistemic uncertainty is very difficult (sometimes impossible) to estimate. &lt;a href=&quot;https://fivethirtyeight.com/features/the-comey-letter-probably-cost-clinton-the-election/&quot; data-href=&quot;https://fivethirtyeight.com/features/the-comey-letter-probably-cost-clinton-the-election/&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;For example, why didn’t FiveThirtyEight’s model incorporate,&lt;/a&gt; &lt;a href=&quot;https://fivethirtyeight.com/features/the-comey-letter-probably-cost-clinton-the-election/&quot; data-href=&quot;https://fivethirtyeight.com/features/the-comey-letter-probably-cost-clinton-the-election/&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;before it happened, a chance that Comey would re-open his investigation into Clintons emails?&lt;/a&gt; Instead, this seems to have caused a massive spike in the variation of the prediction. Likely because this event was impossible to forecast.&lt;/p&gt;
&lt;p name=&quot;2655&quot; id=&quot;2655&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Instead, epistemically uncertain events are ignored a priori and then FiveThirtyEight assumes wild fluctuations in a prediction from unforeseen events are a normal part of forecasting. Which should lead us to ask ‘If the model is ignoring some of the most consequential uncertainties, are we really getting a reliable probability?’&lt;/p&gt;
&lt;p name=&quot;1692&quot; id=&quot;1692&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;To expand on this further, I have consolidated some of FiveThirtyEight’s predictions, &lt;a href=&quot;https://data.fivethirtyeight.com/&quot; data-href=&quot;https://data.fivethirtyeight.com/&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;using their open source data&lt;/a&gt;, for two very different types of events; U.S. Senate elections and National Football Leauge (NFL) Games. Here is a comparison to the final forecast probability and the actual proportion of outcomes.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*aDZ5EWPzWCdd1cpOWkiB6A.png&quot; data-width=&quot;862&quot; data-height=&quot;409&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*aDZ5EWPzWCdd1cpOWkiB6A.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*aDZ5EWPzWCdd1cpOWkiB6A.png&quot;/&gt;&lt;/div&gt;
Stated Probabilities Compared with Average Portions
&lt;p name=&quot;b1e4&quot; id=&quot;b1e4&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;The sports data (NFL games) has an excellent linear relationship. These proportions are built using 30K data points, so, if we assume the system is stable, we have averaged out any sampling error. However, as you can see, there is still a noticable variation of 2–5% of actual proportion to predictions. This is a signal of un-addressed epistemic uncertainty. It also means you cannot take one of these forecast probabilities at face value.&lt;/p&gt;
&lt;p name=&quot;d6f4&quot; id=&quot;d6f4&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Sports, like other games of chance, have very well defined mechanisms which lend themselves to statistical analysis. On the other hand, highly non-linear events, like contested elections, may not. With much fewer data points you can see the variation of the Senate predictions is enormous. Gauging the performance of models on these types of events becomes doubly difficult. It isn’t clear if a prediction is wrong owing to the quality of the model (epistemic) or just luck (aleatory).&lt;/p&gt;
&lt;p name=&quot;c1d2&quot; id=&quot;c1d2&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;One of the most troubling things about this approach to forecasting is that it opens pandora’s box for narrative fallacies. Why did Clinton lose? Comey? Email servers? People can then justify possibly spurious inferences by eyeballing events which occur around the forecast variation. ‘Just look at how the forecast is changing will all this news!’&lt;/p&gt;
&lt;p name=&quot;2ad8&quot; id=&quot;2ad8&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;I think this is what has Taleb up in arms. The blog feels more like a slick sales pitch, complete with quantitative buzzwords, than unbiased analysis (though it may very well be). If a prediction does not obey some fundamental characteristics, it should not be marketed as a probability. More importantly, a prediction should be judged from the time it is given to the public and not just the moment before the event. A forecaster should be held responsible for both aleatory and epistemic uncertainty.&lt;/p&gt;
&lt;p name=&quot;c2c5&quot; id=&quot;c2c5&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;When viewed this way, it is clear that FiveThirtyEight reports too much noise leading up to an event and not enough signal. This is great for driving users to read long series of related articles on the same topic but not so rigorous to bet your fortune on. Taleb and Silvers take on how FiveThirtyEight should be judged can be visualized like this.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*D_tidaT-fHMY3DRLgjwekw.png&quot; data-width=&quot;1800&quot; data-height=&quot;1200&quot; data-is-featured=&quot;true&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*D_tidaT-fHMY3DRLgjwekw.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*D_tidaT-fHMY3DRLgjwekw.png&quot;/&gt;&lt;/div&gt;
Taleb vs. Silvers Different Take On How FiveThirtyEight Should be Judged in 2016
&lt;p name=&quot;5590&quot; id=&quot;5590&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Because there is so much uncertainty around non-linear events, like an election, it could reasonably be considered frivolous to report early stage forecasts. The only conceivable reason to do so is to capture (and monetize?) the interest of a public which is hungry to know the future. &lt;a href=&quot;https://arxiv.org/pdf/1703.06351.pdf&quot; data-href=&quot;https://arxiv.org/pdf/1703.06351.pdf&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;I will not go into the technical arguments, Taleb has written and published a paper on the key issues with a solution.&lt;/a&gt;&lt;/p&gt;
&lt;p name=&quot;bc1b&quot; id=&quot;bc1b&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Here we can say, with some confidence that FiveThirtyEight predictions are not reliable probabilities. However, they masquerade as one, being between 0 and 1 and all. This is Taleb’s primary argument; FiveThirtyEight’s predictions do not behave like probabilities that incorporate all uncertainty and should not be passed off as them.&lt;/p&gt;
&lt;p name=&quot;9de0&quot; id=&quot;9de0&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;I do not want to suggest that FiveThirtyEight is bad at their craft. They are, likely, the best poll aggregator in the business. If we only look at the last reported probabilistic forecast and use the public’s decision boundary, they are more successful than any other source attempting the same task. However, positioning yourself to appear correct regardless of the outcome, making users infer their own decision boundaries, over-reporting of predictions, and ignoring epistemic uncertainty should not be overlooked. How goes FiveThirtyEight’s reputation, so goes much of the data community’s reputation.&lt;/p&gt;
&lt;p name=&quot;8029&quot; id=&quot;8029&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Be clear on your suggested decision boundary, probabilistic statements, assumptions about uncertainty and you’ll be less likely to misguide stakeholders.&lt;/p&gt;
&lt;p name=&quot;0490&quot; id=&quot;0490&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;&lt;a href=&quot;https://community.platform.matrixds.com/community/project/5c09a98a5fd07d6fa67f645d/files&quot; data-href=&quot;https://community.platform.matrixds.com/community/project/5c09a98a5fd07d6fa67f645d/files&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;All code and data can be forklifted from this MatrixDS project.&lt;/a&gt;&lt;/p&gt;
&lt;p name=&quot;7153&quot; id=&quot;7153&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Follow me on LinkedIn: &lt;a href=&quot;https://www.linkedin.com/in/isaacfaber/&quot; data-href=&quot;https://www.linkedin.com/in/isaacfaber/&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;nofollow noopener noopener&quot; target=&quot;_blank&quot;&gt;https://www.linkedin.com/in/isaacfaber/&lt;/a&gt;&lt;/p&gt;
&lt;p name=&quot;0470&quot; id=&quot;0470&quot; class=&quot;graf graf--p graf-after--p graf--trailing&quot;&gt;Follow me on MatrixDS: &lt;a href=&quot;https://community.platform.matrixds.com/community/isaacfab/overview&quot; data-href=&quot;https://community.platform.matrixds.com/community/isaacfab/overview&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;nofollow noopener noopener&quot; target=&quot;_blank&quot;&gt;https://community.platform.matrixds.com/community/isaacfab/overview&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Tue, 18 Dec 2018 03:45:29 +0000</pubDate>
<dc:creator>oska</dc:creator>
<og:title>Why you should care about the Nate Silver vs. Nassim Taleb Twitter war</og:title>
<og:url>https://towardsdatascience.com/why-you-should-care-about-the-nate-silver-vs-nassim-taleb-twitter-war-a581dce1f5fc</og:url>
<og:image>https://cdn-images-1.medium.com/max/1200/1*D_tidaT-fHMY3DRLgjwekw.png</og:image>
<og:description>How can two data experts disagree so much?</og:description>
<og:type>article</og:type>
<dc:format>text/html</dc:format>
<dc:identifier>https://towardsdatascience.com/why-you-should-care-about-the-nate-silver-vs-nassim-taleb-twitter-war-a581dce1f5fc?gi=4abfe6b39d91</dc:identifier>
</item>
<item>
<title>Dotsies (2012)</title>
<link>http://dotsies.org/</link>
<guid isPermaLink="true" >http://dotsies.org/</guid>
<description>&lt;div class=&quot;underline&quot; readability=&quot;38&quot;&gt;
&lt;p class=&quot;connected&quot;&gt;hi there!&lt;/p&gt;
&lt;p class=&quot;connected&quot;&gt;can you read this?&lt;/p&gt;
&lt;p class=&quot;connected&quot;&gt;if you can read this, keep going.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;connected&quot;&gt;this section gr&lt;/span&gt;adua&lt;span class=&quot;connected&quot;&gt;ll&lt;/span&gt;y teaches &lt;span class=&quot;connected&quot;&gt;y&lt;/span&gt;ou to read d&lt;span class=&quot;connected&quot;&gt;o&lt;/span&gt;tsies.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;connected&quot;&gt;t&lt;/span&gt;he d&lt;span class=&quot;connected&quot;&gt;o&lt;/span&gt;tsies font is &lt;span class=&quot;connected&quot;&gt;m&lt;/span&gt;ade out of o&lt;span class=&quot;connected&quot;&gt;nl&lt;/span&gt;y dots.&lt;/p&gt;
&lt;p&gt;here are s&lt;span class=&quot;connected&quot;&gt;o&lt;/span&gt;me &lt;span class=&quot;connected&quot;&gt;w&lt;/span&gt;ords in dotsies: &lt;strong&gt;nice job&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;connected&quot;&gt;m&lt;/span&gt;ove &lt;span class=&quot;connected&quot;&gt;y&lt;/span&gt;our mouse over the light underline to see what they say.&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;from here on out, some letters will be in dotsies.&lt;/p&gt;
&lt;p&gt;move your &lt;strong&gt;mouse&lt;/strong&gt; over their underlines when you need to.&lt;/p&gt;
&lt;p&gt;if you can get all &lt;strong&gt;the&lt;/strong&gt; way to &lt;strong&gt;the&lt;/strong&gt; bottom, you'll be reading &lt;strong&gt;the&lt;/strong&gt; dotsies font.&lt;/p&gt;
&lt;p&gt;believe &lt;strong&gt;it&lt;/strong&gt; or not, you've already made &lt;strong&gt;a&lt;/strong&gt; lot of progress!&lt;/p&gt;
&lt;p&gt;you &lt;strong&gt;are&lt;/strong&gt; on your &lt;strong&gt;way&lt;/strong&gt; to doing what only &lt;strong&gt;a&lt;/strong&gt; few people &lt;strong&gt;have&lt;/strong&gt; done.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;the&lt;/strong&gt; top dot means an &lt;strong&gt;a&lt;/strong&gt;, right? let's t&lt;strong&gt;a&lt;/strong&gt;ke &lt;strong&gt;the&lt;/strong&gt;m &lt;strong&gt;a&lt;/strong&gt;w&lt;strong&gt;a&lt;/strong&gt;y.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;a&lt;/strong&gt;nd &lt;strong&gt;the&lt;/strong&gt; bottom dot is an &lt;strong&gt;e&lt;/strong&gt;, so l&lt;strong&gt;e&lt;/strong&gt;t's hid&lt;strong&gt;e&lt;/strong&gt; &lt;strong&gt;the&lt;/strong&gt;m too.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;the&lt;/strong&gt;s&lt;strong&gt;e&lt;/strong&gt; gr&lt;strong&gt;a&lt;/strong&gt;y und&lt;strong&gt;e&lt;/strong&gt;rlin&lt;strong&gt;e&lt;/strong&gt;s &lt;strong&gt;a&lt;/strong&gt;r&lt;strong&gt;e&lt;/strong&gt; g&lt;strong&gt;e&lt;/strong&gt;tting clutt&lt;strong&gt;e&lt;/strong&gt;r&lt;strong&gt;e&lt;/strong&gt;d, so l&lt;strong&gt;e&lt;/strong&gt;t's r&lt;strong&gt;e&lt;/strong&gt;mov&lt;strong&gt;e&lt;/strong&gt; th&lt;strong&gt;e&lt;/strong&gt;m.&lt;/p&gt;
&lt;/div&gt;
&lt;hr/&gt;&lt;p&gt;you c&lt;strong&gt;a&lt;/strong&gt;n still mov&lt;strong&gt;e&lt;/strong&gt; your mous&lt;strong&gt;e&lt;/strong&gt; und&lt;strong&gt;e&lt;/strong&gt;r &lt;strong&gt;the&lt;/strong&gt; l&lt;strong&gt;e&lt;/strong&gt;tt&lt;strong&gt;e&lt;/strong&gt;rs to &lt;strong&gt;e&lt;/strong&gt;xpos&lt;strong&gt;e&lt;/strong&gt; &lt;strong&gt;the&lt;/strong&gt;m.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;the&lt;/strong&gt; most common conson&lt;strong&gt;a&lt;/strong&gt;nt is &lt;strong&gt;the&lt;/strong&gt; &lt;strong&gt;t&lt;/strong&gt;. goodbye &lt;strong&gt;t&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;ok, w&lt;strong&gt;e&lt;/strong&gt;'v&lt;strong&gt;e&lt;/strong&gt; go&lt;strong&gt;tte&lt;/strong&gt;n rid of &lt;strong&gt;the&lt;/strong&gt; &lt;strong&gt;t&lt;/strong&gt;hr&lt;strong&gt;ee&lt;/strong&gt; mos&lt;strong&gt;t&lt;/strong&gt; common l&lt;strong&gt;ette&lt;/strong&gt;rs.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;the&lt;/strong&gt; four&lt;strong&gt;t&lt;/strong&gt;h mos&lt;strong&gt;t&lt;/strong&gt; common l&lt;strong&gt;e&lt;/strong&gt;&lt;strong&gt;t&lt;/strong&gt;&lt;strong&gt;t&lt;/strong&gt;&lt;strong&gt;e&lt;/strong&gt;r is &lt;strong&gt;the&lt;/strong&gt; &lt;strong&gt;o&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;if y&lt;strong&gt;o&lt;/strong&gt;u g&lt;strong&gt;o&lt;/strong&gt;&lt;strong&gt;t&lt;/strong&gt; &lt;strong&gt;t&lt;/strong&gt;his f&lt;strong&gt;a&lt;/strong&gt;r y&lt;strong&gt;o&lt;/strong&gt;u &lt;strong&gt;a&lt;/strong&gt;r&lt;strong&gt;e&lt;/strong&gt; d&lt;strong&gt;o&lt;/strong&gt;ing r&lt;strong&gt;e&lt;/strong&gt;&lt;strong&gt;a&lt;/strong&gt;lly w&lt;strong&gt;e&lt;/strong&gt;ll!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;o&lt;/strong&gt;nly &lt;strong&gt;t&lt;/strong&gt;w&lt;strong&gt;o&lt;/strong&gt; m&lt;strong&gt;o&lt;/strong&gt;r&lt;strong&gt;e&lt;/strong&gt;, &lt;strong&gt;a&lt;/strong&gt;nd h&lt;strong&gt;a&lt;/strong&gt;lf &lt;strong&gt;o&lt;/strong&gt;f &lt;strong&gt;a&lt;/strong&gt;ll &lt;strong&gt;the&lt;/strong&gt; l&lt;strong&gt;e&lt;/strong&gt;&lt;strong&gt;t&lt;/strong&gt;&lt;strong&gt;t&lt;/strong&gt;&lt;strong&gt;e&lt;/strong&gt;rs will b&lt;strong&gt;e&lt;/strong&gt; hidd&lt;strong&gt;e&lt;/strong&gt;n!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;t&lt;/strong&gt;h&lt;strong&gt;a&lt;/strong&gt;&lt;strong&gt;t&lt;/strong&gt;'s b&lt;strong&gt;e&lt;/strong&gt;c&lt;strong&gt;a&lt;/strong&gt;us&lt;strong&gt;e&lt;/strong&gt; &lt;strong&gt;the&lt;/strong&gt; six m&lt;strong&gt;o&lt;/strong&gt;s&lt;strong&gt;t&lt;/strong&gt; c&lt;strong&gt;o&lt;/strong&gt;mm&lt;strong&gt;o&lt;/strong&gt;n l&lt;strong&gt;e&lt;/strong&gt;&lt;strong&gt;t&lt;/strong&gt;&lt;strong&gt;t&lt;/strong&gt;&lt;strong&gt;e&lt;/strong&gt;rs &lt;strong&gt;o&lt;/strong&gt;ccur h&lt;strong&gt;a&lt;/strong&gt;lf &lt;strong&gt;the&lt;/strong&gt; &lt;strong&gt;t&lt;/strong&gt;im&lt;strong&gt;e&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;l&lt;strong&gt;e&lt;/strong&gt;&lt;strong&gt;t&lt;/strong&gt;&lt;strong&gt;t&lt;/strong&gt;&lt;strong&gt;e&lt;/strong&gt;rs &lt;strong&gt;i&lt;/strong&gt; &lt;strong&gt;a&lt;/strong&gt;nd &lt;strong&gt;n&lt;/strong&gt; &lt;strong&gt;a&lt;/strong&gt;r&lt;strong&gt;e&lt;/strong&gt; &lt;strong&gt;n&lt;/strong&gt;&lt;strong&gt;e&lt;/strong&gt;x&lt;strong&gt;t&lt;/strong&gt;. &lt;strong&gt;t&lt;/strong&gt;h&lt;strong&gt;a&lt;/strong&gt;&lt;strong&gt;t&lt;/strong&gt; w&lt;strong&gt;a&lt;/strong&gt;s&lt;strong&gt;n&lt;/strong&gt;'&lt;strong&gt;t&lt;/strong&gt; &lt;strong&gt;t&lt;/strong&gt;&lt;strong&gt;o&lt;/strong&gt;&lt;strong&gt;o&lt;/strong&gt; b&lt;strong&gt;a&lt;/strong&gt;d, r&lt;strong&gt;i&lt;/strong&gt;gh&lt;strong&gt;t&lt;/strong&gt;?&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;h&lt;strong&gt;e&lt;/strong&gt;r&lt;strong&gt;e&lt;/strong&gt; &lt;strong&gt;a&lt;/strong&gt;r&lt;strong&gt;e&lt;/strong&gt; &lt;strong&gt;a&lt;/strong&gt; gr&lt;strong&gt;e&lt;/strong&gt;&lt;strong&gt;a&lt;/strong&gt;&lt;strong&gt;t&lt;/strong&gt; c&lt;strong&gt;o&lt;/strong&gt;upl&lt;strong&gt;e&lt;/strong&gt; l&lt;strong&gt;i&lt;/strong&gt;&lt;strong&gt;n&lt;/strong&gt;&lt;strong&gt;e&lt;/strong&gt;s fr&lt;strong&gt;o&lt;/strong&gt;m s&lt;strong&gt;t&lt;/strong&gt;&lt;strong&gt;e&lt;/strong&gt;v&lt;strong&gt;e&lt;/strong&gt; j&lt;strong&gt;o&lt;/strong&gt;bs:&lt;/p&gt;
&lt;p&gt;&quot;l&lt;strong&gt;i&lt;/strong&gt;f&lt;strong&gt;e&lt;/strong&gt; c&lt;strong&gt;a&lt;/strong&gt;&lt;strong&gt;n&lt;/strong&gt; b&lt;strong&gt;e&lt;/strong&gt; much br&lt;strong&gt;o&lt;/strong&gt;&lt;strong&gt;a&lt;/strong&gt;d&lt;strong&gt;e&lt;/strong&gt;r &lt;strong&gt;o&lt;/strong&gt;&lt;strong&gt;n&lt;/strong&gt;c&lt;strong&gt;e&lt;/strong&gt; y&lt;strong&gt;o&lt;/strong&gt;u d&lt;strong&gt;i&lt;/strong&gt;sc&lt;strong&gt;o&lt;/strong&gt;v&lt;strong&gt;e&lt;/strong&gt;r &lt;strong&gt;o&lt;/strong&gt;&lt;strong&gt;n&lt;/strong&gt;&lt;strong&gt;e&lt;/strong&gt; s&lt;strong&gt;i&lt;/strong&gt;mpl&lt;strong&gt;e&lt;/strong&gt; f&lt;strong&gt;a&lt;/strong&gt;c&lt;strong&gt;t&lt;/strong&gt;; &lt;strong&gt;t&lt;/strong&gt;h&lt;strong&gt;a&lt;/strong&gt;&lt;strong&gt;t&lt;/strong&gt; &lt;strong&gt;e&lt;/strong&gt;v&lt;strong&gt;e&lt;/strong&gt;ry&lt;strong&gt;t&lt;/strong&gt;h&lt;strong&gt;i&lt;/strong&gt;&lt;strong&gt;n&lt;/strong&gt;g &lt;strong&gt;a&lt;/strong&gt;r&lt;strong&gt;o&lt;/strong&gt;u&lt;strong&gt;n&lt;/strong&gt;d y&lt;strong&gt;o&lt;/strong&gt;u &lt;strong&gt;t&lt;/strong&gt;h&lt;strong&gt;a&lt;/strong&gt;&lt;strong&gt;t&lt;/strong&gt; y&lt;strong&gt;o&lt;/strong&gt;u c&lt;strong&gt;a&lt;/strong&gt;ll l&lt;strong&gt;i&lt;/strong&gt;f&lt;strong&gt;e&lt;/strong&gt; w&lt;strong&gt;a&lt;/strong&gt;s m&lt;strong&gt;a&lt;/strong&gt;d&lt;strong&gt;e&lt;/strong&gt; up by p&lt;strong&gt;e&lt;/strong&gt;&lt;strong&gt;o&lt;/strong&gt;pl&lt;strong&gt;e&lt;/strong&gt; &lt;strong&gt;n&lt;/strong&gt;&lt;strong&gt;o&lt;/strong&gt; sm&lt;strong&gt;a&lt;/strong&gt;r&lt;strong&gt;t&lt;/strong&gt;&lt;strong&gt;e&lt;/strong&gt;r &lt;strong&gt;t&lt;/strong&gt;h&lt;strong&gt;a&lt;/strong&gt;&lt;strong&gt;n&lt;/strong&gt; y&lt;strong&gt;o&lt;/strong&gt;u.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;the&lt;/strong&gt; m&lt;strong&gt;i&lt;/strong&gt;&lt;strong&gt;n&lt;/strong&gt;u&lt;strong&gt;t&lt;/strong&gt;&lt;strong&gt;e&lt;/strong&gt; y&lt;strong&gt;o&lt;/strong&gt;u u&lt;strong&gt;n&lt;/strong&gt;d&lt;strong&gt;e&lt;/strong&gt;rs&lt;strong&gt;t&lt;/strong&gt;&lt;strong&gt;a&lt;/strong&gt;&lt;strong&gt;n&lt;/strong&gt;d &lt;strong&gt;t&lt;/strong&gt;h&lt;strong&gt;a&lt;/strong&gt;&lt;strong&gt;t&lt;/strong&gt;, y&lt;strong&gt;o&lt;/strong&gt;u c&lt;strong&gt;a&lt;/strong&gt;&lt;strong&gt;n&lt;/strong&gt; p&lt;strong&gt;o&lt;/strong&gt;k&lt;strong&gt;e&lt;/strong&gt; l&lt;strong&gt;i&lt;/strong&gt;f&lt;strong&gt;e&lt;/strong&gt;; y&lt;strong&gt;o&lt;/strong&gt;u c&lt;strong&gt;a&lt;/strong&gt;&lt;strong&gt;n&lt;/strong&gt; ch&lt;strong&gt;a&lt;/strong&gt;&lt;strong&gt;n&lt;/strong&gt;g&lt;strong&gt;e&lt;/strong&gt; &lt;strong&gt;i&lt;/strong&gt;&lt;strong&gt;t&lt;/strong&gt;, y&lt;strong&gt;o&lt;/strong&gt;u c&lt;strong&gt;a&lt;/strong&gt;&lt;strong&gt;n&lt;/strong&gt; m&lt;strong&gt;o&lt;/strong&gt;ld &lt;strong&gt;i&lt;/strong&gt;&lt;strong&gt;t&lt;/strong&gt;, &lt;strong&gt;e&lt;/strong&gt;mbr&lt;strong&gt;a&lt;/strong&gt;c&lt;strong&gt;e&lt;/strong&gt; &lt;strong&gt;i&lt;/strong&gt;&lt;strong&gt;t&lt;/strong&gt;, m&lt;strong&gt;a&lt;/strong&gt;k&lt;strong&gt;e&lt;/strong&gt; y&lt;strong&gt;o&lt;/strong&gt;ur m&lt;strong&gt;a&lt;/strong&gt;rk up&lt;strong&gt;o&lt;/strong&gt;&lt;strong&gt;n&lt;/strong&gt; &lt;strong&gt;i&lt;/strong&gt;t.&quot;&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;l&lt;strong&gt;e&lt;/strong&gt;&lt;strong&gt;t&lt;/strong&gt;'s r&lt;strong&gt;e&lt;/strong&gt;m&lt;strong&gt;o&lt;/strong&gt;v&lt;strong&gt;e&lt;/strong&gt; s&lt;strong&gt;o&lt;/strong&gt;m&lt;strong&gt;e&lt;/strong&gt; &lt;strong&gt;o&lt;/strong&gt;f &lt;strong&gt;the&lt;/strong&gt; m&lt;strong&gt;o&lt;/strong&gt;us&lt;strong&gt;e&lt;/strong&gt;&lt;strong&gt;o&lt;/strong&gt;v&lt;strong&gt;e&lt;/strong&gt;r h&lt;strong&gt;i&lt;/strong&gt;&lt;strong&gt;n&lt;/strong&gt;&lt;strong&gt;t&lt;/strong&gt;s, b&lt;strong&gt;e&lt;/strong&gt;f&lt;strong&gt;o&lt;/strong&gt;r&lt;strong&gt;e&lt;/strong&gt; &lt;strong&gt;a&lt;/strong&gt;dd&lt;strong&gt;i&lt;/strong&gt;&lt;strong&gt;n&lt;/strong&gt;g l&lt;strong&gt;e&lt;/strong&gt;&lt;strong&gt;t&lt;/strong&gt;&lt;strong&gt;t&lt;/strong&gt;&lt;strong&gt;e&lt;/strong&gt;rs.&lt;/p&gt;
&lt;p&gt;y&lt;strong&gt;o&lt;/strong&gt;u pr&lt;strong&gt;o&lt;/strong&gt;b&lt;strong&gt;a&lt;/strong&gt;bly k&lt;strong&gt;n&lt;/strong&gt;&lt;strong&gt;o&lt;/strong&gt;w &lt;strong&gt;a&lt;/strong&gt;, &lt;strong&gt;e&lt;/strong&gt;, &lt;strong&gt;a&lt;/strong&gt;&lt;strong&gt;n&lt;/strong&gt;d &lt;strong&gt;o&lt;/strong&gt; pr&lt;strong&gt;e&lt;/strong&gt;&lt;strong&gt;t&lt;/strong&gt;&lt;strong&gt;t&lt;/strong&gt;y w&lt;strong&gt;e&lt;/strong&gt;ll, s&lt;strong&gt;o&lt;/strong&gt; &lt;strong&gt;n&lt;/strong&gt;&lt;strong&gt;o&lt;/strong&gt; m&lt;strong&gt;o&lt;/strong&gt;r&lt;strong&gt;e&lt;/strong&gt; h&lt;strong&gt;i&lt;/strong&gt;&lt;strong&gt;n&lt;/strong&gt;&lt;strong&gt;t&lt;/strong&gt;s f&lt;strong&gt;o&lt;/strong&gt;r &lt;strong&gt;the&lt;/strong&gt;m.&lt;/p&gt;
&lt;p&gt;&lt;u&gt;a&lt;/u&gt;ls&lt;u&gt;o&lt;/u&gt;, &lt;strong&gt;i&lt;/strong&gt; &lt;strong&gt;i&lt;/strong&gt;s pr&lt;u&gt;e&lt;/u&gt;&lt;strong&gt;t&lt;/strong&gt;&lt;strong&gt;t&lt;/strong&gt;y &lt;u&gt;e&lt;/u&gt;&lt;u&gt;a&lt;/u&gt;sy &lt;u&gt;a&lt;/u&gt;&lt;strong&gt;n&lt;/strong&gt;d l&lt;u&gt;o&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;ks l&lt;strong&gt;i&lt;/strong&gt;k&lt;u&gt;e&lt;/u&gt; &lt;u&gt;a&lt;/u&gt;&lt;strong&gt;n&lt;/strong&gt; &lt;strong&gt;i&lt;/strong&gt;, s&lt;u&gt;o&lt;/u&gt; &lt;strong&gt;n&lt;/strong&gt;&lt;u&gt;o&lt;/u&gt; h&lt;u&gt;i&lt;/u&gt;&lt;strong&gt;n&lt;/strong&gt;&lt;strong&gt;t&lt;/strong&gt;s f&lt;u&gt;o&lt;/u&gt;r &lt;strong&gt;i&lt;/strong&gt; &lt;strong&gt;n&lt;/strong&gt;&lt;u&gt;o&lt;/u&gt;w.&lt;/p&gt;
&lt;p&gt;y&lt;u&gt;o&lt;/u&gt;u &lt;u&gt;a&lt;/u&gt;r&lt;u&gt;e&lt;/u&gt; d&lt;u&gt;o&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;&lt;strong&gt;n&lt;/strong&gt;g v&lt;u&gt;e&lt;/u&gt;ry w&lt;u&gt;e&lt;/u&gt;ll &lt;u&gt;i&lt;/u&gt;f y&lt;u&gt;o&lt;/u&gt;u'v&lt;u&gt;e&lt;/u&gt; g&lt;u&gt;o&lt;/u&gt;&lt;strong&gt;t&lt;/strong&gt;&lt;strong&gt;t&lt;/strong&gt;&lt;u&gt;e&lt;/u&gt;&lt;strong&gt;n&lt;/strong&gt; &lt;strong&gt;t&lt;/strong&gt;h&lt;u&gt;i&lt;/u&gt;s f&lt;u&gt;a&lt;/u&gt;r.&lt;/p&gt;
&lt;p&gt;l&lt;u&gt;e&lt;/u&gt;&lt;strong&gt;t&lt;/strong&gt;'s d&lt;u&gt;o&lt;/u&gt; &lt;strong&gt;n&lt;/strong&gt;&lt;u&gt;o&lt;/u&gt; m&lt;u&gt;o&lt;/u&gt;r&lt;u&gt;e&lt;/u&gt; &lt;strong&gt;t&lt;/strong&gt; h&lt;u&gt;i&lt;/u&gt;&lt;strong&gt;n&lt;/strong&gt;&lt;strong&gt;t&lt;/strong&gt;s. &lt;strong&gt;t&lt;/strong&gt; &lt;u&gt;i&lt;/u&gt;s &lt;u&gt;e&lt;/u&gt;v&lt;u&gt;e&lt;/u&gt;rywh&lt;u&gt;e&lt;/u&gt;r&lt;u&gt;e&lt;/u&gt;.&lt;/p&gt;
&lt;p&gt;&lt;u&gt;i&lt;/u&gt;f w&lt;u&gt;e&lt;/u&gt; d&lt;u&gt;o&lt;/u&gt; &lt;strong&gt;n&lt;/strong&gt;&lt;u&gt;o&lt;/u&gt; &lt;strong&gt;n&lt;/strong&gt; h&lt;u&gt;i&lt;/u&gt;&lt;strong&gt;n&lt;/strong&gt;&lt;u&gt;t&lt;/u&gt;s, w&lt;u&gt;e&lt;/u&gt; c&lt;u&gt;a&lt;/u&gt;&lt;strong&gt;n&lt;/strong&gt; m&lt;u&gt;o&lt;/u&gt;v&lt;u&gt;e&lt;/u&gt; &lt;u&gt;o&lt;/u&gt;&lt;strong&gt;n&lt;/strong&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;o&lt;/u&gt; m&lt;u&gt;o&lt;/u&gt;r&lt;u&gt;e&lt;/u&gt; l&lt;u&gt;e&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;rs.&lt;/p&gt;
&lt;p&gt;&lt;u&gt;t&lt;/u&gt;h&lt;u&gt;i&lt;/u&gt;s c&lt;u&gt;o&lt;/u&gt;uld b&lt;u&gt;e&lt;/u&gt; &lt;u&gt;a&lt;/u&gt; g&lt;u&gt;o&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;d &lt;u&gt;t&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;m&lt;u&gt;e&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;u&gt;o&lt;/u&gt; g&lt;u&gt;o&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;u&gt;o&lt;/u&gt; &lt;a href=&quot;http://memorize.com/dotsies&quot;&gt;m&lt;u&gt;e&lt;/u&gt;m&lt;u&gt;o&lt;/u&gt;r&lt;u&gt;i&lt;/u&gt;z&lt;u&gt;e&lt;/u&gt;.c&lt;u&gt;o&lt;/u&gt;m/d&lt;u&gt;o&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;s&lt;u&gt;i&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;s&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;u&gt;o&lt;/u&gt;r, &lt;u&gt;i&lt;/u&gt;f y&lt;u&gt;o&lt;/u&gt;u'r&lt;u&gt;e&lt;/u&gt; &lt;u&gt;e&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;j&lt;u&gt;o&lt;/u&gt;y&lt;u&gt;i&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;g jus&lt;u&gt;t&lt;/u&gt; r&lt;u&gt;e&lt;/u&gt;&lt;u&gt;a&lt;/u&gt;d&lt;u&gt;i&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;g &lt;u&gt;t&lt;/u&gt;h&lt;u&gt;i&lt;/u&gt;s w&lt;u&gt;a&lt;/u&gt;y, &lt;u&gt;t&lt;/u&gt;h&lt;u&gt;a&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;'s g&lt;u&gt;o&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;d &lt;u&gt;a&lt;/u&gt;ls&lt;u&gt;o&lt;/u&gt;.&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;s &lt;u&gt;i&lt;/u&gt;s &lt;u&gt;t&lt;/u&gt;h&lt;u&gt;e&lt;/u&gt; &lt;u&gt;n&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;x&lt;u&gt;t&lt;/u&gt; l&lt;u&gt;e&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;r. &lt;u&gt;i&lt;/u&gt;&lt;u&gt;t&lt;/u&gt; &lt;u&gt;i&lt;/u&gt;s &lt;u&gt;a&lt;/u&gt;&lt;u&gt;n&lt;/u&gt; &lt;u&gt;e&lt;/u&gt;&lt;u&gt;a&lt;/u&gt;sy &lt;u&gt;o&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;.&lt;/p&gt;
&lt;p&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;t&lt;/u&gt; l&lt;u&gt;o&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;k&lt;strong&gt;s&lt;/strong&gt; l&lt;u&gt;i&lt;/u&gt;k&lt;u&gt;e&lt;/u&gt; &lt;u&gt;a&lt;/u&gt; &lt;strong&gt;s&lt;/strong&gt;m&lt;u&gt;a&lt;/u&gt;ll &lt;strong&gt;s&lt;/strong&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;a&lt;/u&gt;k&lt;u&gt;e&lt;/u&gt;. &lt;strong&gt;s&lt;/strong&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; h&lt;u&gt;o&lt;/u&gt;w &lt;u&gt;i&lt;/u&gt;&lt;u&gt;t&lt;/u&gt; &lt;strong&gt;s&lt;/strong&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;strong&gt;s&lt;/strong&gt; &lt;u&gt;i&lt;/u&gt;&lt;u&gt;n&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;h&lt;u&gt;e&lt;/u&gt; m&lt;u&gt;i&lt;/u&gt;ddl&lt;u&gt;e&lt;/u&gt;.&lt;/p&gt;
&lt;p&gt;l&lt;u&gt;e&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;r h &lt;u&gt;i&lt;/u&gt;&lt;strong&gt;s&lt;/strong&gt; &lt;u&gt;a&lt;/u&gt;f&lt;u&gt;t&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;r &lt;strong&gt;s&lt;/strong&gt; &lt;u&gt;o&lt;/u&gt;&lt;u&gt;n&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;h&lt;u&gt;e&lt;/u&gt; fr&lt;u&gt;e&lt;/u&gt;qu&lt;u&gt;e&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;cy l&lt;u&gt;i&lt;/u&gt;&lt;strong&gt;s&lt;/strong&gt;&lt;u&gt;t&lt;/u&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;h&lt;/strong&gt; &lt;u&gt;i&lt;/u&gt;&lt;strong&gt;s&lt;/strong&gt; &lt;strong&gt;h&lt;/strong&gt;&lt;u&gt;a&lt;/u&gt;rd&lt;u&gt;e&lt;/u&gt;r &lt;u&gt;t&lt;/u&gt;&lt;strong&gt;h&lt;/strong&gt;&lt;u&gt;a&lt;/u&gt;&lt;u&gt;n&lt;/u&gt; &lt;strong&gt;s&lt;/strong&gt; bu&lt;u&gt;t&lt;/u&gt; &lt;u&gt;i&lt;/u&gt;&lt;strong&gt;s&lt;/strong&gt; &lt;strong&gt;h&lt;/strong&gt;&lt;u&gt;i&lt;/u&gt;g&lt;strong&gt;h&lt;/strong&gt;&lt;u&gt;e&lt;/u&gt;r &lt;u&gt;t&lt;/u&gt;&lt;strong&gt;h&lt;/strong&gt;&lt;u&gt;a&lt;/u&gt;&lt;u&gt;n&lt;/u&gt; &lt;u&gt;i&lt;/u&gt;.&lt;/p&gt;
&lt;p&gt;d&lt;u&gt;i&lt;/u&gt;d &lt;u&gt;i&lt;/u&gt; m&lt;u&gt;e&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;n&lt;/u&gt; y&lt;u&gt;o&lt;/u&gt;u &lt;u&gt;a&lt;/u&gt;r&lt;u&gt;e&lt;/u&gt; d&lt;u&gt;o&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;g f&lt;u&gt;a&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;a&lt;/u&gt;&lt;strong&gt;s&lt;/strong&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;c&lt;u&gt;a&lt;/u&gt;lly w&lt;u&gt;e&lt;/u&gt;ll?&lt;/p&gt;
&lt;p&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;ly &lt;u&gt;t&lt;/u&gt;w&lt;u&gt;o&lt;/u&gt; m&lt;u&gt;o&lt;/u&gt;r&lt;u&gt;e&lt;/u&gt;, &lt;u&gt;a&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;d &lt;u&gt;a&lt;/u&gt;b&lt;u&gt;o&lt;/u&gt;u&lt;u&gt;t&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;strong&gt;h&lt;/strong&gt;r&lt;u&gt;e&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; f&lt;u&gt;o&lt;/u&gt;ur&lt;u&gt;t&lt;/u&gt;&lt;strong&gt;h&lt;/strong&gt;&lt;strong&gt;s&lt;/strong&gt; w&lt;u&gt;i&lt;/u&gt;ll b&lt;u&gt;e&lt;/u&gt; d&lt;u&gt;o&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;strong&gt;s&lt;/strong&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;strong&gt;s&lt;/strong&gt;!&lt;/p&gt;
&lt;p&gt;r k&lt;u&gt;i&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;d &lt;u&gt;o&lt;/u&gt;f l&lt;u&gt;o&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;k&lt;strong&gt;s&lt;/strong&gt; l&lt;u&gt;i&lt;/u&gt;k&lt;u&gt;e&lt;/u&gt; &lt;u&gt;a&lt;/u&gt;&lt;u&gt;n&lt;/u&gt; r, w&lt;u&gt;i&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;strong&gt;h&lt;/strong&gt; &lt;u&gt;t&lt;/u&gt;&lt;strong&gt;h&lt;/strong&gt;&lt;u&gt;e&lt;/u&gt; &lt;strong&gt;h&lt;/strong&gt;&lt;u&gt;o&lt;/u&gt;l&lt;u&gt;e&lt;/u&gt; &lt;u&gt;a&lt;/u&gt;&lt;u&gt;t&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;strong&gt;h&lt;/strong&gt;&lt;u&gt;e&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;p.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;r&lt;/strong&gt; &lt;u&gt;i&lt;/u&gt;&lt;strong&gt;s&lt;/strong&gt; &lt;u&gt;n&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;t&lt;/u&gt; &lt;strong&gt;r&lt;/strong&gt;&lt;u&gt;a&lt;/u&gt;&lt;strong&gt;r&lt;/strong&gt;&lt;u&gt;e&lt;/u&gt; &lt;strong&gt;s&lt;/strong&gt;&lt;u&gt;o&lt;/u&gt; d&lt;u&gt;o&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;'&lt;u&gt;t&lt;/u&gt; &lt;u&gt;e&lt;/u&gt;&lt;strong&gt;r&lt;/strong&gt;&lt;strong&gt;r&lt;/strong&gt;&lt;u&gt;o&lt;/u&gt;&lt;strong&gt;r&lt;/strong&gt; w&lt;strong&gt;h&lt;/strong&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;n&lt;/u&gt; &lt;strong&gt;r&lt;/strong&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;a&lt;/u&gt;d&lt;u&gt;i&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;g &lt;u&gt;i&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;.&lt;/p&gt;
&lt;p&gt;d &lt;u&gt;i&lt;/u&gt;&lt;strong&gt;s&lt;/strong&gt; &lt;u&gt;a&lt;/u&gt; d&lt;u&gt;o&lt;/u&gt;&lt;u&gt;t&lt;/u&gt; &lt;u&gt;a&lt;/u&gt;b&lt;u&gt;o&lt;/u&gt;v&lt;u&gt;e&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;strong&gt;h&lt;/strong&gt;&lt;u&gt;e&lt;/u&gt; &lt;u&gt;e&lt;/u&gt;, &lt;u&gt;o&lt;/u&gt;f c&lt;u&gt;o&lt;/u&gt;u&lt;strong&gt;r&lt;/strong&gt;&lt;strong&gt;s&lt;/strong&gt;&lt;u&gt;e&lt;/u&gt;.&lt;/p&gt;
&lt;p&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;&lt;strong&gt;d&lt;/strong&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;strong&gt;d&lt;/strong&gt;, &lt;strong&gt;d&lt;/strong&gt; w&lt;u&gt;a&lt;/u&gt;&lt;strong&gt;s&lt;/strong&gt; &lt;u&gt;a&lt;/u&gt;&lt;strong&gt;d&lt;/strong&gt;&lt;strong&gt;d&lt;/strong&gt;&lt;u&gt;e&lt;/u&gt;&lt;strong&gt;d&lt;/strong&gt; u&lt;u&gt;n&lt;/u&gt;&lt;strong&gt;d&lt;/strong&gt;&lt;u&gt;e&lt;/u&gt;&lt;strong&gt;r&lt;/strong&gt; &lt;u&gt;t&lt;/u&gt;&lt;strong&gt;h&lt;/strong&gt;&lt;u&gt;e&lt;/u&gt; m&lt;u&gt;i&lt;/u&gt;&lt;strong&gt;d&lt;/strong&gt;&lt;strong&gt;d&lt;/strong&gt;l&lt;u&gt;e&lt;/u&gt;.&lt;/p&gt;
&lt;hr/&gt;&lt;p class=&quot;sans&quot;&gt;Great job so far! Tweet me at &lt;a href=&quot;http://twitter.com/DotsiesFont&quot;&gt;@DotsiesFont&lt;/a&gt; and tell me your thoughts!&lt;br/&gt;If you want to continue with something a little less intense, try reading a story &lt;a href=&quot;http://dotsies.org/reader&quot;&gt;here&lt;/a&gt;. Or, if you are enjoying the tutorial, continue on:&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;&lt;u&gt;e&lt;/u&gt;xc&lt;u&gt;e&lt;/u&gt;ll&lt;u&gt;e&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;, &lt;u&gt;t&lt;/u&gt;&lt;strong&gt;h&lt;/strong&gt;&lt;u&gt;a&lt;/u&gt;&lt;u&gt;t&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;u&gt;a&lt;/u&gt;k&lt;u&gt;e&lt;/u&gt;&lt;strong&gt;s&lt;/strong&gt; c&lt;u&gt;a&lt;/u&gt;&lt;strong&gt;r&lt;/strong&gt;&lt;u&gt;e&lt;/u&gt; &lt;u&gt;o&lt;/u&gt;f &lt;u&gt;t&lt;/u&gt;&lt;strong&gt;h&lt;/strong&gt;&lt;strong&gt;r&lt;/strong&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; f&lt;u&gt;o&lt;/u&gt;u&lt;strong&gt;r&lt;/strong&gt;&lt;u&gt;t&lt;/u&gt;&lt;strong&gt;h&lt;/strong&gt;&lt;strong&gt;s&lt;/strong&gt; &lt;u&gt;o&lt;/u&gt;f l&lt;u&gt;e&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;strong&gt;r&lt;/strong&gt;&lt;strong&gt;s&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;u&gt;a&lt;/u&gt;f&lt;u&gt;t&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;strong&gt;r&lt;/strong&gt; &lt;u&gt;t&lt;/u&gt;&lt;strong&gt;h&lt;/strong&gt;&lt;u&gt;e&lt;/u&gt; &lt;u&gt;n&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;x&lt;u&gt;t&lt;/u&gt; g&lt;strong&gt;r&lt;/strong&gt;&lt;u&gt;o&lt;/u&gt;up w&lt;u&gt;e&lt;/u&gt;'ll b&lt;u&gt;e&lt;/u&gt; &lt;u&gt;a&lt;/u&gt;&lt;u&gt;t&lt;/u&gt; &lt;u&gt;a&lt;/u&gt;b&lt;u&gt;o&lt;/u&gt;u&lt;u&gt;t&lt;/u&gt; &lt;u&gt;n&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;y p&lt;u&gt;e&lt;/u&gt;&lt;strong&gt;r&lt;/strong&gt;c&lt;u&gt;e&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;!&lt;/p&gt;
&lt;p&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;w &lt;strong&gt;d&lt;/strong&gt;&lt;u&gt;o&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;strong&gt;h&lt;/strong&gt;&lt;u&gt;e&lt;/u&gt; f&lt;u&gt;i&lt;/u&gt;&lt;strong&gt;r&lt;/strong&gt;&lt;strong&gt;s&lt;/strong&gt;&lt;u&gt;t&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;w&lt;u&gt;o&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;u&gt;a&lt;/u&gt;bl&lt;u&gt;e&lt;/u&gt;&lt;strong&gt;s&lt;/strong&gt; &lt;u&gt;o&lt;/u&gt;&lt;u&gt;n&lt;/u&gt; &lt;a href=&quot;http://memorize.com/dotsies&quot;&gt;m&lt;u&gt;e&lt;/u&gt;m&lt;u&gt;o&lt;/u&gt;&lt;strong&gt;r&lt;/strong&gt;&lt;u&gt;i&lt;/u&gt;z&lt;u&gt;e&lt;/u&gt;.c&lt;u&gt;o&lt;/u&gt;m/&lt;strong&gt;d&lt;/strong&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;strong&gt;s&lt;/strong&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;strong&gt;s&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;d&lt;/strong&gt;&lt;u&gt;o&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;strong&gt;h&lt;/strong&gt;&lt;u&gt;e&lt;/u&gt; &lt;strong&gt;s&lt;/strong&gt;&lt;u&gt;i&lt;/u&gt;x&lt;u&gt;t&lt;/u&gt;&lt;strong&gt;h&lt;/strong&gt; &lt;u&gt;a&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;&lt;strong&gt;d&lt;/strong&gt; &lt;strong&gt;s&lt;/strong&gt;&lt;u&gt;e&lt;/u&gt;v&lt;u&gt;e&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;strong&gt;h&lt;/strong&gt; &lt;u&gt;t&lt;/u&gt;&lt;u&gt;a&lt;/u&gt;bl&lt;u&gt;e&lt;/u&gt;&lt;strong&gt;s&lt;/strong&gt; &lt;u&gt;t&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;, &lt;strong&gt;s&lt;/strong&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;c&lt;u&gt;e&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;strong&gt;h&lt;/strong&gt;&lt;u&gt;e&lt;/u&gt;y c&lt;u&gt;o&lt;/u&gt;&lt;strong&gt;r&lt;/strong&gt;&lt;strong&gt;r&lt;/strong&gt;&lt;u&gt;e&lt;/u&gt;&lt;strong&gt;s&lt;/strong&gt;p&lt;u&gt;o&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;&lt;strong&gt;d&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;u&gt;t&lt;/u&gt;&lt;strong&gt;h&lt;/strong&gt;&lt;u&gt;a&lt;/u&gt;&lt;u&gt;t&lt;/u&gt; &lt;strong&gt;s&lt;/strong&gt;&lt;strong&gt;h&lt;/strong&gt;&lt;u&gt;o&lt;/u&gt;ul&lt;strong&gt;d&lt;/strong&gt; &lt;strong&gt;h&lt;/strong&gt;&lt;u&gt;e&lt;/u&gt;lp y&lt;u&gt;o&lt;/u&gt;u b&lt;u&gt;e&lt;/u&gt; c&lt;u&gt;o&lt;/u&gt;mf&lt;u&gt;o&lt;/u&gt;&lt;strong&gt;r&lt;/strong&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;a&lt;/u&gt;bl&lt;u&gt;e&lt;/u&gt; w&lt;u&gt;i&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;strong&gt;h&lt;/strong&gt; &lt;u&gt;t&lt;/u&gt;&lt;strong&gt;h&lt;/strong&gt;&lt;u&gt;e&lt;/u&gt; f&lt;u&gt;i&lt;/u&gt;&lt;strong&gt;r&lt;/strong&gt;&lt;strong&gt;s&lt;/strong&gt;&lt;u&gt;t&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;n&lt;/u&gt; l&lt;u&gt;e&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;strong&gt;r&lt;/strong&gt;&lt;strong&gt;s&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;w w&lt;u&gt;e&lt;/u&gt; c&lt;u&gt;a&lt;/u&gt;&lt;u&gt;n&lt;/u&gt; &lt;strong&gt;s&lt;/strong&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;a&lt;/u&gt;&lt;strong&gt;r&lt;/strong&gt;&lt;u&gt;t&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;u&lt;strong&gt;r&lt;/strong&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;g &lt;strong&gt;s&lt;/strong&gt;&lt;u&gt;o&lt;/u&gt;m&lt;u&gt;e&lt;/u&gt; &lt;strong&gt;h&lt;/strong&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;strong&gt;s&lt;/strong&gt; &lt;u&gt;o&lt;/u&gt;ff.&lt;/p&gt;
&lt;p&gt;l&lt;u&gt;e&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;'&lt;strong&gt;s&lt;/strong&gt; &lt;strong&gt;r&lt;/strong&gt;&lt;u&gt;e&lt;/u&gt;m&lt;u&gt;o&lt;/u&gt;v&lt;u&gt;e&lt;/u&gt; &lt;strong&gt;s&lt;/strong&gt; b&lt;u&gt;e&lt;/u&gt;c&lt;u&gt;a&lt;/u&gt;u&lt;strong&gt;s&lt;/strong&gt;&lt;u&gt;e&lt;/u&gt; &lt;u&gt;i&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;'&lt;strong&gt;s&lt;/strong&gt; &lt;strong&gt;s&lt;/strong&gt;&lt;u&gt;o&lt;/u&gt; &lt;strong&gt;s&lt;/strong&gt;&lt;u&gt;i&lt;/u&gt;mpl&lt;u&gt;e&lt;/u&gt;.&lt;/p&gt;
&lt;p&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;w &lt;u&gt;s&lt;/u&gt;&lt;u&gt;o&lt;/u&gt; l&lt;u&gt;o&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;g &lt;u&gt;t&lt;/u&gt;&lt;u&gt;o&lt;/u&gt; &lt;strong&gt;h&lt;/strong&gt; &lt;strong&gt;h&lt;/strong&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;s&lt;/u&gt; f&lt;u&gt;o&lt;/u&gt;&lt;strong&gt;r&lt;/strong&gt; &lt;u&gt;n&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;w.&lt;/p&gt;
&lt;p&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;ly &lt;u&gt;t&lt;/u&gt;w&lt;u&gt;o&lt;/u&gt; m&lt;u&gt;o&lt;/u&gt;&lt;strong&gt;r&lt;/strong&gt;&lt;u&gt;e&lt;/u&gt; l&lt;u&gt;e&lt;/u&gt;f&lt;u&gt;t&lt;/u&gt;, &lt;u&gt;a&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;&lt;strong&gt;d&lt;/strong&gt; w&lt;u&gt;e&lt;/u&gt;'&lt;strong&gt;r&lt;/strong&gt;&lt;u&gt;e&lt;/u&gt; &lt;u&gt;a&lt;/u&gt;&lt;u&gt;t&lt;/u&gt; &lt;u&gt;s&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;v&lt;u&gt;e&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;y f&lt;u&gt;i&lt;/u&gt;v&lt;u&gt;e&lt;/u&gt; p&lt;u&gt;e&lt;/u&gt;&lt;strong&gt;r&lt;/strong&gt;c&lt;u&gt;e&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;r&lt;/strong&gt; &lt;u&gt;h&lt;/u&gt;&lt;u&gt;a&lt;/u&gt;&lt;u&gt;s&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;u&gt;h&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; &lt;u&gt;h&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;l&lt;u&gt;e&lt;/u&gt; &lt;u&gt;a&lt;/u&gt;&lt;u&gt;t&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;u&gt;h&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;p, &lt;u&gt;s&lt;/u&gt;&lt;u&gt;o&lt;/u&gt; l&lt;u&gt;e&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;'&lt;u&gt;s&lt;/u&gt; &lt;strong&gt;r&lt;/strong&gt;&lt;u&gt;e&lt;/u&gt;m&lt;u&gt;o&lt;/u&gt;v&lt;u&gt;e&lt;/u&gt; &lt;u&gt;i&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;.&lt;/p&gt;
&lt;p&gt;&lt;u&gt;a&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;&lt;strong&gt;d&lt;/strong&gt; &lt;strong&gt;d&lt;/strong&gt; &lt;u&gt;i&lt;/u&gt;&lt;u&gt;s&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;u&gt;h&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; &lt;u&gt;s&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;gl&lt;u&gt;e&lt;/u&gt; &lt;strong&gt;d&lt;/strong&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;, &lt;u&gt;s&lt;/u&gt;&lt;u&gt;o&lt;/u&gt; l&lt;u&gt;e&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;'&lt;u&gt;s&lt;/u&gt; &lt;strong&gt;d&lt;/strong&gt;&lt;u&gt;e&lt;/u&gt;l&lt;u&gt;e&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; &lt;u&gt;i&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;s&lt;/u&gt; &lt;u&gt;h&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;s&lt;/u&gt;.&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;w&lt;u&gt;o&lt;/u&gt;w, &lt;u&gt;n&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;w &lt;u&gt;t&lt;/u&gt;&lt;u&gt;h&lt;/u&gt;&lt;u&gt;r&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; f&lt;u&gt;o&lt;/u&gt;u&lt;u&gt;r&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;h&lt;/u&gt;&lt;u&gt;s&lt;/u&gt; &lt;u&gt;o&lt;/u&gt;f &lt;u&gt;t&lt;/u&gt;&lt;u&gt;h&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; l&lt;u&gt;e&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;r&lt;/u&gt;&lt;u&gt;s&lt;/u&gt; &lt;u&gt;a&lt;/u&gt;&lt;u&gt;r&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; &lt;u&gt;d&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;s&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;s&lt;/u&gt;.&lt;/p&gt;
&lt;p&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;h&lt;/u&gt;&lt;u&gt;a&lt;/u&gt;&lt;u&gt;t&lt;/u&gt; &lt;u&gt;i&lt;/u&gt;&lt;u&gt;s&lt;/u&gt; f&lt;u&gt;a&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;a&lt;/u&gt;&lt;u&gt;s&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;c! b&lt;u&gt;e&lt;/u&gt; &lt;u&gt;s&lt;/u&gt;u&lt;u&gt;r&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;u&gt;o&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;ll u&lt;u&gt;s&lt;/u&gt; &lt;u&gt;o&lt;/u&gt;&lt;u&gt;n&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;w&lt;u&gt;i&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;r&lt;/u&gt;.&lt;/p&gt;
&lt;p&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;t&lt;/u&gt; &lt;u&gt;i&lt;/u&gt;&lt;u&gt;s&lt;/u&gt; &lt;u&gt;d&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;w&lt;u&gt;n&lt;/u&gt; &lt;u&gt;h&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;ll f&lt;u&gt;r&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;m &lt;u&gt;h&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;r&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;.&lt;/p&gt;
&lt;p&gt;&lt;u&gt;d&lt;/u&gt;&lt;u&gt;o&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;u&gt;h&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;u&gt;h&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;r&lt;/u&gt;&lt;u&gt;d&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;u&gt;a&lt;/u&gt;bl&lt;u&gt;e&lt;/u&gt; &lt;u&gt;o&lt;/u&gt;&lt;u&gt;n&lt;/u&gt; &lt;a href=&quot;http://memorize.com/dotsies&quot;&gt;m&lt;u&gt;e&lt;/u&gt;m&lt;u&gt;o&lt;/u&gt;&lt;u&gt;r&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;z&lt;u&gt;e&lt;/u&gt;.c&lt;u&gt;o&lt;/u&gt;m/&lt;u&gt;d&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;s&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;s&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;h&lt;/u&gt;&lt;u&gt;a&lt;/u&gt;&lt;u&gt;t&lt;/u&gt; w&lt;u&gt;a&lt;/u&gt;y w&lt;u&gt;e&lt;/u&gt; c&lt;u&gt;a&lt;/u&gt;&lt;u&gt;n&lt;/u&gt; &lt;u&gt;a&lt;/u&gt;&lt;u&gt;d&lt;/u&gt;&lt;u&gt;d&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;u&gt;h&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; &lt;u&gt;n&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;x&lt;u&gt;t&lt;/u&gt; f&lt;u&gt;i&lt;/u&gt;v&lt;u&gt;e&lt;/u&gt; &lt;u&gt;a&lt;/u&gt;ll &lt;u&gt;a&lt;/u&gt;&lt;u&gt;t&lt;/u&gt; &lt;u&gt;o&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;c&lt;u&gt;e&lt;/u&gt;.&lt;/p&gt;
&lt;p&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;h&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;y &lt;u&gt;a&lt;/u&gt;&lt;u&gt;r&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; l, c, u, m &lt;u&gt;a&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;d&lt;/u&gt; w.&lt;/p&gt;
&lt;p&gt;&lt;u&gt;o&lt;/u&gt;k, &lt;u&gt;s&lt;/u&gt;&lt;u&gt;o&lt;/u&gt; &lt;u&gt;h&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;strong&gt;w&lt;/strong&gt; &lt;u&gt;i&lt;/u&gt;&lt;u&gt;s&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;u&gt;h&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;s&lt;/u&gt;? y&lt;u&gt;o&lt;/u&gt;&lt;strong&gt;u&lt;/strong&gt;'&lt;u&gt;r&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; &lt;u&gt;n&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;strong&gt;w&lt;/strong&gt; &lt;strong&gt;u&lt;/strong&gt;p &lt;u&gt;t&lt;/u&gt;&lt;u&gt;o&lt;/u&gt; &lt;u&gt;n&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;y p&lt;u&gt;e&lt;/u&gt;&lt;u&gt;r&lt;/u&gt;&lt;strong&gt;c&lt;/strong&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;!&lt;/p&gt;
&lt;p&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;h&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; &lt;strong&gt;l&lt;/strong&gt;&lt;u&gt;a&lt;/u&gt;&lt;u&gt;s&lt;/u&gt;&lt;u&gt;t&lt;/u&gt; &lt;u&gt;e&lt;/u&gt;&lt;strong&gt;l&lt;/strong&gt;&lt;u&gt;e&lt;/u&gt;v&lt;u&gt;e&lt;/u&gt;&lt;u&gt;n&lt;/u&gt; &lt;strong&gt;l&lt;/strong&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;r&lt;/u&gt;&lt;u&gt;s&lt;/u&gt; &lt;u&gt;a&lt;/u&gt;&lt;u&gt;r&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; &lt;strong&gt;u&lt;/strong&gt;&lt;u&gt;s&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;d&lt;/u&gt; &lt;u&gt;s&lt;/u&gt;&lt;strong&gt;u&lt;/strong&gt;&lt;u&gt;r&lt;/u&gt;p&lt;u&gt;r&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;s&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;g&lt;strong&gt;l&lt;/strong&gt;y &lt;u&gt;r&lt;/u&gt;&lt;u&gt;a&lt;/u&gt;&lt;u&gt;r&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;strong&gt;l&lt;/strong&gt;y.&lt;/p&gt;
&lt;p&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;h&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; &lt;strong&gt;l&lt;/strong&gt;&lt;u&gt;a&lt;/u&gt;&lt;u&gt;s&lt;/u&gt;&lt;u&gt;t&lt;/u&gt; &lt;u&gt;s&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;x &lt;u&gt;a&lt;/u&gt;&lt;u&gt;r&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; &lt;u&gt;o&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;&lt;strong&gt;l&lt;/strong&gt;y &lt;strong&gt;u&lt;/strong&gt;&lt;u&gt;s&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;d&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;strong&gt;w&lt;/strong&gt;&lt;u&gt;o&lt;/u&gt; p&lt;u&gt;e&lt;/u&gt;&lt;u&gt;r&lt;/u&gt;&lt;strong&gt;c&lt;/strong&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;t&lt;/u&gt; &lt;u&gt;o&lt;/u&gt;f &lt;u&gt;t&lt;/u&gt;&lt;u&gt;h&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;&lt;strong&gt;m&lt;/strong&gt;&lt;u&gt;e&lt;/u&gt;.&lt;/p&gt;
&lt;p&gt;&lt;u&gt;s&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;strong&gt;m&lt;/strong&gt;&lt;u&gt;e&lt;/u&gt; &lt;u&gt;h&lt;/u&gt;&lt;u&gt;a&lt;/u&gt;v&lt;u&gt;e&lt;/u&gt; &lt;u&gt;a&lt;/u&gt;&lt;u&gt;r&lt;/u&gt;g&lt;strong&gt;u&lt;/strong&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;d&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;u&gt;h&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;y &lt;u&gt;s&lt;/u&gt;&lt;u&gt;h&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;strong&gt;u&lt;/strong&gt;&lt;strong&gt;l&lt;/strong&gt;&lt;u&gt;d&lt;/u&gt; b&lt;u&gt;e&lt;/u&gt; &lt;u&gt;r&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;strong&gt;m&lt;/strong&gt;&lt;u&gt;o&lt;/u&gt;v&lt;u&gt;e&lt;/u&gt;&lt;u&gt;d&lt;/u&gt; f&lt;u&gt;r&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;strong&gt;m&lt;/strong&gt; &lt;u&gt;t&lt;/u&gt;&lt;u&gt;h&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; &lt;u&gt;a&lt;/u&gt;&lt;strong&gt;l&lt;/strong&gt;p&lt;u&gt;h&lt;/u&gt;&lt;u&gt;a&lt;/u&gt;b&lt;u&gt;e&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;.&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;&lt;strong&gt;l&lt;/strong&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;'&lt;u&gt;s&lt;/u&gt; &lt;u&gt;s&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; &lt;strong&gt;w&lt;/strong&gt;&lt;u&gt;h&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;r&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; &lt;strong&gt;w&lt;/strong&gt;&lt;u&gt;e&lt;/u&gt; &lt;u&gt;a&lt;/u&gt;&lt;u&gt;r&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; &lt;u&gt;n&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;strong&gt;w&lt;/strong&gt;: &lt;u&gt;a&lt;/u&gt;b&lt;strong&gt;c&lt;/strong&gt;&lt;u&gt;d&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;fg&lt;u&gt;h&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;jk&lt;strong&gt;l&lt;/strong&gt;&lt;strong&gt;m&lt;/strong&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;pq&lt;u&gt;r&lt;/u&gt;&lt;u&gt;s&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;strong&gt;u&lt;/strong&gt;v&lt;strong&gt;w&lt;/strong&gt;xyz.&lt;/p&gt;
&lt;p&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;t&lt;/u&gt; b&lt;u&gt;a&lt;/u&gt;&lt;u&gt;d&lt;/u&gt;! y&lt;u&gt;o&lt;/u&gt;&lt;strong&gt;u&lt;/strong&gt; &lt;u&gt;a&lt;/u&gt;&lt;u&gt;r&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; &lt;u&gt;d&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;g &lt;u&gt;s&lt;/u&gt;p&lt;strong&gt;l&lt;/strong&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;d&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;d&lt;/u&gt;&lt;strong&gt;l&lt;/strong&gt;y &lt;u&gt;i&lt;/u&gt;f y&lt;u&gt;o&lt;/u&gt;&lt;strong&gt;u&lt;/strong&gt;'r&lt;u&gt;e&lt;/u&gt; &lt;u&gt;r&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;a&lt;/u&gt;&lt;u&gt;d&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;g &lt;u&gt;t&lt;/u&gt;&lt;u&gt;h&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;s&lt;/u&gt;!&lt;/p&gt;
&lt;p&gt;&lt;u&gt;r&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;a&lt;/u&gt;&lt;strong&gt;c&lt;/strong&gt;&lt;u&gt;h&lt;/u&gt; &lt;u&gt;a&lt;/u&gt;&lt;u&gt;r&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;strong&gt;u&lt;/strong&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;d&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;u&gt;o&lt;/u&gt; y&lt;u&gt;o&lt;/u&gt;&lt;strong&gt;u&lt;/strong&gt;&lt;u&gt;r&lt;/u&gt; b&lt;u&gt;a&lt;/u&gt;&lt;strong&gt;c&lt;/strong&gt;k &lt;u&gt;a&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;d&lt;/u&gt; g&lt;u&gt;i&lt;/u&gt;v&lt;u&gt;e&lt;/u&gt; y&lt;u&gt;o&lt;/u&gt;&lt;strong&gt;u&lt;/strong&gt;&lt;u&gt;r&lt;/u&gt;&lt;u&gt;s&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;strong&gt;l&lt;/strong&gt;f &lt;u&gt;a&lt;/u&gt; g&lt;u&gt;o&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;d&lt;/u&gt; p&lt;u&gt;a&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;.&lt;/p&gt;
&lt;p&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;r&lt;/u&gt; &lt;strong&gt;m&lt;/strong&gt;&lt;u&gt;a&lt;/u&gt;yb&lt;u&gt;e&lt;/u&gt; &lt;u&gt;e&lt;/u&gt;v&lt;u&gt;e&lt;/u&gt;&lt;u&gt;n&lt;/u&gt; &lt;u&gt;a&lt;/u&gt; q&lt;strong&gt;u&lt;/strong&gt;&lt;u&gt;i&lt;/u&gt;&lt;strong&gt;c&lt;/strong&gt;k &lt;strong&gt;m&lt;/strong&gt;&lt;u&gt;a&lt;/u&gt;&lt;u&gt;s&lt;/u&gt;&lt;u&gt;s&lt;/u&gt;&lt;u&gt;a&lt;/u&gt;g&lt;u&gt;e&lt;/u&gt;.&lt;/p&gt;
&lt;p&gt;&lt;u&gt;o&lt;/u&gt;k, &lt;u&gt;s&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;p &lt;strong&gt;m&lt;/strong&gt;&lt;u&gt;a&lt;/u&gt;&lt;u&gt;s&lt;/u&gt;&lt;u&gt;s&lt;/u&gt;&lt;u&gt;a&lt;/u&gt;g&lt;u&gt;i&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;g y&lt;u&gt;o&lt;/u&gt;&lt;strong&gt;u&lt;/strong&gt;&lt;u&gt;r&lt;/u&gt;&lt;u&gt;s&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;strong&gt;l&lt;/strong&gt;f. &lt;u&gt;h&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;s&lt;/u&gt; &lt;u&gt;o&lt;/u&gt;ff!&lt;/p&gt;
&lt;p&gt;&lt;u&gt;w&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;'&lt;u&gt;l&lt;/u&gt;&lt;u&gt;l&lt;/u&gt; &lt;u&gt;d&lt;/u&gt;&lt;u&gt;o&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;u&gt;h&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; &lt;u&gt;n&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;x&lt;u&gt;t&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;u&gt;w&lt;/u&gt;&lt;u&gt;o&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;u&gt;a&lt;/u&gt;b&lt;u&gt;l&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;s&lt;/u&gt; q&lt;u&gt;u&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;c&lt;/u&gt;k&lt;u&gt;l&lt;/u&gt;y.&lt;/p&gt;
&lt;p&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;c&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; y&lt;u&gt;o&lt;/u&gt;&lt;u&gt;u&lt;/u&gt; k&lt;u&gt;n&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;w&lt;/u&gt; &lt;u&gt;m&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;s&lt;/u&gt;&lt;u&gt;t&lt;/u&gt; &lt;u&gt;o&lt;/u&gt;f &lt;u&gt;t&lt;/u&gt;&lt;u&gt;h&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; &lt;u&gt;l&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;r&lt;/u&gt;&lt;u&gt;s&lt;/u&gt; y&lt;u&gt;o&lt;/u&gt;&lt;u&gt;u&lt;/u&gt; &lt;u&gt;c&lt;/u&gt;&lt;u&gt;a&lt;/u&gt;&lt;u&gt;n&lt;/u&gt; &lt;u&gt;o&lt;/u&gt;f&lt;u&gt;t&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;n&lt;/u&gt; g&lt;u&gt;u&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;s&lt;/u&gt;&lt;u&gt;s&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;u&gt;h&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; &lt;u&gt;r&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;s&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;.&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;w&lt;/u&gt; g&lt;u&gt;o&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;u&gt;o&lt;/u&gt; &lt;a href=&quot;http://memorize.com/dotsies&quot;&gt;&lt;u&gt;m&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;m&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;r&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;z&lt;u&gt;e&lt;/u&gt;.&lt;u&gt;c&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;m&lt;/u&gt;/&lt;u&gt;d&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;s&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;s&lt;/u&gt;&lt;/a&gt; &lt;u&gt;a&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;d&lt;/u&gt; &lt;u&gt;d&lt;/u&gt;&lt;u&gt;o&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;u&gt;h&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; f&lt;u&gt;o&lt;/u&gt;&lt;u&gt;u&lt;/u&gt;&lt;u&gt;r&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;h&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;u&gt;a&lt;/u&gt;b&lt;u&gt;l&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;.&lt;/p&gt;
&lt;p&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;h&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; &lt;u&gt;l&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;r&lt;/u&gt;&lt;u&gt;s&lt;/u&gt; &lt;u&gt;a&lt;/u&gt;&lt;u&gt;r&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; f, g, y, p &lt;u&gt;a&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;d&lt;/u&gt; b.&lt;/p&gt;
&lt;p&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;h&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;strong&gt;y&lt;/strong&gt;'&lt;u&gt;r&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; &lt;u&gt;o&lt;/u&gt;&lt;strong&gt;f&lt;/strong&gt;&lt;strong&gt;f&lt;/strong&gt; &lt;u&gt;n&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;w&lt;/u&gt;, &lt;strong&gt;b&lt;/strong&gt;&lt;u&gt;u&lt;/u&gt;&lt;u&gt;t&lt;/u&gt; &lt;u&gt;i&lt;/u&gt;&lt;u&gt;t&lt;/u&gt; &lt;u&gt;d&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;s&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;'&lt;u&gt;t&lt;/u&gt; &lt;u&gt;l&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;k &lt;u&gt;m&lt;/u&gt;&lt;u&gt;u&lt;/u&gt;&lt;u&gt;c&lt;/u&gt;&lt;u&gt;h&lt;/u&gt; &lt;u&gt;d&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;&lt;strong&gt;f&lt;/strong&gt;&lt;strong&gt;f&lt;/strong&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;r&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;, &lt;u&gt;e&lt;/u&gt;&lt;u&gt;h&lt;/u&gt;?&lt;/p&gt;
&lt;p&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;'&lt;u&gt;s&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;u&gt;r&lt;/u&gt;&lt;u&gt;u&lt;/u&gt;&lt;u&gt;l&lt;/u&gt;&lt;strong&gt;y&lt;/strong&gt; &lt;u&gt;d&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;w&lt;/u&gt;&lt;u&gt;n&lt;/u&gt; &lt;u&gt;h&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;l&lt;/u&gt;&lt;u&gt;l&lt;/u&gt; &lt;u&gt;n&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;w&lt;/u&gt;. &lt;u&gt;o&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;l&lt;/u&gt;&lt;strong&gt;y&lt;/strong&gt; &lt;u&gt;o&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; &lt;u&gt;m&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;r&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; &lt;strong&gt;g&lt;/strong&gt;&lt;u&gt;r&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;u&lt;/u&gt;&lt;strong&gt;p&lt;/strong&gt; &lt;u&gt;a&lt;/u&gt;&lt;strong&gt;f&lt;/strong&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;r&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;u&gt;h&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;s&lt;/u&gt;.&lt;/p&gt;
&lt;p&gt;&lt;u&gt;i&lt;/u&gt;'&lt;u&gt;m&lt;/u&gt; &lt;strong&gt;g&lt;/strong&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;&lt;strong&gt;g&lt;/strong&gt; &lt;u&gt;t&lt;/u&gt;&lt;u&gt;o&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;u&gt;u&lt;/u&gt;&lt;u&gt;r&lt;/u&gt;&lt;u&gt;n&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;u&gt;h&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; &lt;u&gt;h&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;s&lt;/u&gt; &lt;u&gt;o&lt;/u&gt;&lt;strong&gt;f&lt;/strong&gt;&lt;strong&gt;f&lt;/strong&gt; &lt;u&gt;i&lt;/u&gt;&lt;u&gt;n&lt;/u&gt; &lt;u&gt;a&lt;/u&gt; &lt;u&gt;m&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;m&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;.&lt;/p&gt;
&lt;p&gt;&lt;u&gt;a&lt;/u&gt;&lt;u&gt;r&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; &lt;strong&gt;y&lt;/strong&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;u&lt;/u&gt; &lt;u&gt;r&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;a&lt;/u&gt;&lt;u&gt;d&lt;/u&gt;&lt;strong&gt;y&lt;/strong&gt;? &lt;u&gt;t&lt;/u&gt;&lt;u&gt;h&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; &lt;u&gt;l&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;r&lt;/u&gt;&lt;u&gt;s&lt;/u&gt; &lt;u&gt;i&lt;/u&gt;&lt;u&gt;n&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;u&gt;h&lt;/u&gt;&lt;u&gt;a&lt;/u&gt;&lt;u&gt;t&lt;/u&gt; &lt;strong&gt;g&lt;/strong&gt;&lt;u&gt;r&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;u&lt;/u&gt;&lt;strong&gt;p&lt;/strong&gt; &lt;u&gt;w&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;r&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; &lt;u&gt;s&lt;/u&gt;&lt;u&gt;o&lt;/u&gt; &lt;u&gt;r&lt;/u&gt;&lt;u&gt;a&lt;/u&gt;&lt;u&gt;r&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; &lt;u&gt;a&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;&lt;strong&gt;y&lt;/strong&gt;&lt;u&gt;w&lt;/u&gt;&lt;u&gt;a&lt;/u&gt;&lt;strong&gt;y&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;u&gt;o&lt;/u&gt;k, &lt;u&gt;t&lt;/u&gt;&lt;u&gt;h&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; &lt;u&gt;h&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;s&lt;/u&gt; &lt;u&gt;a&lt;/u&gt;&lt;u&gt;r&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; &lt;u&gt;o&lt;/u&gt;&lt;strong&gt;f&lt;/strong&gt;&lt;strong&gt;f&lt;/strong&gt; &lt;u&gt;a&lt;/u&gt;&lt;strong&gt;g&lt;/strong&gt;&lt;u&gt;a&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;.&lt;/p&gt;
&lt;p&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;w&lt;/u&gt;, &lt;u&gt;o&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;o&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;u&gt;h&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; v&lt;u&gt;e&lt;/u&gt;&lt;u&gt;r&lt;/u&gt;&lt;u&gt;y&lt;/u&gt; &lt;u&gt;l&lt;/u&gt;&lt;u&gt;a&lt;/u&gt;&lt;u&gt;s&lt;/u&gt;&lt;u&gt;t&lt;/u&gt; &lt;u&gt;g&lt;/u&gt;&lt;u&gt;r&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;u&lt;/u&gt;&lt;u&gt;p&lt;/u&gt;!&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;&lt;u&gt;g&lt;/u&gt;&lt;u&gt;o&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;u&gt;o&lt;/u&gt; &lt;a href=&quot;http://memorize.com/dotsies&quot;&gt;&lt;u&gt;m&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;m&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;r&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;z&lt;u&gt;e&lt;/u&gt;.&lt;u&gt;c&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;m&lt;/u&gt;/&lt;u&gt;d&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;s&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;s&lt;/u&gt;.&lt;/a&gt; &lt;u&gt;a&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;d&lt;/u&gt; &lt;u&gt;d&lt;/u&gt;&lt;u&gt;o&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;u&gt;h&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; &lt;u&gt;l&lt;/u&gt;&lt;u&gt;a&lt;/u&gt;&lt;u&gt;s&lt;/u&gt;&lt;u&gt;t&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;u&gt;a&lt;/u&gt;&lt;u&gt;b&lt;/u&gt;&lt;u&gt;l&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;.&lt;/p&gt;
&lt;p&gt;&lt;u&gt;l&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;r&lt;/u&gt;&lt;u&gt;s&lt;/u&gt; v, k, j, x, q &lt;u&gt;a&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;d&lt;/u&gt; z &lt;u&gt;a&lt;/u&gt;&lt;u&gt;r&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; &lt;u&gt;n&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;w&lt;/u&gt; &lt;u&gt;d&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;s&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;f&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;d&lt;/u&gt;!&lt;/p&gt;
&lt;p&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;h&lt;/u&gt;&lt;u&gt;a&lt;/u&gt;&lt;u&gt;t&lt;/u&gt; &lt;u&gt;m&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;a&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;s&lt;/u&gt; &lt;u&gt;e&lt;/u&gt;&lt;strong&gt;v&lt;/strong&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;r&lt;/u&gt;&lt;u&gt;y&lt;/u&gt; &lt;u&gt;s&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;g&lt;/u&gt;&lt;u&gt;l&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; &lt;u&gt;l&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;r&lt;/u&gt; &lt;u&gt;i&lt;/u&gt;&lt;u&gt;s&lt;/u&gt; &lt;u&gt;d&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;s&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;f&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;d&lt;/u&gt; &lt;u&gt;a&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;d&lt;/u&gt; &lt;u&gt;y&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;u&lt;/u&gt;'&lt;u&gt;r&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; &lt;u&gt;a&lt;/u&gt; &lt;u&gt;f&lt;/u&gt;&lt;u&gt;r&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;g&lt;/u&gt;&lt;u&gt;g&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;n&lt;/u&gt; &lt;u&gt;e&lt;/u&gt;&lt;strong&gt;x&lt;/strong&gt;&lt;u&gt;p&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;r&lt;/u&gt;&lt;u&gt;t&lt;/u&gt; :).&lt;/p&gt;
&lt;p&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;f&lt;/u&gt; &lt;u&gt;y&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;u&lt;/u&gt; &lt;u&gt;d&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;d&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;'&lt;u&gt;t&lt;/u&gt; &lt;u&gt;n&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;c&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;, &lt;u&gt;c&lt;/u&gt;&lt;u&gt;h&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;c&lt;/u&gt;&lt;strong&gt;k&lt;/strong&gt; &lt;u&gt;o&lt;/u&gt;&lt;u&gt;u&lt;/u&gt;&lt;u&gt;t&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;u&gt;h&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; &quot;&lt;u&gt;c&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;m&lt;/u&gt;&lt;u&gt;b&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&quot; &lt;u&gt;l&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;&lt;strong&gt;k&lt;/strong&gt; &lt;u&gt;o&lt;/u&gt;&lt;u&gt;n&lt;/u&gt; &lt;u&gt;m&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;m&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;r&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;&lt;strong&gt;z&lt;/strong&gt;&lt;u&gt;e&lt;/u&gt;.&lt;u&gt;c&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;m&lt;/u&gt;.&lt;/p&gt;
&lt;p&gt;&lt;u&gt;y&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;u&lt;/u&gt; &lt;u&gt;c&lt;/u&gt;&lt;u&gt;a&lt;/u&gt;&lt;u&gt;n&lt;/u&gt; &lt;u&gt;u&lt;/u&gt;&lt;u&gt;s&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; &lt;u&gt;i&lt;/u&gt;&lt;u&gt;t&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;u&gt;o&lt;/u&gt; &lt;u&gt;d&lt;/u&gt;&lt;u&gt;o&lt;/u&gt; &lt;u&gt;a&lt;/u&gt;&lt;u&gt;l&lt;/u&gt;&lt;u&gt;l&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;u&gt;h&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;u&gt;a&lt;/u&gt;&lt;u&gt;b&lt;/u&gt;&lt;u&gt;l&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;&lt;u&gt;s&lt;/u&gt; &lt;u&gt;a&lt;/u&gt;&lt;u&gt;t&lt;/u&gt; &lt;u&gt;o&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;c&lt;/u&gt;&lt;u&gt;e&lt;/u&gt;.&lt;/p&gt;
&lt;p&gt;&lt;u&gt;o&lt;/u&gt;&lt;strong&gt;k&lt;/strong&gt;, &lt;u&gt;h&lt;/u&gt;&lt;u&gt;i&lt;/u&gt;&lt;u&gt;n&lt;/u&gt;&lt;u&gt;t&lt;/u&gt;&lt;u&gt;s&lt;/u&gt; &lt;u&gt;a&lt;/u&gt;&lt;u&gt;r&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; &lt;u&gt;n&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;w&lt;/u&gt; &lt;u&gt;o&lt;/u&gt;&lt;u&gt;f&lt;/u&gt;&lt;u&gt;f&lt;/u&gt; &lt;u&gt;f&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;r&lt;/u&gt; &lt;u&gt;t&lt;/u&gt;&lt;u&gt;h&lt;/u&gt;&lt;u&gt;e&lt;/u&gt; &lt;u&gt;l&lt;/u&gt;&lt;u&gt;a&lt;/u&gt;&lt;u&gt;s&lt;/u&gt;&lt;u&gt;t&lt;/u&gt; &lt;u&gt;g&lt;/u&gt;&lt;u&gt;r&lt;/u&gt;&lt;u&gt;o&lt;/u&gt;&lt;u&gt;u&lt;/u&gt;&lt;u&gt;p&lt;/u&gt;!&lt;/p&gt;
&lt;hr/&gt;&lt;div class=&quot;dotsies&quot; readability=&quot;14&quot;&gt;
&lt;p&gt;this is the full dotsies font without the hints!&lt;/p&gt;
&lt;p&gt;you may notice that it's no longer stretched out as well.&lt;/p&gt;
&lt;p&gt;the dots are very close to squares.&lt;/p&gt;
&lt;p&gt;and here it is a bit smaller. congrats - well done! this makes you one of a pretty select group. chat with us on twitter!&lt;/p&gt;
&lt;/div&gt;
&lt;p class=&quot;sans&quot;&gt;How far did you get? Tweet me at &lt;a href=&quot;http://twitter.com/DotsiesFont&quot;&gt;@DotsiesFont&lt;/a&gt; and tell me what you think! Maybe try &lt;a href=&quot;http://dotsies.org/reader&quot;&gt;reading a story&lt;/a&gt;. Or see &lt;a href=&quot;http://dotsies.org/learn&quot;&gt;How to Learn&lt;/a&gt;.  &lt;/p&gt;
</description>
<pubDate>Tue, 18 Dec 2018 01:16:54 +0000</pubDate>
<dc:creator>severine</dc:creator>
<dc:format>text/html</dc:format>
<dc:identifier>http://dotsies.org/</dc:identifier>
</item>
<item>
<title>Millitext – A subpixel text encoding font</title>
<link>https://advent.morr.cc/2018/17</link>
<guid isPermaLink="true" >https://advent.morr.cc/2018/17</guid>
<description>&lt;head&gt;&lt;title&gt;Millitext · Advent Calendar of Curiosities 2018&lt;/title&gt;&lt;meta charset=&quot;utf-8&quot;/&gt;&lt;link rel=&quot;stylesheet&quot; href=&quot;/css/default.css&quot; type=&quot;text/css&quot;/&gt;&lt;link rel=&quot;alternate&quot; type=&quot;application/atom+xml&quot; href=&quot;/feed&quot;/&gt;&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=0.5, user-scalable=yes&quot;/&gt;&lt;meta name=&quot;twitter:card&quot; content=&quot;summary_large_image&quot;/&gt;&lt;meta name=&quot;twitter:site&quot; content=&quot;@blinry&quot;/&gt;&lt;meta name=&quot;twitter:title&quot; content=&quot;Millitext&quot;/&gt;&lt;meta name=&quot;twitter:description&quot; content=&quot;Pixels of LCD monitors are usually composed of three stripes of the colors red, green, and blue. Tech enthusiast Matt Sarnoff used this property to his advantage when inventing [a subpixel text encoding font](http://www.msarnoff.org/millitext/). Its glyphs are comprised of colored strips only one pixel wide. But when viewed on LCD monitors, the color strips clearly form letters and numbers! Fun fact: In 2013, I had a [Twitter avatar containing millitext](https://files.morr.cc/avatar-2013-04-16-small.png)! Can you decipher it?&quot;/&gt;&lt;meta name=&quot;twitter:creator&quot; content=&quot;@blinry&quot;/&gt;&lt;meta name=&quot;twitter:image&quot; content=&quot;/2018/17/image&quot;/&gt;&lt;/head&gt;&lt;body id=&quot;readabilityBody&quot; readability=&quot;24.082291666667&quot;&gt;

&lt;div class=&quot;door&quot; readability=&quot;13.056277056277&quot;&gt;

 &lt;a href=&quot;https://advent.morr.cc/2018/17/image&quot;&gt;&lt;img class=&quot;small&quot; src=&quot;https://advent.morr.cc/2018/17/image&quot;/&gt;&lt;/a&gt;
&lt;p&gt;Pixels of LCD monitors are usually composed of three stripes of the colors red, green, and blue. Tech enthusiast Matt Sarnoff used this property to his advantage when inventing &lt;a href=&quot;http://www.msarnoff.org/millitext/&quot;&gt;a subpixel text encoding font&lt;/a&gt;. Its glyphs are comprised of colored strips only one pixel wide. But when viewed on LCD monitors, the color strips clearly form letters and numbers!&lt;/p&gt;
&lt;p&gt;Fun fact: In 2013, I had a &lt;a href=&quot;https://files.morr.cc/avatar-2013-04-16-small.png&quot;&gt;Twitter avatar containing millitext&lt;/a&gt;! Can you decipher it?&lt;/p&gt;
&lt;/div&gt;

&lt;/body&gt;</description>
<pubDate>Mon, 17 Dec 2018 22:36:03 +0000</pubDate>
<dc:creator>jonshariat</dc:creator>
<dc:language>de</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://advent.morr.cc/2018/17</dc:identifier>
</item>
<item>
<title>Neural Networks as Ordinary Differential Equations</title>
<link>https://rkevingibson.github.io/blog/neural-networks-as-ordinary-differential-equations/</link>
<guid isPermaLink="true" >https://rkevingibson.github.io/blog/neural-networks-as-ordinary-differential-equations/</guid>
<description>&lt;p&gt;Recently I found a paper being presented at NeurIPS this year, entitled &lt;a href=&quot;https://arxiv.org/abs/1806.07366&quot;&gt;Neural Ordinary Differential Equations&lt;/a&gt;, written by Ricky Chen, Yulia Rubanova, Jesse Bettencourt, and David Duvenaud from the University of Toronto. The core idea is that certain types of neural networks are analogous to a discretized differential equation, so maybe using off-the-shelf differential equation solvers will help get better results. This led me down a bit of a rabbit hole of papers that I found very interesting, so I thought I would share a short summary/view-from-30,000 feet on this idea.&lt;/p&gt;
&lt;p&gt;Typically, we think about neural networks as a series of discrete layers, each one taking in a previous state vector &lt;span class=&quot;math&quot;&gt;\( \mathbf{h}_n \)&lt;/span&gt; and producing a new state vector &lt;span class=&quot;math&quot;&gt;\( \mathbf{h}_{n+1} = F(\mathbf{h}_{n}) \)&lt;/span&gt;. Here, let's assume that each layer is the same width (e.g. &lt;span class=&quot;math&quot;&gt;\( \mathbf{h}_{n} \)&lt;/span&gt; and &lt;span class=&quot;math&quot;&gt;\( \mathbf{h}_{n+1} \)&lt;/span&gt; have the same dimension, for every &lt;span class=&quot;math&quot;&gt;\( n \)&lt;/span&gt;). Note that we don't particularly care about what &lt;span class=&quot;math&quot;&gt;\(F\)&lt;/span&gt; looks like, but typically it's something like &lt;span class=&quot;math&quot;&gt;\(F(x) = \sigma(\sum_{i}\theta_i x_i)\)&lt;/span&gt;, where &lt;span class=&quot;math&quot;&gt;\(\sigma\)&lt;/span&gt; is an activation function (e.g. &lt;a href=&quot;https://en.wikipedia.org/wiki/Rectifier_(neural_networks)&quot;&gt;relu&lt;/a&gt; or a &lt;a href=&quot;https://en.wikipedia.org/wiki/Logistic_function&quot;&gt;sigmoid&lt;/a&gt;), and &lt;span class=&quot;math&quot;&gt;\(\theta\)&lt;/span&gt; is a vector of parameters we're learning. This core formulation has some problems - notably, adding more layers, while theoretically increasing the ability of the network to learn, can actually &lt;em&gt;decrease&lt;/em&gt; the accuracy of it, both in training and test results.&lt;/p&gt;
&lt;p&gt;This problem was adressed by &lt;a href=&quot;https://arxiv.org/pdf/1512.03385.pdf&quot;&gt;Deep Residual Learning&lt;/a&gt;, from Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun out of Microsoft Reasearch. The idea in a nutshell is to learn a function of the difference between layers: &lt;span class=&quot;math&quot;&gt;\( \mathbf{h}_{n+1} = F(\mathbf{h}_n) + \mathbf{h}_n \)&lt;/span&gt;. In the paper, they show this simple transformation in what you're learning allows the networks to keep improving as they add more layers. To me, this reminds me of &lt;a href=&quot;https://en.wikipedia.org/wiki/Delta_encoding&quot;&gt;delta encoding&lt;/a&gt;, in which you represent a stream of data as a series of changes from the previous state. This can make certain types of data much more suitable to compression (see, e.g. &lt;a href=&quot;https://gafferongames.com/post/snapshot_compression/&quot;&gt;this article&lt;/a&gt; from Glenn Fiedler on compressing physics data to send over a network). It makes some kind of sense that if delta encoding can make data easier to compress, it could also make it easier to represent for a neural network.&lt;/p&gt;
&lt;h3 id=&quot;eulers-method-and-residual-networks&quot;&gt;Euler's method and residual networks&lt;/h3&gt;
&lt;p&gt;But how do residual networks relate to differential equations? Suppose we have some constant that we'll call &lt;span class=&quot;math&quot;&gt;\( \Delta t \in \mathbb{R}\)&lt;/span&gt;. Then we can write the state update of our neural network as&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math&quot;&gt;\[ \begin{aligned} \mathbf{h}_{t+1} &amp;amp;= F(\mathbf{h}_t) + \mathbf{h}_t \\ \\ &amp;amp;= \frac{\Delta t}{\Delta t} F(\mathbf{h}_t) + \mathbf{h}_t \\ \\ &amp;amp;= \Delta t G(\mathbf{h}_t) + \mathbf{h}_t \end{aligned} \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where now we're learning &lt;span class=&quot;math&quot;&gt;\( G(\mathbf{h}_t) = F(\mathbf{h}_t)/\Delta t \)&lt;/span&gt;. If you have experience with differential equations, this formulation looks very familiar - it is a single step of &lt;a href=&quot;https://en.wikipedia.org/wiki/Euler_method&quot;&gt;Euler's method&lt;/a&gt; for solving ordinary differential equations. It seems this was first noticed by Weinan E in &lt;a href=&quot;https://link.springer.com/article/10.1007/s40304-017-0103-z&quot;&gt;A proposal on Machine Learning via Dynamical Systems&lt;/a&gt;, and expanded upon by Yiping Lu et al. in &lt;a href=&quot;https://arxiv.org/pdf/1710.10121.pdf&quot;&gt;Beyond Finite Layer Neural Networks&lt;/a&gt;. However, Lu et al. continue to treat the network as a series of discrete steps, and use a discrete solver with fixed timesteps to come up with a novel neural network architecture. The reason for this is that we need to be able to train the networks, and it's not really clear how to &quot;learn&quot; a differential system. Chen, Rubanova, Bettencourt and Duvenaud solve this problem by using some clever math which enables them to compute the gradients they need for backpropagation.&lt;/p&gt;
&lt;h3 id=&quot;evaluating-odes&quot;&gt;Evaluating ODEs&lt;/h3&gt;
&lt;p&gt;Before we get to that, let's look at what we're trying to solve. If we consider a layer of our neural network to be doing a step of Euler's method, then we can model our system by the differential equation&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math&quot;&gt;\[ \frac{d \mathbf{h}(t)}{dt} = G(\mathbf{h}(t), t, \theta) \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Here we've made explicit &lt;span class=&quot;math&quot;&gt;\(G\)&lt;/span&gt;'s dependency on &lt;span class=&quot;math&quot;&gt;\(t\)&lt;/span&gt;, as well as some parameters &lt;span class=&quot;math&quot;&gt;\(\theta\)&lt;/span&gt; which we will train on. In this formulation, the output of our &quot;network&quot; is the state &lt;span class=&quot;math&quot;&gt;\(\mathbf{h}(t_1)\)&lt;/span&gt; at some time &lt;span class=&quot;math&quot;&gt;\(t_1\)&lt;/span&gt;. Therefore, if we know how to describe the function &lt;span class=&quot;math&quot;&gt;\(G\)&lt;/span&gt;, we can use any number of off-the-shelf ODE solvers to evaluate the neural network.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math&quot;&gt;\[ \mathbf{h}(t_1) = \text{ODESolve}(\mathbf{h}(t_0), G, t_0, t_1, \theta) \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;There is a ton of research on different methods that can be used as our ODESolve function, but for now we'll treat it as a black box. What matters is that if you substitute in Euler's method, you get exactly the residual state update from above, with&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math&quot;&gt;\[ \text{ODESolve}(\mathbf{h}(t_0), G, t_0, t_1, \theta) = \mathbf{h}(t_0) + (t_1 - t_0)G(\mathbf{h}(t_0), t_0, \theta)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;However, we don't need to limit ourselves to Euler's method, and in fact will do much better if we use more modern approaches.&lt;/p&gt;
&lt;h3 id=&quot;training-the-beast&quot;&gt;Training the beast&lt;/h3&gt;
&lt;p&gt;So how to train it? Suppose we have a loss function&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math&quot;&gt;\[ L(h(t_1)) = L(\text{ODESolve}(\mathbf{h}(t_0), G, t_0, t_1, \theta))\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;To optimize &lt;span class=&quot;math&quot;&gt;\(L\)&lt;/span&gt;, we require gradients with respect to its parameters &lt;span class=&quot;math&quot;&gt;\(\mathbf{h}(t)\)&lt;/span&gt; (the state of our system at time &lt;span class=&quot;math&quot;&gt;\(t\)&lt;/span&gt;), &lt;span class=&quot;math&quot;&gt;\(t\)&lt;/span&gt; (our &quot;time&quot; variable, which is sort of a continuous analog to depth), and &lt;span class=&quot;math&quot;&gt;\(\theta\)&lt;/span&gt;, our training parameters. &lt;a href=&quot;https://cs.stanford.edu/~ambrad/adjoint_tutorial.pdf&quot;&gt;The adjoint method&lt;/a&gt; describes a way to come up with this. The adjoint method is a neat trick which uses a simple substitution of variables to make solving certain linear systems easier. Part of the reason this paper grabbed my eye is because I've seen the adjoint method before, in a completely unrelated area: fluid simulation! In &lt;a href=&quot;http://grail.cs.washington.edu/projects/control/fluidAdjoint.pdf&quot;&gt;this&lt;/a&gt; paper from McNamara et al., they make controlling a fluid simulation easier by using the adjoint method to efficiently compute some gradients with respect to user controlled parameters. That certainly sounds similar to our problem.&lt;/p&gt;
&lt;p&gt;So what is the adjoint method? Suppose we have 2 known matrices &lt;span class=&quot;math&quot;&gt;\(A\)&lt;/span&gt; and &lt;span class=&quot;math&quot;&gt;\(C\)&lt;/span&gt;, and a known vector &lt;span class=&quot;math&quot;&gt;\(\mathbf{u}\)&lt;/span&gt; and we would like to compute a product&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math&quot;&gt;\[\mathbf{u}^{\intercal}B \text{ such that } AB=C\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We could first solve the linear system to find the unknown matrix &lt;span class=&quot;math&quot;&gt;\(B\)&lt;/span&gt;, then compute the product, but solving the linear system could be expensive. Instead, let's solve a different problem. Let's find a vector &lt;span class=&quot;math&quot;&gt;\(\mathbf{v}\)&lt;/span&gt; and compute&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math&quot;&gt;\[\mathbf{v}^{\intercal}C \text{ such that } A^{\intercal}\mathbf{v}=\mathbf{u}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We can show that these are in fact the same problem:&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math&quot;&gt;\[\mathbf{v}^{\intercal}C = \mathbf{v}^{\intercal}AB = (A^{\intercal}\mathbf{v})^{\intercal}B = \mathbf{u}^{\intercal}B\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Through this transformation, we've reduced the problem from solving for a matrix, and reduced it to solving for a vector. This can be a big computational win! So how do we use it to train networks? I'm not going to go into the complete details here as it's slightly involved, but Appendix B in the paper has the complete derivation. In brief, we define the adjoint state as&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math&quot;&gt;\[ a(t) = -\partial L / \partial \mathbf{h}(t) \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;And we can describe its dynamics via&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math&quot;&gt;\[ \frac{da(t)}{dt} = - a(t)^{\intercal} \frac{\partial G(\mathbf{h}(t), t, \theta)}{\partial \mathbf{h}} \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We can compute the derivative of &lt;span class=&quot;math&quot;&gt;\(G\)&lt;/span&gt; with respect to &lt;span class=&quot;math&quot;&gt;\(\mathbf{h}\)&lt;/span&gt; already - we compute this gradient during backpropagation of traditional neural networks. With this, we can then compute &lt;span class=&quot;math&quot;&gt;\(a(t)\)&lt;/span&gt; by using another call to an ODE solver. There is one other derivative, &lt;span class=&quot;math&quot;&gt;\(dL/d\theta\)&lt;/span&gt;, that can be computed similarly. The paper shows that we can wrap up all of these ODE solves into a single call to an ODE solver, which computes all the necessary gradients for training the system.&lt;/p&gt;
&lt;h3 id=&quot;whats-the-point&quot;&gt;What's the point?&lt;/h3&gt;
&lt;p&gt;Why do we want to do this? According to the paper, we're able to train a model with much less memory, with fewer parameters, and we are able to backpropagate more efficiently. All of these seem like good things! Modern ODE solvers are also adaptive, and can do more work only when needed to get an accurate solution. In the paper they show an experiment where the number of function evaluations that the ODE solver does increases with the number of training epochs - effectively, the system can quickly reach a rough solution, then take more time to refine the training.&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;&lt;img src=&quot;https://rkevingibson.github.io/img/ode_networks_1.png&quot; alt=&quot;illustration of an ode network compared to a residual network&quot; title=&quot;An example from the paper showing how using an ode solver can adaptively evaluate the function. Circles represent function evaluations.&quot;/&gt;An example from the paper showing how using an ode solver can adaptively evaluate the function. Circles represent function evaluations.&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;I think the most interesting aspect is that treating our system like a continuous time model, allows us to predict continuous time systems. They show a way to take data which arrives at arbitrary times, rather than at fixed intervals, and they can predict the output at arbitrary future times. They test this on fairly simple synthetic data, predicting trajectories of spirals, but get really nice results. I definitely want to see more of this type of work in the future, on larger real-world problems, to see how it does. Being able to draw on the &amp;gt; 100 years of research in solving differential equations could be very useful for a young field like deep learning, and hey, I just find the math neat.&lt;/p&gt;
&lt;p class=&quot;back-to-posts&quot;&gt;&lt;a href=&quot;https://rkevingibson.github.io/blog&quot;&gt;Back to posts&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Mon, 17 Dec 2018 21:58:37 +0000</pubDate>
<dc:creator>agronaut</dc:creator>
<og:title>Neural networks as Ordinary Differential Equations</og:title>
<og:description>Recently I found a paper being presented at NeurIPS this year, entitled Neural Ordinary Differential Equations, written by Ricky Chen, Yulia Rubanova, Jesse Bettencourt, and David Duvenaud from the University of Toronto. The core idea is that certain types of neural networks are analogous to a discretized differential equation, so maybe using off-the-shelf differential equation solvers will help get better results. This led me down a bit of a rabbit hole of papers that I found very interesting, so I thought I would share a short summary/view-from-30,000 feet on this idea.</og:description>
<og:type>article</og:type>
<og:url>https://rkevingibson.github.io/blog/neural-networks-as-ordinary-differential-equations/</og:url>
<dc:language>en-us</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://rkevingibson.github.io/blog/neural-networks-as-ordinary-differential-equations/</dc:identifier>
</item>
<item>
<title>Show HN: Fancy fonts you can use almost anywhere</title>
<link>https://beautifuldingbats.com/hey-howd-you-do-that</link>
<guid isPermaLink="true" >https://beautifuldingbats.com/hey-howd-you-do-that</guid>
<description>[unable to retrieve full-text content]
&lt;p&gt;Article URL: &lt;a href=&quot;https://beautifuldingbats.com/hey-howd-you-do-that&quot;&gt;https://beautifuldingbats.com/hey-howd-you-do-that&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Comments URL: &lt;a href=&quot;https://news.ycombinator.com/item?id=18701772&quot;&gt;https://news.ycombinator.com/item?id=18701772&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Points: 232&lt;/p&gt;
&lt;p&gt;# Comments: 160&lt;/p&gt;
</description>
<pubDate>Mon, 17 Dec 2018 20:14:12 +0000</pubDate>
<dc:creator>shadowfaxRodeo</dc:creator>
<dc:format>text/html</dc:format>
<dc:identifier>https://beautifuldingbats.com/hey-howd-you-do-that</dc:identifier>
</item>
<item>
<title>MIPS Goes Open Source</title>
<link>https://www.eetimes.com/document.asp?doc_id=1334087</link>
<guid isPermaLink="true" >https://www.eetimes.com/document.asp?doc_id=1334087</guid>
<description>[unable to retrieve full-text content]
&lt;p&gt;Article URL: &lt;a href=&quot;https://www.eetimes.com/document.asp?doc_id=1334087&quot;&gt;https://www.eetimes.com/document.asp?doc_id=1334087&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Comments URL: &lt;a href=&quot;https://news.ycombinator.com/item?id=18701145&quot;&gt;https://news.ycombinator.com/item?id=18701145&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Points: 490&lt;/p&gt;
&lt;p&gt;# Comments: 144&lt;/p&gt;
</description>
<pubDate>Mon, 17 Dec 2018 18:58:26 +0000</pubDate>
<dc:creator>walterbell</dc:creator>
<dc:identifier>https://www.eetimes.com/document.asp?doc_id=1334087</dc:identifier>
</item>
</channel>
</rss>