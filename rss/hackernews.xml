<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=hnrss.org%2Fnewest%3Fpoints%3D200&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://hnrss.org/newest?points=200" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>Hacker News: Newest</title>
<link>https://news.ycombinator.com/newest</link>
<description>Hacker News RSS</description>
<item>
<title>Algorithms, by Jeff Erickson</title>
<link>http://jeffe.cs.illinois.edu/teaching/algorithms/?</link>
<guid isPermaLink="true" >http://jeffe.cs.illinois.edu/teaching/algorithms/?</guid>
<description>[unable to retrieve full-text content]
&lt;p&gt;Article URL: &lt;a href=&quot;http://jeffe.cs.illinois.edu/teaching/algorithms/?&quot;&gt;http://jeffe.cs.illinois.edu/teaching/algorithms/?&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Comments URL: &lt;a href=&quot;https://news.ycombinator.com/item?id=18805624&quot;&gt;https://news.ycombinator.com/item?id=18805624&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Points: 395&lt;/p&gt;
&lt;p&gt;# Comments: 60&lt;/p&gt;
</description>
<pubDate>Wed, 02 Jan 2019 11:51:10 +0000</pubDate>
<dc:creator>bdr</dc:creator>
<dc:identifier>http://jeffe.cs.illinois.edu/teaching/algorithms/?</dc:identifier>
</item>
<item>
<title>Flair: A simple framework for natural language processing</title>
<link>https://github.com/zalandoresearch/flair</link>
<guid isPermaLink="true" >https://github.com/zalandoresearch/flair</guid>
<description>&lt;div class=&quot;Box-body p-6&quot;&gt;
&lt;article class=&quot;markdown-body entry-content&quot; itemprop=&quot;text&quot;&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; href=&quot;https://github.com/zalandoresearch/flair/blob/master/resources/docs/flair_logo.svg&quot;&gt;&lt;img src=&quot;https://github.com/zalandoresearch/flair/raw/master/resources/docs/flair_logo.svg?sanitize=true&quot; alt=&quot;alt text&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://badge.fury.io/py/flair&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/11898672ef0d1fa33f5526eabe3f027bd556196e/68747470733a2f2f62616467652e667572792e696f2f70792f666c6169722e737667&quot; alt=&quot;PyPI version&quot; data-canonical-src=&quot;https://badge.fury.io/py/flair.svg&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/zalandoresearch/flair/issues&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/9668e526be4a977b76c3f732e4bf1728ab4abd71/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f7a616c616e646f72657365617263682f666c6169722e737667&quot; alt=&quot;GitHub Issues&quot; data-canonical-src=&quot;https://img.shields.io/github/issues/zalandoresearch/flair.svg&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/zalandoresearch/flair/blob/master/resources/docs/CONTRIBUTING.md&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/8f697c48adc5026cc6d83dd45e42b9b93ee1803c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f6e747269627574696f6e732d77656c636f6d652d627269676874677265656e2e737667&quot; alt=&quot;Contributions welcome&quot; data-canonical-src=&quot;https://img.shields.io/badge/contributions-welcome-brightgreen.svg&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://opensource.org/licenses/MIT&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/a2753323735099059bdc88b724534a1a6bd134ee/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d627269676874677265656e2e737667&quot; alt=&quot;License: MIT&quot; data-canonical-src=&quot;https://img.shields.io/badge/License-MIT-brightgreen.svg&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://travis-ci.org/zalandoresearch/flair&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/6006aeef0265927856e9233064789c9d582bea78/68747470733a2f2f696d672e736869656c64732e696f2f7472617669732f7a616c616e646f72657365617263682f666c6169722e737667&quot; alt=&quot;Travis&quot; data-canonical-src=&quot;https://img.shields.io/travis/zalandoresearch/flair.svg&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;A very simple framework for &lt;strong&gt;state-of-the-art NLP&lt;/strong&gt;. Developed by &lt;a href=&quot;https://research.zalando.com/&quot; rel=&quot;nofollow&quot;&gt;Zalando Research&lt;/a&gt;.&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;Flair is:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;
&lt;p&gt;&lt;strong&gt;A powerful NLP library.&lt;/strong&gt; Flair allows you to apply our state-of-the-art natural language processing (NLP) models to your text, such as named entity recognition (NER), part-of-speech tagging (PoS), sense disambiguation and classification.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Multilingual.&lt;/strong&gt; Thanks to the Flair community, we support a rapidly growing number of languages. We also now include '&lt;em&gt;one model, many languages&lt;/em&gt;' taggers, i.e. single models that predict PoS or NER tags for input text in various languages.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;A text embedding library.&lt;/strong&gt; Flair has simple interfaces that allow you to use and combine different word and document embeddings, including our proposed &lt;strong&gt;&lt;a href=&quot;https://drive.google.com/file/d/17yVpFA7MmXaQFTe-HDpZuqw9fJlmzg56/view?usp=sharing&quot; rel=&quot;nofollow&quot;&gt;Flair embeddings&lt;/a&gt;&lt;/strong&gt;, BERT embeddings and ELMo embeddings.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;A Pytorch NLP framework.&lt;/strong&gt; Our framework builds directly on &lt;a href=&quot;https://pytorch.org/&quot; rel=&quot;nofollow&quot;&gt;Pytorch&lt;/a&gt;, making it easy to train your own models and experiment with new approaches using Flair embeddings and classes.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Now at &lt;a href=&quot;https://github.com/zalandoresearch/flair/releases&quot;&gt;version 0.4.0&lt;/a&gt;!&lt;/p&gt;
&lt;h2&gt;Comparison with State-of-the-Art&lt;/h2&gt;
&lt;p&gt;Flair outperforms the previous best methods on a range of NLP tasks:&lt;/p&gt;
&lt;p&gt;Here's how to &lt;a href=&quot;https://github.com/zalandoresearch/flair/blob/master/resources/docs/EXPERIMENTS.md&quot;&gt;reproduce these numbers&lt;/a&gt; using Flair. You can also find a detailed evaluation and discussion in our paper:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;a href=&quot;https://aclanthology.coli.uni-saarland.de/papers/C18-1139/c18-1139&quot; rel=&quot;nofollow&quot;&gt;Contextual String Embeddings for Sequence Labeling&lt;/a&gt;. Alan Akbik, Duncan Blythe and Roland Vollgraf. 27th International Conference on Computational Linguistics, COLING 2018.&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;Quick Start&lt;/h2&gt;
&lt;h3&gt;Requirements and Installation&lt;/h3&gt;
&lt;p&gt;The project is based on PyTorch 0.4+ and Python 3.6+, because methods signatures and type hints are beautiful. If you do not have Python 3.6, install it first. &lt;a href=&quot;https://vsupalov.com/developing-with-python3-6-on-ubuntu-16-04/&quot; rel=&quot;nofollow&quot;&gt;Here is how for Ubuntu 16.04&lt;/a&gt;. Then, in your favorite virtual environment, simply do:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;pip install flair
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3&gt;Example Usage&lt;/h3&gt;
&lt;p&gt;Let's run named entity recognition (NER) over an example sentence. All you need to do is make a &lt;code&gt;Sentence&lt;/code&gt;, load a pre-trained model and use it to predict tags for the sentence:&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-python&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;pl-k&quot;&gt;from&lt;/span&gt; flair.data &lt;span class=&quot;pl-k&quot;&gt;import&lt;/span&gt; Sentence
&lt;span class=&quot;pl-k&quot;&gt;from&lt;/span&gt; flair.models &lt;span class=&quot;pl-k&quot;&gt;import&lt;/span&gt; SequenceTagger

&lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;#&lt;/span&gt; make a sentence&lt;/span&gt;
sentence &lt;span class=&quot;pl-k&quot;&gt;=&lt;/span&gt; Sentence(&lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;I love Berlin .&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;&lt;/span&gt;)

&lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;#&lt;/span&gt; load the NER tagger&lt;/span&gt;
tagger &lt;span class=&quot;pl-k&quot;&gt;=&lt;/span&gt; SequenceTagger.load(&lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;ner&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;&lt;/span&gt;)

&lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;#&lt;/span&gt; run NER over sentence&lt;/span&gt;
tagger.predict(sentence)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Done! The &lt;code&gt;Sentence&lt;/code&gt; now has entity annotations. Print the sentence to see what the tagger found.&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-python&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;pl-c1&quot;&gt;print&lt;/span&gt;(sentence)
&lt;span class=&quot;pl-c1&quot;&gt;print&lt;/span&gt;(&lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;The following NER tags are found:&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;&lt;/span&gt;)

&lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;#&lt;/span&gt; iterate over entities and print&lt;/span&gt;
&lt;span class=&quot;pl-k&quot;&gt;for&lt;/span&gt; entity &lt;span class=&quot;pl-k&quot;&gt;in&lt;/span&gt; sentence.get_spans(&lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;ner&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;&lt;/span&gt;):
    &lt;span class=&quot;pl-c1&quot;&gt;print&lt;/span&gt;(entity)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This should print:&lt;/p&gt;
&lt;div class=&quot;highlight highlight-text-shell-session&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;pl-c1&quot;&gt;Sentence: &quot;I love Berlin .&quot; - 4 Tokens&lt;/span&gt;

&lt;span class=&quot;pl-c1&quot;&gt;The following NER tags are found: &lt;/span&gt;

&lt;span class=&quot;pl-c1&quot;&gt;LOC-span [3]: &quot;Berlin&quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Tutorials&lt;/h2&gt;
&lt;p&gt;We provide a set of quick tutorials to get you started with the library:&lt;/p&gt;
&lt;p&gt;The tutorials explain how the base NLP classes work, how you can load pre-trained models to tag your text, how you embed your text with different word or document embeddings, and how you can train your own language models, sequence labeling models, and text classification models. Let us know if anything is unclear.&lt;/p&gt;
&lt;p&gt;Here also a link to a useful article:&lt;/p&gt;
&lt;h2&gt;Citing Flair&lt;/h2&gt;
&lt;p&gt;Please cite the following paper when using Flair:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;@inproceedings{akbik2018coling,
  title={Contextual String Embeddings for Sequence Labeling},
  author={Akbik, Alan and Blythe, Duncan and Vollgraf, Roland},
  booktitle = {{COLING} 2018, 27th International Conference on Computational Linguistics},
  pages     = {1638--1649},
  year      = {2018}
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2&gt;Contact&lt;/h2&gt;
&lt;p&gt;Please email your questions or comments to &lt;a href=&quot;http://alanakbik.github.io/&quot; rel=&quot;nofollow&quot;&gt;Alan Akbik&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Contributing&lt;/h2&gt;
&lt;p&gt;Thanks for your interest in contributing! There are many ways to get involved; start with our &lt;a href=&quot;https://github.com/zalandoresearch/flair/blob/master/resources/docs/CONTRIBUTING.md&quot;&gt;contributor guidelines&lt;/a&gt; and then check these &lt;a href=&quot;https://github.com/zalandoresearch/flair/issues&quot;&gt;open issues&lt;/a&gt; for specific tasks.&lt;/p&gt;
&lt;p&gt;For contributors looking to get deeper into the API we suggest cloning the repository and checking out the unit tests for examples of how to call methods. Nearly all classes and methods are documented, so finding your way around the code should hopefully be easy.&lt;/p&gt;
&lt;h3&gt;Running unit tests locally&lt;/h3&gt;
&lt;p&gt;You need &lt;a href=&quot;https://pipenv.readthedocs.io/&quot; rel=&quot;nofollow&quot;&gt;Pipenv&lt;/a&gt; for this:&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-shell&quot;&gt;
&lt;pre&gt;
pipenv install --dev &lt;span class=&quot;pl-k&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; pipenv shell
pytest tests/
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To run integration tests execute:&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-shell&quot;&gt;
&lt;pre&gt;
pytest --runintegration tests/
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The integration tests will train small models. Afterwards, the trained model will be loaded for prediction.&lt;/p&gt;
&lt;p&gt;To also run slow tests, such as loading and using the embeddings provided by flair, you should execute:&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-shell&quot;&gt;
&lt;pre&gt;
pytest --runslow tests/
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The MIT License (MIT)&lt;/p&gt;
&lt;p&gt;Flair is licensed under the following MIT license: The MIT License (MIT) Copyright © 2018 Zalando SE, &lt;a href=&quot;https://tech.zalando.com&quot; rel=&quot;nofollow&quot;&gt;https://tech.zalando.com&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:&lt;/p&gt;
&lt;p&gt;The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.&lt;/p&gt;
&lt;p&gt;THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;
</description>
<pubDate>Wed, 02 Jan 2019 06:51:15 +0000</pubDate>
<dc:creator>kumaranvpl</dc:creator>
<og:image>https://avatars0.githubusercontent.com/u/30869512?s=400&amp;v=4</og:image>
<og:type>object</og:type>
<og:title>zalandoresearch/flair</og:title>
<og:url>https://github.com/zalandoresearch/flair</og:url>
<og:description>A very simple framework for state-of-the-art Natural Language Processing (NLP) - zalandoresearch/flair</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://github.com/zalandoresearch/flair</dc:identifier>
</item>
<item>
<title>IQ is largely a pseudoscientific swindle</title>
<link>https://medium.com/incerto/iq-is-largely-a-pseudoscientific-swindle-f131c101ba39</link>
<guid isPermaLink="true" >https://medium.com/incerto/iq-is-largely-a-pseudoscientific-swindle-f131c101ba39</guid>
<description>&lt;div class=&quot;uiScale uiScale-ui--regular uiScale-caption--regular u-flexCenter u-marginVertical24 u-fontSize15 js-postMetaLockup&quot;&gt;
&lt;div class=&quot;u-flex0&quot;&gt;&lt;a class=&quot;link u-baseColor--link avatar&quot; href=&quot;https://medium.com/@nntaleb?source=post_header_lockup&quot; data-action=&quot;show-user-card&quot; data-action-source=&quot;post_header_lockup&quot; data-action-value=&quot;f138bf5466fe&quot; data-action-type=&quot;hover&quot; data-user-id=&quot;f138bf5466fe&quot; dir=&quot;auto&quot;&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/fit/c/100/100/1*dvvBFludHXwlKf1vs-BhtQ.jpeg&quot; class=&quot;avatar-image u-size50x50&quot; alt=&quot;Go to the profile of Nassim Nicholas Taleb&quot;/&gt;&lt;/a&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;p name=&quot;33d8&quot; id=&quot;33d8&quot; class=&quot;graf graf--p graf-after--h3&quot;&gt;&lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;Background :&lt;/strong&gt; “IQ” is a stale test meant to measure mental capacity but in fact mostly measures &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;extreme&lt;/strong&gt; &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;unintelligence&lt;/strong&gt; (learning difficulties), as well as, to a lesser extent, a form of intelligence, stripped of 2nd order effects. It is meant to select exam-takers, paper shufflers, obedient IYIs (intellectuals yet idiots), ill adapted for “real life”. The test is poorly thought out mathematically, and seemed to be promoted by&lt;/p&gt;
&lt;ul class=&quot;postList&quot;&gt;&lt;li name=&quot;9e5f&quot; id=&quot;9e5f&quot; class=&quot;graf graf--li graf-after--p&quot;&gt;racists/eugenists, people bent on showing that &lt;em class=&quot;markup--em markup--li-em&quot;&gt;some&lt;/em&gt; populations have inferior mental abilities based on &lt;em class=&quot;markup--em markup--li-em&quot;&gt;IQ test=intelligence;&lt;/em&gt; those have been upset with me for suddenly robbing them of a “scientific” tool (as evidenced by the bitter reactions to the initial post on twitter/smear campaigns by such mountebanks as Charles Murray). (Note: there were close to 3.1 million views of the tweetstorms).&lt;/li&gt;
&lt;li name=&quot;d518&quot; id=&quot;d518&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;psychometrics peddlers looking for suckers (military, large corporations) buying the “this is the best measure in psychology” argument when it is not even technically a measure — it explains at best between 13% and 50% of the performance in &lt;em class=&quot;markup--em markup--li-em&quot;&gt;some&lt;/em&gt; tasks, minus the data massaging and statistical cherrypicking by psychologists; it doesn’t satisfy the monotonicity and transitivity required to have a measure. No measure that fails 60–95% of the time should be part of “science” (nor should psychology — owing to its sinister track record — be part of science (rather &lt;strong class=&quot;markup--strong markup--li-strong&quot;&gt;scientism&lt;/strong&gt;), but that’s another discussion).&lt;/li&gt;
&lt;/ul&gt;&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*l-6_W0JLRnm4c_6EgiCbgg.png&quot; data-width=&quot;1570&quot; data-height=&quot;1692&quot; data-is-featured=&quot;true&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*l-6_W0JLRnm4c_6EgiCbgg.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1200/1*l-6_W0JLRnm4c_6EgiCbgg.png&quot;/&gt;&lt;/div&gt;
&lt;strong class=&quot;markup--strong markup--figure-strong&quot;&gt;Fig 1:&lt;/strong&gt; The graph that summarizes the flaw, showing that “correlation” is meaningless in the absence of symmetry. We construct (in red) an intelligence test (horizontal), that is 100% correlated with negative performance (when IQ is, say, below 100) and 0% with upside, positive performance. We progressively add noise (with a 0 mean) and see correlation (on top) drop. Performance is on the vertical axis. The problem gets worse with the “g” intelligence based on principal components. By comparison we show (graph below) the distribution of &lt;strong class=&quot;markup--strong markup--figure-strong&quot;&gt;IQ and SAT scores&lt;/strong&gt;. Most “correlations” entailing IQ suffer the same pathology. Note that IQ tests correlate with SAT scores! (To echo Haldane, one ounce of rigorous algebra is worth more than a century of verbalistic statisticopsycholophastering).
&lt;p name=&quot;b1e9&quot; id=&quot;b1e9&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Some argue that IQ measures intellectual capacity, not “wisdom” or patience, or “conscientiousness”, or decision-making or something of the sort. No. &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;It does not even &lt;em class=&quot;markup--em markup--p-em&quot;&gt;measure&lt;/em&gt; intellectual capacity/mental powers.&lt;/strong&gt;&lt;/p&gt;
&lt;p name=&quot;c0e8&quot; id=&quot;c0e8&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;If you want to detect how someone fares at a task, say loan sharking, tennis playing, or random matrix theory, make him/her do that task; we don’t need theoretical exams for a real world function by probability-challenged psychologists. Traders get it right away: hypothetical P/L from “simulated” paper strategies doesn’t count. Performance=actual. What goes in people’s head or reaction to a screen image doesn’t exist (except via negativa).&lt;/p&gt;
&lt;p name=&quot;9791&quot; id=&quot;9791&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;&lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;Fat Tails&lt;/strong&gt; If IQ is Gaussian &lt;em class=&quot;markup--em markup--p-em&quot;&gt;by construction&lt;/em&gt; and if real world performance were, net, fat tailed (it is), then either the covariance between IQ and performance doesn’t exist or it is uninformational. It will show a finite number &lt;em class=&quot;markup--em markup--p-em&quot;&gt;in sample&lt;/em&gt; but doesn’t exist statistically. Another problem: when they say “black people are &lt;em class=&quot;markup--em markup--p-em&quot;&gt;x&lt;/em&gt; standard deviations away”. Different populations have different variances, even different skewness and these comparisons require richer models. See the formal treatment &lt;a href=&quot;https://www.academia.edu/37221402/THE_STATISTICAL_CONSEQUENCES_OF_FAT_TAILS_TECHNICAL_INCERTO_COLLECTION_&quot; data-href=&quot;https://www.academia.edu/37221402/THE_STATISTICAL_CONSEQUENCES_OF_FAT_TAILS_TECHNICAL_INCERTO_COLLECTION_&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener nofollow&quot; target=&quot;_blank&quot;&gt;in my next book&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*6Y_N__E_dPc-L2278b417A.jpeg&quot; data-width=&quot;320&quot; data-height=&quot;248&quot; src=&quot;https://cdn-images-1.medium.com/max/1200/1*6Y_N__E_dPc-L2278b417A.jpeg&quot;/&gt;&lt;/div&gt;
Mensa members: typically high “IQ” losers in Birkenstocks.
&lt;p name=&quot;26c3&quot; id=&quot;26c3&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;But the “intelligence” in IQ is determined by academic psychologists like the “paper trading” we mentioned above, via statistical constructs s.a. &lt;em class=&quot;markup--em markup--p-em&quot;&gt;correlation&lt;/em&gt; that I show here (see Fig. 1) that &lt;em class=&quot;markup--em markup--p-em&quot;&gt;they patently don’t understand&lt;/em&gt;. It does correlate to negative performance (as it was initially designed to detect learning special needs) but then any measure would work there. A measure that works in left tail not right tail (IQ decorrelates as it goes higher) is problematic. We have gotten similar results since the famous Terman longitudinal study, even with massaged data for later studies. (To get the point, consider that if someone has mental needs, there will be 100% correlation between performance and IQ tests. But the performance doesn’t correlate as well at higher levels, though the psychologists will think it does.)&lt;/p&gt;
&lt;p name=&quot;1d83&quot; id=&quot;1d83&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;It is a false comparison to claim that IQ “measures the hardware” rather than the software. It can measures &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;some&lt;/strong&gt; arbitrarily selected mental abilities (in a testing environment) believed to be useful. However, if you take a Popperian-Hayekian view on intelligence, you would realize that to measure it you would need to know the &lt;em class=&quot;markup--em markup--p-em&quot;&gt;mental&lt;/em&gt; skills needed in a future ecology, which requires predictability of said future ecology. It also requires the skills to make it to the future (hence the need for mental biases for survival).&lt;/p&gt;
&lt;p name=&quot;d09b&quot; id=&quot;d09b&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;&lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;Real Life:&lt;/strong&gt; In academia there is no difference between academia and the real world; in the real world there is. 1) When someone asks you a question in the real world, you focus first on “&lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;why&lt;/strong&gt; is he/she asking me that?”, which shifts you to the environment (see Fat Tony vs Dr John in &lt;em class=&quot;markup--em markup--p-em&quot;&gt;The Black Swan&lt;/em&gt;) and detracts you from the problem at hand. &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;Only suckers don’t have that instinct&lt;/strong&gt;. 2) Real life never never offers crisp questions with crisp answers (most questions don’t have answers; perhaps the worst problem with IQ is that it seem to selects for people who don’t like to say “there is no answer, don’t waste time, find something else”.) 3) It takes a certain type of person to waste intelligent concentration on classroom/academic problems. These are lifeless bureaucrats who can muster &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;sterile motivation&lt;/strong&gt;. Some people can only focus on problems that are real, not fictional textbook ones (see the note below where I explain that I can only concentrate with real not fictional problems). 4) IQ doesn’t detect &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;convexity&lt;/strong&gt; (by an argument similar to bias-variance you need to make a lot of small inconsequential mistake in order to avoid a large consequential one. See &lt;em class=&quot;markup--em markup--p-em&quot;&gt;Antifragile&lt;/em&gt; and how &lt;em class=&quot;markup--em markup--p-em&quot;&gt;a&lt;/em&gt;ny measure of “intelligence” w/o convexity is sterile &lt;a href=&quot;https://www.edge.org/conversation/nassim_nicholas_taleb-understanding-is-a-poor-substitute-for-convexity-antifragility&quot; data-href=&quot;https://www.edge.org/conversation/nassim_nicholas_taleb-understanding-is-a-poor-substitute-for-convexity-antifragility&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener nofollow&quot; target=&quot;_blank&quot;&gt;edge.org/conversation/n…&lt;/a&gt;). To do well you must survive, survival requires some mental biases directing to some errors. 5) &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;&lt;em class=&quot;markup--em markup--p-em&quot;&gt;Fooled by Randomness&lt;/em&gt;&lt;/strong&gt;: seeing shallow patterns in not a virtue — leads to naive interventionism. Some psychologist wrote back to me: “IQ selects for pattern recognition, essential for functioning in modern society”. No. Not seeing patterns except when they are significant is a virtue in real life. 6) To do well in life you need depth and ability to select your own problems and to think independently.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*RlEAvb8KejpEBFWslwQuGQ.png&quot; data-width=&quot;598&quot; data-height=&quot;604&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*RlEAvb8KejpEBFWslwQuGQ.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1200/1*RlEAvb8KejpEBFWslwQuGQ.png&quot;/&gt;&lt;/div&gt;
Upper bound: discount the massaging and correlation effects. Picked up from the highly unrigorous &lt;strong class=&quot;markup--strong markup--figure-strong&quot;&gt;Intelligence: All That Matters&lt;/strong&gt; &lt;em class=&quot;markup--em markup--figure-em&quot;&gt;by S. Ritchie.&lt;/em&gt;
&lt;p name=&quot;a538&quot; id=&quot;a538&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;&lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;Functionary Quotient&lt;/strong&gt;: If you renamed IQ , from “Intelligent Quotient” to FQ “Functionary Quotient” or SQ “Salaryperson Quotient”, then some of the stuff will be true. It measures best the ability to be a good slave. “IQ” is good for &lt;a href=&quot;https://twitter.com/davidgraeber&quot; data-href=&quot;https://twitter.com/davidgraeber&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener nofollow&quot; target=&quot;_blank&quot;&gt;@davidgraeber&lt;/a&gt;’s “BS jobs”.&lt;/p&gt;
&lt;p name=&quot;6bcd&quot; id=&quot;6bcd&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;&lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;Metrification&lt;/strong&gt;: If someone came up w/a numerical“Well Being Quotient” WBQ or “Sleep Quotient”, SQ, trying to mimic temperature or a physical quantity, you’d find it absurd. But put enough academics w/physics envy on it and it will become an official measure.&lt;/p&gt;
&lt;h3 name=&quot;9ddb&quot; id=&quot;9ddb&quot; class=&quot;graf graf--h3 graf-after--p&quot;&gt;Notes And Technical Notes&lt;/h3&gt;
&lt;ul class=&quot;postList&quot;&gt;&lt;li name=&quot;4f3a&quot; id=&quot;4f3a&quot; class=&quot;graf graf--li graf--startsWithDoubleQuote graf-after--h3&quot;&gt;“IQ” is most predictive of performance in military training, with correlation~.5, (which is circular since hiring isn’t random and training is another test).&lt;/li&gt;
&lt;li name=&quot;f252&quot; id=&quot;f252&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;I have here no psychological references for backup: simply, the field is bust. So far ~ 50% of the research does notreplicate, and papers that do have weaker effect. Not counting poor transfer to reality (psychological papers are &lt;em class=&quot;markup--em markup--li-em&quot;&gt;ludic&lt;/em&gt;).&lt;/li&gt;
&lt;li name=&quot;799e&quot; id=&quot;799e&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;How P values often — rather almost always — fraudulent: my paper &lt;a href=&quot;https://arxiv.org/pdf/1603.07532.pdf&quot; data-href=&quot;https://arxiv.org/pdf/1603.07532.pdf&quot; class=&quot;markup--anchor markup--li-anchor&quot; rel=&quot;noopener nofollow&quot; target=&quot;_blank&quot;&gt;arxiv.org/pdf/1603.07532…&lt;/a&gt;&lt;/li&gt;
&lt;li name=&quot;4247&quot; id=&quot;4247&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;The Flynn effect should warn us not just that IQ is somewhat environment dependent, but that it is at least partly circular.&lt;/li&gt;
&lt;li name=&quot;bd1a&quot; id=&quot;bd1a&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;&lt;strong class=&quot;markup--strong markup--li-strong&quot;&gt;Verbalism:&lt;/strong&gt; Psychologists have a skin-deep statistical education &amp;amp; can’t translate something as trivial as “correlation” or “explained variance” into meaning, esp. under nonlinearities (see paper at the end).&lt;/li&gt;
&lt;li name=&quot;0289&quot; id=&quot;0289&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;&lt;strong class=&quot;markup--strong markup--li-strong&quot;&gt;The “best measure” charlatans&lt;/strong&gt;: IQ is reminiscent of risk charlatans insisting on selling “value at risk”, VaR, and RiskMetrics saying “it’s the best measure”. That “best” measure, being unreliable blew them up many many times. Note the class of suckers for whom a bad measure is better than no measure across domains.&lt;/li&gt;
&lt;li name=&quot;2d9d&quot; id=&quot;2d9d&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;You can’t do statistics without probability.&lt;/li&gt;
&lt;li name=&quot;d3e1&quot; id=&quot;d3e1&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;Much of the stuff about IQ of physicists is suspicious, from self-reporting biases/selection in tests.&lt;/li&gt;
&lt;li name=&quot;b61b&quot; id=&quot;b61b&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;If you looked at Northern Europe from Ancient Babylon/Ancient Med/Egypt, you would have written the inhabitants off... Then look at what happened after 1600. Be careful when you discuss populations.&lt;/li&gt;
&lt;li name=&quot;3416&quot; id=&quot;3416&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;The same people hold that IQ is heritable, that it determines success, that Asians have higher IQs than Caucasians, degrade Africans, then don’t realize that China for about a Century had one order of magnitude lower GDP than the West.&lt;/li&gt;
&lt;/ul&gt;&lt;h3 name=&quot;98cf&quot; id=&quot;98cf&quot; class=&quot;graf graf--h3 graf-after--li&quot;&gt;Mathematical Considerations&lt;/h3&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;0*fwVORidx__534SXz.jpg&quot; data-width=&quot;576&quot; data-height=&quot;1200&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/0*fwVORidx__534SXz.jpg&quot;/&gt;&lt;/div&gt;
&lt;p name=&quot;962a&quot; id=&quot;962a&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;&lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;CURSE OF DIMENSIONALITY&lt;/strong&gt; A flaw in the attempts to identify “intelligence” genes. You can get monogenic traits, not polygenic (note: additive monogenic used in animal breeding is NOT polygenic).&lt;/p&gt;
&lt;h3 name=&quot;bcb3&quot; id=&quot;bcb3&quot; class=&quot;graf graf--h3 graf-after--p&quot;&gt;The Skin in the game issue&lt;/h3&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;0*VWygbW_Tfr7vM5EY.jpg&quot; data-width=&quot;896&quot; data-height=&quot;1160&quot; data-action=&quot;zoom&quot; data-action-value=&quot;0*VWygbW_Tfr7vM5EY.jpg&quot; src=&quot;https://cdn-images-1.medium.com/max/1200/0*VWygbW_Tfr7vM5EY.jpg&quot;/&gt;&lt;/div&gt;
Note From Skin in the Game, 1
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;0*np4pBJZw3w-pbeMh.jpg&quot; data-width=&quot;916&quot; data-height=&quot;968&quot; data-action=&quot;zoom&quot; data-action-value=&quot;0*np4pBJZw3w-pbeMh.jpg&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/0*np4pBJZw3w-pbeMh.jpg&quot;/&gt;&lt;/div&gt;
&lt;em class=&quot;markup--em markup--figure-em&quot;&gt;Note from Skin in the Game, 2&lt;/em&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;0*CduMoQjTz_kyxAFu.jpg&quot; data-width=&quot;967&quot; data-height=&quot;1200&quot; data-action=&quot;zoom&quot; data-action-value=&quot;0*CduMoQjTz_kyxAFu.jpg&quot; src=&quot;https://cdn-images-1.medium.com/max/1200/0*CduMoQjTz_kyxAFu.jpg&quot;/&gt;&lt;/div&gt;
&lt;h4 name=&quot;87e3&quot; id=&quot;87e3&quot; class=&quot;graf graf--h4 graf-after--figure&quot;&gt;How social scientists have trouble translating a statistical construct into its practical meaning.&lt;/h4&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;0*76fPv686eOXo1b7F.jpg&quot; data-width=&quot;1200&quot; data-height=&quot;1091&quot; data-action=&quot;zoom&quot; data-action-value=&quot;0*76fPv686eOXo1b7F.jpg&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/0*76fPv686eOXo1b7F.jpg&quot;/&gt;&lt;/div&gt;
</description>
<pubDate>Wed, 02 Jan 2019 01:21:50 +0000</pubDate>
<dc:creator>oska</dc:creator>
<og:title>IQ is largely a pseudoscientific swindle – INCERTO – Medium</og:title>
<og:url>https://medium.com/incerto/iq-is-largely-a-pseudoscientific-swindle-f131c101ba39</og:url>
<og:image>https://cdn-images-1.medium.com/max/1200/1*l-6_W0JLRnm4c_6EgiCbgg.png</og:image>
<og:description>Background : “IQ” is a stale test meant to measure mental capacity but in fact mostly measures extreme unintelligence (learning…</og:description>
<og:type>article</og:type>
<dc:format>text/html</dc:format>
<dc:identifier>https://medium.com/incerto/iq-is-largely-a-pseudoscientific-swindle-f131c101ba39</dc:identifier>
</item>
<item>
<title>Lessons from Running a Small-Scale Electronics Factory in My Guest Bedroom</title>
<link>https://spun.io/2018/12/15/lessons-from-running-a-small-scale-electronics-factory-in-my-guest-bedroom-part-1-design/</link>
<guid isPermaLink="true" >https://spun.io/2018/12/15/lessons-from-running-a-small-scale-electronics-factory-in-my-guest-bedroom-part-1-design/</guid>
<description>&lt;p&gt;After assembling over 200 &lt;a href=&quot;https://hackaday.com/2018/08/14/all-the-badges-of-def-con-26-vol-1/&quot;&gt;Telephreak badges&lt;/a&gt; by hand for DEFCON 26 (and taking *way* longer to accomplish it than I estimated) I figured I should document some of the lessons that I learned along the way – from initial design to finished product. The subject of many of the examples of the &lt;em&gt;right way&lt;/em&gt; to do things are a small batch of boards I’m currently assembling for &lt;a rel=&quot;noreferrer noopener&quot; aria-label=&quot; (opens in a new tab)&quot; href=&quot;https://cloud9perception.com/&quot; target=&quot;_blank&quot;&gt;Cloud 9 Perception&lt;/a&gt;, a friend’s computer vision and robotics company.&lt;/p&gt;
&lt;p&gt;This post primarily focuses on design choices for PCBs and the firmware running on them, the next post will show some tricks I’ve learned to save time and energy actually assembling and baking your boards.&lt;/p&gt;
&lt;p&gt;There are a number of design choices that &lt;em&gt;really&lt;/em&gt; wish I’d considered while making the Telephreak badges. Here are the ones I think would’ve made the most impact to make my life simpler.&lt;/p&gt;
&lt;h2&gt;Cut some holes in your boards&lt;/h2&gt;
&lt;a href=&quot;https://spun.io/wp-content/uploads/2019/01/Screenshot_22.png&quot;&gt;&lt;img src=&quot;https://spun.io/wp-content/uploads/2019/01/Screenshot_22.png&quot; alt=&quot;&quot; class=&quot;wp-image-359&quot;/&gt;&lt;/a&gt;
&lt;p&gt;This one is pretty simple but it can make a big difference. Even if you don’t need to mount your board to anything, adding few holes for alignment purposes can make your life easier in all sorts of ways – primarily when putting together jigs for programming or even mounting through-hole components during assembly. The Telephreak badges *did* have a single hole at the top, but two are really necessary to get decent alignment.&lt;/p&gt;
&lt;h2&gt;Add proper programming and debugging interfaces&lt;/h2&gt;
&lt;div class=&quot;wp-block-image&quot;&gt;&lt;a href=&quot;https://spun.io/wp-content/uploads/2019/01/Djcq3DjUwAAziXR.jpg-large.jpg&quot;&gt;&lt;img src=&quot;https://spun.io/wp-content/uploads/2019/01/Djcq3DjUwAAziXR.jpg-large.jpg&quot; alt=&quot;&quot; class=&quot;wp-image-362&quot; width=&quot;279&quot; height=&quot;372&quot;/&gt;&lt;/a&gt;Doing this a bunch of times really sucked.&lt;/div&gt;
&lt;p&gt;I also really wished I’d added some sort of proper debugging/programming interface to the each of the boards. I had every pin for every device broken out on the board, but I didn’t realize what a pain it would be to reprogram them en masse if the firmware I burned onto the microcontrollers wasn’t perfect. The first step was to forcibly disable 1) the display, 2) the radio, and 3) the flash chip from using the SPI bus by adding three jumper wires to tie their CE pins to VCC. With those three jumper wires in place, the next task was to wire up the four SPI bus lines, the reset line, and VCC and GND. It would’ve been a massive pain to solder wires or pins into the through-holes to do this, even temporarily, so the end result was a bodge of ten leads going to various places on the board, all being held in place by thoughts and prayers.&lt;/p&gt;
&lt;p&gt;Next time around, at a minimum, I’ll be adding standard pin headers for the SPI bus, or perhaps even adding a microcontroller and USB port to handle programming.&lt;/p&gt;
&lt;h2&gt;Align &lt;strong&gt;&lt;em&gt;all&lt;/em&gt;&lt;/strong&gt; of your pin headers to be on the same 0.1″ grid&lt;/h2&gt;
&lt;div class=&quot;wp-block-image&quot;&gt;&lt;a href=&quot;https://spun.io/wp-content/uploads/2019/01/DjJQEV5UcAELeqV.jpg-large.jpg&quot;&gt;&lt;img src=&quot;https://spun.io/wp-content/uploads/2019/01/DjJQEV5UcAELeqV.jpg-large.jpg&quot; alt=&quot;&quot; class=&quot;wp-image-365&quot; width=&quot;256&quot; height=&quot;188&quot;/&gt;&lt;/a&gt;More wires everywhere, even after I added pin headers to a test board&lt;/div&gt;
&lt;p&gt;The third thing that would’ve helped would’ve been simply ensuring that the pins I broke out all lined up on the same 0.1″ grid so I could’ve made programming and other jigs by adding pin headers to normal protoboard.&lt;/p&gt;
&lt;h2&gt;Think about component dimensions&lt;/h2&gt;
&lt;div class=&quot;wp-block-image&quot;&gt;&lt;a href=&quot;https://spun.io/wp-content/uploads/2019/01/DSC00211.jpg&quot;&gt;&lt;img src=&quot;https://spun.io/wp-content/uploads/2019/01/DSC00211.jpg&quot; alt=&quot;&quot; class=&quot;wp-image-387&quot; width=&quot;235&quot; height=&quot;156&quot;/&gt;&lt;/a&gt;Sorry little dude!&lt;/div&gt;
&lt;p&gt;One issue that I saw quite often was that the surface-mount HC49-profile clock crystals were being knocked off, mainly due to being the tallest component on the board. It would’ve been trivial to use a lower-profile component if I’d thought about it beforehand.&lt;/p&gt;
&lt;h2&gt;Eliminate as many assembly steps as possible&lt;/h2&gt;
&lt;p&gt;This is a big one. There were two components on the devices that had to be hand-soldered: the battery pack, and the graphic display. For the battery pack, wires had to be trimmed, stripped, tinned, held in place, and then soldered, and the battery pack had to be glued to the board. This ended up being a really tedious process and took up quite a bit of time. Instead, next time for a project like this, I’ll be using battery packs with fixed pins that I can quickly put in place.&lt;/p&gt;
&lt;p&gt;As far as the displays, hand-soldering them wasn’t &lt;em&gt;too&lt;/em&gt; time-consuming, but it was definitely an error-prone process, and it derived from the fact that I couldn’t bake the LCDs because of temperature issues, and because the flat polyamide cable had to bend backwards and would’ve never held in place. Next time, I’ll add a surface-mount socket for the connector that I can simply bake on with the other components&lt;/p&gt;
&lt;h2&gt;Rename your components once your board layout is finalized&lt;/h2&gt;
&lt;div class=&quot;wp-block-image&quot;&gt;&lt;a href=&quot;https://spun.io/wp-content/uploads/2019/01/Screenshot_24.png&quot;&gt;&lt;img src=&quot;https://spun.io/wp-content/uploads/2019/01/Screenshot_24.png&quot; alt=&quot;&quot; class=&quot;wp-image-403&quot; width=&quot;160&quot; height=&quot;162&quot;/&gt;&lt;/a&gt;C1 is right by C2, where you’d expect&lt;/div&gt;
&lt;p&gt;This one is also pretty trivial, but can save a ton of time during assembly if your device has a lot of components. Once your board layout is complete, rename the components so they’re in rough numeric order. This way, when you’re looking for the right spots to place your components, C10 will hopefully be somewhere near C9, and so forth, reducing the amount of space you’re searching for tiny text labels.&lt;/p&gt;
&lt;h2&gt;Add a test cycle to your firmware&lt;/h2&gt;
&lt;p&gt;This one would’ve been a big deal for me. The first badges had to wait to receive a radio signal and spend a couple minutes downloading a bitmap over the air before I could confirm that they worked. Not ideal when you’re making 200+ units. Eventually I added a change so I could get *something* on the display at boot to show that it and the microcontroller were alive, but the radio and flash chip weren’t tested.&lt;/p&gt;
&lt;p&gt;The Cloud 9 boards I’m working with have a full test cycle, and by using LEDs along with relays, you can actually get audible feedback that things are working. It tests all of the hardware, including Ethernet and the camera, and will deliver some very satisfying relay clicks as tests complete successfully (or give you an idea of where the problem is if something isn’t working correctly)&lt;/p&gt;
&lt;div class=&quot;wp-block-embed__wrapper&quot;&gt;&lt;iframe width=&quot;830&quot; height=&quot;467&quot; src=&quot;https://www.youtube.com/embed/hDDEqaK86UA?feature=oembed&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;[embedded content]&lt;/iframe&gt;&lt;/div&gt;
&lt;h2&gt;Coming next, my favorite part… assembly!&lt;/h2&gt;
</description>
<pubDate>Wed, 02 Jan 2019 00:28:40 +0000</pubDate>
<dc:creator>DominoTree</dc:creator>
<og:title>Lessons from Running a Small-Scale Electronics Factory in my Guest Bedroom, part 1: Design</og:title>
<og:url>https://spun.io/2018/12/15/lessons-from-running-a-small-scale-electronics-factory-in-my-guest-bedroom-part-1-design/</og:url>
<og:type>article</og:type>
<og:description>After assembling over 200 Telephreak badges by hand for DEFCON 26 (and taking *way* longer to accomplish it than I estimated) I figured I should document some of the lessons that I learned along the way - from initial design to finished product. The subject of many of the examples of the right way t</og:description>
<og:image>https://spun.io/wp-content/uploads/2018/12/OdCcNWg_TvGPfWpz.jpg</og:image>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://spun.io/2018/12/15/lessons-from-running-a-small-scale-electronics-factory-in-my-guest-bedroom-part-1-design/</dc:identifier>
</item>
<item>
<title>Courier Prime: It’s Courier, Just Better</title>
<link>https://quoteunquoteapps.com/courierprime/</link>
<guid isPermaLink="true" >https://quoteunquoteapps.com/courierprime/</guid>
<description>&lt;p&gt;Since the beginning, screenplays have been written in Courier. Its uniformity allows filmmakers to make handy comparisons and estimates, such as 1 page = 1 minute of screen time.&lt;/p&gt;
&lt;p&gt;But there’s no reason Courier has to look terrible. We set out to make the best damn Courier ever.&lt;/p&gt;
&lt;p&gt;We call it Courier Prime.&lt;/p&gt;
</description>
<pubDate>Tue, 01 Jan 2019 21:53:28 +0000</pubDate>
<dc:creator>ingve</dc:creator>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://quoteunquoteapps.com/courierprime/</dc:identifier>
</item>
<item>
<title>Mickey Mouse and Batman will soon be public domain</title>
<link>https://arstechnica.com/tech-policy/2019/01/a-whole-years-worth-of-works-just-fell-into-the-public-domain/</link>
<guid isPermaLink="true" >https://arstechnica.com/tech-policy/2019/01/a-whole-years-worth-of-works-just-fell-into-the-public-domain/</guid>
<description>&lt;img src=&quot;https://cdn.arstechnica.net/wp-content/uploads/2019/01/MV5BMTc1Njk5ODQ4Ml5BMl5BanBnXkFtZTcwMTMwOTM0OQ@@._V1_SX1777_CR001777744_AL_-800x335.jpg&quot; alt=&quot;The copyright to &amp;lt;i&amp;gt;The Great Gatsby&amp;lt;/i&amp;gt;—the 1925 novel, not the 2013 movie starring Leonardo di Caprio—will expire two years from today.&quot;/&gt;&lt;div class=&quot;caption-text&quot;&gt;&lt;a href=&quot;https://cdn.arstechnica.net/wp-content/uploads/2019/01/MV5BMTc1Njk5ODQ4Ml5BMl5BanBnXkFtZTcwMTMwOTM0OQ@@._V1_SX1777_CR001777744_AL_.jpg&quot; class=&quot;enlarge-link&quot; data-height=&quot;744&quot; data-width=&quot;1777&quot;&gt;Enlarge&lt;/a&gt; &lt;span class=&quot;sep&quot;&gt;/&lt;/span&gt; The copyright to &lt;em&gt;The Great Gatsby&lt;/em&gt;—the 1925 novel, not the 2013 movie starring Leonardo di Caprio—will expire two years from today.&lt;/div&gt;&lt;div class=&quot;caption-credit&quot;&gt;Warner Bros. Picture&lt;/div&gt;
&lt;aside id=&quot;social-left&quot; aria-label=&quot;Read the comments or share this article&quot;&gt;
&lt;h4 class=&quot;comment-count-before&quot;&gt;&lt;a title=&quot;125 posters participating, including story author&quot; class=&quot;comment-count icon-comment-bubble-down&quot; href=&quot;https://arstechnica.com/tech-policy/2019/01/a-whole-years-worth-of-works-just-fell-into-the-public-domain/?comments=1&quot;&gt;reader comments&lt;/a&gt;&lt;/h4&gt;
&lt;a title=&quot;125 posters participating, including story author&quot; class=&quot;comment-count icon-comment-bubble-down&quot; href=&quot;https://arstechnica.com/tech-policy/2019/01/a-whole-years-worth-of-works-just-fell-into-the-public-domain/?comments=1&quot;&gt;&lt;span class=&quot;comment-count-number&quot;&gt;257&lt;/span&gt; &lt;span class=&quot;visually-hidden&quot;&gt;with 125 posters participating, including story author&lt;/span&gt;&lt;/a&gt;
&lt;div class=&quot;share-links&quot;&gt;
&lt;h4&gt;Share this story&lt;/h4&gt;
&lt;/div&gt;
&lt;/aside&gt;&lt;p&gt;As the ball dropped over Times Square last night, all copyrighted works published in 1923 fell into the public domain (with a few exceptions). Everyone now has the right to republish them or adapt them for use in new works.&lt;/p&gt;
&lt;p&gt;It's the first time this has happened in 21 years.&lt;/p&gt;
&lt;p&gt;In 1998, works published in 1922 or earlier were in the public domain, with 1923 works scheduled to expire at the beginning of 1999. But then Congress passed the Sonny Bono Copyright Term Extension Act. It added 20 years to the terms of older works, keeping 1923 works locked up until 2019.&lt;/p&gt;
&lt;p&gt;Many people—including me—expected another fight over copyright extension in 2018. But it never happened. Congress left the existing law in place, and so those 1923 copyrights expired on schedule this morning.&lt;/p&gt;
&lt;p&gt;And assuming Congress doesn't interfere, more works will fall into the public domain each January from now on.&lt;/p&gt;
&lt;p&gt;Next January, George Gershwin's &lt;em&gt;Rhapsody in Blue&lt;/em&gt; will fall into the public domain. It will be followed by &lt;a href=&quot;https://www.eff.org/deeplinks/2013/05/why-isnt-gatsby-public-domain&quot;&gt;&lt;em&gt;The Great Gatsby&lt;/em&gt;&lt;/a&gt; in January 2021 and Ernest Hemingway's &lt;em&gt;The Sun Also Rises&lt;/em&gt; in January 2022.&lt;/p&gt;
&lt;p&gt;On January 1, 2024, we'll see the expiration of the copyright for &lt;em&gt;Steamboat Willie&lt;/em&gt;—and with it Disney's claim to the film's star, Mickey Mouse. The copyrights to Superman, Batman, Disney's Snow White, and early Looney Tunes characters will all fall into the public domain between 2031 and 2035.&lt;/p&gt;
&lt;p&gt;The expiration of copyrights for characters like Mickey Mouse and Batman will raise tricky new legal questions. After 2024, Disney won't have any copyright protection for Mickey's original incarnation. But Disney will still own copyrights for later incarnations of the character—and it will also own Mickey-related trademarks.&lt;/p&gt;
&lt;p&gt;James Grimmelmann, a copyright scholar at Cornell Law School, tells Ars that this is an uncharted area of law because licensing practices for modern characters are &quot;so much more intensive and so much more comprehensive now&quot; than in the 1920s and 1930s. &quot;We never had megacharacters in the same way&quot; prior to the 1920s, he says.&lt;/p&gt;
&lt;h2&gt;Internet activism made another extension untenable&lt;/h2&gt;
&lt;a href=&quot;https://cdn.arstechnica.net/wp-content/uploads/2019/01/GettyImages-3295411.jpg&quot; class=&quot;enlarge&quot; data-height=&quot;2194&quot; data-width=&quot;2777&quot; alt=&quot;Sonny Bono (right) in 1965. Bono was elected to Congress and then died in 1998. His colleagues in Congress dedicated the 1998 copyright extension legislation to his memory.&quot;&gt;&lt;img src=&quot;https://cdn.arstechnica.net/wp-content/uploads/2019/01/GettyImages-3295411-640x506.jpg&quot; width=&quot;640&quot; height=&quot;506&quot; srcset=&quot;https://cdn.arstechnica.net/wp-content/uploads/2019/01/GettyImages-3295411-1280x1011.jpg 2x&quot; alt=&quot;Sonny Bono (right) in 1965. Bono was elected to Congress and then died in 1998. His colleagues in Congress dedicated the 1998 copyright extension legislation to his memory.&quot;/&gt;&lt;/a&gt;
&lt;div class=&quot;caption-text&quot;&gt;&lt;a href=&quot;https://cdn.arstechnica.net/wp-content/uploads/2019/01/GettyImages-3295411.jpg&quot; class=&quot;enlarge-link&quot; data-height=&quot;2194&quot; data-width=&quot;2777&quot;&gt;Enlarge&lt;/a&gt; &lt;span class=&quot;sep&quot;&gt;/&lt;/span&gt; Sonny Bono (right) in 1965. Bono was elected to Congress and then died in 1998. His colleagues in Congress dedicated the 1998 copyright extension legislation to his memory.&lt;/div&gt;
&lt;p&gt;Dennis Karjala was a law professor who helped lead the doomed resistance to the 1998 extension. He passed away in 2017, but when I interviewed him in 2013, he &lt;a href=&quot;https://www.washingtonpost.com/news/the-switch/wp/2013/10/25/15-years-ago-congress-kept-mickey-mouse-out-of-the-public-domain-will-they-do-it-again/&quot;&gt;told me&lt;/a&gt; that it was &quot;basically the Gershwin family trust, grandchildren of Oscar Hammerstein, Disney, others of that ilk&quot; who pushed for ever-longer copyright terms.&lt;/p&gt;
&lt;p&gt;Most copyrighted works become commercially worthless within a decade or two. But a small minority of famous works from the 1920s and 1930s were still generating significant revenues in the 1990s. Retroactively extending copyright terms meant an enormous windfall for the companies and families that owned the copyrights.&lt;/p&gt;
&lt;p&gt;&quot;There was not a single argument that actually can stand up to any kind of reasonable analysis,&quot; Karjala said. But the public domain had few defenders. So even though the arguments for longer copyright terms weren't very strong, they won the day in Congress.&lt;/p&gt;
&lt;p&gt;Until recently, I assumed that the same interest groups would try to extend copyright terms again in 2018. But the political climate for copyright legislation has changed radically over the last 20 years.&lt;/p&gt;
&lt;p&gt;A year ago, Ars Technica &lt;a href=&quot;https://arstechnica.com/tech-policy/2018/01/hollywood-says-its-not-planning-another-copyright-extension-push/&quot;&gt;broke the news&lt;/a&gt; that three of the nation's most powerful rights holder groups in the country, the Motion Picture Association of America, the Recording Industry Association of America, and the Authors Guild, were not even going to try to pass legislation extending copyrights.&lt;/p&gt;
&lt;p&gt;&quot;It's not something we are pursuing,&quot; an RIAA spokesman told me.&lt;/p&gt;
&lt;p&gt;The reason was simple, Grimmelmann argues: they knew they weren't going to win.&lt;/p&gt;
&lt;p&gt;&quot;There's now a well-organized, grassroots lobby against copyright expansion,&quot; Grimmelmann tells Ars. &quot;There are large business interests now on the anti-expansion side. Also a wide popular movement that they can tie it into.&quot;&lt;/p&gt;
&lt;p&gt;The rise of the Internet and its remix culture means that a lot of people now benefit from a growing public domain in ways that weren't true in 1998. That includes big companies like Google, but it also includes grassroots communities like Wikipedia editors and Reddit users. This emerging copyright reform coalition flexed its lobbying muscles in 2012 when it &lt;a href=&quot;https://arstechnica.com/tech-policy/2012/01/internet-wins-sopa-and-pipa-both-shelved/&quot;&gt;overwhelmingly defeated&lt;/a&gt; an Internet filtering bill called the Stop Online Piracy Act.&lt;/p&gt;
&lt;p&gt;So if the usual suspects had pushed for another copyright extension, they would have had a serious fight on their hands. Digital rights groups, online activists, and lobbyists from big technology companies would have swarmed Capitol Hill, making the case against copyright extension. Evidently, major rights holders didn't have the stomach for another battle like that.&lt;/p&gt;
&lt;p&gt;Of course, it's possible they could make another effort in the future. But such an effort would face long odds: today's opponents of copyright extensions are vastly better organized and better funded than the ragtag band that tried to stop the 1998 copyright extension.&lt;/p&gt;
</description>
<pubDate>Tue, 01 Jan 2019 18:42:03 +0000</pubDate>
<dc:creator>Tomte</dc:creator>
<og:url>https://arstechnica.com/tech-policy/2019/01/a-whole-years-worth-of-works-just-fell-into-the-public-domain/</og:url>
<og:title>Mickey Mouse will be public domain soon—here’s what that means</og:title>
<og:image>https://cdn.arstechnica.net/wp-content/uploads/2019/01/MV5BMTc1Njk5ODQ4Ml5BMl5BanBnXkFtZTcwMTMwOTM0OQ@@._V1_SX1777_CR001777744_AL_-760x380.jpg</og:image>
<og:description>The Internet stopped another copyright extension without firing a shot.</og:description>
<og:type>article</og:type>
<dc:language>en-us</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://arstechnica.com/tech-policy/2019/01/a-whole-years-worth-of-works-just-fell-into-the-public-domain/</dc:identifier>
</item>
<item>
<title>New Horizons Reaches Ultima Thule</title>
<link>https://www.nytimes.com/interactive/2018/12/31/science/new-horizons-ultima-thule-flyby.html</link>
<guid isPermaLink="true" >https://www.nytimes.com/interactive/2018/12/31/science/new-horizons-ultima-thule-flyby.html</guid>
<description>&lt;p&gt;
&lt;h2&gt;&lt;span class=&quot;g-date-head&quot;&gt;Jan. 1&lt;/span&gt; Flyby&lt;/h2&gt;
&lt;/p&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;22.964705882353&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;New Horizons &lt;a href=&quot;https://www.nytimes.com/2018/12/31/science/new-horizons-ultima-thule.html&quot;&gt;zipped past Ultima Thule&lt;/a&gt; at 12:33 a.m. Eastern time on New Year’s Day.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;33&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;NASA received a confirmation signal from the spacecraft at 10:31 a.m. and expects to receive images from the flyby in coming days.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;35&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;A low-resolution image taken before the flyby gives more detail about the shape of Ultima Thule, which appears to be either a single object shaped like a bowling pin or two objects orbiting each other.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-graphic&quot;&gt;
&lt;div class=&quot;g-item-graphic&quot;&gt;
&lt;div id=&quot;g-shape-box&quot; class=&quot;ai2html ai2html-box-v5&quot;&gt;
&lt;div id=&quot;g-shape-300&quot; class=&quot;g-artboard&quot; data-aspect-ratio=&quot;1.603&quot; data-min-width=&quot;300&quot; data-max-width=&quot;599&quot;&gt;&lt;img id=&quot;g-shape-300-img&quot; class=&quot;g-aiImg g-aiAbs&quot; data-src=&quot;https://static01.nyt.com/newsgraphics/2018/12/31/new-horizons-ultima-thule/fa81be8357458729db23662d6b90a56e22ff7223/shape-300.jpg&quot; src=&quot;data:image/gif;base64,R0lGODlhCgAKAIAAAB8fHwAAACH5BAEAAAAALAAAAAAKAAoAAAIIhI+py+0PYysAOw==&quot;/&gt;
&lt;/div&gt;
&lt;div id=&quot;g-shape-600&quot; class=&quot;g-artboard&quot; data-aspect-ratio=&quot;1.736&quot; data-min-width=&quot;600&quot;&gt;&lt;img id=&quot;g-shape-600-img&quot; class=&quot;g-aiImg g-aiAbs&quot; data-src=&quot;https://static01.nyt.com/newsgraphics/2018/12/31/new-horizons-ultima-thule/fa81be8357458729db23662d6b90a56e22ff7223/shape-600.jpg&quot; src=&quot;data:image/gif;base64,R0lGODlhCgAKAIAAAB8fHwAAACH5BAEAAAAALAAAAAAKAAoAAAIIhI+py+0PYysAOw==&quot;/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;
&lt;h2&gt;&lt;span class=&quot;g-date-head&quot;&gt;Dec. 31&lt;/span&gt; Outward bound&lt;/h2&gt;
&lt;/p&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;34&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;Ultima Thule lies a billion miles beyond Pluto and is thought to be an undisturbed, primitive fragment of the early solar system.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-graphic&quot;&gt;
&lt;div class=&quot;g-item-graphic&quot;&gt;
&lt;div id=&quot;g-trajectory-box&quot; class=&quot;ai2html ai2html-box-v5&quot;&gt;
&lt;div id=&quot;g-trajectory-720&quot; class=&quot;g-artboard&quot; data-aspect-ratio=&quot;2.667&quot; data-min-width=&quot;720&quot;&gt;&lt;img id=&quot;g-trajectory-720-img&quot; class=&quot;g-aiImg g-aiAbs&quot; data-src=&quot;https://static01.nyt.com/newsgraphics/2018/12/31/new-horizons-ultima-thule/fa81be8357458729db23662d6b90a56e22ff7223/trajectory-720.png&quot; src=&quot;data:image/gif;base64,R0lGODlhCgAKAIAAAB8fHwAAACH5BAEAAAAALAAAAAAKAAoAAAIIhI+py+0PYysAOw==&quot;/&gt;



&lt;div id=&quot;g-ai0-5&quot; class=&quot;g-type g-aiAbs g-aiPointText&quot;&gt;
&lt;p class=&quot;g-pstyle2&quot;&gt;Pluto flyby in 2015&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;g-ai0-6&quot; class=&quot;g-type g-aiAbs g-aiPointText&quot;&gt;
&lt;p class=&quot;g-pstyle3&quot;&gt;Ultima Thule&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&quot;g-trajectory-450&quot; class=&quot;g-artboard&quot; data-aspect-ratio=&quot;1.667&quot; data-min-width=&quot;450&quot; data-max-width=&quot;599&quot;&gt;&lt;img id=&quot;g-trajectory-450-img&quot; class=&quot;g-aiImg g-aiAbs&quot; data-src=&quot;https://static01.nyt.com/newsgraphics/2018/12/31/new-horizons-ultima-thule/fa81be8357458729db23662d6b90a56e22ff7223/trajectory-450.png&quot; src=&quot;data:image/gif;base64,R0lGODlhCgAKAIAAAB8fHwAAACH5BAEAAAAALAAAAAAKAAoAAAIIhI+py+0PYysAOw==&quot;/&gt;



&lt;div id=&quot;g-ai1-5&quot; class=&quot;g-type_copy_3 g-aiAbs g-aiPointText&quot;&gt;
&lt;p class=&quot;g-pstyle1&quot;&gt;Pluto flyby in 2015&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;g-ai1-6&quot; class=&quot;g-type_copy_3 g-aiAbs g-aiPointText&quot;&gt;
&lt;p class=&quot;g-pstyle2&quot;&gt;Ultima Thule&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&quot;g-trajectory-300&quot; class=&quot;g-artboard&quot; data-aspect-ratio=&quot;1.2&quot; data-min-width=&quot;300&quot; data-max-width=&quot;449&quot;&gt;&lt;img id=&quot;g-trajectory-300-img&quot; class=&quot;g-aiImg g-aiAbs&quot; data-src=&quot;https://static01.nyt.com/newsgraphics/2018/12/31/new-horizons-ultima-thule/fa81be8357458729db23662d6b90a56e22ff7223/trajectory-300.png&quot; src=&quot;data:image/gif;base64,R0lGODlhCgAKAIAAAB8fHwAAACH5BAEAAAAALAAAAAAKAAoAAAIIhI+py+0PYysAOw==&quot;/&gt;

&lt;div id=&quot;g-ai2-3&quot; class=&quot;g-type_copy_2 g-aiAbs g-aiPointText&quot;&gt;
&lt;p class=&quot;g-pstyle1&quot;&gt;Pluto flyby in 2015&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;g-ai2-4&quot; class=&quot;g-type_copy_2 g-aiAbs g-aiPointText&quot;&gt;
&lt;p class=&quot;g-pstyle2&quot;&gt;Ultima Thule&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&quot;g-trajectory-600&quot; class=&quot;g-artboard&quot; data-aspect-ratio=&quot;2.222&quot; data-min-width=&quot;600&quot; data-max-width=&quot;719&quot;&gt;&lt;img id=&quot;g-trajectory-600-img&quot; class=&quot;g-aiImg g-aiAbs&quot; data-src=&quot;https://static01.nyt.com/newsgraphics/2018/12/31/new-horizons-ultima-thule/fa81be8357458729db23662d6b90a56e22ff7223/trajectory-600.png&quot; src=&quot;data:image/gif;base64,R0lGODlhCgAKAIAAAB8fHwAAACH5BAEAAAAALAAAAAAKAAoAAAIIhI+py+0PYysAOw==&quot;/&gt;



&lt;div id=&quot;g-ai3-5&quot; class=&quot;g-type_copy g-aiAbs g-aiPointText&quot;&gt;
&lt;p class=&quot;g-pstyle2&quot;&gt;Pluto flyby in 2015&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;g-ai3-6&quot; class=&quot;g-type_copy g-aiAbs g-aiPointText&quot;&gt;
&lt;p class=&quot;g-pstyle3&quot;&gt;Ultima Thule&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;
&lt;h2&gt;&lt;span class=&quot;g-date-head&quot;&gt;Dec. 30&lt;/span&gt; A crescent of light&lt;/h2&gt;
&lt;/p&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;34&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;An image taken by New Horizons from 1.2 million miles away suggests that Ultima Thule is about 20 miles wide and elongated, not round.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-graphic&quot;&gt;
&lt;div class=&quot;g-item-graphic&quot;&gt;
&lt;div id=&quot;g-elongated-box&quot; class=&quot;ai2html ai2html-box-v5&quot;&gt;
&lt;div id=&quot;g-elongated-300&quot; class=&quot;g-artboard&quot; data-aspect-ratio=&quot;2.015&quot; data-min-width=&quot;300&quot; data-max-width=&quot;599&quot;&gt;&lt;img id=&quot;g-elongated-300-img&quot; class=&quot;g-aiImg g-aiAbs&quot; data-src=&quot;https://static01.nyt.com/newsgraphics/2018/12/31/new-horizons-ultima-thule/fa81be8357458729db23662d6b90a56e22ff7223/elongated-300.jpg&quot; src=&quot;data:image/gif;base64,R0lGODlhCgAKAIAAAB8fHwAAACH5BAEAAAAALAAAAAAKAAoAAAIIhI+py+0PYysAOw==&quot;/&gt;
&lt;div id=&quot;g-ai0-2&quot; class=&quot;g-300 g-aiAbs g-aiPointText&quot;&gt;
&lt;p class=&quot;g-pstyle0&quot;&gt;Sharpened image&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&quot;g-elongated-600&quot; class=&quot;g-artboard&quot; data-aspect-ratio=&quot;2.018&quot; data-min-width=&quot;600&quot;&gt;&lt;img id=&quot;g-elongated-600-img&quot; class=&quot;g-aiImg g-aiAbs&quot; data-src=&quot;https://static01.nyt.com/newsgraphics/2018/12/31/new-horizons-ultima-thule/fa81be8357458729db23662d6b90a56e22ff7223/elongated-600.jpg&quot; src=&quot;data:image/gif;base64,R0lGODlhCgAKAIAAAB8fHwAAACH5BAEAAAAALAAAAAAKAAoAAAIIhI+py+0PYysAOw==&quot;/&gt;
&lt;div id=&quot;g-ai1-2&quot; class=&quot;g-600 g-aiAbs g-aiPointText&quot;&gt;
&lt;p class=&quot;g-pstyle0&quot;&gt;Sharpened image&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;
&lt;h2&gt;&lt;span class=&quot;g-date-head&quot;&gt;Dec. 24&lt;/span&gt; A world among the pixels&lt;/h2&gt;
&lt;/p&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;34&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;On Christmas Eve, New Horizons’ long-range camera caught sight of Ultima Thule from a distance of 6.3 million miles.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-image&quot;&gt;
&lt;div class=&quot;g-item-image&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://static01.nyt.com/packages/flash/multimedia/ICONS/transparent.png&quot; class=&quot;g-freebird-lazy&quot; data-pattern=&quot;https://static01.nyt.com/newsgraphics/2018/12/31/new-horizons-ultima-thule/assets/images/181224-ultima-thule-1x1-{{size}}.jpg&quot; data-widths=&quot;[320,640,720,940,1050]&quot; data-ratio=&quot;1&quot;/&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;
&lt;h2&gt;&lt;span class=&quot;g-date-head&quot;&gt;Dec. 17&lt;/span&gt; X marks the flyby&lt;/h2&gt;
&lt;/p&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;35&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;Images of Ultima Thule reveal no rings or other surrounding debris, so New Horizons will make a relatively close approach of about 2,200 miles. The spacecraft is aiming for the white X in this image.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-image&quot;&gt;
&lt;div class=&quot;g-item-image&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://static01.nyt.com/packages/flash/multimedia/ICONS/transparent.png&quot; class=&quot;g-freebird-lazy&quot; data-pattern=&quot;https://static01.nyt.com/newsgraphics/2018/12/31/new-horizons-ultima-thule/assets/images/181217-LORRI-Search-{{size}}.jpg&quot; data-widths=&quot;[320,640,720,940,1050]&quot; data-ratio=&quot;0.9060150375939849&quot;/&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;
&lt;h2&gt;&lt;span class=&quot;g-date-head&quot;&gt;Aug. 16&lt;/span&gt; First glimpse of Ultima Thule&lt;/h2&gt;
&lt;/p&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;35&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;New Horizons took its first image of Ultima Thule, from a distance of 107 million miles. The object is easier to see in the image at right, where background stars have been obscured.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-image&quot;&gt;
&lt;div class=&quot;g-item-image&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://static01.nyt.com/packages/flash/multimedia/ICONS/transparent.png&quot; class=&quot;g-freebird-lazy&quot; data-pattern=&quot;https://static01.nyt.com/newsgraphics/2018/12/31/new-horizons-ultima-thule/assets/images/180816-first-detection-{{size}}.jpg&quot; data-widths=&quot;[320,640,720,940,1050]&quot; data-ratio=&quot;0.5&quot;/&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;
&lt;h2&gt;&lt;span class=&quot;g-date-head&quot;&gt;March&lt;/span&gt; MU69 gets a nickname&lt;/h2&gt;
&lt;/p&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;33&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;After suggestions from the public, the New Horizons team gave 2014 MU69 a nickname: Ultima Thule.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;33&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;The name’s direct translation is “beyond Thule” and evokes distant places beyond the edges of the known world.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;34&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;The mythical island of Thule — labeled “TILE” — appears near the Faroe Islands in the Carta Marina, a map of the Nordic world from 1539.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-image&quot; readability=&quot;6&quot;&gt;
&lt;div class=&quot;g-item-image&quot; readability=&quot;7&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://static01.nyt.com/packages/flash/multimedia/ICONS/transparent.png&quot; class=&quot;g-freebird-lazy&quot; data-pattern=&quot;https://static01.nyt.com/newsgraphics/2018/12/31/new-horizons-ultima-thule/assets/images/carta-marina-faroe-{{size}}.jpg&quot; data-widths=&quot;[320,640,720,940,1050]&quot; data-ratio=&quot;0.655793991416309&quot;/&gt;&lt;p&gt;&lt;span class=&quot;g-credit&quot;&gt;Plymouth Marine Laboratory&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;
&lt;h2&gt;&lt;span class=&quot;g-date-head&quot;&gt;Dec. 2017&lt;/span&gt; A distance record&lt;/h2&gt;
&lt;/p&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;33&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;New Horizons sets a new record for the farthest images ever taken by a spacecraft. The probe was about 3.79 billion miles from Earth when it photographed the Wishing Well star cluster.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-image&quot;&gt;
&lt;div class=&quot;g-item-image&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://static01.nyt.com/packages/flash/multimedia/ICONS/transparent.png&quot; class=&quot;g-freebird-lazy&quot; data-pattern=&quot;https://static01.nyt.com/newsgraphics/2018/12/31/new-horizons-ultima-thule/assets/images/171205-wishing-well-{{size}}.jpg&quot; data-widths=&quot;[320,640,720,940,1050]&quot; data-ratio=&quot;1&quot;/&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;34&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;The record was previously held by Voyager 1’s mosaic of the solar system, which includes the famous “Pale Blue Dot” image of Earth.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-image&quot; readability=&quot;7&quot;&gt;
&lt;div class=&quot;g-item-image&quot; readability=&quot;9&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://static01.nyt.com/packages/flash/multimedia/ICONS/transparent.png&quot; class=&quot;g-freebird-lazy&quot; data-pattern=&quot;https://static01.nyt.com/newsgraphics/2018/12/31/new-horizons-ultima-thule/assets/images/900214-PIA00451-Voyager-family-portrait-{{size}}.jpg&quot; data-widths=&quot;[320,640,720,940,1050]&quot; data-ratio=&quot;0.3&quot;/&gt;&lt;p&gt;&lt;span class=&quot;g-caption&quot;&gt;Voyager 1’s mosaic of the solar system, taken on Valentine’s Day, 1990.&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;33&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;For more about Voyager and the Pale Blue Dot, watch the short documentary below:&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;
&lt;h2&gt;&lt;span class=&quot;g-date-head&quot;&gt;July 2017&lt;/span&gt; The shadow of MU69&lt;/h2&gt;
&lt;/p&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;35&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;After several attempts to observe MU69 crossing in front of a star, the New Horizons team finally observed it briefly blocking the light of a distant, unnamed star.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-image&quot;&gt;
&lt;div class=&quot;g-item-image&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://static01.nyt.com/packages/flash/multimedia/ICONS/transparent.png&quot; class=&quot;g-freebird-lazy&quot; data-src=&quot;https://static01.nyt.com/newsgraphics/2018/12/31/new-horizons-ultima-thule/fa81be8357458729db23662d6b90a56e22ff7223/170717-wink.gif&quot;/&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;35&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;By comparing the object’s shadow from different telescopes, the team estimated that MU69 is not round. It might be elongated or barbell-shaped, or possibly two objects orbiting each other closely.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-image&quot;&gt;
&lt;div class=&quot;g-item-image&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://static01.nyt.com/packages/flash/multimedia/ICONS/transparent.png&quot; class=&quot;g-freebird-lazy&quot; data-pattern=&quot;https://static01.nyt.com/newsgraphics/2018/12/31/new-horizons-ultima-thule/assets/images/170717-occultation-sketch-{{size}}.jpg&quot; data-widths=&quot;[320,640,720,940,1050]&quot; data-ratio=&quot;0.8421428571428572&quot;/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;
&lt;h2&gt;&lt;span class=&quot;g-date-head&quot;&gt;June 2014&lt;/span&gt; Hubble finds a target&lt;/h2&gt;
&lt;/p&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;33&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;MU69 is part of the Kuiper Belt, a wide band of rubble beyond the orbit of Neptune.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-video&quot;&gt;
&lt;div class=&quot;g-item-video&quot;&gt;

&lt;div class=&quot;g-asset-source&quot;&gt;&lt;span class=&quot;g-caption&quot;&gt;An orange dot shows MU69’s location in the Kuiper Belt.&lt;/span&gt; &lt;span class=&quot;g-credit&quot;&gt;Animation by &lt;a href=&quot;https://twitter.com/alex_parker/status/1078019177200476162&quot;&gt;Alex Parker&lt;/a&gt;&lt;/span&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;35&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;After years of searching the Kuiper Belt with ground-based telescopes, the New Horizons team turned to the Hubble Space Telescope, which discovered a promising object in 2014.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-image&quot; readability=&quot;6&quot;&gt;
&lt;div class=&quot;g-item-image&quot; readability=&quot;7&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://static01.nyt.com/packages/flash/multimedia/ICONS/transparent.png&quot; class=&quot;g-freebird-lazy&quot; data-pattern=&quot;https://static01.nyt.com/newsgraphics/2018/12/31/new-horizons-ultima-thule/assets/images/140601-KBO-{{size}}.jpg&quot; data-widths=&quot;[320,640,720,940,1050]&quot; data-ratio=&quot;0.9433962264150944&quot;/&gt;&lt;p&gt;&lt;span class=&quot;g-caption&quot;&gt;The Kuiper Belt object formally known as (486958) 2014 MU69.&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;
&lt;h2&gt;&lt;span class=&quot;g-date-head&quot;&gt;July 14, 2015&lt;/span&gt; Pluto revealed&lt;/h2&gt;
&lt;/p&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;17.852631578947&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;New Horizons &lt;a href=&quot;https://www.nytimes.com/interactive/2015/07/14/science/space/pluto-flyby.html&quot;&gt;zipped past Pluto&lt;/a&gt; and returned images of a surprisingly &lt;a href=&quot;https://www.nytimes.com/interactive/2015/07/15/science/space/new-horizons-pluto-flyby-photos.html&quot;&gt;dynamic and complex world&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-image&quot;&gt;
&lt;div class=&quot;g-item-image&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://static01.nyt.com/packages/flash/multimedia/ICONS/transparent.png&quot; class=&quot;g-freebird-lazy&quot; data-pattern=&quot;https://static01.nyt.com/newsgraphics/2018/12/31/new-horizons-ultima-thule/assets/images/150714-pluto-{{size}}.jpg&quot; data-widths=&quot;[320,640,720,940,1050]&quot; data-ratio=&quot;1&quot;/&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;22.30303030303&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;Experience a simulated flyby and stand on Pluto in virtual reality: &lt;a href=&quot;https://www.nytimes.com/video/science/100000004657443/seeking-plutos-frigid-heart.html&quot;&gt;Seeking Pluto’s Frigid Heart&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;
&lt;h2&gt;&lt;span class=&quot;g-date-head&quot;&gt;Before 2015&lt;/span&gt; Unknown worlds&lt;/h2&gt;
&lt;/p&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;35&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;Before New Horizons, humanity had only fuzzy images of Pluto and its moon Charon, and had little idea of what to expect from the flyby.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;27.654929577465&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;Learn more about how New Horizons was poised to change our understanding of the outer solar system in the documentary &lt;a href=&quot;https://www.nytimes.com/video/science/100000003783764/fast-and-light-to-pluto.html&quot;&gt;Fast and Light to Pluto&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;


&lt;div class=&quot;g-item g-text&quot; readability=&quot;8.4597701149425&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;&lt;span class=&quot;g-sync&quot;&gt;Subscribe to the &lt;a href=&quot;http://nyti.ms/1MbHaRU&quot;&gt;Science Times newsletter&lt;/a&gt; and &lt;a href=&quot;http://nyti.ms/2A875EL&quot;&gt;sync your calendar with the solar system&lt;/a&gt;.&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;g-item g-text&quot; readability=&quot;35&quot;&gt;
&lt;p class=&quot;g-body&quot;&gt;&lt;span class=&quot;g-sync&quot;&gt;Images by NASA, Johns Hopkins Applied Physics Laboratory and Southwest Research Institute, except where noted.&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
<pubDate>Tue, 01 Jan 2019 15:41:08 +0000</pubDate>
<dc:creator>daegloe</dc:creator>
<og:url>https://www.nytimes.com/interactive/2018/12/31/science/new-horizons-ultima-thule-flyby.html</og:url>
<og:type>article</og:type>
<og:title>New Horizons Reaches Ultima Thule</og:title>
<og:image>https://static01.nyt.com/images/2019/01/01/science/new-horizons-ultima-thule-mu69-flyby-1546292568420/new-horizons-ultima-thule-mu69-flyby-1546292568420-facebookJumbo-v3.jpg</og:image>
<og:description>NASA’s New Horizons spacecraft flew past the most distant object ever visited.</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.nytimes.com/interactive/2018/12/31/science/new-horizons-ultima-thule-flyby.html</dc:identifier>
</item>
<item>
<title>Pathfinding for Tower Defense</title>
<link>https://www.redblobgames.com/pathfinding/tower-defense/</link>
<guid isPermaLink="true" >https://www.redblobgames.com/pathfinding/tower-defense/</guid>
<description>&lt;p&gt;In a Tower Defense game, there are many enemies that are all headed to the same place. In many Tower Defense games, there is a predetermined path, or a small number of paths. In some, such as the classic &lt;a href=&quot;http://armorgames.com/play/1128/desktop-tower-defense-15&quot;&gt;Desktop Tower Defense&lt;/a&gt;&lt;sup class=&quot;print-endnote&quot;&gt;[1]&lt;/sup&gt;, you can place towers anywhere, and they act as obstacles that affect the paths taken by enemies. &lt;strong&gt;Try it out&lt;/strong&gt;, and &lt;strong&gt;click on the map&lt;/strong&gt; to toggle walls:&lt;/p&gt;&lt;p&gt;To solve this problem we need either a &lt;em&gt;vector field&lt;/em&gt; (also called a flow field) or a &lt;em&gt;distance field&lt;/em&gt; (also called a Dijkstra Map). Enemies will move in the direction that gets them closer to the player:&lt;/p&gt;
&lt;p&gt;How would we implement this?&lt;/p&gt;
&lt;p&gt;Graph search algorithms like A* are often used to find the shortest path from one point to another point. You can use this for each enemy to find a path to the goal. There are lots of different graph search algorithms we could use in this type of game. These are the classics:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;strong&gt;One source, one destination&lt;/strong&gt;:
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;One source, all destinations&lt;/strong&gt;, or &lt;strong&gt;all sources, one destination&lt;/strong&gt;:
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;All sources, all destinations&lt;/strong&gt;:
&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;A game like Desktop Tower Defense has lots of enemy positions (sources) and one destination for all of them. This puts it into the &lt;strong&gt;all sources, one destination&lt;/strong&gt; category. Instead of running A* once per enemy, we can run an algorithm once, and it will calculate the path for all enemies. Even better, it will calculate the shortest path from every location, so as enemies get jostled around or new enemies created, their paths have already been computed. This is sometimes called a &lt;strong&gt;flow field&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Let’s explore &lt;strong&gt;Breadth First Search&lt;/strong&gt;, which is sometimes called “flood fill” (FIFO variant). Although graph search works on any &lt;a href=&quot;http://en.wikipedia.org/wiki/Graph_(mathematics)&quot;&gt;node-and-edge graph&lt;/a&gt;&lt;sup class=&quot;print-endnote&quot;&gt;[9]&lt;/sup&gt;, I’m using a square grid for these examples. Grids are a special case of graphs. &lt;a href=&quot;https://www.redblobgames.com/pathfinding/grids/graphs.html&quot;&gt;Each grid tile is a graph node, and the borders between grid tiles are the graph edges&lt;/a&gt;. I’ll explore non-grid graphs in &lt;a href=&quot;https://www.redblobgames.com/pathfinding/grids/algorithms.html&quot;&gt;another article&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Breadth First Search starts with one node and repeatedly visits neighbors. The key concept is a “frontier”, the boundary between the explored and unexplored areas. The frontier expands outwards from the original node until it has explored the entire graph.&lt;/p&gt;
&lt;p&gt;The &lt;strong class=&quot;frontier&quot;&gt;frontier&lt;/strong&gt; queue is the frontier: a list/array of graph nodes (grid tiles) that need to be analyzed. It starts out containing only a single element, the &lt;strong class=&quot;start&quot;&gt;start&lt;/strong&gt; node. The &lt;strong class=&quot;visited&quot;&gt;visited&lt;/strong&gt; flag on each node keeps track of whether we’ve seen it yet. It starts out as False everywhere except at the &lt;span class=&quot;start&quot;&gt;start&lt;/span&gt; node. &lt;strong&gt;Use the slider&lt;/strong&gt; to see how the frontier expands:&lt;/p&gt;
&lt;p&gt;How does the algorithm work? At every step, take a single element out of &lt;span class=&quot;frontier&quot;&gt;frontier&lt;/span&gt; and call it &lt;strong class=&quot;current&quot;&gt;current&lt;/strong&gt;. Then look for each of &lt;span class=&quot;current&quot;&gt;current&lt;/span&gt;’s neighbors, &lt;strong class=&quot;next&quot;&gt;next&lt;/strong&gt;. Add them to the &lt;span class=&quot;frontier&quot;&gt;frontier&lt;/span&gt; queue if they haven’t been &lt;span class=&quot;visited&quot;&gt;visited&lt;/span&gt; before. Here’s some Python code:&lt;/p&gt;
&lt;pre&gt;
frontier = Queue()
frontier.put(start)
visited = {}
visited[start] = True

while not frontier.empty():
   current = frontier.get()
   for next in graph.neighbors(current):
      if next not in visited:
         frontier.put(next)
         visited[next] = True
&lt;/pre&gt;
&lt;p&gt;Now that you’ve seen the code, &lt;strong&gt;try stepping through the animation&lt;/strong&gt; above. Pay attention to the &lt;span class=&quot;frontier&quot;&gt;frontier&lt;/span&gt; queue, the &lt;span class=&quot;current&quot;&gt;current&lt;/span&gt; node, and the set of &lt;span class=&quot;next&quot;&gt;next&lt;/span&gt; nodes. At each step, an element of the frontier becomes the current node, the neighbors are marked, and any unvisited neighbors get added to the frontier. Some neighbors will have been visited already so they don’t need to be added into the frontier.&lt;/p&gt;
&lt;p&gt;It’s a relatively simple algorithm, and useful for all sorts of things, &lt;a href=&quot;http://www.roguebasin.com/index.php?title=Dijkstra_Maps_Visualized&quot;&gt;including game AI&lt;/a&gt;&lt;sup class=&quot;print-endnote&quot;&gt;[10]&lt;/sup&gt;. There are three main ways I use it:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;strong&gt;Mark&lt;/strong&gt; all reachable nodes. This is useful if your map isn’t completely connected, and you want to know what’s reachable. That’s what we did above, with the &lt;strong class=&quot;visited&quot;&gt;visited&lt;/strong&gt; field.&lt;/li&gt;
&lt;li&gt;Find &lt;strong&gt;paths&lt;/strong&gt; from one node to all other nodes, or from all nodes to one node. This is what I used for the animated demo at the top of the page.&lt;/li&gt;
&lt;li&gt;Measure &lt;strong&gt;distances&lt;/strong&gt; from one node to all other nodes. This is useful to know what’s in a given walking distance of a monster.&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;If you are generating paths, you will want to know which direction to move from every node. When you visit a neighbor, remember where you came from. Let’s rename the &lt;span class=&quot;visited&quot;&gt;visited&lt;/span&gt; table to &lt;span class=&quot;came_from&quot;&gt;came_from&lt;/span&gt; and use it to keep track of the previous location:&lt;/p&gt;
&lt;pre&gt;
frontier = Queue()
frontier.put(start)
&lt;em&gt;came_from&lt;/em&gt; = {}
&lt;em&gt;came_from&lt;/em&gt;[start] = &lt;em&gt;None&lt;/em&gt;

while not frontier.empty():
   current = frontier.get()
   for next in graph.neighbors(current):
      if next not in &lt;em&gt;came_from&lt;/em&gt;:
         frontier.put(next)
         &lt;em&gt;came_from&lt;/em&gt;[next] = &lt;em&gt;current&lt;/em&gt;
&lt;/pre&gt;
&lt;p&gt;Let’s see what this vector field looks like:&lt;/p&gt;

&lt;p&gt;If you need distances, you can start with a counter set to 0 at the start node, and increment it each time you visit a neighbor. Let rename the &lt;span class=&quot;visited&quot;&gt;visited&lt;/span&gt; table into &lt;span class=&quot;distance&quot;&gt;distance&lt;/span&gt; and use it to keep a counter:&lt;/p&gt;
&lt;pre&gt;
frontier = Queue()
frontier.put(start)
&lt;em&gt;distance&lt;/em&gt; = {}
&lt;em&gt;distance&lt;/em&gt;[start] = &lt;em&gt;0&lt;/em&gt;

while not frontier.empty():
   current = frontier.get()
   for next in graph.neighbors(current):
      if next not in &lt;em&gt;distance&lt;/em&gt;:
         frontier.put(next)
         &lt;em&gt;distance&lt;/em&gt;[next] = &lt;em&gt;1 + distance[current]&lt;/em&gt;
&lt;/pre&gt;
&lt;p&gt;Let’s see what this distance field looks like:&lt;/p&gt;
&lt;p&gt;You can have both variables if you want to compute both paths and distances. The two are related. The vector field (“flow field”) is the negative &lt;a href=&quot;https://en.wikipedia.org/wiki/Gradient&quot;&gt;gradient&lt;/a&gt;&lt;sup class=&quot;print-endnote&quot;&gt;[11]&lt;/sup&gt; (∇) of the distance field (“Dijkstra Map”), and you can calculate the vector by looking at which direction makes the distance decrease.&lt;/p&gt;
&lt;p&gt;So that’s Breadth First Search. For Tower Defense style games, I’ve used it to find paths from all locations to a given location, instead of using A* repeatedly to separately find a path for enemy. I’ve used it to to find all locations within a certain walking distance of a monster. I’ve also used it for procedural map generation. Minecraft &lt;a href=&quot;http://tomcc.github.io/2014/08/31/visibility-1.html&quot;&gt;uses it for visibility culling&lt;/a&gt;&lt;sup class=&quot;print-endnote&quot;&gt;[12]&lt;/sup&gt;. For flow field pathfinding, where units aren’t in the center of a grid cell, you can &lt;em&gt;interpolate&lt;/em&gt; the flow arrows in each cell. Breadth First Search is a nice algorithm to know.&lt;/p&gt;
&lt;p&gt;Next steps:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;I have &lt;a href=&quot;https://www.redblobgames.com/pathfinding/a-star/implementation.html&quot;&gt;implementation notes&lt;/a&gt; with Python and C++ code.&lt;/li&gt;
&lt;li&gt;If you want paths &lt;em&gt;from&lt;/em&gt; a single location instead of &lt;em&gt;to&lt;/em&gt; a single location, reverse the &lt;code&gt;came_from&lt;/code&gt; pointers when following paths.&lt;/li&gt;
&lt;li&gt;If you want paths to one of &lt;em&gt;several&lt;/em&gt; locations instead of a single location, you can add edges to your graphs from each of your destinations to an extra destination node. The extra node won’t show up on the grid, but in the graph it will represent the destination. I have some examples of this &lt;a href=&quot;https://www.redblobgames.com/pathfinding/distance-to-any/&quot;&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Early exit: if you’re looking for a path to/from a single location, you can stop searching as soon as you find that location. I describe this in &lt;a href=&quot;https://www.redblobgames.com/pathfinding/a-star/introduction.html&quot;&gt;the A* article&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Weighted edges: if you need varying movement costs, Breadth First Search becomes Dijkstra’s Algorithm. I describe this in &lt;a href=&quot;https://www.redblobgames.com/pathfinding/a-star/introduction.html&quot;&gt;the A* article&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Heuristic: if you add a way to guide the search towards the goal, &lt;em&gt;Breath&lt;/em&gt; First Search becomes &lt;em&gt;Best&lt;/em&gt; First Search. I describe this in &lt;a href=&quot;https://www.redblobgames.com/pathfinding/a-star/introduction.html&quot;&gt;the A* article&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;If you start with Breadth First Search and &lt;strong&gt;add early exit, weighted edges, and a heuristic, you get A*&lt;/strong&gt;. As you might guess, I describe this in &lt;a href=&quot;https://www.redblobgames.com/pathfinding/a-star/introduction.html&quot;&gt;the A* article&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;</description>
<pubDate>Tue, 01 Jan 2019 15:13:26 +0000</pubDate>
<dc:creator>ingve</dc:creator>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.redblobgames.com/pathfinding/tower-defense/</dc:identifier>
</item>
<item>
<title>The old guard of Mac indy apps has thrived for more than 25 years</title>
<link>https://www.macworld.com/article/3327502/macs/mac-indy-apps-thrived-for-more-than-25-years.html</link>
<guid isPermaLink="true" >https://www.macworld.com/article/3327502/macs/mac-indy-apps-thrived-for-more-than-25-years.html</guid>
<description>&lt;p&gt;It seems like it was only yesterday that I first used BareBones Software’s &lt;a href=&quot;http://www.barebones.com/products/bbedit/index.html&quot; rel=&quot;nofollow&quot;&gt;BBEdit&lt;/a&gt;, but in actuality, yesterday is so far away—25 years, in fact. With all the twists and turns across more than two decades of Apple as a company, Mac hardware, and the underlying operating system, you might think that BBEdit stands alone as a continuously-developed app shepherded largely or exclusively by the same independent developer—an app without a giant company behind it. As it turns out, BBEdit is one of several apps that’s been around the block more than a few times.&lt;/p&gt;
&lt;p&gt;The longevity of indie apps is more extraordinary when you consider the changes Apple put the Mac through from the early 1990s to 2018. Apple switched from Motorola 680x0 processors to PowerPC to Intel chips, from 32-bit to 64-bit code, and among supported coding languages. It revved System 7 to 8 to 9, then to Unix across now 15 major releases (from 10.0 to 10.14). That’s a lot for any individual programmer or small company to cope with.&lt;/p&gt;
&lt;p&gt;Bare Bones’s head honcho, Rich Siegel, and the developers behind three other long-running Mac software programs shared with me their insight on development histories for over 25 years, what’s changed the most during that time, and any hidden treasures users haven’t yet found.&lt;/p&gt;
&lt;h2 class=&quot;toc&quot; id=&quot;toc-1&quot;&gt;BBEdit: More than a text editor&lt;/h2&gt;
&lt;p&gt;BBEdit emerged first as something more like a demo of a text editor in 1989, then developed into a feature-complete but free app in 1992. Bare Bones released it as a fully-supported commercial program with version 2.5 on May 11, 1993, and it’s from that date they count its anniversary, despite its bragging rights for a longer vintage. Founder Rich Siegel continues to drive development today from Rhode Island.&lt;/p&gt;
&lt;img src=&quot;https://images.idgesg.net/images/article/2018/12/bbedit12-mac-icon-100783214-medium.jpg&quot; border=&quot;0&quot; alt=&quot;bbedit12 mac icon&quot; width=&quot;300&quot; height=&quot;200&quot; data-imageid=&quot;100783214&quot;/&gt;&lt;small class=&quot;credit&quot;&gt;Bare Bones Software&lt;/small&gt;
&lt;p&gt;“We’ve extensively rewritten, upgraded, and optimized [BBEdit’s] internal architecture,” said Siegel. But the program continues to scratch the same itch it did at its start. “Even though it has evolved a great deal, BBEdit has stayed very close to its fundamental mission: empowering its users to accomplish tasks which would challenge or defeat other tools.”&lt;/p&gt;
&lt;p&gt;BBEdit has added many features over the years, including clever and highly configurable auto-completion, website management, and multi-file search. While it began life as a coding tool, it now offers a minimalist environment with powerful search-and-replace and text-shuffling tools that appeals to programmers, writers (I spent hours in it daily), HTML coders, and people who have to massage text from one shape into another.&lt;/p&gt;
&lt;p&gt;Siegel said one of the most unusual features BBEdit incorporated was built-in FTP and SFTP editing. Before it was integrated, BBEdit could work with file-transfer software like Fetch (see below) in a kind of round-trip arrangement. Siegel said a customer created a plug-in, and Bare Bones adopted his code and incorporated it.&lt;/p&gt;
&lt;p&gt;But Siegel said what he would never have imagined adding is a “&lt;a href=&quot;http://www.openculture.com/2015/03/the-story-of-lorem-ipsum.html&quot; rel=&quot;nofollow&quot;&gt;lorem ipsum&lt;/a&gt;” generator, which appeared in the recent 12.5 release. This generates placeholder text, and the option dates back decades in page-layout software. “There’s been a remarkable level of interest in that feature,” he said.&lt;/p&gt;
&lt;aside class=&quot;nativo-promo nativo-promo-1 smartphone tablet desktop&quot; id=&quot;&quot;/&gt;&lt;img src=&quot;https://images.idgesg.net/images/article/2018/12/veteran-mac-app-bbedit-100782761-large.jpg&quot; border=&quot;0&quot; alt=&quot;veteran mac app bbedit&quot; width=&quot;700&quot; height=&quot;320&quot; data-imageid=&quot;100782761&quot; data-license=&quot;IDG&quot;/&gt;&lt;small class=&quot;credit&quot;&gt;IDG&lt;/small&gt;
&lt;p&gt;Did somebody say “bacon filler text”? BBEdit obliges in version 12.5.&lt;/p&gt;
&lt;p&gt;After nearly 30 years of development, Siegel said he’s still motivated to improve BBEdit because of customer feedback. “They’re the ones we’re here to serve, and so when someone writes in and expresses a need that we can address directly, we’re motivated to make that change,” he said. (I can testify from personal experience: I’ve asked for a lot of features over the years, and some made sense for the company to add.)&lt;/p&gt;
&lt;p&gt;Bare Bones’s workload has grown and shrunk over the decades. At one point, the company sold and supported five apps, but currently it keeps its focus on BBEdit. “We’re constantly seeking to balance new feature development for major upgrades, maintenance work to fix issues that immediately affect our customers, and internal modernizations to support platform evolution,” Siegel said.&lt;/p&gt;
&lt;p&gt;The most important question, however, is what Easter eggs remain largely undiscovered, even by long-term users:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The one in the About box is a perennial favorite, but a remarkable number of folks don’t scroll down far enough to see it. (Or perhaps they’ve noticed it but assumed it was someone else.) There’s also one that shows up on April first, if you happen to be using one of the core non-editing features of BBEdit.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Bare Bones celebrated BBEdit’s 25th anniversary with some new “merch.” Faithful coders and writers &lt;a href=&quot;https://merch.barebones.com/&quot; rel=&quot;nofollow&quot;&gt;can purchase branded T-shirts&lt;/a&gt;, enamel pins, and more, some of which bear the app’s long-running slogan, “It still doesn’t suck.”&lt;/p&gt;
&lt;aside class=&quot;nativo-promo nativo-promo-2 tablet desktop smartphone&quot; id=&quot;&quot;/&gt;&lt;h2 class=&quot;toc&quot; id=&quot;toc-2&quot;&gt;PCalc: The programmer’s calculator&lt;/h2&gt;
&lt;p&gt;James Thomson was a student at Glasgow University in 1992 when he decided to use principles learned in a human computer interaction class to test out his programming skills. He coded a more advanced calculator than the one shipping with Apple’s System 7. With binary and hexadecimal calculations useful for his programming work, he dubbed it &lt;a href=&quot;https://www.pcalc.com/&quot; rel=&quot;nofollow&quot;&gt;PCalc&lt;/a&gt;, short for “programmer’s calculator.”&lt;/p&gt;
&lt;img src=&quot;https://images.idgesg.net/images/article/2018/08/pcalc-mac-icon-2018-100770252-medium.jpg&quot; border=&quot;0&quot; alt=&quot;pcalc mac icon 2018&quot; width=&quot;300&quot; height=&quot;200&quot; data-imageid=&quot;100770252&quot;/&gt;&lt;small class=&quot;credit&quot;&gt;TLA Systems&lt;/small&gt;
&lt;p&gt;He released it as a free program on December 23, 1992, but didn’t charge for it while he was working a stint for Apple in the 1990s. In 2000, he released the first commercial version, and it was briefly licensed by Apple to include on some iMacs in the early 2000s. PCalc for iOS appeared along with a few hundred other apps in 2008 the day that Apple opened its third-party App Store.&lt;/p&gt;
&lt;p&gt;PCalc largely works the same as in its early days, providing a full-featured equivalent of a variety of calculator types, including scientific calculators. It offers some programmable functions, but stops short of simulating a graphing calculator like a TI-84. Nonetheless, Thomson has routinely had to update its interface to match changing Apple aesthetics, and revamped the app’s innards as Apple created a core engine for math that’s consistent across all four of its hardware platforms—macOS, iOS, watchOS, and tvOS. (Yup, there’s a PCalc for Apple TV.)&lt;/p&gt;
&lt;p&gt;At the center, though, lies code written in 1992, and translated from its original programming language (“like V’ger from &lt;em&gt;Star Trek The Motion Picture&lt;/em&gt;,” said Thomson). “Something new comes along from Apple, and yet another bird is added to the PCalc &lt;a href=&quot;https://en.wikipedia.org/wiki/Turducken&quot; rel=&quot;nofollow&quot;&gt;turducken&lt;/a&gt;” of software development, he said.&lt;/p&gt;
&lt;p&gt;Thomson noted that the iOS and Watch interactions mark the biggest change in development. “PCalc has always been an ‘emulation’ of a physical calculator. You use a mouse or type on a keyboard to press the buttons,” he said. “Now, with iOS, you’re tapping directly on the buttons and it has become a physical calculator all by itself, one that fits in your pocket. As the old saying goes, the best calculator is the one that’s with you.”&lt;/p&gt;
&lt;p&gt;PCalc always had a layout editor that Thomson relied on to produce new calculator types, and he ultimately opened this up to users, too. The app added custom conversions—useful if you’re a type geek like me, and may need pica to points and points to inches—as well as supporting Siri Shortcuts in the latest iOS.&lt;/p&gt;
&lt;p&gt;With core functionality relatively fixed—math doesn’t change over time, fortunately—Thomson has devoted efforts to make PCalc more customizable and more fun across multiple platforms. The About screen of macOS and iOS includes a banana physics simulator and a racing game. And those aren’t even Easter eggs. He’s also developed iMessage stickers using a panda motif that he adopted for PCalc along the way.&lt;/p&gt;
&lt;img src=&quot;https://images.idgesg.net/images/article/2018/12/veteran-mac-app-pcalc-100782764-large.jpg&quot; border=&quot;0&quot; alt=&quot;veteran mac app pcalc&quot; width=&quot;700&quot; height=&quot;541&quot; data-imageid=&quot;100782764&quot; data-license=&quot;IDG&quot;/&gt;&lt;small class=&quot;credit&quot;&gt;IDG&lt;/small&gt;
&lt;p&gt;And why shouldn’t a calculator app feature a physics simulator and a racing game in its About box?&lt;/p&gt;
&lt;p&gt;Thomson and his wife, Saskia, work full-time in Scotland on PCalc, the sole product of his company, TLA Systems, and he said that’s a motivating factor in continuing its development. (They also sell &lt;a href=&quot;https://cottonbureau.com/people/tla-systems&quot; rel=&quot;nofollow&quot;&gt;PCalc merch&lt;/a&gt;, however.)&lt;/p&gt;
&lt;p&gt;“I do actually enjoy working on it and making something that people equally enjoy using,” said Thomson, “And it’s a process of constant learning, every day I learn something new.” He’s got no plans to retire the app (or himself) any time soon. “My passion since I first discovered the Mac nearly 30 years ago has always been making interesting and fun user interfaces. And look forward to keep doing it for a long time to come”, he said.&lt;/p&gt;
&lt;p&gt;While the Mac version of PCalc lacks unexplored Easter eggs, he did offer this hint in iOS: “Most people probably haven’t even found Level 2 of the About screen—for that, turn the truck around and look for the golden banana. I’ve said too much already!”&lt;/p&gt;
&lt;h2 class=&quot;toc&quot; id=&quot;toc-3&quot;&gt;Fetch: A &lt;em&gt;Who Wants To Be a Millionaire&lt;/em&gt; prize&lt;/h2&gt;
&lt;p&gt;Jim Matthews, the creator of the file-transfer program &lt;a href=&quot;https://fetchsoftworks.com&quot; rel=&quot;nofollow&quot;&gt;Fetch&lt;/a&gt;, made the right decision in 2000 when &lt;a href=&quot;https://youtu.be/8rMvtx_J5D0?t=1451&quot; rel=&quot;nofollow&quot;&gt;asked by Regis Philbin&lt;/a&gt; whether he could answer the top-yielding question in &lt;em&gt;Who Wants To Be a Millionaire?&lt;/em&gt;. First, he used his audience lifeline. Then, he opted to pass, and walk home with $500,000. That was good, because the audience majority was wrong and Matthews didn’t know the correct response. (&lt;a href=&quot;https://millionaire.wikia.com/wiki/Jim_Matthews&quot; rel=&quot;nofollow&quot;&gt;The question&lt;/a&gt; asked which network news anchor had hosted a children’s radio program at age 9. The answer? Peter Jennings.)&lt;/p&gt;
&lt;p&gt;&lt;iframe src=&quot;https://www.youtube.com/embed/8rMvtx_J5D0&quot; width=&quot;560&quot; height=&quot;315&quot; frameborder=&quot;0&quot;&gt;[embedded content]&lt;/iframe&gt;&lt;/p&gt;
&lt;p&gt;Matthews used some of that money to purchase Fetch and spin out his own company from Dartmouth College, where he’d worked for many years, and where he began development on Fetch in 1989 as an in-house program useful to staff and students. Matthews said that Dartmouth had picked the Mac as its preferred desktop computer, but had all sorts of central computer systems. He pitched writing Fetch as a kind of universal file-transfer app, and chose FTP (File Transfer Protocol), because it was the only standard that worked across all of them.&lt;/p&gt;
&lt;img src=&quot;https://images.idgesg.net/images/article/2018/12/veteran-mac-app-fetch-100782762-large.jpg&quot; border=&quot;0&quot; alt=&quot;veteran mac app fetch&quot; width=&quot;700&quot; height=&quot;438&quot; data-imageid=&quot;100782762&quot; data-license=&quot;IDG&quot;/&gt;&lt;small class=&quot;credit&quot;&gt;IDG&lt;/small&gt;
&lt;p&gt;Fetch has become a side project, but Matthews continues to update it, and plans a 64-bit release for macOS 10.15.&lt;/p&gt;
&lt;p&gt;Fetch predates System 7, and originally ran in System 6 as an application—an as a desk accessory, because not everyone was using MultiFinder, Apple’s first entry into allowing multiple simultaneously available programs.&lt;/p&gt;
&lt;p&gt;As the internet rose in availability, some institutions began hosting archives of legally available software and other files, notably Stanford’s Info-Mac Archives. These required an FTP client, and Matthews said that ultimately led to more users outside of Dartmouth than on campus. The growth of the web didn’t put the kibosh on Fetch’s popularity, as early browsers were fairly terrible at FTP access and download. “To my surprise, Fetch flipped from being a tool that was mostly used for retrieving information to one that was mostly used for publishing information,” Matthews said.&lt;/p&gt;
&lt;img src=&quot;https://images.idgesg.net/images/article/2018/12/fetch5-mac-icon-100783216-medium.jpg&quot; border=&quot;0&quot; alt=&quot;fetch5 mac icon&quot; width=&quot;300&quot; height=&quot;200&quot; data-imageid=&quot;100783216&quot;/&gt;&lt;small class=&quot;credit&quot;&gt;Fetch Softworks&lt;/small&gt;
&lt;p&gt;Fetch has always used a dog as its icon, and Matthews said his father in law created the first icon. He sent him a bitmap rendering in MacPaint that had the dog’s legs in different positions, which led him to create a tiny animation for the program’s cursor while the app is take action. “It was a silly addition, but has garnered more comment from users over the years than any other feature,” he said. (Matthews said Fetch now sports a cursor with more frames that’s drawn by Anthony Piraino of the Iconfactory.)&lt;/p&gt;
&lt;p&gt;After spinning Fetch out of Dartmouth, Matthews said Ben Artin and Scott McGuire helped him turn it into what he called “a professional piece of software.” But as time has passed, Fetch has receded from a full-time job into a side project for Matthews, who now works on &lt;a href=&quot;https://trello.com&quot; rel=&quot;nofollow&quot;&gt;Trello&lt;/a&gt; for Atlassian. He still lives in New Hampshire.&lt;/p&gt;
&lt;p&gt;Fetch’s future isn’t entirely certain, as Matthews said he has no major new releases planned. But Fetch users keep telling him they want to use Fetch after macOS 10.15 ships in 2019, which will eliminate 32-bit apps. “I am tapping at it to see if I can pull Fetch into the 64-bit world in time for its 30th birthday in September 2019,” he said.&lt;/p&gt;
&lt;p&gt;As for Easter eggs, Matthews confesses, “Any true Easter eggs are well enough hidden that I’ve forgotten where they are.” But, he adds, “There is a hidden preference for adjusting the speed of the running dog cursor that I think was just a left-over from testing—maybe it qualifies.”&lt;/p&gt;
&lt;h2 class=&quot;toc&quot; id=&quot;toc-4&quot;&gt;GraphicConverter: Over 200 file formats supported&lt;/h2&gt;
&lt;p&gt;Thorsten Lemke wanted a way to convert a few image file formats—Atari, Amiga, DOS, and Windows—to use on a Mac. That modest start in 1992 with &lt;a href=&quot;https://www.lemkesoft.de/en/products/graphicconverter/&quot; rel=&quot;nofollow&quot;&gt;GraphicConverter&lt;/a&gt; has grown to include over 200 file formats in version 10, also known as GraphicConverter X.&lt;/p&gt;
&lt;img src=&quot;https://images.idgesg.net/images/article/2018/12/graphicconverter10-mac-icon-100783218-medium.jpg&quot; border=&quot;0&quot; alt=&quot;graphicconverter10 mac icon&quot; width=&quot;300&quot; height=&quot;200&quot; data-imageid=&quot;100783218&quot;/&gt;&lt;small class=&quot;credit&quot;&gt;Lemke Software&lt;/small&gt;
&lt;p&gt;GraphicConverter evolved from simple file conversion into a full-fledged image editor, image file browser, batch-process manager, and metadata inspector and editor. Lemke noted that the program now includes over 200 filters for modifying images, too.&lt;/p&gt;
&lt;p&gt;Despite all the development, Lemke said there’s always a full plate of user requests for new features and other workflows. “Further development is assured,” he said.&lt;/p&gt;
&lt;p&gt;While the app has expanded in features, and Lemke’s company, Lemkesoft, now maintains several software packages, he’s the primary mover. On the website, Lemke noted, “Thorsten personally answers between 200 to 300 emails from users worldwide.”&lt;/p&gt;
&lt;p&gt;He said that while he developed most of the app himself, he’s relied on contract developers to handle transitions. Like most of the other long-running apps, that’s meant several, including shifting the underlying coding language from Pascal to C to the current combination of Objective-C and Apple’s newer Swift.&lt;/p&gt;
&lt;img src=&quot;https://images.idgesg.net/images/article/2018/12/veteran-mac-app-gc-100782763-large.jpg&quot; border=&quot;0&quot; alt=&quot;veteran mac app gc&quot; width=&quot;700&quot; height=&quot;489&quot; data-imageid=&quot;100782763&quot; data-license=&quot;IDG&quot;/&gt;&lt;small class=&quot;credit&quot;&gt;IDG&lt;/small&gt;
&lt;p&gt;GraphicConverter has grown from a few image file-format conversions to a full-featured image editor with hundreds of filters and formats.&lt;/p&gt;
&lt;p&gt;Lemke said after all these years, he still “likes the challenges of the new developments and techniques.” That helps him get up in the morning and get to work. But, he noted, he also has to get his kids off to school: “My day starts at 5:30 in the morning.”&lt;/p&gt;
&lt;p&gt;[&lt;em&gt;Disclosures: Glenn wrote a book about BBEdit a few years ago for Take Control Books, an independent publisher. In early 2017, Glenn wrote PCalc’s first-ever manual on a one-time, flat-fee contract basis.&lt;/em&gt;]&lt;/p&gt;
&lt;div class=&quot;end-note&quot;&gt;
&lt;div id=&quot;&quot; class=&quot;blx blxParticleendnote blxM2007 blox4_html blxC24067&quot;&gt;
&lt;aside&gt;To comment on this article and other Macworld content, visit our &lt;a href=&quot;https://www.facebook.com/Macworld/&quot; target=&quot;_blank&quot;&gt;Facebook&lt;/a&gt; page or our &lt;a href=&quot;https://twitter.com/macworld&quot; target=&quot;_blank&quot;&gt;Twitter&lt;/a&gt; feed.&lt;/aside&gt;&lt;/div&gt;
&lt;/div&gt;
</description>
<pubDate>Tue, 01 Jan 2019 15:01:09 +0000</pubDate>
<dc:creator>PretzelFisch</dc:creator>
<og:type>article</og:type>
<og:url>https://www.macworld.com/article/3327502/macs/mac-indy-apps-thrived-for-more-than-25-years.html</og:url>
<og:image>https://images.idgesg.net/images/article/2018/12/25yrs-indy-mac-apps-100783250-large.3x2.jpg</og:image>
<og:title>The old guard of Mac indy apps has thrived for more than 25 years</og:title>
<og:description>BBEdit and other popular indy Mac apps have been around for over 25 years. Here are insights from over a century of development of Mac apps from four long-term developers.</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.macworld.com/article/3327502/macs/mac-indy-apps-thrived-for-more-than-25-years.html</dc:identifier>
</item>
<item>
<title>Learning KVM – implement your own kernel</title>
<link>https://david942j.blogspot.com/2018/10/note-learning-kvm-implement-your-own.html</link>
<guid isPermaLink="true" >https://david942j.blogspot.com/2018/10/note-learning-kvm-implement-your-own.html</guid>
<description>Few weeks ago I solved a great KVM escaping challenge from TWCTF hosted by &lt;a href=&quot;https://twitter.com/TokyoWesterns&quot; target=&quot;_blank&quot;&gt;@TokyoWesterns&lt;/a&gt;. I have given a writeup on my blog: &lt;a href=&quot;https://david942j.blogspot.com/2018/09/write-up-tokyowesterns-ctf-2018.html&quot; target=&quot;_blank&quot;&gt;[Write-up] TokyoWesterns CTF 2018 - pwn240+300+300 EscapeMe&lt;/a&gt;, but it mentions nothing about KVM because there's no bug (at least I didn't find) around it.&lt;p&gt;Most introduction of KVM I found are actually introducing either libvirt or qemu, lack of how to utilize KVM by hand, that's why I have this post.&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://lwn.net/Articles/658511/&quot; target=&quot;_blank&quot;&gt;This thread&lt;/a&gt; is a good start to implement a simple KVM program. Some projects such as &lt;a href=&quot;https://github.com/dpw/kvm-hello-world&quot;&gt;kvm-hello-world&lt;/a&gt; and &lt;a href=&quot;https://github.com/kvmtool/kvmtoo&quot;&gt;kvmtool&lt;/a&gt; are worthy to take a look as well. And &lt;a href=&quot;https://wiki.osdev.org/Main_Page&quot;&gt;OSDev.org&lt;/a&gt; has great resources to learn system architecture knowledge.&lt;/p&gt;&lt;p&gt;In this post I will introduce how to use KVM directly and how it works, wish this article can be a quick start for beginners learning KVM.&lt;/p&gt;&lt;p&gt;I've created a public repository for the source code of KVM-based hypervisor and the kernel: &lt;a href=&quot;https://github.com/david942j/kvm-kernel-example&quot; target=&quot;_blank&quot;&gt;david942j/kvm-kernel-example&lt;/a&gt;. You can clone and try it after reading this article.&lt;br/&gt;&lt;em&gt;Warning&lt;/em&gt;: all code in this post may be simplified to clearly show its function, if you want to write some code, I highly recommend you read examples in the repository instead of copy-paste code from here.&lt;/p&gt;&lt;p&gt;&lt;br/&gt;The kernel I implemented is able to execute an ELF in user-space, this is the screenshot of execution result:&lt;br/&gt;&lt;a href=&quot;https://1.bp.blogspot.com/--7vsSQoMFw8/W7OZ3zPoETI/AAAAAAAAApI/M9JC3Fgbxb864DKaxb2hcKqTw1wUOkFMwCK4BGAYYCw/s1600/%25E8%259E%25A2%25E5%25B9%2595%25E5%25BF%25AB%25E7%2585%25A7%2B2018-10-03%2B00.15.07.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; height=&quot;263&quot; src=&quot;https://1.bp.blogspot.com/--7vsSQoMFw8/W7OZ3zPoETI/AAAAAAAAApI/M9JC3Fgbxb864DKaxb2hcKqTw1wUOkFMwCK4BGAYYCw/s640/%25E8%259E%25A2%25E5%25B9%2595%25E5%25BF%25AB%25E7%2585%25A7%2B2018-10-03%2B00.15.07.png&quot; width=&quot;640&quot;/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Introduction&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;KVM (Kernel-base Virtual Machine) is a virtual machine that implemented native in Linux kernel. As you know, VM usually used for creating a separated and independent environment. As the official site described, each virtual machine created by KVM has private virtualized hardware: a network card, disk, graphics adapter, etc.&lt;/p&gt;&lt;p&gt;First I'll introduce how to use KVM to execute simple assembled code, and then describe some key points to implement a Linux kernel. The Linux kernel we will implement is extremely simple, but more features might be added after this post released.&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Get Started&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;All communication with KVM is done by the &lt;span&gt;ioctl&lt;/span&gt; syscall, which is usually used for getting and setting device status.&lt;/p&gt;&lt;p&gt;Creating a KVM-based VM basically needs 7 steps:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Open the KVM device, &lt;span&gt;kvmfd=open(&quot;/dev/kvm&quot;, O_RDWR|O_CLOEXEC)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;Do create a VM,&lt;/span&gt; &lt;span&gt;vmfd=ioctl(kvmfd, KVM_CREATE_VM, 0)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Set up memory for VM guest, &lt;span&gt;ioctl(vmfd, KVM_SET_USER_MEMORY_REGION, &amp;amp;region)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;Create a virtual CPU for the VM, &lt;/span&gt;&lt;span&gt;vcpufd=ioctl(vmfd, KVM_CREATE_VCPU, 0)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Set up memory for the vCPU
&lt;ul&gt;&lt;li&gt;&lt;span&gt;vcpu_size=ioctl(kvmfd, KVM_GET_VCPU_MMAP_SIZE, NULL)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;run=(struct kvm_run*)mmap(NULL, mmap_size, PROT_READ|PROT_WRITE, MAP_SHARED, vcpufd, 0)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Put assembled code on user memory region, set up vCPU's registers such as &lt;span&gt;rip&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Run and handle exit reason. &lt;span&gt;while(1) { ioctl(vcpufd, KVM_RUN, 0); ... }&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;br/&gt;Too complicated!? See this figure&lt;div class=&quot;separator&quot;&gt;&lt;a href=&quot;https://3.bp.blogspot.com/-JAMnkb_Wrf4/W5EfEu4By_I/AAAAAAAAAoY/GLwczGKZgmE9T57Y390gLjPhkr_Sf11BQCK4BGAYYCw/s1600/kvm.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; height=&quot;308&quot; src=&quot;https://3.bp.blogspot.com/-JAMnkb_Wrf4/W5EfEu4By_I/AAAAAAAAAoY/GLwczGKZgmE9T57Y390gLjPhkr_Sf11BQCK4BGAYYCw/s320/kvm.png&quot; width=&quot;320&quot;/&gt;&lt;/a&gt;&lt;/div&gt;&lt;br/&gt;A VM needs &lt;strong&gt;user memory region&lt;/strong&gt; and &lt;strong&gt;virtual CPU(s)&lt;/strong&gt;, so all we need is to create VM, set up user memory region, create vCPU(s) and its working space then execute it!&lt;p&gt;Code is better than plaintext for hackers. &lt;em&gt;Warning&lt;/em&gt;:&lt;strong&gt; &lt;/strong&gt;code posted here has no error handling&lt;strong&gt;.&lt;/strong&gt;&lt;br/&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt; &lt;strong&gt;Step 1 - 3, set up a new VM&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;pre class=&quot;prettyprint lang-c&quot;&gt;
/* step 1~3, create VM and set up user memory region */
void kvm(uint8_t code[], size_t code_len) {
  // step 1, open /dev/kvm
  int kvmfd = open(&quot;/dev/kvm&quot;, O_RDWR|O_CLOEXEC);
  if(kvmfd == -1) errx(1, &quot;failed to open /dev/kvm&quot;);

  // step 2, create VM
  int vmfd = ioctl(kvmfd, KVM_CREATE_VM, 0);

  // step 3, set up user memory region
  size_t mem_size = 0x40000000; // size of user memory you want to assign
  void *mem = mmap(0, mem_size, PROT_READ|PROT_WRITE,
                   MAP_SHARED|MAP_ANONYMOUS, -1, 0);
  int user_entry = 0x0;
  memcpy((void*)((size_t)mem + user_entry), code, code_len);
  struct kvm_userspace_memory_region region = {
    .slot = 0,
    .flags = 0,
    .guest_phys_addr = 0,
    .memory_size = mem_size,
    .userspace_addr = (size_t)mem
  };
  ioctl(vmfd, KVM_SET_USER_MEMORY_REGION, &amp;amp;region);
  /* end of step 3 */
  // not finished ...
}
&lt;/pre&gt;
In above code fragment I assign 1GB memory (&lt;span&gt;mem_size&lt;/span&gt;) to the guest, and put assembled code on the first page. Later we will set the instruction pointer to 0x0 (&lt;span&gt;user_entry&lt;/span&gt;), where the guest should start to execute.&lt;p&gt;&lt;strong&gt;Step 4 - 6, set up a new vCPU&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;pre class=&quot;prettyprint lang-c&quot;&gt;
/* step 4~6, create and set up vCPU */
void kvm(uint8_t code[], size_t code_len) {
  /* ... step 1~3 omitted */

  // step 4, create vCPU
  int vcpufd = ioctl(vmfd, KVM_CREATE_VCPU, 0);

  // step 5, set up memory for vCPU
  size_t vcpu_mmap_size = ioctl(kvmfd, KVM_GET_VCPU_MMAP_SIZE, NULL);
  struct kvm_run* run = (struct kvm_run*) mmap(0, vcpu_mmap_size,
                                               PROT_READ | PROT_WRITE, MAP_SHARED,
                                               vcpufd, 0);

  // step 6, set up vCPU's registers
  /* standard registers include general-purpose registers and flags */
  struct kvm_regs regs;
  ioctl(vcpufd, KVM_GET_REGS, &amp;amp;regs);
  regs.rip = user_entry;
  regs.rsp = 0x200000; // stack address
  regs.rflags = 0x2; // in x86 the 0x2 bit should always be set
  ioctl(vcpufd, KVM_SET_REGS, &amp;amp;regs); // set registers

  /* special registers include segment registers */
  struct kvm_sregs sregs;
  ioctl(vcpufd, KVM_GET_SREGS, &amp;amp;sregs);
  sregs.cs.base = sregs.cs.selector = 0; // let base of code segment equal to zero
  ioctl(vcpufd, KVM_SET_SREGS, &amp;amp;sregs);
  // not finished ...
}
&lt;/pre&gt;
Here we create a vCPU and set up its registers include standard registers and &quot;special&quot; registers. Each &lt;span&gt;kvm_run&lt;/span&gt; structure corresponds to one vCPU, and we will use it to get the CPU status after execution. Notice that we can create multiple vCPUs under one VM, then with multithread we can emulate a VM with multiple CPUs. Note: by default, the vCPU runs in &lt;a href=&quot;https://en.wikipedia.org/wiki/Real_mode&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;real mode&lt;/strong&gt;&lt;/a&gt;, which only executes &lt;strong&gt;16-bit assembled code&lt;/strong&gt;. &lt;strong&gt;To run 32 or 64-bit, the page table must be set up&lt;/strong&gt;, which we'll describe later.&lt;p&gt;&lt;strong&gt;Step 7, execute!&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;pre class=&quot;prettyprint lang-c&quot;&gt;
/* last step, run it! */
void kvm(uint8_t code[], size_t code_len) {
  /* ... step 1~6 omitted */
  // step 7, execute vm and handle exit reason
  while (1) {
    ioctl(vcpufd, KVM_RUN, NULL);
    switch (run-&amp;gt;exit_reason) {
    case KVM_EXIT_HLT:
      fputs(&quot;KVM_EXIT_HLT&quot;, stderr);
      return 0;
    case KVM_EXIT_IO:
      /* TODO: check port and direction here */
      putchar(*(((char *)run) + run-&amp;gt;io.data_offset));
      break;
    case KVM_EXIT_FAIL_ENTRY:
      errx(1, &quot;KVM_EXIT_FAIL_ENTRY: hardware_entry_failure_reason = 0x%llx&quot;,
        run-&amp;gt;fail_entry.hardware_entry_failure_reason);
    case KVM_EXIT_INTERNAL_ERROR:
      errx(1, &quot;KVM_EXIT_INTERNAL_ERROR: suberror = 0x%x&quot;,
        run-&amp;gt;internal.suberror);
    case KVM_EXIT_SHUTDOWN:
      errx(1, &quot;KVM_EXIT_SHUTDOWN&quot;);
    default:
      errx(1, &quot;Unhandled reason: %d&quot;, run-&amp;gt;exit_reason);
    }
  }
}
&lt;/pre&gt;
Typically we only care about the first two cases, &lt;span&gt;KVM_EXIT_HLT&lt;/span&gt; and &lt;span&gt;KVM_EXIT_IO&lt;/span&gt;. With instruction &lt;span&gt;hlt&lt;/span&gt;, the &lt;span&gt;KVM_EXIT_HLT&lt;/span&gt; is triggered. Instructions &lt;a href=&quot;https://c9x.me/x86/html/file_module_x86_id_139.html&quot; target=&quot;_blank&quot;&gt;in&lt;/a&gt; and &lt;a href=&quot;https://c9x.me/x86/html/file_module_x86_id_222.html&quot; target=&quot;_blank&quot;&gt;out&lt;/a&gt; trigger &lt;span&gt;KVM_EXIT_IO&lt;/span&gt;. And not only for I/O, we can also use this as hypercall, i.e. to &lt;strong&gt;communicate with the host&lt;/strong&gt;. Here we only print one character sent to device.&lt;br/&gt;&lt;span&gt;ioctl(vcpufd, KVM_RUN, NULL)&lt;/span&gt; will run until an exit-like instruction occurred (such as &lt;span&gt;hlt&lt;/span&gt;, &lt;span&gt;out&lt;/span&gt;, or an error). You can also enable the single-step mode (not demonstrated here), then it will stop on every instructions.&lt;p&gt;Let's try our first KVM-based VM:&lt;br/&gt;&lt;/p&gt;&lt;pre class=&quot;prettyprint lang-c&quot;&gt;
int main() {
  /*
  .code16
  mov al, 0x61
  mov dx, 0x217
  out dx, al
  mov al, 10
  out dx, al
  hlt
  */
  uint8_t code[] = &quot;\xB0\x61\xBA\x17\x02\xEE\xB0\n\xEE\xF4&quot;;
  kvm(code, sizeof(code));
}
&lt;/pre&gt;
And the execution result is:&lt;pre class=&quot;prettyprint&quot;&gt;
$ ./kvm
a
KVM_EXIT_HLT
&lt;/pre&gt;
&lt;br/&gt;&lt;strong&gt;&lt;span&gt;64-bit World&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;To execute 64-bit assembled code, we need to set vCPU into &lt;a href=&quot;https://en.wikipedia.org/wiki/Long_mode&quot; target=&quot;_blank&quot;&gt;long mode&lt;/a&gt;. And &lt;a href=&quot;https://wiki.osdev.org/Setting_Up_Long_Mode&quot; target=&quot;_blank&quot;&gt;this wiki page&lt;/a&gt; describes how to switch from real mode to long mode, I highly recommend you read it as well. The most complicated part of switching into long mode is to set up the page tables for mapping virtual address into physical address. x86-64 processor uses a memory management feature named &lt;a href=&quot;https://en.wikipedia.org/wiki/Physical_Address_Extension&quot; target=&quot;_blank&quot;&gt;PAE (Physical Address Extension)&lt;/a&gt;, contains of four kinds of tables: PML4T, PDPT, PDT, and PT. The way these tables work is that each entry in the PML4T points to a PDPT, each entry in a PDPT to a PDT and each entry in a PDT to a PT. Each entry in a PT then points to the physical address.&lt;br/&gt;

The figure above is called 4K paging. There's another paging method named 2M paging, with the PT (page table) removed. In this method the PDT entries point to physical address.&lt;p&gt;The control registers (&lt;span&gt;cr*&lt;/span&gt;) are used for setting paging attributes. For example, &lt;span&gt;cr3&lt;/span&gt; should point to physical address of &lt;span&gt;pml4&lt;/span&gt;. More information about control registers can be found &lt;a href=&quot;https://en.wikipedia.org/wiki/Control_register&quot; target=&quot;_blank&quot;&gt;in wikipedia&lt;/a&gt;.&lt;br/&gt;This code set up the tables, using the &lt;strong&gt;2M paging&lt;/strong&gt;.&lt;br/&gt;&lt;/p&gt;&lt;pre class=&quot;prettyprint lang-c&quot;&gt;
/* Maps: 0 ~ 0x200000 -&amp;gt; 0 ~ 0x200000 */
void setup_page_tables(void *mem, struct kvm_sregs *sregs){
  uint64_t pml4_addr = 0x1000;
  uint64_t *pml4 = (void *)(mem + pml4_addr);

  uint64_t pdpt_addr = 0x2000;
  uint64_t *pdpt = (void *)(mem + pdpt_addr);

  uint64_t pd_addr = 0x3000;
  uint64_t *pd = (void *)(mem + pd_addr);

  pml4[0] = 3 | pdpt_addr; // PDE64_PRESENT | PDE64_RW | pdpt_addr
  pdpt[0] = 3 | pd_addr; // PDE64_PRESENT | PDE64_RW | pd_addr
  pd[0] = 3 | 0x80; // PDE64_PRESENT | PDE64_RW | PDE64_PS

  sregs-&amp;gt;cr3 = pml4_addr;
  sregs-&amp;gt;cr4 = 1 &amp;lt;&amp;lt; 5; // CR4_PAE;
  sregs-&amp;gt;cr4 |= 0x600; // CR4_OSFXSR | CR4_OSXMMEXCPT; /* enable SSE instruction */
  sregs-&amp;gt;cr0 = 0x80050033; // CR0_PE | CR0_MP | CR0_ET | CR0_NE | CR0_WP | CR0_AM | CR0_PG
  sregs-&amp;gt;efer = 0x500; // EFER_LME | EFER_LMA
}
&lt;/pre&gt;
There're some control bits record in the tables, include if the page is mapped, is writable, and can be accessed in user-mode. e.g. 3 (&lt;span&gt;PDE64_PRESENT|PDE64_RW&lt;/span&gt;) stands for the memory is mapped and writable, and 0x80 (&lt;span&gt;PDE64_PS&lt;/span&gt;) stands for it's 2M paging instead of 4K. As a result, these page tables can map address below 0x200000 to itself (i.e. virtual address equals to physical address).&lt;p&gt;Remaining is setting segment registers:&lt;br/&gt;&lt;/p&gt;&lt;pre class=&quot;prettyprint lang-c&quot;&gt;
void setup_segment_registers(struct kvm_sregs *sregs) {
  struct kvm_segment seg = {
    .base = 0,
    .limit = 0xffffffff,
    .selector = 1 &amp;lt;&amp;lt; 3,
    .present = 1,
    .type = 11, /* execute, read, accessed */
    .dpl = 0, /* privilege level 0 */
    .db = 0,
    .s = 1,
    .l = 1,
    .g = 1,
  };
  sregs-&amp;gt;cs = seg;
  seg.type = 3; /* read/write, accessed */
  seg.selector = 2 &amp;lt;&amp;lt; 3;
  sregs-&amp;gt;ds = sregs-&amp;gt;es = sregs-&amp;gt;fs = sregs-&amp;gt;gs = sregs-&amp;gt;ss = seg;
}
&lt;/pre&gt;
&lt;br/&gt;We only need to modify VM setup in step 6 to support 64-bit instructions, change code from&lt;pre class=&quot;prettyprint lang-c&quot;&gt;
  sregs.cs.base = sregs.cs.selector = 0; // let base of code segment equal to zero
&lt;/pre&gt;
to&lt;pre class=&quot;prettyprint lang-c&quot;&gt;
  setup_page_tables(mem, &amp;amp;sregs);
  setup_segment_registers(&amp;amp;sregs);
&lt;/pre&gt;
&lt;br/&gt;Now we can execute 64-bit assembled code.&lt;pre class=&quot;prettyprint lang-c&quot;&gt;
int main() {
  /*
  movabs rax, 0x0a33323144434241
  push 8
  pop rcx
  mov edx, 0x217
OUT:
  out dx, al
  shr rax, 8
  loop OUT
  hlt
  */
  uint8_t code[] = &quot;H\xB8\x41\x42\x43\x44\x31\x32\x33\nj\bY\xBA\x17\x02\x00\x00\xEEH\xC1\xE8\b\xE2\xF9\xF4&quot;;
  kvm(code, sizeof(code));
}
&lt;/pre&gt;
And the execution result is:&lt;pre class=&quot;prettyprint&quot;&gt;
$ ./kvm64
ABCD123
KVM_EXIT_HLT
&lt;/pre&gt;
&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;The source code of hypervisor can be found in the &lt;a href=&quot;https://github.com/david942j/kvm-kernel-example/tree/master/hypervisor&quot; target=&quot;_blank&quot;&gt;repository/hypervisor&lt;/a&gt;.&lt;/span&gt;&lt;br/&gt;&lt;span&gt;So far you are already able to run x86-64 assembled code under KVM, so our &lt;strong&gt;introduction to KVM is almost finished&lt;/strong&gt; (except handling hypercalls). In the next section I will describe how to implement a simple kernel, which contains some OS knowledge. If you are interesting in how kernel works, go ahead.&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt; &lt;strong&gt;Kernel&lt;/strong&gt;&lt;br/&gt;Before implementing a kernel, some questions need to be dealt with:&lt;br/&gt;&lt;ol&gt;&lt;li&gt;How CPU distinguishes between kernel-mode and user-mode?&lt;/li&gt;
&lt;li&gt;How could CPU transfer control to kernel when user invokes &lt;span&gt;syscall&lt;/span&gt;?&lt;/li&gt;
&lt;li&gt;How kernel switches between kernel and user?&lt;/li&gt;
&lt;/ol&gt;&lt;div&gt;&lt;span&gt;&lt;strong&gt;kernel-mode v.s. user-mode&lt;/strong&gt;&lt;/span&gt;&lt;/div&gt;
&lt;div&gt;An important difference between kernel-mode and user-mode is some instructions can only be executed under kernel-mode, such as &lt;span&gt;hlt&lt;/span&gt; and &lt;span&gt;wrmsr&lt;/span&gt;. The two modes are distinguish by the &lt;span&gt;dpl&lt;/span&gt; (descriptor privilege level) field in segment register &lt;span&gt;cs&lt;/span&gt;. &lt;span&gt;dpl=3&lt;/span&gt;  in &lt;span&gt;cs&lt;/span&gt; for user-mode, and zero for kernel-mode (not sure if this &quot;level&quot; equivalent to so-called ring3 and ring0).&lt;br/&gt;In real mode kernel should handle the segment registers carefully, while in x86-64, instructions &lt;span&gt;syscall&lt;/span&gt; and &lt;span&gt;sysret&lt;/span&gt; will properly set segment registers automatically, so we don't need to maintain segment registers manually.&lt;/div&gt;

&lt;div&gt;And another difference is the permission setting in page tables. In the above example I set all entries as non-user-accessible:&lt;pre class=&quot;prettyprint lang-c&quot;&gt;
  pml4[0] = 3 | pdpt_addr; // PDE64_PRESENT | PDE64_RW | pdpt_addr
  pdpt[0] = 3 | pd_addr; // PDE64_PRESENT | PDE64_RW | pd_addr
  pd[0] = 3 | 0x80; // PDE64_PRESENT | PDE64_RW | PDE64_PS
&lt;/pre&gt;
If kernel wants to create virtual memory for user-space, such as handling &lt;span&gt;mmap&lt;/span&gt; syscall from user, the page tables must set the 3rd bit, i.e. have bit (&lt;span&gt;1 &amp;lt;&amp;lt; 2&lt;/span&gt;) set, then the page can be accessed in user-space. For example,&lt;pre class=&quot;prettyprint lang-c&quot;&gt;
  pml4[0] = 7 | pdpt_addr; // PDE64_USER | PDE64_PRESENT | PDE64_RW | pdpt_addr
  pdpt[0] = 7 | pd_addr; // PDE64_USER | PDE64_PRESENT | PDE64_RW | pd_addr
  pd[0] = 7 | 0x80; // PDE64_USER | PDE64_PRESENT | PDE64_RW | PDE64_PS
&lt;/pre&gt;
&lt;br/&gt;This is just an example, we should &lt;strong&gt;NOT&lt;/strong&gt; set user-accessible pages in hypervisor, user-accessible pages should be handled by our kernel.&lt;p&gt;&lt;span&gt;&lt;strong&gt;Syscall&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;There's a special register can enable &lt;span&gt;syscall&lt;/span&gt;/&lt;span&gt;sysenter&lt;/span&gt; instruction: &lt;a href=&quot;https://wiki.osdev.org/CPU_Registers_x86-64#IA32_EFER&quot; target=&quot;_blank&quot;&gt;EFER (Extended Feature Enable Register)&lt;/a&gt;. We have used it for entering long mode before:&lt;br/&gt;&lt;/p&gt;&lt;pre class=&quot;prettyprint lang-c&quot;&gt;
sregs-&amp;gt;efer = 0x500; // EFER_LME | EFER_LMA
&lt;/pre&gt;
LME and LMA stand for Long Mode Enable and Long Mode Active, respectively.&lt;br/&gt;To enable &lt;span&gt;syscall&lt;/span&gt; as well, we should do&lt;pre class=&quot;prettyprint lang-c&quot;&gt;
sregs-&amp;gt;efer |= 0x1; // EFER_SCE
&lt;/pre&gt;&lt;/div&gt;

&lt;div&gt;We also need to register syscall handler so that CPU knows where to jump when user invokes syscalls. And of course, this registration should be done in kernel instead of hypervisor. Registration of syscall handler can be achieved via setting special registers named &lt;a href=&quot;https://wiki.osdev.org/Model_Specific_Registers&quot; target=&quot;_blank&quot;&gt;MSR (Model Specific Registers)&lt;/a&gt;. We can get/set MSR in hypervisor through &lt;span&gt;ioctl&lt;/span&gt; on &lt;span&gt;vcpufd&lt;/span&gt;, or in kernel using instructions &lt;span&gt;rdmsr&lt;/span&gt; and &lt;span&gt;wrmsr&lt;/span&gt;.&lt;br/&gt;To register a syscall handler:&lt;pre class=&quot;prettyprint lang-c&quot;&gt;
  lea rdi, [rip+syscall_handler]
  call set_handler
syscall_handler:
  // handle syscalls!
set_handler:
  mov eax, edi
  mov rdx, rdi
  shr rdx, 32
  /* input of msr is edx:eax */
  mov ecx, 0xc0000082 /* MSR_LSTAR, Long Syscall TARget */
  wrmsr
  ret
&lt;/pre&gt;
&lt;br/&gt;The magic number 0xc0000082 is the index for MSR, you can find the definitions in &lt;a href=&quot;https://code.woboq.org/linux/linux/arch/x86/include/asm/msr-index.h.html#12&quot; target=&quot;_blank&quot;&gt;Linux source code&lt;/a&gt;.&lt;p&gt;After setup, we can invoke &lt;span&gt;syscall&lt;/span&gt; instruction and the program will jump to the handler we registered. &lt;span&gt;syscall&lt;/span&gt; instruction not only changes &lt;span&gt;rip&lt;/span&gt;, but also sets &lt;span&gt;rcx&lt;/span&gt; as return address so that kernel knows where to go back after handling syscall, and sets &lt;span&gt;r11&lt;/span&gt; as rflags. It will change two segment registers &lt;span&gt;cs&lt;/span&gt; and &lt;span&gt;ss&lt;/span&gt; as well, which we will describe in the next section.&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Switching between kernel and user&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;We also need to register the &lt;span&gt;cs&lt;/span&gt;'s selector for both kernel and user, via the register MSR we have used before.&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.felixcloutier.com/x86/SYSCALL.html&quot; target=&quot;_blank&quot;&gt;Here&lt;/a&gt; and &lt;a href=&quot;https://www.felixcloutier.com/x86/SYSRET.html&quot; target=&quot;_blank&quot;&gt;here&lt;/a&gt; describe what does &lt;span&gt;syscall&lt;/span&gt; and &lt;span&gt;sysret&lt;/span&gt; do in details, respectively.&lt;br/&gt;From the pseudo code of &lt;span&gt;sysret&lt;/span&gt; you can see it sets attributes of &lt;span&gt;cs&lt;/span&gt; and &lt;span&gt;ss&lt;/span&gt; explicitly:&lt;br/&gt;&lt;/p&gt;&lt;pre class=&quot;prettyprint lang-c&quot;&gt;
CS.Selector ← IA32_STAR[63:48]+16;
CS.Selector ← CS.Selector OR 3; /* RPL forced to 3 */
/* Set rest of CS to a fixed value */
CS.Base ← 0; /* Flat segment */
CS.Limit ← FFFFFH; /* With 4-KByte granularity, implies a 4-GByte limit */
CS.Type ← 11; /* Execute/read code, accessed */
CS.S ← 1;
CS.DPL ← 3;
CS.P ← 1;
CS.L ← 1;
CS.G ← 1; /* 4-KByte granularity */
CPL ← 3;
SS.Selector ← (IA32_STAR[63:48]+8) OR 3; /* RPL forced to 3 */
/* Set rest of SS to a fixed value */
SS.Base ← 0; /* Flat segment */
SS.Limit ← FFFFFH; /* With 4-KByte granularity, implies a 4-GByte limit */
SS.Type ← 3; /* Read/write data, accessed */
SS.S ← 1;
SS.DPL ← 3;
SS.P ← 1;
SS.B ← 1; /* 32-bit stack segment*/
SS.G ← 1; /* 4-KByte granularity */
&lt;/pre&gt;
&lt;br/&gt;We have to register the value of &lt;span&gt;cs&lt;/span&gt; for both kernel and user through MSR:&lt;br/&gt;&lt;div&gt;
&lt;pre class=&quot;prettyprint lang-asm&quot;&gt;
  xor rax, rax
  mov rdx, 0x00200008
  mov ecx, 0xc0000081 /* MSR_STAR */
  wrmsr
&lt;/pre&gt;
&lt;br/&gt;The last is set flags mask:&lt;pre class=&quot;prettyprint lang-asm&quot;&gt;
  mov eax, 0x3f7fd5
  xor rdx, rdx
  mov ecx, 0xc0000084 /* MSR_SYSCALL_MASK */
  wrmsr
&lt;/pre&gt;
The mask is important, when &lt;span&gt;syscall&lt;/span&gt; instruction is invoked, CPU will do:&lt;pre class=&quot;prettyprint lang-c&quot;&gt;
rcx = rip;
r11 = rflags;
rflags &amp;amp;= ~SYSCALL_MASK;
&lt;/pre&gt;
If the mask is not set properly, kernel will inherit the &lt;span&gt;rflags&lt;/span&gt; set in user mode, which can cause severely security issues.&lt;/div&gt;
&lt;br/&gt;The full code of registration is:&lt;pre class=&quot;prettyprint lang-asm&quot;&gt;
register_syscall:
  xor rax, rax
  mov rdx, 0x00200008
  mov ecx, 0xc0000081 /* MSR_STAR */
  wrmsr

  mov eax, 0x3f7fd5
  xor rdx, rdx
  mov ecx, 0xc0000084 /* MSR_SYSCALL_MASK */
  wrmsr

  lea rdi, [rip + syscall_handler]
  mov eax, edi
  mov rdx, rdi
  shr rdx, 32
  mov ecx, 0xc0000082 /* MSR_LSTAR */
  wrmsr
&lt;/pre&gt;
&lt;br/&gt;Then we can safely use the &lt;span&gt;syscall&lt;/span&gt; instruction in user-mode. Now let's implement the &lt;span&gt;syscall_handler&lt;/span&gt;:&lt;pre class=&quot;prettyprint lang-asm&quot;&gt;
.globl syscall_handler, kernel_stack
.extern do_handle_syscall
.intel_syntax noprefix

kernel_stack: .quad 0 /* initialize it before the first time switching into user-mode */
user_stack: .quad 0

syscall_handler:
  mov [rip + user_stack], rsp
  mov rsp, [rip + kernel_stack]
  /* save non-callee-saved registers */
  push rdi
  push rsi
  push rdx
  push rcx
  push r8
  push r9
  push r10
  push r11

  /* the forth argument */
  mov rcx, r10
  call do_handle_syscall

  pop r11
  pop r10
  pop r9
  pop r8
  pop rcx
  pop rdx
  pop rsi
  pop rdi

  mov rsp, [rip + user_stack]
  .byte 0x48 /* REX.W prefix, to indicate sysret is a 64-bit instruction */
  sysret
&lt;/pre&gt;
Notice that we have to properly push-and-pop not callee-saved registers. The &lt;span&gt;syscall&lt;/span&gt;/&lt;span&gt;sysret&lt;/span&gt; will not modify the stack pointer &lt;span&gt;rsp&lt;/span&gt;, so we have to handle it manually.&lt;p&gt;&lt;span&gt;&lt;strong&gt;Hypercall&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;Sometimes our kernel needs to communicate with the hypervisor, this can be done in many ways, in my kernel I use the &lt;span&gt;out&lt;/span&gt;/&lt;span&gt;in&lt;/span&gt; instructions for hypercalls. We have used the &lt;span&gt;out&lt;/span&gt; instruction to simply print a byte to stdout, now we extend it to do more fun things.&lt;br/&gt;An &lt;span&gt;in&lt;/span&gt;/&lt;span&gt;out&lt;/span&gt; instruction contains two arguments, 16-bit &lt;span&gt;dx&lt;/span&gt; and 32-bit &lt;span&gt;eax&lt;/span&gt;. I use the value of &lt;span&gt;dx&lt;/span&gt; for indicating what kind of hypercalls is intended to call, and &lt;span&gt;eax&lt;/span&gt; as its argument. I defined these hypercalls:&lt;br/&gt;&lt;/p&gt;&lt;pre class=&quot;prettyprint lang-c&quot;&gt;
#define HP_NR_MARK 0x8000

#define NR_HP_open  (HP_NR_MARK | 0)
#define NR_HP_read  (HP_NR_MARK | 1)
#define NR_HP_write  (HP_NR_MARK | 2)
#define NR_HP_close  (HP_NR_MARK | 3)
#define NR_HP_lseek  (HP_NR_MARK | 4)
#define NR_HP_exit  (HP_NR_MARK | 5)

#define NR_HP_panic (HP_NR_MARK | 0x7fff)
&lt;/pre&gt;
&lt;br/&gt;Then modify the hypervisor to not only print bytes when encountering &lt;span&gt;KVM_EXIT_IO&lt;/span&gt;:&lt;pre class=&quot;prettyprint lang-c&quot;&gt;
while (1) {
  ioctl(vm-&amp;gt;vcpufd, KVM_RUN, NULL);
  switch (vm-&amp;gt;run-&amp;gt;exit_reason) {
  /* other cases omitted */
  case KVM_EXIT_IO:
    // putchar(*(((char *)vm-&amp;gt;run) + vm-&amp;gt;run-&amp;gt;io.data_offset));
    if(vm-&amp;gt;run-&amp;gt;io.port &amp;amp; HP_NR_MARK) {
      switch(vm-&amp;gt;run-&amp;gt;io.port) {
      case NR_HP_open: hp_handle_open(vm); break;
      /* other cases omitted */
      default: errx(1, &quot;Invalid hypercall&quot;);
    }
    else errx(1, &quot;Unhandled I/O port: 0x%x&quot;, vm-&amp;gt;run-&amp;gt;io.port);
    break;
  }
}
&lt;/pre&gt;
&lt;br/&gt;Take &lt;span&gt;open&lt;/span&gt; as example, I implemented the handler of &lt;span&gt;open&lt;/span&gt; hypercall in hypervisor as: (&lt;strong&gt;&lt;em&gt;warning&lt;/em&gt;: this code lacks security checks&lt;/strong&gt;):&lt;pre class=&quot;prettyprint lang-c&quot;&gt;
/* hypervisor/hypercall.c */
static void hp_handle_open(VM *vm) {
  static int ret = 0;
  if(vm-&amp;gt;run-&amp;gt;io.direction == KVM_EXIT_IO_OUT) { // out instruction
    uint32_t offset = *(uint32_t*)((uint8_t*)vm-&amp;gt;run + vm-&amp;gt;run-&amp;gt;io.data_offset);
    const char *filename = (char*) vm-&amp;gt;mem + offset;

    MAY_INIT_FD_MAP(); // initialize fd_map if it's not initialized
    int min_fd;
    for(min_fd = 0; min_fd &amp;lt;= MAX_FD; min_fd++)
      if(fd_map[min_fd].opening == 0) break;
    if(min_fd &amp;gt; MAX_FD) ret = -ENFILE;
    else {
      int fd = open(filename, O_RDONLY, 0);
      if(fd &amp;lt; 0) ret = -errno;
      else {
        fd_map[min_fd].real_fd = fd;
        fd_map[min_fd].opening = 1;
        ret = min_fd;
      }
    }
  } else { // in instruction
    *(uint32_t*)((uint8_t*)vm-&amp;gt;run + vm-&amp;gt;run-&amp;gt;io.data_offset) = ret;
  }
}
&lt;/pre&gt;
In kernel we invoke the &lt;span&gt;open&lt;/span&gt; hypercall with:&lt;pre class=&quot;prettyprint lang-c&quot;&gt;
/* kernel/hypercalls/hp_open.c */
int hp_open(uint32_t filename_paddr) {
  int ret = 0;
  asm(
    &quot;mov dx, %[port];&quot; /* hypercall number */
    &quot;mov eax, %[data];&quot;
    &quot;out dx, eax;&quot; /* trigger hypervisor to handle the hypercall */
    &quot;in eax, dx;&quot;  /* get return value of the hypercall */
    &quot;mov %[ret], eax;&quot;
    : [ret] &quot;=r&quot;(ret)
    : [port] &quot;r&quot;(NR_HP_open), [data] &quot;r&quot;(filename_paddr)
    : &quot;rax&quot;, &quot;rdx&quot;
  );
  return ret;
}
&lt;/pre&gt;
&lt;br/&gt;&lt;span&gt;&lt;strong&gt;Almost done&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;Now you should know all things to implement a simple Linux kernel running under KVM. Some details are worthy to be mentioned during the implementation.&lt;br/&gt;&lt;span&gt;&lt;strong&gt;execve&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;My kernel is able to execute a simple ELF, to do this you will need knowledge with structure of ELF, which is too complicated to introduce here. You can refer to the source code of Linux for details: &lt;a href=&quot;https://code.woboq.org/linux/linux/fs/binfmt_elf.c.html#load_elf_binary&quot; target=&quot;_blank&quot;&gt;linux/fs/binfmt_elf.c#load_elf_binary&lt;/a&gt;.&lt;p&gt;&lt;span&gt;&lt;strong&gt;memory allocator&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;You will need &lt;span&gt;malloc&lt;/span&gt;/&lt;span&gt;free&lt;/span&gt; for kernel, try to implement a memory allocator by yourself!&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;paging&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;Kernel has to handle the &lt;span&gt;mmap&lt;/span&gt; request from user mode, so you will need to modify the page tables during runtime. Be care of NOT mixing kernel-only addresses with user-accessible addresses.&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;permission checking&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;All arguments passed from user-mode most be carefully checked. I've implemented checking methods in &lt;a href=&quot;https://github.com/david942j/kvm-kernel-example/blob/master/kernel/mm/uaccess.c&quot; target=&quot;_blank&quot;&gt;kernel/mm/uaccess.c&lt;/a&gt;. Without properly checking, user-mode may be able to do arbitrary read/write on kernel-space, which is a severe security issue.&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;This post introduces how to implement a KVM-based hypervisor and a simple Linux kernel, wish it can help you know about KVM and Linux more clearly.&lt;br/&gt;I know I've omitted many details here, especially for the kernel part. Since this post is intended to be an introduction of KVM, I think this arrangement is appropriate.&lt;/p&gt;&lt;p&gt;If you have any questions or find bugs in my code, leave comments here or file an issue on &lt;a href=&quot;https://github.com/david942j/kvm-kernel-example&quot; target=&quot;_blank&quot;&gt;github&lt;/a&gt;.&lt;br/&gt;If this post is helpful to you, I'll be very grateful to see 'thanks' on twitter &lt;a href=&quot;https://twitter.com/david942j&quot; target=&quot;_blank&quot;&gt;@david942j&lt;/a&gt; :D&lt;/p&gt;&lt;/div&gt;

</description>
<pubDate>Tue, 01 Jan 2019 04:25:13 +0000</pubDate>
<dc:creator>signa11</dc:creator>
<og:url>https://david942j.blogspot.com/2018/10/note-learning-kvm-implement-your-own.html</og:url>
<og:title>[Note] Learning KVM - implement your own Linux kernel</og:title>
<og:description>Few weeks ago I solved a great KVM escaping challenge from TWCTF hosted by @TokyoWesterns . I have given a writeup on my blog:  [Write-up] T...</og:description>
<og:image>https://1.bp.blogspot.com/--7vsSQoMFw8/W7OZ3zPoETI/AAAAAAAAApI/M9JC3Fgbxb864DKaxb2hcKqTw1wUOkFMwCK4BGAYYCw/w1200-h630-p-k-no-nu/%25E8%259E%25A2%25E5%25B9%2595%25E5%25BF%25AB%25E7%2585%25A7%2B2018-10-03%2B00.15.07.png</og:image>
<dc:language>zh-TW</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://david942j.blogspot.com/2018/10/note-learning-kvm-implement-your-own.html</dc:identifier>
</item>
</channel>
</rss>