<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=hnrss.org%2Fnewest%3Fpoints%3D200&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://hnrss.org/newest?points=200" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>Hacker News: Newest</title>
<link>https://news.ycombinator.com/newest</link>
<description>Hacker News RSS</description>
<item>
<title>Alexandria Ocasio-Cortez Is Absolutely Right About Racist Algorithms</title>
<link>https://breakermag.com/alexandria-ocasio-cortez-is-absolutely-right-about-racist-algorithms/</link>
<guid isPermaLink="true" >https://breakermag.com/alexandria-ocasio-cortez-is-absolutely-right-about-racist-algorithms/</guid>
<description>&lt;p&gt;Freshman Democratic congresswoman Alexandria Ocasio-Cortez is making headlines on a daily basis, because she’s simultaneously &lt;a href=&quot;https://www.rollingstone.com/politics/politics-features/alexandria-ocasio-cortez-media-781571/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;hugely popular&lt;/a&gt; among young progressives, and regularly enraging to conservatives and moderates. In just one of several headline moments from the past few days, Ocasio-Cortez appeared on an MLK Day broadcast with author Ta-Nahesi Coates, and declared that facial recognition technologies “always have these racial inequities that get translated, because algorithms are still made by human beings, and those algorithms are still pegged to basic human assumptions. They’re just automated. And automated assumptions—if you don’t fix the bias, then you’re just automating the bias.”&lt;/p&gt;
&lt;p&gt;The comments were highlighted on Twitter by Ryan Saavedra, a reporter for the conservative Daily Wire, who commented: “Socialist Rep. Alexandria Ocasio-Cortez (D-NY) claims that algorithms, which are driven by math, are racist.”&lt;/p&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; data-width=&quot;550&quot; data-dnt=&quot;true&quot; readability=&quot;8.5027027027027&quot;&gt;
&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Socialist Rep. Alexandria Ocasio-Cortez (D-NY) claims that algorithms, which are driven by math, are racist &lt;a href=&quot;https://t.co/X2veVvAU1H&quot;&gt;pic.twitter.com/X2veVvAU1H&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;— Ryan Saavedra (@RealSaavedra) &lt;a href=&quot;https://twitter.com/RealSaavedra/status/1087627739861897216?ref_src=twsrc%5Etfw&quot;&gt;January 22, 2019&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The implication of Saavedra’s attempted rebuttal (which was followed by a &lt;a href=&quot;https://twitter.com/RealSaavedra/status/1087843247840358400&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;classic double-down&lt;/a&gt;) is that mathematics constitutes a kind of objective truth, unswayed by the flawed nature of human judgment. That’s a notion that’s quite widespread in crypto circles, though not usually directly linked to the issue of racism. It’s also total horseshit, and deeply dangerous.&lt;/p&gt;
&lt;p&gt;Anyone with even a tangential familiarity with computer science will recognize that Saavedra’s counterpoint is based on a fundamental misunderstanding of the nature of computers in general, and artificial intelligence in particular. Rather than emotionless, all-seeing eyes, machine-learning algorithms are better thought of as blind, deaf, silicon-based infants, being fed information about how humans think until they can crudely imitate those patterns.&lt;/p&gt;
&lt;p&gt;Both the data used to train these systems, and the training practices themselves, can pass on human biases about race. Some varieties of the facial-recognition software Ocasio-Cortez was referring to, for example, have been found by MIT and Microsoft researchers to &lt;a href=&quot;http://proceedings.mlr.press/v81/buolamwini18a/buolamwini18a.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;misidentify dark-skinned people&lt;/a&gt; at vastly higher rates than light-skinned people. That’s a near-perfect analogue of white people’s tendency to misidentify people of color, leading to higher rates of &lt;a href=&quot;https://www.nytimes.com/2015/09/20/nyregion/the-science-behind-they-all-look-alike-to-me.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;false arrest&lt;/a&gt; and &lt;a href=&quot;https://www.vox.com/policy-and-politics/2017/3/7/14834454/exoneration-innocence-prison-racism&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;conviction&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It’s hard to describe that as anything other than “a racist algorithm,” but humans are ultimately to blame—apparently the flaw came about because the data sets used to train the software had far more &lt;a href=&quot;https://www.veridiumid.com/blog/racial-profiling-and-biometrics/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;light-skinned males&lt;/a&gt; than members of other groups. Bias can find its way into algorithms in many different ways, though: another great example (&lt;a href=&quot;https://twitter.com/benjaminopowers/status/1087876426660044800&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;highlighted&lt;/a&gt; by our new intern Benjamin Powers), was a recruiting tool built by Amazon that simply reproduced human recruiters’ bias towards male job-seekers, because it was only trained using selections made by humans biased towards male job-seekers.&lt;/p&gt;
&lt;p&gt;And it’s not all about race and gender. Saavedra was quickly confronted with clear examples of how right Ocasio-Cortez was . . . directly from his own Twitter feed. Saavedra had &lt;a href=&quot;https://twitter.com/OsitaNwanevu/status/1087841319219802113&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;repeatedly complained&lt;/a&gt; about supposed bias in social media algorithms, including tweeting that “tech companies tend to be liberal &amp;amp; something is off with their algorithms because they won’t show a lot of content I find by manual search.” There’s not much evidence for this claim of anti-conservative algorithmic bias—content algorithms seem to favor &lt;a href=&quot;http://fortune.com/2018/03/11/youtube-extreme-content/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;extremism in general&lt;/a&gt; more than any particular ideology. But Saavedra is clearly happy to echo Ocasio-Cortez’ points about algorithmic bias, when it suits his narrative.&lt;/p&gt;
&lt;p&gt;In short, algorithms aimed at making subtle decisions involving human beings are, mostly, really good at repeating human errors, very fast, many times over.&lt;/p&gt;
&lt;p&gt;This matters immensely for blockchain entrepreneurs, whose rhetoric often implicitly echoes the idea that math is inherently infallible. That’s perhaps best summed up by the mantra that “code is law” among smart-contracts advocates, a phrase which threatens to conflate the &lt;em&gt;inflexibility&lt;/em&gt; of blockchain transactions with &lt;em&gt;infallibility—&lt;/em&gt;two extremely different things. That blurring might be made easier because crypto is premised on a particular case where code is, in a very limited sense, infallible—cryptography. Cryptography doesn’t involve any real judgment or decision-making, just numerical matching: A hash or a private key are either right or wrong.&lt;/p&gt;
&lt;p&gt;But that clarity fails pretty quickly as you move into more complex realms of human life, and crypto and blockchain efforts are aimed at some areas where bias is a clear risk, most obviously finance. Loan and credit decisions have historically been highly subject to human racial and gender bias, and there’s concern that the existing credit-rating system may contain algorithmic elements that &lt;a href=&quot;https://www.theatlantic.com/technology/archive/2016/12/how-algorithms-can-bring-down-minorities-credit-scores/509333/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;perpetuate racial bias&lt;/a&gt;. If crypto hopes to break down the power imbalances built into the legacy banking system, that seems like a decent place to put some energy.&lt;/p&gt;
&lt;p&gt;It’s also worth noting that there’s something much deeper to the specifically conservative yearning for a perfect, neutral, algorithmic decision-maker. The nature of that yearning may be best captured in the writing of Eliezer Yudkowski, an AI theorist and philosopher. Yudkowski has for more than a decade pursued the possibility of perfect human reasoning, while also believing that we will inevitably create an all-knowing artificial intelligence that will become a sort of super-rational God.&lt;/p&gt;
&lt;p&gt;Saavedra, with his tweet about how algorithms “driven by math” can’t be racist, was echoing Yudkowski’s unending faith in the perfectibility of reason and reasoning technology. It turns out that the possibility that ethics can be computerized and formalized is pretty appealing to arch-conservatives, and Yudkowski’s thought constitutes a core pillar for the Silicon Valley wing of &lt;a href=&quot;https://breakermag.com/heres-the-dark-enlightenment-explainer-you-never-wanted/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;neo-reactionaries&lt;/a&gt; who often refer to themselves as “rationalists.”&lt;/p&gt;
&lt;p&gt;Yudkowski’s rationalism is also, notoriously, fatally flawed: His system of coldly logical reason was by many accounts completely undone by a logical paradox known as &lt;a href=&quot;https://rationalwiki.org/wiki/Roko%27s_basilisk&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Roko’s Basilisk&lt;/a&gt;. The thought experiment is too complicated to unpack here. But it boils down to the irrefutable conclusion, if one proceeds from Yudkowski’s own premises, that any future super-intelligent AI, even a “friendly” one, would endlessly torture a simulated copy of any human that hadn’t worked to create it.&lt;/p&gt;
&lt;p&gt;That’s a hell of an endpoint for a system of thought aimed at creating a future rationalist utopia. For super-nerd bonus points, it’s also arguably a spin on Godel’s &lt;a href=&quot;https://en.wikipedia.org/wiki/G%C3%B6del%27s_incompleteness_theorems&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;incompleteness theorem&lt;/a&gt;, which proved that no purely rational algorithmic system can completely and consistently model reality, or prove its own rationality. The whole thing is worth reading about in the excellent book &lt;em&gt;&lt;a href=&quot;https://www.amazon.com/Neoreaction-Basilisk-Essays-Around-Alt-Right-ebook/dp/B0782JDGVQ/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Neoreaction A Basilisk&lt;/a&gt;.&lt;/em&gt; But the takeaway is clear enough: Just because something is expressed in numbers doesn’t make it right, or even rational. And rationality itself might not be quite what it’s cracked up to be.&lt;/p&gt;
</description>
<pubDate>Wed, 23 Jan 2019 18:59:24 +0000</pubDate>
<dc:creator>StellarTabi</dc:creator>
<og:type>article</og:type>
<og:title>Alexandria Ocasio-Cortez Is Absolutely Right About Racist Algorithms</og:title>
<og:url>https://breakermag.com/alexandria-ocasio-cortez-is-absolutely-right-about-racist-algorithms/</og:url>
<og:description>It might sound ridiculous to say math can be racist. But when we rely on it to make decisions, it's just as flawed as we are.</og:description>
<og:image>https://breakermag.com/wp-content/uploads/2019/01/Screen-Shot-2019-01-23-at-12.58.13-PM.png?w=327</og:image>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://breakermag.com/alexandria-ocasio-cortez-is-absolutely-right-about-racist-algorithms/</dc:identifier>
</item>
<item>
<title>Oracle allegedly underpaid $400M in wages to underrepresented employees</title>
<link>https://techcrunch.com/2019/01/22/oracle-discrimination-400-million/</link>
<guid isPermaLink="true" >https://techcrunch.com/2019/01/22/oracle-discrimination-400-million/</guid>
<description>&lt;p id=&quot;speakable-summary&quot;&gt;&lt;a class=&quot;crunchbase-link&quot; href=&quot;https://crunchbase.com/organization/oracle&quot; target=&quot;_blank&quot; data-type=&quot;organization&quot; data-entity=&quot;oracle&quot;&gt;Oracle&lt;/a&gt; has allegedly withheld $400 million in wages from racially underrepresented workers (black, Latinx and Asian) as well as women, &lt;a href=&quot;http://src.bna.com/EXa&quot;&gt;the U.S. Department of Labor’s Office of Federal Contract Compliance Programs said in a filing today&lt;/a&gt;. The OFCCP is the office within the DOL that enforces equal pay and ensures government contractors comply with anti-discrimination regulation.&lt;/p&gt;
&lt;p&gt;In the OFCCP’s second amended complaint today, the office alleges Oracle “impermissibly denies equal employment opportunity to non-Asian applicants for employment, strongly preferring a workforce that it can later underpay. Once employed, women, Blacks and Asians are systematically underpaid relative to their peers,” the complaint alleges.&lt;/p&gt;
&lt;p&gt;Allegedly, Oracle’s underpayment of certain employees is driven by the company’s reliance on prior salary information and funneling non-white, non-male employees into lower-paid roles.&lt;/p&gt;
&lt;p&gt;The department argues that Oracle’s “stark patterns of discrimination” started back in 2013 and continues into the present day. More specifically, the OFCCP alleges Oracle discriminated against black, Asian and female employees. This has all ultimately resulted in the collective loss of more than $400 million for this group of employees, the suit alleges.&lt;/p&gt;
&lt;p&gt;The office also alleges Oracle discriminates against those who have visas, often putting them in low-level jobs. The vast majority of hires from Oracle’s college recruiting program, the suit alleges, were international students with student visas.&lt;/p&gt;
&lt;p&gt;“These students required work authorization to remain in the United States after graduation,” the suit alleges. “In other words, Oracle overwhelmingly hires workers dependent upon Oracle for sponsorship to remain in the United States.”&lt;/p&gt;
&lt;p&gt;The OFCCP filed the suit against Oracle last January, following the Labor Department’s 2014 audit of the company. &lt;a href=&quot;https://techcrunch.com/2017/09/29/former-oracle-employees-sue-company-for-alleged-pay-discrimination/&quot;&gt;That suit was followed by an employee-led class-action lawsuit&lt;/a&gt; last September alleging Oracle pays women less than men in similar jobs.&lt;/p&gt;
&lt;p&gt;Oracle is subject to auditing as a result of its contracts with the federal government. Given Oracle’s agreement to provide equal employment opportunity, the OFCCP is asking the Court to require Oracle to pay those affected and correct its “discriminatory compensation and hiring practices.” The office is also demanding that Oracle lose its $100 million worth of annual contracts with the government.&lt;/p&gt;
&lt;p&gt;Oracle, which declined to comment for this story, is not the only company the OFCCP has gone after. A couple of years ago, &lt;a href=&quot;https://techcrunch.com/2017/01/05/the-u-s-department-of-labor-is-suing-google-for-compensation-data/&quot;&gt;the office went after Google&lt;/a&gt; in an attempt to obtain compensation data, followed by a claim that Google has systemic gender-based pay inequities. That same year, the office &lt;a href=&quot;https://techcrunch.com/2016/09/26/u-s-department-of-labor-sues-palantir-for-racial-discrimination/&quot;&gt;sued Palantir for racial discrimination&lt;/a&gt;. Palantir, several months later, &lt;a href=&quot;https://techcrunch.com/2017/04/25/palantir-settles-racial-discrimination-lawsuit-with-the-department-of-labor/&quot;&gt;settled with the DOL&lt;/a&gt;, agreeing to pay $1.7 million in back wages and other types of monetary relief to those affected.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Update Jan 23. 2019: &lt;/strong&gt;Oracle has since decided to comment. See story below.&lt;/p&gt;



</description>
<pubDate>Wed, 23 Jan 2019 17:55:52 +0000</pubDate>
<dc:creator>samfisher83</dc:creator>
<og:title>Oracle allegedly withheld $400 million in wages from underrepresented employees</og:title>
<og:description>Oracle has allegedly withheld $400 million in wages from racially underrepresented workers (black, Latinx and Asian) as well as women, the U.S. Department of Labor’s Office of Federal Contract Compliance Programs said in a filing today. The OFCCP is the office within the DOL that enforces equ…</og:description>
<og:image>https://techcrunch.com/wp-content/uploads/2016/07/gettyimages-494272836.jpg?w=599</og:image>
<og:url>http://social.techcrunch.com/2019/01/22/oracle-discrimination-400-million/</og:url>
<og:type>article</og:type>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://techcrunch.com/2019/01/22/oracle-discrimination-400-million/</dc:identifier>
</item>
<item>
<title>New Dell XPS 13 developer edition now available</title>
<link>https://bartongeorge.io/2019/01/23/the-new-dell-xps-13-developer-edition-now-available-in-the-us-europe-and-canada/</link>
<guid isPermaLink="true" >https://bartongeorge.io/2019/01/23/the-new-dell-xps-13-developer-edition-now-available-in-the-us-europe-and-canada/</guid>
<description>&lt;p&gt;Last January the Dell XPS 13 developer edition (9370) made its debut.  Today we’re excited to announce that one year later its successor, the &lt;a href=&quot;https://www.dell.com/en-us/work/shop/laptops/new-13-9380/spd/xps-13-9380-laptop?appliedRefinements=302&quot;&gt;XPS 13 developer edition (9380)&lt;/a&gt;, is now available in the US, Canada and Europe.  (Note: both the 9370 and 9380 will coexist for a period of time.)&lt;strong&gt;&lt;a href=&quot;https://bartongeorge.io/2019/01/23/the-new-dell-xps-13-developer-edition-now-available-in-the-us-europe-and-canada/will-9380-18-04-cropped/&quot; rel=&quot;attachment wp-att-10140&quot;&gt;&lt;img data-attachment-id=&quot;10140&quot; data-permalink=&quot;https://bartongeorge.io/2019/01/23/the-new-dell-xps-13-developer-edition-now-available-in-the-us-europe-and-canada/will-9380-18-04-cropped/&quot; data-orig-file=&quot;https://barton808.files.wordpress.com/2019/01/will-9380-18.04-cropped.png&quot; data-orig-size=&quot;525,309&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;0&amp;quot;}&quot; data-image-title=&quot;will 9380 + 18.04 cropped&quot; data-image-description=&quot;&quot; data-medium-file=&quot;https://barton808.files.wordpress.com/2019/01/will-9380-18.04-cropped.png?w=300&quot; data-large-file=&quot;https://barton808.files.wordpress.com/2019/01/will-9380-18.04-cropped.png?w=450&amp;amp;h=265&quot; class=&quot;aligncenter size-large wp-image-10140&quot; src=&quot;https://barton808.files.wordpress.com/2019/01/will-9380-18.04-cropped.png?w=450&amp;amp;h=265&quot; alt=&quot;&quot; width=&quot;450&quot; height=&quot;265&quot; srcset=&quot;https://barton808.files.wordpress.com/2019/01/will-9380-18.04-cropped.png?w=450&amp;amp;h=265 450w, https://barton808.files.wordpress.com/2019/01/will-9380-18.04-cropped.png?w=150&amp;amp;h=88 150w, https://barton808.files.wordpress.com/2019/01/will-9380-18.04-cropped.png?w=300&amp;amp;h=177 300w, https://barton808.files.wordpress.com/2019/01/will-9380-18.04-cropped.png 525w&quot; sizes=&quot;(max-width: 450px) 100vw, 450px&quot;/&gt;&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Project Sputnik&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The 9380 represents the eighth generation of Dell’s Ubuntu-based XPS 13 developer edition series.  The first generation of the developer edition &lt;a href=&quot;https://bartongeorge.io/2012/11/29/sputnik-has-landed-introducing-the-dell-xps-13-laptop-developer-edition/&quot;&gt;debuted&lt;/a&gt; over six years ago and it, along with the Ubuntu-based Precision mobile workstations that &lt;a href=&quot;https://bartongeorge.io/2015/01/27/welcome-the-dell-precision-m3800-mobile-workstation-developer-edition/&quot;&gt;launched in 2015&lt;/a&gt;, make up &lt;a href=&quot;https://bartongeorge.io/2017/11/29/project-sputnik-turns-five/&quot;&gt;Project Sputnik&lt;/a&gt;.  In case you’re not familiar with it, Project Sputnik is Dell’s skunkworks initiative driven by input from the developer community (see the timeline at the end of the post for the complete XPS 13 developer edition progression).&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;&lt;a href=&quot;https://www.dell.com/en-us/work/shop/laptops/new-13-9380/spd/xps-13-9380-laptop?appliedRefinements=302&quot;&gt;Dell XPS 13 developer edition (9380)&lt;/a&gt; — &lt;/strong&gt;&lt;strong&gt;System highlights&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Although there are many great features and specs that characterize the latest developer edition (see below), the one that will likely bring the most joy is the new placement of the webcam.  In the 9370 the camera is located directly below the screen.  In the new 9380 the camera has been moved to the top, providing a much more flattering view of the user while still maintaining the system’s sleek, compact design.&lt;/p&gt;
&lt;p&gt;Not only that but the 8&lt;sup&gt;th&lt;/sup&gt; generation developer edition supports Suspend-to-idle natively which allows the system to resume much more quickly from sleep.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; 9380 Specifications&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Intel 8&lt;sup&gt;th&lt;/sup&gt; generation i3, i5 and i7 processors (Intel Whiskey Lake U, 15W, non-vPro)&lt;/li&gt;
&lt;li&gt;Ubuntu 18.04 LTS preloaded&lt;/li&gt;
&lt;li&gt;InfinityEdge display with top camera placement&lt;/li&gt;
&lt;li&gt;Easier to open&lt;/li&gt;
&lt;li&gt;FHD and UHD resolution support&lt;/li&gt;
&lt;li&gt;Up to 16GB of LPDDR3 memory at 2133MHz&lt;/li&gt;
&lt;li&gt;1 x NVMe slot for 2230-128GB / 2280 up to 2TB&lt;/li&gt;
&lt;li&gt;Thunderbolt 3 (x2) with USB3.1 Gen2 + type-C x1 with USB3.1 Gen2 speed&lt;/li&gt;
&lt;li&gt;Improved Thunderbolt runtime power management&lt;/li&gt;
&lt;li&gt;Killer&lt;sup&gt;®&lt;/sup&gt; 1435 802.11ac [2×2] + Bluetooth 4.2&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;&lt;strong&gt;The United States and Canada &lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;In the US and Canada there are four base configs that can be configured in a multitude of ways, yielding 22 configurations.  These base configs are:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;i7 QC|8GB|256GB|FHD T&lt;/li&gt;
&lt;li&gt;i7 QC|8GB|256GB|UHD T&lt;/li&gt;
&lt;li&gt;i7 QC|16GB|512GB|UHD T&lt;/li&gt;
&lt;li&gt;i7 QC|16GB|256GB|UHD T&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;(Note: unlike Europe, in the United States and Canada the developer edition can only be purchased in the “For Work” section.)&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;Europe&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Beating the US and Canada to the punch, on January 9&lt;sup&gt;th&lt;/sup&gt; the first configurations of the new XPS 13 developer edition became available in Europe.  At the end of last week two more joined to complete the lineup:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;i7 QC|16GB|512GB|UHD T&lt;/li&gt;
&lt;li&gt;i7 QC|16GB|1TB|UHD T&lt;/li&gt;
&lt;li&gt;i7 QC|8GB|256GB|FHD NT&lt;/li&gt;
&lt;li&gt;i7 QC|16GB|512GB|FHD NT&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;The above configurations are available in both the “For Home” and “For Work” sections on Dell.com and are available online in the following countries:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Austria&lt;/li&gt;
&lt;li&gt;Belgium (Dutch and French)&lt;/li&gt;
&lt;li&gt;Switzerland (German and French)&lt;/li&gt;
&lt;li&gt;Germany&lt;/li&gt;
&lt;li&gt;Denmark&lt;/li&gt;
&lt;li&gt;Spain&lt;/li&gt;
&lt;li&gt;France&lt;/li&gt;
&lt;li&gt;Ireland&lt;/li&gt;
&lt;li&gt;Italy&lt;/li&gt;
&lt;li&gt;The Netherlands&lt;/li&gt;
&lt;li&gt;Norway&lt;/li&gt;
&lt;li&gt;Sweden&lt;/li&gt;
&lt;li&gt;The United Kingdom &lt;em&gt;&amp;lt;- The developer editions will be added to shortly to the 9380 product page.  Until then, the systems can be purchased via chat on the product page or by calling the number that pops up.&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;&lt;strong&gt;Stay tuned&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Being able to announce the next generation of the XPS 13 developer edition is a great way to begin the year.  Watch this space to see what is next on the agenda for 2019.&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;XPS 13 developer edition timeline&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;2012&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2013&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2015&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;4th gen Dell XPS 13 developer edition in US and Europe — &lt;a href=&quot;http://bartongeorge.net/2015/04/09/4th-gen-dell-xps-13-developer-edition-available/&quot;&gt;April 9, 2015&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;2016&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2018&lt;/strong&gt;&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;Extra-credit reading&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;Exclusive: Dell Opens Up About Its Linux Efforts And Project Sputnik – &lt;a href=&quot;https://www.forbes.com/sites/jasonevangelho/2019/01/14/exclusive-dell-opens-up-about-its-linux-efforts-and-project-sputnik/#4f12c4545264&quot;&gt;Forbes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Dell Shipped Linux On 162 Unique Platforms In Fiscal Year 2019 – &lt;a href=&quot;https://www.forbes.com/sites/jasonevangelho/2019/01/10/dell-shipped-linux-on-162-unique-platforms-in-fiscal-year-2019/#5d6570c31593&quot;&gt;Forbes&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Pau for now…&lt;/p&gt;
&lt;div id=&quot;jp-post-flair&quot; class=&quot;sharedaddy sd-rating-enabled sd-like-enabled sd-sharing-enabled&quot;&gt;
&lt;div class=&quot;sharedaddy sd-sharing-enabled&quot;&gt;
&lt;div class=&quot;robots-nocontent sd-block sd-social sd-social-icon-text sd-sharing&quot;&gt;
&lt;h3 class=&quot;sd-title&quot;&gt;Share this:&lt;/h3&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sharedaddy sd-block sd-like jetpack-likes-widget-wrapper jetpack-likes-widget-unloaded&quot; id=&quot;like-post-wrapper-4695609-10123-5c49000115317&quot; data-src=&quot;//widgets.wp.com/likes/index.html?ver=20180319#blog_id=4695609&amp;amp;post_id=10123&amp;amp;origin=barton808.wordpress.com&amp;amp;obj_id=4695609-10123-5c49000115317&quot; data-name=&quot;like-post-frame-4695609-10123-5c49000115317&quot;&gt;
&lt;h3 class=&quot;sd-title&quot;&gt;Like this:&lt;/h3&gt;
&lt;p&gt;&lt;span class=&quot;button&quot;&gt;&lt;span&gt;Like&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;loading&quot;&gt;Loading...&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;
&lt;h3 class=&quot;jp-relatedposts-headline&quot;&gt;&lt;em&gt;Related&lt;/em&gt;&lt;/h3&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;p class=&quot;postmetadata alt&quot;&gt;&lt;small&gt;This entry was posted on Wednesday, January 23rd, 2019 at 10:01 am and is filed under &lt;a href=&quot;https://bartongeorge.io/category/uncategorized/&quot; rel=&quot;category tag&quot;&gt;Uncategorized&lt;/a&gt;. You can follow any responses to this entry through the &lt;a href=&quot;https://bartongeorge.io/2019/01/23/the-new-dell-xps-13-developer-edition-now-available-in-the-us-europe-and-canada/feed/&quot;&gt;RSS 2.0&lt;/a&gt; feed. You can &lt;a href=&quot;https://bartongeorge.io/2019/01/23/the-new-dell-xps-13-developer-edition-now-available-in-the-us-europe-and-canada/#respond&quot;&gt;leave a response&lt;/a&gt;, or &lt;a href=&quot;https://bartongeorge.io/2019/01/23/the-new-dell-xps-13-developer-edition-now-available-in-the-us-europe-and-canada/trackback/&quot; rel=&quot;trackback&quot;&gt;trackback&lt;/a&gt; from your own site.&lt;/small&gt;&lt;/p&gt;
&lt;nav id=&quot;nav-below&quot;&gt;&lt;h3 class=&quot;assistive-text&quot;&gt;Post navigation&lt;/h3&gt;
&lt;span class=&quot;nav-previous&quot;&gt;&lt;a href=&quot;https://bartongeorge.io/2018/12/17/ubuntu-18-04-lts-now-available-on-dell-precision-mobile-workstations/&quot; rel=&quot;prev&quot;&gt;« Previous Post&lt;/a&gt;&lt;/span&gt;&lt;/nav&gt;</description>
<pubDate>Wed, 23 Jan 2019 17:43:15 +0000</pubDate>
<dc:creator>sahaskatta</dc:creator>
<og:type>article</og:type>
<og:title>The new Dell XPS 13 developer edition now available in the US, Europe and Canada</og:title>
<og:url>https://bartongeorge.io/2019/01/23/the-new-dell-xps-13-developer-edition-now-available-in-the-us-europe-and-canada/</og:url>
<og:description>Last January the Dell XPS 13 developer edition (9370) made its debut.  Today we’re excited to announce that one year later its successor, the XPS 13 developer edition (9380), is now available…</og:description>
<og:image>https://barton808.files.wordpress.com/2019/01/will-9380-18.04-cropped.png</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://bartongeorge.io/2019/01/23/the-new-dell-xps-13-developer-edition-now-available-in-the-us-europe-and-canada/</dc:identifier>
</item>
<item>
<title>Why are glasses so expensive? The eyewear industry prefers to keep that blurry</title>
<link>https://www.latimes.com/business/lazarus/la-fi-lazarus-why-are-eyeglasses-so-expensive-20190122-story.html#nws=mcnewsletter</link>
<guid isPermaLink="true" >https://www.latimes.com/business/lazarus/la-fi-lazarus-why-are-eyeglasses-so-expensive-20190122-story.html#nws=mcnewsletter</guid>
<description>[unable to retrieve full-text content]
&lt;p&gt;Article URL: &lt;a href=&quot;https://www.latimes.com/business/lazarus/la-fi-lazarus-why-are-eyeglasses-so-expensive-20190122-story.html#nws=mcnewsletter&quot;&gt;https://www.latimes.com/business/lazarus/la-fi-lazarus-why-are-eyeglasses-so-expensive-20190122-story.html#nws=mcnewsletter&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Comments URL: &lt;a href=&quot;https://news.ycombinator.com/item?id=18980191&quot;&gt;https://news.ycombinator.com/item?id=18980191&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Points: 558&lt;/p&gt;
&lt;p&gt;# Comments: 392&lt;/p&gt;
</description>
<pubDate>Wed, 23 Jan 2019 17:16:46 +0000</pubDate>
<dc:creator>prostoalex</dc:creator>
<og:url>https://www.latimes.com/business/lazarus/la-fi-lazarus-why-are-eyeglasses-so-expensive-20190122-story.html</og:url>
<og:title>Why are glasses so expensive? The eyewear industry prefers to keep that blurry</og:title>
<og:image>https://www.latimes.com/resizer/hwEpgye3WXu0f5SJe3HBee81RKQ=/1200x0/arc-anglerfish-arc2-prod-tronc.s3.amazonaws.com/public/XKVLQT5A4VGUZCMILSSP2BL6VU.jpg</og:image>
<og:description>Eyewear is a near-monopolistic, $100-billion industry dominated by a single company. That's why 1,000% markups for frames and lenses are commonplace.</og:description>
<og:type>article</og:type>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.latimes.com/business/lazarus/la-fi-lazarus-why-are-eyeglasses-so-expensive-20190122-story.html</dc:identifier>
</item>
<item>
<title>Our Software Dependency Problem</title>
<link>https://research.swtch.com/deps</link>
<guid isPermaLink="true" >https://research.swtch.com/deps</guid>
<description>&lt;p&gt;For decades, discussion of software reuse was far more common than actual software reuse. Today, the situation is reversed: developers reuse software written by others every day, in the form of software dependencies, and the situation goes mostly unexamined.&lt;/p&gt;
&lt;p&gt;My own background includes a decade of working with Google’s internal source code system, which treats software dependencies as a first-class concept,&lt;a class=&quot;footnote&quot; id=&quot;body1&quot; href=&quot;https://research.swtch.com/deps#note1&quot;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; and also developing support for dependencies in the Go programming language.&lt;a class=&quot;footnote&quot; id=&quot;body2&quot; href=&quot;https://research.swtch.com/deps#note2&quot;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Software dependencies carry with them serious risks that are too often overlooked. The shift to easy, fine-grained software reuse has happened so quickly that we do not yet understand the best practices for choosing and using dependencies effectively, or even for deciding when they are appropriate and when not. My purpose in writing this article is to raise awareness of the risks and encourage more investigation of solutions.&lt;/p&gt;

&lt;p&gt;In today’s software development world, a &lt;em&gt;dependency&lt;/em&gt; is additional code that you want to call from your program. Adding a dependency avoids repeating work already done: designing, writing, testing, debugging, and maintaining a specific unit of code. In this article we’ll call that unit of code a &lt;em&gt;package&lt;/em&gt;; some systems use terms like library or module instead of package.&lt;/p&gt;
&lt;p&gt;Taking on externally-written dependencies is an old practice: most programmers have at one point in their careers had to go through the steps of manually downloading and installing a required library, like C’s PCRE or zlib, or C++’s Boost or Qt, or Java’s JodaTime or JUnit. These packages contain high-quality, debugged code that required significant expertise to develop. For a program that needs the functionality provided by one of these packages, the tedious work of manually downloading, installing, and updating the package is easier than the work of redeveloping that functionality from scratch. But the high fixed costs of reuse mean that manually-reused packages tend to be big: a tiny package would be easier to reimplement.&lt;/p&gt;
&lt;p&gt;A &lt;em&gt;dependency manager&lt;/em&gt; (sometimes called a package manager) automates the downloading and installation of dependency packages. As dependency managers make individual packages easier to download and install, the lower fixed costs make smaller packages economical to publish and reuse.&lt;/p&gt;
&lt;p&gt;For example, the Node.js dependency manager NPM provides access to over 750,000 packages. One of them, &lt;code&gt;escape-string-regexp&lt;/code&gt;, provides a single function that escapes regular expression operators in its input. The entire implementation is:&lt;/p&gt;
&lt;pre&gt;
var matchOperatorsRe = /[|\\{}()[\]^$+*?.]/g;

module.exports = function (str) {
        if (typeof str !== 'string') {
                throw new TypeError('Expected a string');
        }
        return str.replace(matchOperatorsRe, '\\$&amp;amp;');
};
&lt;/pre&gt;
&lt;p&gt;Before dependency managers, publishing an eight-line code library would have been unthinkable: too much overhead for too little benefit. But NPM has driven the overhead approximately to zero, with the result that nearly-trivial functionality can be packaged and reused. In late January 2019, the &lt;code&gt;escape-string-regexp&lt;/code&gt; package is explicitly depended upon by almost a thousand other NPM packages, not to mention all the packages developers write for their own use and don’t share.&lt;/p&gt;
&lt;p&gt;Dependency managers now exist for essentially every programming language. Maven Central (Java), Nuget (.NET), Packagist (PHP), PyPI (Python), and RubyGems (Ruby) each host over 100,000 packages. The arrival of this kind of fine-grained, widespread software reuse is one of the most consequential shifts in software development over the past two decades. And if we’re not more careful, it will lead to serious problems.&lt;/p&gt;

&lt;p&gt;A package, for this discussion, is code you download from the internet. Adding a package as a dependency outsources the work of developing that code—designing, writing, testing, debugging, and maintaining—to someone else on the internet, someone you often don’t know. By using that code, you are exposing your own program to all the failures and flaws in the dependency. Your program’s execution now literally &lt;em&gt;depends&lt;/em&gt; on code downloaded from this stranger on the internet. Presented this way, it sounds incredibly unsafe. Why would anyone do this?&lt;/p&gt;
&lt;p&gt;We do this because it’s easy, because it seems to work, because everyone else is doing it too, and, most importantly, because it seems like a natural continuation of age-old established practice. But there are important differences we’re ignoring.&lt;/p&gt;
&lt;p&gt;Decades ago, most developers already trusted others to write software they depended on, such as operating systems and compilers. That software was bought from known sources, often with some kind of support agreement. There was still a potential for bugs or outright mischief,&lt;a class=&quot;footnote&quot; id=&quot;body3&quot; href=&quot;https://research.swtch.com/deps#note3&quot;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt; but at least we knew who we were dealing with and usually had commercial or legal recourses available.&lt;/p&gt;
&lt;p&gt;The phenomenon of open-source software, distributed at no cost over the internet, has displaced many of those earlier software purchases. When reuse was difficult, there were fewer projects publishing reusable code packages. Even though their licenses typically disclaimed, among other things, any “implied warranties of merchantability and fitness for a particular purpose,” the projects built up well-known reputations that often factored heavily into people’s decisions about which to use. The commercial and legal support for trusting our software sources was replaced by reputational support. Many common early packages still enjoy good reputations: consider BLAS (published 1979), Netlib (1987), libjpeg (1991), LAPACK (1992), HP STL (1994), and zlib (1995).&lt;/p&gt;
&lt;p&gt;Dependency managers have scaled this open-source code reuse model down: now, developers can share code at the granularity of individual functions of tens of lines. This is a major technical accomplishment. There are myriad available packages, and writing code can involve such a large number of them, but the commercial, legal, and reputational support mechanisms for trusting the code have not carried over. We are trusting more code with less justification for doing so.&lt;/p&gt;
&lt;p&gt;The cost of adopting a bad dependency can be viewed as the sum, over all possible bad outcomes, of the cost of each bad outcome multiplied by its probability of happening (risk).&lt;/p&gt;
&lt;p&gt;&lt;img name=&quot;deps-cost&quot; class=&quot;center pad&quot; width=&quot;383&quot; height=&quot;95&quot; src=&quot;https://research.swtch.com/deps-cost.png&quot; srcset=&quot;deps-cost.png 1x, deps-cost@1.5x.png 1.5x, deps-cost@2x.png 2x, deps-cost@3x.png 3x, deps-cost@4x.png 4x&quot;/&gt;&lt;/p&gt;
&lt;p&gt;The context where a dependency will be used determines the cost of a bad outcome. At one end of the spectrum is a personal hobby project, where the cost of most bad outcomes is near zero: you’re just having fun, bugs have no real impact other than wasting some time, and even debugging them can be fun. So the risk probability almost doesn’t matter: it’s being multiplied by zero. At the other end of the spectrum is production software that must be maintained for years. Here, the cost of a bug in a dependency can be very high: servers may go down, sensitive data may be divulged, customers may be harmed, companies may fail. High failure costs make it much more important to estimate and then reduce any risk of a serious failure.&lt;/p&gt;
&lt;p&gt;No matter what the expected cost, experiences with larger dependencies suggest some approaches for estimating and reducing the risks of adding a software dependency. It is likely that better tooling is needed to help reduce the costs of these approaches, much as dependency managers have focused to date on reducing the costs of download and installation.&lt;/p&gt;

&lt;p&gt;You would not hire a software developer you’ve never heard of and know nothing about. You would learn more about them first: check references, conduct a job interview, run background checks, and so on. Before you depend on a package you found on the internet, it is similarly prudent to learn a bit about it first.&lt;/p&gt;
&lt;p&gt;A basic inspection can give you a sense of how likely you are to run into problems trying to use this code. If the inspection reveals likely minor problems, you can take steps to prepare for or maybe avoid them. If the inspection reveals major problems, it may be best not to use the package: maybe you’ll find a more suitable one, or maybe you need to develop one yourself. Remember that open-source packages are published by their authors in the hope that they will be useful but with no guarantee of usability or support. In the middle of a production outage, you’ll be the one debugging it. As the original GNU General Public License warned, “The entire risk as to the quality and performance of the program is with you. Should the program prove defective, you assume the cost of all necessary servicing, repair or correction.”&lt;a class=&quot;footnote&quot; id=&quot;body4&quot; href=&quot;https://research.swtch.com/deps#note4&quot;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The rest of this section outlines some considerations when inspecting a package and deciding whether to depend on it.&lt;/p&gt;
&lt;h3 id=&quot;design&quot;&gt;&lt;a class=&quot;anchor&quot; href=&quot;https://research.swtch.com/deps#design&quot;&gt;Design&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Is package’s documentation clear? Does the API have a clear design? If the authors can explain the package’s API and its design well to you, the user, in the documentation, that increases the likelihood they have explained the implementation well to the computer, in the source code. Writing code for a clear, well-designed API is also easier, faster, and hopefully less error-prone. Have the authors documented what they expect from client code in order to make future upgrades compatible? (Examples include the C++&lt;a class=&quot;footnote&quot; id=&quot;body5&quot; href=&quot;https://research.swtch.com/deps#note5&quot;&gt;&lt;sup&gt;5&lt;/sup&gt;&lt;/a&gt; and Go&lt;a class=&quot;footnote&quot; id=&quot;body6&quot; href=&quot;https://research.swtch.com/deps#note6&quot;&gt;&lt;sup&gt;6&lt;/sup&gt;&lt;/a&gt; compatibility documents.)&lt;/p&gt;
&lt;h3 id=&quot;code_quality&quot;&gt;&lt;a class=&quot;anchor&quot; href=&quot;https://research.swtch.com/deps#code_quality&quot;&gt;Code Quality&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Is the code well-written? Read some of it. Does it look like the authors have been careful, conscientious, and consistent? Does it look like code you’d want to debug? You may need to.&lt;/p&gt;
&lt;p&gt;Develop your own systematic ways to check code quality. For example, something as simple as compiling a C or C++ program with important compiler warnings enabled (for example, &lt;code&gt;-Wall&lt;/code&gt;) can give you a sense of how seriously the developers work to avoid various undefined behaviors. Recent languages like Go, Rust, and Swift use an &lt;code&gt;unsafe&lt;/code&gt; keyword to mark code that violates the type system; look to see how much unsafe code there is. More advanced semantic tools like Infer&lt;a class=&quot;footnote&quot; id=&quot;body7&quot; href=&quot;https://research.swtch.com/deps#note7&quot;&gt;&lt;sup&gt;7&lt;/sup&gt;&lt;/a&gt; or SpotBugs&lt;a class=&quot;footnote&quot; id=&quot;body8&quot; href=&quot;https://research.swtch.com/deps#note8&quot;&gt;&lt;sup&gt;8&lt;/sup&gt;&lt;/a&gt; are helpful too. Linters are less helpful: you should ignore rote suggestions about topics like brace style and focus instead on semantic problems.&lt;/p&gt;
&lt;p&gt;Keep an open mind to development practices you may not be familiar with. For example, the SQLite library ships as a single 200,000-line C source file and a single 11,000-line header, the “amalgamation.” The sheer size of these files should raise an initial red flag, but closer investigation would turn up the actual development source code, a traditional file tree with over a hundred C source files, tests, and support scripts. It turns out that the single-file distribution is built automatically from the original sources and is easier for end users, especially those without dependency managers. (The compiled code also runs faster, because the compiler can see more optimization opportunities.)&lt;/p&gt;
&lt;h3 id=&quot;testing&quot;&gt;&lt;a class=&quot;anchor&quot; href=&quot;https://research.swtch.com/deps#testing&quot;&gt;Testing&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Does the code have tests? Can you run them? Do they pass? Tests establish that the code’s basic functionality is correct, and they signal that the developer is serious about keeping it correct. For example, the SQLite development tree has an incredibly thorough test suite with over 30,000 individual test cases as well as developer documentation explaining the testing strategy.&lt;a class=&quot;footnote&quot; id=&quot;body9&quot; href=&quot;https://research.swtch.com/deps#note9&quot;&gt;&lt;sup&gt;9&lt;/sup&gt;&lt;/a&gt; On the other hand, if there are few tests or no tests, or if the tests fail, that’s a serious red flag: future changes to the package are likely to introduce regressions that could easily have been caught. If you insist on tests in code you write yourself (you do, right?), you should insist on tests in code you outsource to others.&lt;/p&gt;
&lt;p&gt;Assuming the tests exist, run, and pass, you can gather more information by running them with run-time instrumentation like code coverage analysis, race detection,&lt;a class=&quot;footnote&quot; id=&quot;body10&quot; href=&quot;https://research.swtch.com/deps#note10&quot;&gt;&lt;sup&gt;10&lt;/sup&gt;&lt;/a&gt; memory allocation checking, and memory leak detection.&lt;/p&gt;
&lt;h3 id=&quot;debugging&quot;&gt;&lt;a class=&quot;anchor&quot; href=&quot;https://research.swtch.com/deps#debugging&quot;&gt;Debugging&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Find the package’s issue tracker. Are there many open bug reports? How long have they been open? Are there many fixed bugs? Have any bugs been fixed recently? If you see lots of open issues about what look like real bugs, especially if they have been open for a long time, that’s not a good sign. On the other hand, if the closed issues show that bugs are rarely found and promptly fixed, that’s great.&lt;/p&gt;
&lt;h3 id=&quot;maintenance&quot;&gt;&lt;a class=&quot;anchor&quot; href=&quot;https://research.swtch.com/deps#maintenance&quot;&gt;Maintenance&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Look at the package’s commit history. How long has the code been actively maintained? Is it actively maintained now? Packages that have been actively maintained for an extended amount of time are more likely to continue to be maintained. How many people work on the package? Many packages are personal projects that developers create and share for fun in their spare time. Others are the result of thousands of hours of work by a group of paid developers. In general, the latter kind of package is more likely to have prompt bug fixes, steady improvements, and general upkeep.&lt;/p&gt;
&lt;p&gt;On the other hand, some code really is “done.” For example, NPM’s &lt;code&gt;escape-string-regexp&lt;/code&gt;, shown earlier, may never need to be modified again.&lt;/p&gt;
&lt;h3 id=&quot;usage&quot;&gt;&lt;a class=&quot;anchor&quot; href=&quot;https://research.swtch.com/deps#usage&quot;&gt;Usage&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Do many other packages depend on this code? Dependency managers can often provide statistics about usage, or you can use a web search to estimate how often others write about using the package. More users should at least mean more people for whom the code works well enough, along with faster detection of new bugs. Widespread usage is also a hedge against the question of continued maintenance: if a widely-used package loses its maintainer, an interested user is likely to step forward.&lt;/p&gt;
&lt;p&gt;For example, libraries like PCRE or Boost or JUnit are incredibly widely used. That makes it more likely—although certainly not guaranteed—that bugs you might otherwise run into have already been fixed, because others ran into them first.&lt;/p&gt;
&lt;h3 id=&quot;security&quot;&gt;&lt;a class=&quot;anchor&quot; href=&quot;https://research.swtch.com/deps#security&quot;&gt;Security&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Will you be processing untrusted inputs with the package? If so, does it seem to be robust against malicious inputs? Does it have a history of security problems listed in the National Vulnerability Database (NVD)?&lt;a class=&quot;footnote&quot; id=&quot;body11&quot; href=&quot;https://research.swtch.com/deps#note11&quot;&gt;&lt;sup&gt;11&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For example, when Jeff Dean and I started work on Google Code Search&lt;a class=&quot;footnote&quot; id=&quot;body12&quot; href=&quot;https://research.swtch.com/deps#note12&quot;&gt;&lt;sup&gt;12&lt;/sup&gt;&lt;/a&gt;—&lt;code&gt;grep&lt;/code&gt; over public source code—in 2006, the popular PCRE regular expression library seemed like an obvious choice. In an early discussion with Google’s security team, however, we learned that PCRE had a history of problems like buffer overflows, especially in its parser. We could have learned the same by searching for PCRE in the NVD. That discovery didn’t immediately cause us to abandon PCRE, but it did make us think more carefully about testing and isolation.&lt;/p&gt;
&lt;h3 id=&quot;licensing&quot;&gt;&lt;a class=&quot;anchor&quot; href=&quot;https://research.swtch.com/deps#licensing&quot;&gt;Licensing&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Is the code properly licensed? Does it have a license at all? Is the license acceptable for your project or company? A surprising fraction of projects on GitHub have no clear license. Your project or company may impose further restrictions on the allowed licenses of dependencies. For example, Google disallows the use of code licensed under AGPL-like licenses (too onerous) as well as WTFPL-like licenses (too vague).&lt;a class=&quot;footnote&quot; id=&quot;body13&quot; href=&quot;https://research.swtch.com/deps#note13&quot;&gt;&lt;sup&gt;13&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;dependencies&quot;&gt;&lt;a class=&quot;anchor&quot; href=&quot;https://research.swtch.com/deps#dependencies&quot;&gt;Dependencies&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Does the code have dependencies of its own? Flaws in indirect dependencies are just as bad for your program as flaws in direct dependencies. Dependency managers can list all the transitive dependencies of a given package, and each of them should ideally be inspected as described in this section. A package with many dependencies incurs additional inspection work, because those same dependencies incur additional risk that needs to be evaluated.&lt;/p&gt;
&lt;p&gt;Many developers have never looked at the full list of transitive dependencies of their code and don’t know what they depend on. For example, in March 2016 the NPM user community discovered that many popular projects—including Babel, Ember, and React—all depended indirectly on a tiny package called &lt;code&gt;left-pad&lt;/code&gt;, consisting of a single 8-line function body. They discovered this when the author of &lt;code&gt;left-pad&lt;/code&gt; deleted that package from NPM, inadvertently breaking most Node.js users’ builds.&lt;a class=&quot;footnote&quot; id=&quot;body14&quot; href=&quot;https://research.swtch.com/deps#note14&quot;&gt;&lt;sup&gt;14&lt;/sup&gt;&lt;/a&gt; And &lt;code&gt;left-pad&lt;/code&gt; is hardly exceptional in this regard. For example, 30% of the 750,000 packages published on NPM depend—at least indirectly—on &lt;code&gt;escape-string-regexp&lt;/code&gt;. Adapting Leslie Lamport’s observation about distributed systems, a dependency manager can easily create a situation in which the failure of a package you didn’t even know existed can render your own code unusable.&lt;/p&gt;

&lt;p&gt;The inspection process should include running a package’s own tests. If the package passes the inspection and you decide to make your project depend on it, the next step should be to write new tests focused on the functionality needed by your application. These tests often start out as short standalone programs written to make sure you can understand the package’s API and that it does what you think it does. (If you can’t or it doesn’t, turn back now!) It is worth then taking the extra effort to turn those programs into automated tests that can be run against newer versions of the package. If you find a bug and have a potential fix, you’ll want to be able to rerun these project-specific tests easily, to make sure that the fix did not break anything else.&lt;/p&gt;
&lt;p&gt;It is especially worth exercising the likely problem areas identified by the basic inspection. For Code Search, we knew from past experience that PCRE sometimes took a long time to execute certain regular expression searches. Our initial plan was to have separate thread pools for “simple” and “complicated” regular expression searches. One of the first tests we ran was a benchmark, comparing &lt;code&gt;pcregrep&lt;/code&gt; with a few other &lt;code&gt;grep&lt;/code&gt; implementations. When we found that, for one basic test case, &lt;code&gt;pcregrep&lt;/code&gt; was 70X slower than the fastest &lt;code&gt;grep&lt;/code&gt; available, we started to rethink our plan to use PCRE. Even though we eventually dropped PCRE entirely, that benchmark remains in our code base today.&lt;/p&gt;

&lt;p&gt;Depending on a package is a decision that you are likely to revisit later. Perhaps updates will take the package in a new direction. Perhaps serious security problems will be found. Perhaps a better option will come along. For all these reasons, it is worth the effort to make it easy to migrate your project to a new dependency.&lt;/p&gt;
&lt;p&gt;If the package will be used from many places in your project’s source code, migrating to a new dependency would require making changes to all those different source locations. Worse, if the package will be exposed in your own project’s API, migrating to a new dependency would require making changes in all the code calling your API, which you might not control. To avoid these costs, it makes sense to define an interface of your own, along with a thin wrapper implementing that interface using the dependency. Note that the wrapper should include only what your project needs from the dependency, not everything the dependency offers. Ideally, that allows you to substitute a different, equally appropriate dependency later, by changing only the wrapper. Migrating your per-project tests to use the new interface tests the interface and wrapper implementation and also makes it easy to test any potential replacements for the dependency.&lt;/p&gt;
&lt;p&gt;For Code Search, we developed an abstract &lt;code&gt;Regexp&lt;/code&gt; class that defined the interface Code Search needed from any regular expression engine. Then we wrote a thin wrapper around PCRE implementing that interface. The indirection made it easy to test alternate libraries, and it kept us from accidentally introducing knowledge of PCRE internals into the rest of the source tree. That in turn ensured that it would be easy to switch to a different dependency if needed.&lt;/p&gt;

&lt;p&gt;It may also be appropriate to isolate a dependency at run-time, to limit the possible damage caused by bugs in it. For example, Google Chrome allows users to add dependencies—extension code—to the browser. When Chrome launched in 2008, it introduced the critical feature (now standard in all browsers) of isolating each extension in a sandbox running in a separate operating-system process.&lt;a class=&quot;footnote&quot; id=&quot;body15&quot; href=&quot;https://research.swtch.com/deps#note15&quot;&gt;&lt;sup&gt;15&lt;/sup&gt;&lt;/a&gt; An exploitable bug in an badly-written extension therefore did not automatically have access to the entire memory of the browser itself and could be stopped from making inappropriate system calls.&lt;a class=&quot;footnote&quot; id=&quot;body16&quot; href=&quot;https://research.swtch.com/deps#note16&quot;&gt;&lt;sup&gt;16&lt;/sup&gt;&lt;/a&gt; For Code Search, until we dropped PCRE entirely, our plan was to isolate at least the PCRE parser in a similar sandbox. Today, another option would be a lightweight hypervisor-based sandbox like gVisor.&lt;a class=&quot;footnote&quot; id=&quot;body17&quot; href=&quot;https://research.swtch.com/deps#note17&quot;&gt;&lt;sup&gt;17&lt;/sup&gt;&lt;/a&gt; Isolating dependencies reduces the associated risks of running that code.&lt;/p&gt;
&lt;p&gt;Even with these examples and other off-the-shelf options, run-time isolation of suspect code is still too difficult and rarely done. True isolation would require a completely memory-safe language, with no escape hatch into untyped code. That’s challenging not just in entirely unsafe languages like C and C++ but also in languages that provide restricted unsafe operations, like Java when including JNI, or like Go, Rust, and Swift when including their “unsafe” features. Even in a memory-safe language like JavaScript, code often has access to far more than it needs. In November 2018, the latest version of the NPM package &lt;code&gt;event-stream&lt;/code&gt;, which provided a functional streaming API for JavaScript events, was discovered to contain obfuscated malicious code that had been added two and a half months earlier. The code, which harvested large Bitcoin wallets from users of the Copay mobile app, was accessing system resources entirely unrelated to processing event streams.&lt;a class=&quot;footnote&quot; id=&quot;body18&quot; href=&quot;https://research.swtch.com/deps#note18&quot;&gt;&lt;sup&gt;18&lt;/sup&gt;&lt;/a&gt; One of many possible defenses to this kind of problem would be to better restrict what dependencies can access.&lt;/p&gt;

&lt;p&gt;If a dependency seems too risky and you can’t find a way to isolate it, the best answer may be to avoid it entirely, or at least to avoid the parts you’ve identified as most problematic.&lt;/p&gt;
&lt;p&gt;For example, as we better understood the risks and costs associated with PCRE, our plan for Google Code Search evolved from “use PCRE directly,” to “use PCRE but sandbox the parser,” to “write a new regular expression parser but keep the PCRE execution engine,” to “write a new parser and connect it to a different, more efficient open-source execution engine.” Later we rewrote the execution engine as well, so that no dependencies were left, and we open-sourced the result: RE2.&lt;a class=&quot;footnote&quot; id=&quot;body19&quot; href=&quot;https://research.swtch.com/deps#note19&quot;&gt;&lt;sup&gt;19&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;If you only need a tiny fraction of a dependency, it may be simplest to make a copy of what you need (preserving appropriate copyright and other legal notices, of course). You are taking on responsibility for fixing bugs, maintenance, and so on, but you’re also completely isolated from the larger risks. The Go developer community has a proverb about this: “A little copying is better than a little dependency.”&lt;a class=&quot;footnote&quot; id=&quot;body20&quot; href=&quot;https://research.swtch.com/deps#note20&quot;&gt;&lt;sup&gt;20&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;For a long time, the conventional wisdom about software was “if it ain’t broke, don’t fix it.” Upgrading carries a chance of introducing new bugs; without a corresponding reward—like a new feature you need—why take the risk? This analysis ignores two costs. The first is the cost of the eventual upgrade. In software, the difficulty of making code changes does not scale linearly: making ten small changes is less work and easier to get right than making one equivalent large change. The second is the cost of discovering already-fixed bugs the hard way. Especially in a security context, where known bugs are actively exploited, every day you wait is another day that attackers can break in.&lt;/p&gt;
&lt;p&gt;For example, consider the year 2017 at Equifax, as recounted by executives in detailed congressional testimony.&lt;a class=&quot;footnote&quot; id=&quot;body21&quot; href=&quot;https://research.swtch.com/deps#note21&quot;&gt;&lt;sup&gt;21&lt;/sup&gt;&lt;/a&gt; On March 7, a new vulnerability in Apache Struts was disclosed, and a patched version was released. On March 8, Equifax received a notice from US-CERT about the need to update any uses of Apache Struts. Equifax ran source code and network scans on March 9 and March 15, respectively; neither scan turned up a particular group of public-facing web servers. On May 13, attackers found the servers that Equifax’s security teams could not. They used the Apache Struts vulnerability to breach Equifax’s network and then steal detailed personal and financial information about 148 million people over the next two months. Equifax finally noticed the breach on July 29 and publicly disclosed it on September 4. By the end of September, Equifax’s CEO, CIO, and CSO had all resigned, and a congressional investigation was underway.&lt;/p&gt;
&lt;p&gt;Equifax’s experience drives home the point that although dependency managers know the versions they are using at build time, you need other arrangements to track that information through your production deployment process. For the Go language, we are experimenting with automatically including a version manifest in every binary, so that deployment processes can scan binaries for dependencies that need upgrading. Go also makes that information available at run-time, so that servers can consult databases of known bugs and self-report to monitoring software when they are in need of upgrades.&lt;/p&gt;
&lt;p&gt;Upgrading promptly is important, but upgrading means adding new code to your project, which should mean updating your evaluation of the risks of using the dependency based on the new version. As minimum, you’d want to skim the diffs showing the changes being made from the current version to the upgraded versions, or at least read the release notes, to identify the most likely areas of concern in the upgraded code. If a lot of code is changing, so that the diffs are difficult to digest, that is also information you can incorporate into your risk assessment update.&lt;/p&gt;
&lt;p&gt;You’ll also want to re-run the tests you’ve written that are specific to your project, to make sure the upgraded package is at least as suitable for the project as the earlier version. It also makes sense to re-run the package’s own tests. If the package has its own dependencies, it is entirely possible that your project’s configuration uses different versions of those dependencies (either older or newer ones) than the package’s authors use. Running the package’s own tests can quickly identify problems specific to your configuration.&lt;/p&gt;
&lt;p&gt;Again, upgrades should not be completely automatic. You need to verify that the upgraded versions are appropriate for your environment before deploying them.&lt;a class=&quot;footnote&quot; id=&quot;body22&quot; href=&quot;https://research.swtch.com/deps#note22&quot;&gt;&lt;sup&gt;22&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;If your upgrade process includes re-running the integration and qualification tests you’ve already written for the dependency, so that you are likely to identify new problems before they reach production, then, in most cases, delaying an upgrade is riskier than upgrading quickly.&lt;/p&gt;
&lt;p&gt;The window for security-critical upgrades is especially short. In the aftermath of the Equifax breach, forensic security teams found evidence that attackers (perhaps different ones) had successfully exploited the Apache Struts vulnerability on the affected servers on March 10, only three days after it was publicly disclosed, but they’d only run a single &lt;code&gt;whoami&lt;/code&gt; command.&lt;/p&gt;

&lt;p&gt;Even after all that work, you’re not done tending your dependencies. It’s important to continue to monitor them and perhaps even re-evaluate your decision to use them.&lt;/p&gt;
&lt;p&gt;First, make sure that you keep using the specific package versions you think you are. Most dependency managers now make it easy or even automatic to record the cryptographic hash of the expected source code for a given package version and then to check that hash when re-downloading the package on another computer or in a test environment. This ensures that your build use the same dependency source code you inspected and tested. These kinds of checks prevented the &lt;code&gt;event-stream&lt;/code&gt; attacker, described earlier, from silently inserting malicious code in the already-released version 3.3.5. Instead, the attacker had to create a new version, 3.3.6, and wait for people to upgrade (without looking closely at the changes).&lt;/p&gt;
&lt;p&gt;It is also important to watch for new indirect dependencies creeping in: upgrades can easily introduce new packages upon which the success of your project now depends. They deserve your attention as well. In the case of &lt;code&gt;event-stream&lt;/code&gt;, the malicious code was hidden in a different package, &lt;code&gt;flatmap-stream&lt;/code&gt;, which the new &lt;code&gt;event-stream&lt;/code&gt; release added as a new dependency.&lt;/p&gt;
&lt;p&gt;Creeping dependencies can also affect the size of your project. During the development of Google’s Sawzall&lt;a class=&quot;footnote&quot; id=&quot;body23&quot; href=&quot;https://research.swtch.com/deps#note23&quot;&gt;&lt;sup&gt;23&lt;/sup&gt;&lt;/a&gt;—a JIT’ed logs processing language—the authors discovered at various times that the main interpreter binary contained not just Sawzall’s JIT but also (unused) PostScript, Python, and JavaScript interpreters. Each time, the culprit turned out to be unused dependencies declared by some library Sawzall did depend on, combined with the fact that Google’s build system eliminated any manual effort needed to start using a new dependency.. This kind of error is the reason that the Go language makes importing an unused package a compile-time error.&lt;/p&gt;
&lt;p&gt;Upgrading is a natural time to revisit the decision to use a dependency that’s changing. It’s also important to periodically revisit any dependency that &lt;em&gt;isn’t&lt;/em&gt; changing. Does it seem plausible that there are no security problems or other bugs to fix? Has the project been abandoned? Maybe it’s time to start planning to replace that dependency.&lt;/p&gt;
&lt;p&gt;It’s also important to recheck the security history of each dependency. For example, Apache Struts disclosed different major remote code execution vulnerabilities in 2016, 2017, and 2018. Even if you have a list of all the servers that run it and update them promptly, that track record might make you rethink using it at all.&lt;/p&gt;

&lt;p&gt;Software reuse is finally here, and I don’t mean to understate its benefits: it has brought an enormously positive transformation for software developers. Even so, we’ve accepted this transformation without completely thinking through the potential consequences. The old reasons for trusting dependencies are becoming less valid at exactly the same time we have more dependencies than ever.&lt;/p&gt;
&lt;p&gt;The kind of critical examination of specific dependencies that I outlined in this article is a significant amount of work and remains the exception rather than the rule. But I doubt there are any developers who actually make the effort to do this for every possible new dependency. I have only done a subset of them for a subset of my own dependencies. Most of the time the entirety of the decision is “let’s see what happens.” Too often, anything more than that seems like too much effort.&lt;/p&gt;
&lt;p&gt;But the Copay and Equifax attacks are clear warnings of real problems in the way we consume software dependencies today. We should not ignore the warnings. I offer three broad recommendations.&lt;/p&gt;
&lt;ol readability=&quot;8.5&quot;&gt;&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;&lt;em&gt;Recognize the problem.&lt;/em&gt; If nothing else, I hope this article has convinced you that there is a problem here worth addressing. We need many people to focus significant effort on solving it.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;7&quot;&gt;
&lt;p&gt;&lt;em&gt;Establish best practices for today.&lt;/em&gt; We need to establish best practices for managing dependencies using what’s available today. This means working out processes that evaluate, reduce, and track risk, from the original adoption decision through to production use. In fact, just as some engineers specialize in testing, it may be that we need engineers who specialize in managing dependencies.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;6&quot;&gt;
&lt;p&gt;&lt;em&gt;Develop better dependency technology for tomorrow.&lt;/em&gt; Dependency managers have essentially eliminated the cost of downloading and installing a dependency. Future development effort should focus on reducing the cost of the kind of evaluation and maintenance necessary to use a dependency. For example, package discovery sites might work to find more ways to allow developers to share their findings. Build tools should, at the least, make it easy to run a package’s own tests. More aggressively, build tools and package management systems could also work together to allow package authors to test new changes against all public clients of their APIs. Languages should also provide easy ways to isolate a suspect package.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;There’s a lot of good software out there. Let’s work together to find out how to reuse it safely.&lt;/p&gt;

&lt;ol&gt;&lt;li&gt; Rachel Potvin and Josh Levenberg, “Why Google Stores Billions of Lines of Code in a Single Repository,” &lt;em&gt;Communications of the ACM&lt;/em&gt; 59(7) (July 2016), pp. 78-87. &lt;a href=&quot;https://doi.org/10.1145/2854146&quot;&gt;https://doi.org/10.1145/2854146&lt;/a&gt; &lt;a class=&quot;back&quot; href=&quot;https://research.swtch.com/deps#body1&quot;&gt;(⇡)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt; Russ Cox, “Go &amp;amp; Versioning,” February 2018. &lt;a href=&quot;https://research.swtch.com/vgo&quot;&gt;https://research.swtch.com/vgo&lt;/a&gt; &lt;a class=&quot;back&quot; href=&quot;https://research.swtch.com/deps#body2&quot;&gt;(⇡)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt; Ken Thompson, “Reflections on Trusting Trust,” &lt;em&gt;Communications of the ACM&lt;/em&gt; 27(8) (August 1984), pp. 761–763. &lt;a href=&quot;https://doi.org/10.1145/358198.358210&quot;&gt;https://doi.org/10.1145/358198.358210&lt;/a&gt; &lt;a class=&quot;back&quot; href=&quot;https://research.swtch.com/deps#body3&quot;&gt;(⇡)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt; GNU Project, “GNU General Public License, version 1,” February 1989. &lt;a href=&quot;https://www.gnu.org/licenses/old-licenses/gpl-1.0.html&quot;&gt;https://www.gnu.org/licenses/old-licenses/gpl-1.0.html&lt;/a&gt; &lt;a class=&quot;back&quot; href=&quot;https://research.swtch.com/deps#body4&quot;&gt;(⇡)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt; Titus Winters, “SD-8: Standard Library Compatibility,” C++ Standing Document, August 2018. &lt;a href=&quot;https://isocpp.org/std/standing-documents/sd-8-standard-library-compatibility&quot;&gt;https://isocpp.org/std/standing-documents/sd-8-standard-library-compatibility&lt;/a&gt; &lt;a class=&quot;back&quot; href=&quot;https://research.swtch.com/deps#body5&quot;&gt;(⇡)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt; Go Project, “Go 1 and the Future of Go Programs,” September 2013. &lt;a href=&quot;https://golang.org/doc/go1compat&quot;&gt;https://golang.org/doc/go1compat&lt;/a&gt; &lt;a class=&quot;back&quot; href=&quot;https://research.swtch.com/deps#body6&quot;&gt;(⇡)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt; Facebook, “Infer: A tool to detect bugs in Java and C/C++/Objective-C code before it ships.” &lt;a href=&quot;https://fbinfer.com/&quot;&gt;https://fbinfer.com/&lt;/a&gt; &lt;a class=&quot;back&quot; href=&quot;https://research.swtch.com/deps#body7&quot;&gt;(⇡)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt; “SpotBugs: Find bugs in Java Programs.” &lt;a href=&quot;https://spotbugs.github.io/&quot;&gt;https://spotbugs.github.io/&lt;/a&gt; &lt;a class=&quot;back&quot; href=&quot;https://research.swtch.com/deps#body8&quot;&gt;(⇡)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt; D. Richard Hipp, “How SQLite is Tested.” &lt;a href=&quot;https://www.sqlite.org/testing.html&quot;&gt;https://www.sqlite.org/testing.html&lt;/a&gt; &lt;a class=&quot;back&quot; href=&quot;https://research.swtch.com/deps#body9&quot;&gt;(⇡)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt; Alexander Potapenko, “Testing Chromium: ThreadSanitizer v2, a next-gen data race detector,” April 2014. &lt;a href=&quot;https://blog.chromium.org/2014/04/testing-chromium-threadsanitizer-v2.html&quot;&gt;https://blog.chromium.org/2014/04/testing-chromium-threadsanitizer-v2.html&lt;/a&gt; &lt;a class=&quot;back&quot; href=&quot;https://research.swtch.com/deps#body10&quot;&gt;(⇡)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt; NIST, “National Vulnerability Database – Search and Statistics.” &lt;a href=&quot;https://nvd.nist.gov/vuln/search&quot;&gt;https://nvd.nist.gov/vuln/search&lt;/a&gt; &lt;a class=&quot;back&quot; href=&quot;https://research.swtch.com/deps#body11&quot;&gt;(⇡)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt; Russ Cox, “Regular Expression Matching with a Trigram Index, or How Google Code Search Worked,” January 2012. &lt;a href=&quot;https://swtch.com/~rsc/regexp/regexp4.html&quot;&gt;https://swtch.com/~rsc/regexp/regexp4.html&lt;/a&gt; &lt;a class=&quot;back&quot; href=&quot;https://research.swtch.com/deps#body12&quot;&gt;(⇡)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt; Google, “Google Open Source: Using Third-Party Licenses.” &lt;a href=&quot;https://opensource.google.com/docs/thirdparty/licenses/#banned&quot;&gt;https://opensource.google.com/docs/thirdparty/licenses/#banned&lt;/a&gt; &lt;a class=&quot;back&quot; href=&quot;https://research.swtch.com/deps#body13&quot;&gt;(⇡)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt; Nathan Willis, “A single Node of failure,” LWN, March 2016. &lt;a href=&quot;https://lwn.net/Articles/681410/&quot;&gt;https://lwn.net/Articles/681410/&lt;/a&gt; &lt;a class=&quot;back&quot; href=&quot;https://research.swtch.com/deps#body14&quot;&gt;(⇡)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt; Charlie Reis, “Multi-process Architecture,” September 2008. &lt;a href=&quot;https://blog.chromium.org/2008/09/multi-process-architecture.html&quot;&gt;https://blog.chromium.org/2008/09/multi-process-architecture.html&lt;/a&gt; &lt;a class=&quot;back&quot; href=&quot;https://research.swtch.com/deps#body15&quot;&gt;(⇡)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt; Adam Langley, “Chromium’s seccomp Sandbox,” August 2009. &lt;a href=&quot;https://www.imperialviolet.org/2009/08/26/seccomp.html&quot;&gt;https://www.imperialviolet.org/2009/08/26/seccomp.html&lt;/a&gt; &lt;a class=&quot;back&quot; href=&quot;https://research.swtch.com/deps#body16&quot;&gt;(⇡)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt; Nicolas Lacasse, “Open-sourcing gVisor, a sandboxed container runtime,” May 2018. &lt;a href=&quot;https://cloud.google.com/blog/products/gcp/open-sourcing-gvisor-a-sandboxed-container-runtime&quot;&gt;https://cloud.google.com/blog/products/gcp/open-sourcing-gvisor-a-sandboxed-container-runtime&lt;/a&gt; &lt;a class=&quot;back&quot; href=&quot;https://research.swtch.com/deps#body17&quot;&gt;(⇡)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt; Adam Baldwin, “Details about the event-stream incident,” November 2018. &lt;a href=&quot;https://blog.npmjs.org/post/180565383195/details-about-the-event-stream-incident&quot;&gt;https://blog.npmjs.org/post/180565383195/details-about-the-event-stream-incident&lt;/a&gt; &lt;a class=&quot;back&quot; href=&quot;https://research.swtch.com/deps#body18&quot;&gt;(⇡)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt; Russ Cox, “RE2: a principled approach to regular expression matching,” March 2010. &lt;a href=&quot;https://opensource.googleblog.com/2010/03/re2-principled-approach-to-regular.html&quot;&gt;https://opensource.googleblog.com/2010/03/re2-principled-approach-to-regular.html&lt;/a&gt; &lt;a class=&quot;back&quot; href=&quot;https://research.swtch.com/deps#body19&quot;&gt;(⇡)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt; Rob Pike, “Go Proverbs,” November 2015. &lt;a href=&quot;https://go-proverbs.github.io/&quot;&gt;https://go-proverbs.github.io/&lt;/a&gt; &lt;a class=&quot;back&quot; href=&quot;https://research.swtch.com/deps#body20&quot;&gt;(⇡)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt; U.S. House of Representatives Committee on Oversight and Government Reform, “The Equifax Data Breach,” Majority Staff Report, 115th Congress, December 2018. &lt;a href=&quot;https://oversight.house.gov/report/committee-releases-report-revealing-new-information-on-equifax-data-breach/&quot;&gt;https://oversight.house.gov/report/committee-releases-report-revealing-new-information-on-equifax-data-breach/&lt;/a&gt; &lt;a class=&quot;back&quot; href=&quot;https://research.swtch.com/deps#body21&quot;&gt;(⇡)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt; Russ Cox, “The Principles of Versioning in Go,” GopherCon Singapore, May 2018. &lt;a href=&quot;https://www.youtube.com/watch?v=F8nrpe0XWRg&quot;&gt;https://www.youtube.com/watch?v=F8nrpe0XWRg&lt;/a&gt; &lt;a class=&quot;back&quot; href=&quot;https://research.swtch.com/deps#body22&quot;&gt;(⇡)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt; Rob Pike, Sean Dorward, Robert Griesemer, and Sean Quinlan, “Interpreting the Data: Parallel Analysis with Sawzall,” &lt;em&gt;Scientific Programming Journal&lt;/em&gt;, vol. 13 (2005). &lt;a href=&quot;https://doi.org/10.1155/2005/962135&quot;&gt;https://doi.org/10.1155/2005/962135&lt;/a&gt; &lt;a class=&quot;back&quot; href=&quot;https://research.swtch.com/deps#body23&quot;&gt;(⇡)&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This post is a draft of my current thinking on this topic. I hope that sharing it will provoke productive discussion, attract more attention to the general problem, and help me refine my own thoughts. I also intend to publish a revised copy of this as an article elsewhere. For both these reasons, unlike most of my blog posts, &lt;em&gt;this post is not Creative Commons-licensed&lt;/em&gt;. Please link people to this post instead of making a copy. When a more final version is published, I will link to it here.&lt;/p&gt;
&lt;p class=&quot;copyright&quot;&gt;© 2019 Russ Cox. All Rights Reserved.&lt;/p&gt;
</description>
<pubDate>Wed, 23 Jan 2019 16:22:48 +0000</pubDate>
<dc:creator>dmit</dc:creator>
<dc:format>text/html</dc:format>
<dc:identifier>https://research.swtch.com/deps</dc:identifier>
</item>
<item>
<title>Why I use old hardware</title>
<link>https://drewdevault.com/2019/01/23/Why-I-use-old-hardware.html?</link>
<guid isPermaLink="true" >https://drewdevault.com/2019/01/23/Why-I-use-old-hardware.html?</guid>
<description>&lt;p&gt;Recently I was making sure my main laptop is ready for travel&lt;sup id=&quot;fnref:1&quot;/&gt;, which mostly just entails syncing up the latest version of my music collection. This laptop is a Thinkpad X200, which turns 11 years old in July and is my main workstation away from home (though I bring a second monitor and an external keyboard for long trips). This laptop is a great piece of hardware. 100% of the hardware is supported by the upstream Linux kernel, including the usual offenders like WiFi and Bluetooth. Niche operating systems like 9front and Minix work great, too. Even coreboot works! It’s durable, user-serviceable, light, and still looks brand new after all of these years. I love all of these things, but there’s no denying that it’s 11 years behind on performance innovations.&lt;/p&gt;&lt;p&gt;Last year &lt;a href=&quot;https://kde.org&quot;&gt;KDE&lt;/a&gt; generously &lt;a href=&quot;https://drewdevault.com/2018/04/28/KDE-Sprint-retrospective.html&quot;&gt;invited me&lt;/a&gt; to and sponsored my travel to their development sprint in Berlin. One of my friends there teased me - in a friendly way - about my laptop, asking why I used such an old system. There was a pensive moment when I answered: “it forces me to empathise with users who can’t use high-end hardware”. I showed him how it could cold boot to a productive &lt;a href=&quot;https://swaywm.org&quot;&gt;sway&lt;/a&gt; desktop in &amp;lt;30 seconds, then I installed KDE to compare. It doubled the amount of disk space in use, took almost 10x as long to reach a usable desktop, and had severe rendering issues with my old Intel GPU.&lt;/p&gt;
&lt;p&gt;To be clear, KDE is a wonderful piece of software and my first recommendation to most non-technical computer users who ask me for advice on using Linux. But software often grows to use the hardware you give it. Software developers tend to be computer enthusiasts, and use enthusiast-grade hardware. In reality, this high-end hardware isn’t really &lt;em&gt;necessary&lt;/em&gt; for most applications outside of video encoding, machine learning, and a few other domains.&lt;/p&gt;
&lt;p&gt;I do have a more powerful workstation at home, but it’s not really anything special. I upgrade it very infrequently. I bought a new mid-range GPU which is able to drive my four displays&lt;sup id=&quot;fnref:2&quot;/&gt; last year, I’ve added the occasional hard drive as it gets full, and I replaced the case with something lighter weight 3 years ago. Outside of those minor upgrades, I’ve been using the same desktop workstation for 7 years, and intend to use it for much longer. My servers are similarly running on older hardware which is spec’d to their needs (actually, I left a lot of room to grow and &lt;em&gt;still&lt;/em&gt; was able to buy old hardware).&lt;/p&gt;
&lt;p&gt;My 11-year-old laptop can compile the Linux kernel from scratch in 20 minutes, and it can play 1080p video in real-time. That’s all I need! Many users cannot afford high-end computer hardware, and most have better things to spend their money on. And you know, I work hard for my money, too - if I can get a computer which can do nearly 5 &lt;em&gt;billion&lt;/em&gt; operations per second for $60, that should be sufficient to solve nearly any problem. No doubt, there are faster laptops out there, many of them with similarly impressive levels of compatibility with my ideals. But why bother?&lt;/p&gt;

&lt;hr/&gt;&lt;p&gt;Have a comment on one of my posts? Start a discussion in my &lt;a href=&quot;https://lists.sr.ht/~sircmpwn/public-inbox&quot;&gt;public inbox&lt;/a&gt; by sending an email to &lt;a href=&quot;mailto:~sircmpwn/public-inbox@lists.sr.ht?Subject=Re%3A%20Why%20I%20use%20old%20hardware&quot;&gt;~sircmpwn/public-inbox@lists.sr.ht&lt;/a&gt; &lt;small&gt;[&lt;a href=&quot;https://man.sr.ht/lists.sr.ht/etiquette.md&quot;&gt;mailing list etiquette&lt;/a&gt;]&lt;/small&gt;&lt;/p&gt;
</description>
<pubDate>Wed, 23 Jan 2019 14:40:29 +0000</pubDate>
<dc:creator>Sir_Cmpwn</dc:creator>
<og:title>Why I use old hardware</og:title>
<og:description>Recently I was making sure my main laptop is ready for travel1, which mostly just entails syncing up the latest version of my music collection. This laptop is a Thinkpad X200, which turns 11 years old in July and is my main workstation away from home (though I bring a second monitor and an external keyboard for long trips). This laptop is a great piece of hardware. 100% of the hardware is supported by the upstream Linux kernel, including the usual offenders like WiFi and Bluetooth. Niche operating systems like 9front and Minix work great, too. Even coreboot works! It’s durable, user-serviceable, light, and still looks brand new after all of these years. I love all of these things, but there’s no denying that it’s 11 years behind on performance innovations. To FOSDEM - see you there! ↩</og:description>
<og:type>article</og:type>
<dc:format>text/html</dc:format>
<dc:identifier>https://drewdevault.com/2019/01/23/Why-I-use-old-hardware.html?</dc:identifier>
</item>
<item>
<title>Travis CI acquired by Idera</title>
<link>https://blog.travis-ci.com/2019-01-23-travis-ci-joins-idera-inc</link>
<guid isPermaLink="true" >https://blog.travis-ci.com/2019-01-23-travis-ci-joins-idera-inc</guid>
<description>&lt;p&gt;When we started working on a Continuous Integration solution back in 2011, it was hard to imagine what Travis CI would become. Years later, we’re still continuously working to make our community and the tech industry better and stronger. Today we are excited to announce that Travis CI has been acquired by &lt;a href=&quot;https://www.ideracorp.com/&quot;&gt;Idera, Inc&lt;/a&gt;. Idera is the parent company of many software productivity tools and will support us in delivering quality software to all of you, our users.&lt;/p&gt;
&lt;p&gt;Grown out of the open source community, Travis CI became the leading CI solution and we now provide enhanced features, performance, and support to projects and teams of all sizes. We are proud to serve more than 700,000 people worldwide to build and test software applications. Our customers include IBM, Schibsted, and Zendesk, amongst many others. Together with Idera, we want to expand on this success and help many more people build better software faster.&lt;/p&gt;
&lt;h3 id=&quot;will-anything-change-for-me&quot;&gt;Will anything change for me?&lt;/h3&gt;
&lt;p&gt;At Travis CI, we are committed to remaining the solid stand-alone solution you have come to rely on. We will continue to offer the same services to our hosted and on-premises users. With the support from our new partners, we will be able to invest in expanding and improving our core product, to have Travis CI be the best Continuous Integration and Development solution for software projects out there. We will join Idera’s Testing Tools division, which also includes &lt;a href=&quot;https://www.gurock.com/testrail&quot;&gt;TestRail&lt;/a&gt;, &lt;a href=&quot;https://www.ranorex.com/&quot;&gt;Ranorex&lt;/a&gt;, and &lt;a href=&quot;https://www.kiuwan.com/&quot;&gt;Kiuwan&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&quot;what-impact-will-this-have-on-open-source&quot;&gt;What impact will this have on open source?&lt;/h3&gt;
&lt;p&gt;Open source is at the heart of Travis CI. We will continue to maintain a free, hosted service for open source projects, and will keep building features for the open source community. Additionally, &lt;a href=&quot;https://github.com/travis-ci&quot;&gt;our code&lt;/a&gt; will stay open source and under an MIT license. This is who we are, this is what made us successful.&lt;/p&gt;
&lt;h3 id=&quot;what-about-the-travis-foundation&quot;&gt;What about the Travis Foundation?&lt;/h3&gt;
&lt;p&gt;The &lt;a href=&quot;https://foundation.travis-ci.org/&quot;&gt;Travis Foundation&lt;/a&gt; has done phenomenal work running projects like &lt;a href=&quot;https://railsgirlssummerofcode.org/&quot;&gt;Rails Girls Summer of Code&lt;/a&gt;, &lt;a href=&quot;https://diversitytickets.org/&quot;&gt;Diversity Tickets&lt;/a&gt;, &lt;a href=&quot;https://speakerinnen.org/&quot;&gt;Speakerinnen&lt;/a&gt;, and &lt;a href=&quot;http://mhprompt.org/&quot;&gt;Prompt&lt;/a&gt;. While this is new territory for Idera, they are impressed with what we have built, and fully committed to not just to keep it running, but also see how we can increase our efforts in making the tech industry a better place for everyone.&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;We’re very excited to start off 2019 with the support of Idera and have a better platform to continue building and improving Travis CI for all of you. We’re happy to answer any questions on our &lt;a href=&quot;https://travis-ci.community/t/travis-ci-joins-the-idera-family/1975&quot;&gt;Community Forum&lt;/a&gt;.&lt;/p&gt;
</description>
<pubDate>Wed, 23 Jan 2019 14:16:36 +0000</pubDate>
<dc:creator>involans</dc:creator>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://blog.travis-ci.com/2019-01-23-travis-ci-joins-idera-inc</dc:identifier>
</item>
<item>
<title>Julia Language Co-Creators Win James H. Wilkinson Prize for Numerical Software</title>
<link>https://sinews.siam.org/Details-Page/january-prize-spotlight-jeff-bezanson-steven-l-brunton-jack-dongarra-stefan-karpinski-and-viral-b-shah</link>
<guid isPermaLink="true" >https://sinews.siam.org/Details-Page/january-prize-spotlight-jeff-bezanson-steven-l-brunton-jack-dongarra-stefan-karpinski-and-viral-b-shah</guid>
<description>&lt;p&gt;Congratulations to these five members of the SIAM community who were recently awarded the James H. Wilkinson Prize for Numerical Software, SIAG/CSE Early Career Prize, and SIAM/ACM Prize in Computational Science and Engineering.&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;Jeff Bezanson, Stefan Karpinski, and Viral B. Shah - James H. Wilkinson Prize for Numerical Software&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;Jeff Bezanson, Stefan Karpinski, and Viral B. Shah of &lt;a href=&quot;https://juliacomputing.com/&quot; target=&quot;_blank&quot;&gt;Julia Computing&lt;/a&gt; are the 2019 recipients of the &lt;a href=&quot;https://www.siam.org/Prizes-Recognition/Major-Prizes-Lectures/Detail/james-h-wilkinson-prize-for-numerical-software&quot; target=&quot;_blank&quot;&gt;James H. Wilkinson Prize for Numerical Software&lt;/a&gt;. The prize will be awarded at the &lt;a href=&quot;https://www.siam.org/Conferences/CM/Main/cse19&quot; target=&quot;_blank&quot;&gt;2019 SIAM Conference on Computational Science and Engineering (CSE19)&lt;/a&gt;, held February 25 – March 1, 2019 in Spokane, Washington. The three of them will receive their prize and give their talk, “Solving the Two Language Problem in Scientific Computing and Machine Learning with Julia,” on February 28, 2019.&lt;/p&gt;
&lt;p&gt;The James H. Wilkinson Prize for Numerical Software recognizes innovative software in scientific computing by researchers in the earlier stages of their career. Candidates must have worked in mathematics or science for at most 12 years after receiving their PhD, allowing for breaks in continuity. The prize is awarded every four years to the authors of an outstanding piece of numerical software, or to individuals who have made an outstanding contribution to an existing piece of numerical software. It is awarded for an entry that best addresses all phases of the preparation of high-quality numerical software.&lt;/p&gt;
&lt;p&gt;The prize was established, in honor of James H. Wilkinson’s outstanding contributions to the field of numerical software, by &lt;a href=&quot;https://www.anl.gov/&quot; target=&quot;_blank&quot;&gt;Argonne National Laboratory&lt;/a&gt; (ANL; Argonne, IL), the &lt;a href=&quot;http://www.npl.co.uk/&quot; target=&quot;_blank&quot;&gt;National Physical Laboratory&lt;/a&gt; (NPL; Teddington, Middlesex, England), and the &lt;a href=&quot;https://www.nag.com/&quot; target=&quot;_blank&quot;&gt;Numerical Algorithms Group Ltd&lt;/a&gt; (NAG; Oxford, England). They sponsored the award every four years at the &lt;a href=&quot;http://www.iciam.org/&quot; target=&quot;_blank&quot;&gt;International Congress on Industrial and Applied Mathematics (ICIAM)&lt;/a&gt; beginning with the 1991 award. By agreement in 2015 among ANL, NPL, NAG, and SIAM, the prize will be administered by SIAM starting with the 2019 award.&lt;/p&gt;
&lt;p&gt;The 2019 award recognizes Bezanson, Karpinski, and Shah for the development of Julia, an innovative environment for the creation of high-performance tools that enable the analysis and solution of computational science problems. Julia allows researchers to write high-level code in an intuitive syntax and produce code with the speed of production programming languages. It has been widely adopted by the scientific computing community for application areas that include astronomy, economics, deep learning, energy optimization, and medicine. In particular, the Federal Aviation Administration has chosen Julia as the language for the next generation airborne collision avoidance system.&lt;/p&gt;
&lt;div class=&quot;in_article_image right&quot;&gt;
&lt;div class=&quot; no_text&quot;&gt;&lt;img right=&quot;&quot; alt=&quot;&quot; src=&quot;https://sinews.siam.org/Portals/SiNews2/EasyDNNNews/thumbs/3697/6211Jeff-Bezanson-cropped.jpg&quot;/&gt;&lt;/div&gt;
&lt;p&gt;Jeff Bezanson&lt;/p&gt;
&lt;/div&gt;
Jeff Bezanson got his start in technical computing with a high school summer job as a programmer in an MRI research group led by Yi Wang. After an AB in computer science at Harvard University, he worked at Interactive Supercomputing where he met Viral Shah and Alan Edelman. The experience led him to continue pursuing numerical computing as a PhD student of Edelman’s at Massachusetts Institute of Technology, receiving the degree in 2015. For his thesis work on Julia, he received the 2015 George M. Sprowls Award for outstanding PhD thesis in computer science at MIT. Soon after, Jeff co-founded Julia Computing in order to continue pushing the ideas and abstractions behind Julia into new domains.
&lt;div class=&quot;in_article_image left&quot;&gt;
&lt;div class=&quot; no_text&quot;&gt;&lt;img left=&quot;&quot; alt=&quot;&quot; src=&quot;https://sinews.siam.org/Portals/SiNews2/EasyDNNNews/thumbs/3697/6219Stefan-Karpinski.jpg&quot;/&gt;&lt;/div&gt;
&lt;p&gt;Stefan Karpinski&lt;/p&gt;
&lt;/div&gt;
Stefan Karpinski is a New York native who attended Harvard University for his AB in mathematics. He taught himself to program in Pascal in eighth grade for a science fair project in which he simulated “Logic Creatures”—a thought experiment from a Scientific American column by Martin Gardner. Stefan has completed most of a PhD at the University of California Santa Barbara and is “all but dissertation.” He has worked as a combination data scientist, research engineer, and software engineer at a variety of companies, including Akamai, Citrix Online and Etsy. Along with the other recipients of this prize, Stefan co-founded Julia Computing in 2015 to help bring the benefits of Julia to industry and academic users around the world. He also has an appointment as a research engineer at New York University.
&lt;div class=&quot;in_article_image right&quot;&gt;
&lt;div class=&quot; no_text&quot;&gt;&lt;img right=&quot;&quot; alt=&quot;&quot; src=&quot;https://sinews.siam.org/Portals/SiNews2/EasyDNNNews/thumbs/3697/6213Viral-B.-Shah-cropped.jpg&quot;/&gt;&lt;/div&gt;
&lt;p&gt;Viral B. Shah&lt;/p&gt;
&lt;/div&gt;
Viral B. Shah started programming in BASIC in eighth grade and taught himself C in high school. As an undergraduate at PVPP College of Engineering in Mumbai, he implemented a risk management system for derivatives trading on the National Stock Exchange in India. He was then accepted into the PhD program at University of California Santa Barbara, where his thesis on abstractions for large scale combinatorial computing was advised by John Gilbert. There, he also developed Circuitscape, a widely used tool in conservation and landscape ecology, for which he received an award from the Wildlife Society in 2013. Soon after, Viral relocated to India to work on India’s Aadhaar (National ID) project, and published his experiences in a book, Rebooting India. While Julia started out as a hobby, it has now become a full time preoccupation; Viral is currently the CEO of Julia Computing.
&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt; &lt;em&gt;Why are you excited to be winning the prize?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; We are very excited on a personal level to win the 2019 James H. Wilkinson Prize for Numerical Software, but even more so for the &lt;a href=&quot;https://julialang.org/&quot; target=&quot;_blank&quot;&gt;Julia&lt;/a&gt; community as a whole—the prize is really a recognition of the community and the accomplishments of the people developing amazing projects and libraries in Julia. The past winners of the Wilkinson Prize for Numerical Software have been a huge inspiration to us. They have created lighthouse numerical software projects such as DASSL, FFTW and IPOPT, which are used around the world and have changed the face of numerical computing. It is an incredible honor to be counted among them.&lt;/p&gt;
&lt;p&gt;FFTW pioneered using a high-level language, OCaml, to generate extremely optimized, architecture-specialized, low-level C code. This approach was a big influence on us, and gave us ideas about what numerical programming could look like in the future. We wanted a language that could make this kind of multistage, high-performance programming simple and accessible to everyone. And now for years, we’ve been seeing numerical codes get 10-100x speed-ups simply from direct ports to Julia from other high-level languages. That is gratifying every time it happens. But the real payoff has come in the form of new field-redefining numerical libraries like &lt;a href=&quot;http://juliadiffeq.org/&quot; target=&quot;_blank&quot;&gt;DifferentialEquations.jl&lt;/a&gt;, &lt;a href=&quot;http://www.juliaopt.org/&quot; target=&quot;_blank&quot;&gt;JuMP.jl&lt;/a&gt; (for operations research), and &lt;a href=&quot;http://fluxml.ai/&quot; target=&quot;_blank&quot;&gt;Flux.jl&lt;/a&gt; (for flexible, intuitive machine learning). These are projects whose performance and generality would have been out of reach in other languages. Julia lets numerical programmers dream bigger than they have before. We will know that we’ve really succeeded when a future award of this Wilkinson prize is given for software written in Julia.&lt;/p&gt;
&lt;p&gt;We would like to recognize the contributions of Alan Edelman, who is not eligible for this prize, but is the fourth co-founder of the Julia project. Without Alan’s support and mentorship, Julia would have been extremely difficult to pull off—and it was already a long shot.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt; &lt;em&gt;Could you tell us a bit about the research that won you the prize?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Julia is the result of our research into programming language design, compilers, numerical analysis, distributed and parallel computing, and applied mathematics. We have been passionate about bringing the power of modern programming language design and implementation to bear in the area of numerical computing for a long time. We started with the goal of building a language that is as fast as C and Fortran, but as easy and interactive as Python, R, or Matlab. We have been driven by the conviction that the historical dilemma of picking either productivity or performance—but not both at once—was holding the computational sciences back. For various reasons, the best general purpose languages have not been ergonomic for day-to-day numerical work, and numerical languages have been considered niche and inadequate for general purpose programming. We wanted to explore a design space where you could have both performance and productivity in a single, coherent general purpose system that is great for exploration and for writing the highest performance applications on supercomputers. We have sometimes said that Julia solves the two language problem: instead of needing to use a high level language for productivity and high-level logic and a separate low-level language for performance, you can smoothly transition between high and low level programming modes in a single language.&lt;/p&gt;
&lt;p&gt;The key to our approach is to use a single flexible mechanism—multiple dispatch—for everything. Even the most fundamental operations like addition, array indexing, and numeric promotion use the same dispatch mechanism as user-defined functions. As a result, user-defined numeric types and operations are every bit as efficient and capable as the built in ones, leading to a proliferation of innovative libraries implementing everything from efficient structured array types to interval arithmetic to units. Perhaps most importantly, everything is composable: you can create structured arrays with units, and take automatic derivatives of computations using interval arithmetic—even though these libraries know nothing about each other.&lt;/p&gt;
&lt;p&gt;In statically typed languages, the programmer writes some code and the compiler tells them what they did wrong. While that can be helpful, we also believe that there is a time and place for running code without getting into arguments with your software. We see this empirically in the tremendous success of dynamic languages in numerical programming. But in our view, the programmer and the compiler are fundamentally trying to do the same thing: understand what a program means. So we tried to design a language that, although dynamically-typed, limits the kind of unpredictability that makes programs hard to understand—for both the programmer and the compiler. Julia’s compilation process more closely resembles a C++ compiler with a very delayed compile time than modern just-in-time compilers that have been forced to deal with the highly unpredictable behaviors of legacy dynamic languages that were never designed for performance.&lt;/p&gt;
&lt;p&gt;We also believe strongly in experimental language design. A programming language cannot be derived from first principles alone. Language design is applied psychology—the computer program is the ultimate human-computer interface. Sometimes you have to try a design out and see how people interact with it and iterate based on that real-world feedback.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt; &lt;em&gt;What does your research mean to the public?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Julia brings down the time and cost for trying out new ideas, inventing new algorithms, and creating new products. Our community does research related to many of the grand challenges identified by the National Academy of Engineering—climate change, affordable healthcare, clean energy, personalized medicine, personalized education, and more. We stay attuned to our community and focus on building abstractions and capabilities in Julia that will help them achieve these greater goals. Enabling them and seeing the amazing things they do with it is what gets us excited working on Julia every morning!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt; &lt;em&gt;What does being a SIAM member mean to you?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; We have always been highly appreciative of SIAM. It has been a key part of our academic and professional journey. The Julia community overall has been present at various SIAM meetings, and has organized many minisymposia. Jeff attended and presented Julia at CSE13. We published our first Julia paper, “&lt;a href=&quot;https://epubs.siam.org/doi/10.1137/141000671&quot; target=&quot;_blank&quot;&gt;Julia: A Fresh Approach to Numerical Computing&lt;/a&gt;”, in the February 2017 issue of &lt;a href=&quot;https://www.siam.org/Publications/Journals/SIAM-Review-SIREV&quot; target=&quot;_blank&quot;&gt;&lt;em&gt;SIAM Review&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;Steven L. Brunton - SIAG/CSE Early Career Prize&lt;/strong&gt;&lt;/h3&gt;

&lt;div class=&quot;in_article_image left&quot;&gt;
&lt;div class=&quot; no_text&quot;&gt;&lt;img left=&quot;&quot; alt=&quot;&quot; src=&quot;https://sinews.siam.org/Portals/SiNews2/EasyDNNNews/thumbs/3697/6209Steven-L.-Brunton-cropped.jpg&quot;/&gt;&lt;/div&gt;
&lt;p&gt;Steven L. Brunton&lt;/p&gt;
&lt;/div&gt;
Steven L. Brunton of the University of Washington will receive the &lt;a href=&quot;https://www.siam.org/Prizes-Recognition/Activity-Group-Prizes/Detail/siag-cse-early-career-prize&quot; target=&quot;_blank&quot;&gt;2019 SIAM Activity Group on Computational Science and Engineering Early Career Prize&lt;/a&gt; at the &lt;a href=&quot;https://www.siam.org/Conferences/CM/Main/cse19&quot; target=&quot;_blank&quot;&gt;SIAM Conference on Computational Science and Engineering (CSE19)&lt;/a&gt; held February 25 – March 1, 2019 in Spokane, Washington. He will accept the award and deliver his lecture, “Data-Driven Discovery and Control of Complex Systems: Uncovering Interpretable and Generalizable Nonlinear Models,” on February 28, 2019. The award recognizes Brunton for his significant contributions to a broad range of techniques for, and applications of, data-driven analytics, control theory, sparse sensing, and reduced order modeling.
&lt;p&gt;The &lt;a href=&quot;https://www.siam.org/Membership/Activity-Groups/Detail/computational-science-and-engineering&quot; target=&quot;_blank&quot;&gt;SIAM Activity Group on Computational Science and Engineering (SIAG/CSE)&lt;/a&gt; awards the &lt;a href=&quot;https://www.siam.org/Prizes-Recognition/Activity-Group-Prizes/Detail/SIAG-CSE-Early-Career-Prize&quot; target=&quot;_blank&quot;&gt;SIAG/CSE Early Career Prize&lt;/a&gt; every two years to a post-PhD early career researcher in the field of computational science and engineering for outstanding, influential, and potentially long-lasting contributions to the field within seven years of receiving the PhD or equivalent degree as of January 1 of the award year. The candidate’s work must contain significant research contributions to the development and use of mathematical and computational tools and methods for the solution of scientific and engineering problems. The contributions must be contained in a paper or papers published in English in peer-reviewed journals.&lt;/p&gt;
&lt;p&gt;Steven L. Brunton is an Associate Professor of Mechanical Engineering at the University of Washington. He is also Adjunct Associate Professor of Applied Mathematics and a Data Science Fellow at the eScience Institute there. He received the BS in mathematics from California Institute of Technology in 2006 and the PhD in mechanical and aerospace engineering from Princeton University in 2012. His research combines machine learning with dynamical systems to model and control systems in fluid dynamics, biolocomotion, optics, energy systems, and manufacturing. Brunton is a co-author of three textbooks. He has received the Army and Air Force Young Investigator Program awards, the Army Early Career Award for Scientists and Engineers, and the University of Washington College of Engineering junior faculty and teaching awards.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt; &lt;em&gt;Why are you excited about winning this prize?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; I am thrilled to be selected for the SIAG/CSE Early Career Prize! I am incredibly fortunate to have wonderful students and collaborators, and it is great to know that our work is appreciated by the community.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt; &lt;em&gt;Could you tell us a bit about the research that won you the prize?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Our work has largely focused on the data-driven modeling and control of complex dynamical systems, including how to obtain parsimonious nonlinear models using modern techniques in sparse optimization. Identifying interpretable and generalizable nonlinear models from data has been a long-held goal of the community, and recent advances are increasingly making this tractable, for example in fluid mechanics and computational biology. We are now aggressively working to make these methods more suitable for real-world systems by focusing on noise, multiscale dynamics, latent variables, sensor placement, and coordinate transformations that simplify dynamics.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt; &lt;em&gt;What does your research mean to the public?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Dynamical systems are central to how we describe our changing world. Advances in data-driven optimization (i.e., machine learning) are promising to improve modeling capabilities in canonically challenging fields, such as turbulence, neuroscience, and epidemiology, to name a few. Applying these techniques to systems with physics and constraints will also hopefully benefit the fields of learning and optimization.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt; &lt;em&gt;What does being a SIAM member mean to you?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; SIAM has always been a wonderful community to be a part of, and I have been going to SIAM conferences ever since I was a graduate student. I love interdisciplinary research that really applies mathematical modeling to solve real problems in science and engineering, and SIAM provides a great place for us to interact and share. I also find the SIAM community to be incredibly collaborative and open minded, which keeps it fun and interesting.&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;Jack Dongarra - SIAM/ACM Prize in Computational Science and Engineering&lt;/strong&gt;&lt;/h3&gt;

&lt;div class=&quot;in_article_image right&quot;&gt;
&lt;div class=&quot; no_text&quot;&gt;&lt;img right=&quot;&quot; alt=&quot;&quot; src=&quot;https://sinews.siam.org/Portals/SiNews2/EasyDNNNews/thumbs/3697/6210Jack-Dongarra-cropped.jpg&quot;/&gt;&lt;/div&gt;
&lt;p&gt;Jack Dongarra&lt;/p&gt;
&lt;/div&gt;
Jack Dongarra of the University of Tennessee will receive the &lt;a href=&quot;https://www.siam.org/Prizes-Recognition/Major-Prizes-Lectures/Detail/siam-acm-prize-in-computational-science-and-engineering&quot; target=&quot;_blank&quot;&gt;SIAM/ACM Prize in Computational Science and Engineering&lt;/a&gt; at the &lt;a href=&quot;https://www.siam.org/Conferences/CM/Main/cse19&quot; target=&quot;_blank&quot;&gt;SIAM Conference on Computational Science and Engineering (CSE19)&lt;/a&gt; held February 25 – March 1, 2019 in Spokane, Washington. He will receive the award and deliver his prize lecture, “The Singular Value Decomposition: Anatomy of an Algorithm, Optimizing for Performance,” on February 28, 2019.
&lt;p&gt;SIAM and the &lt;a href=&quot;https://www.acm.org/&quot; target=&quot;_blank&quot;&gt;Association for Computing Machinery (ACM)&lt;/a&gt; jointly award the SIAM/ACM Prize in Computational Science and Engineering every two years at the SIAM Conference on Computational Science and Engineering for outstanding contributions to the development and use of mathematical and computational tools and methods for the solution of science and engineering problems. With this award, SIAM and ACM recognize Dongarra for his key role in the development of software and software standards, software repositories, performance and benchmarking software, and in community efforts to prepare for the challenges of exascale computing, especially in adapting linear algebra infrastructure to emerging architectures.&lt;/p&gt;
&lt;p&gt;Jack Dongarra received his PhD in applied mathematics from the University of New Mexico in 1980. He worked at the Argonne National Laboratory until 1989, becoming a senior scientist. He currently holds an appointment as University Distinguished Professor of Computer Science in the Electrical Engineering and Computer Science Department at the University of Tennessee and holds the title of Distinguished Research Staff in the Computer Science and Mathematics Division at Oak Ridge National Laboratory. At the University of Tennessee, he is the director of the Innovative Computing Laboratory and director of the Center for Information Technology Research, which coordinates and facilitates IT research efforts at the University. Dongarra is also a Turing Fellow at Manchester University and an Adjunct Professor in the Computer Science Department at Rice University. He is a Fellow of the &lt;a href=&quot;https://www.aaas.org/&quot; target=&quot;_blank&quot;&gt;AAAS&lt;/a&gt;, &lt;a href=&quot;https://www.acm.org/&quot; target=&quot;_blank&quot;&gt;ACM&lt;/a&gt;, &lt;a href=&quot;https://www.ieee.org/&quot; target=&quot;_blank&quot;&gt;IEEE&lt;/a&gt;, and SIAM. He is a foreign member of the Russian Academy of Sciences and a member of the U.S. National Academy of Engineering.&lt;/p&gt;
&lt;p&gt;Dongarra specializes in numerical algorithms in linear algebra, parallel computing, the use of advanced-computer architectures, programming methodology, and tools for parallel computers. His research includes the development, testing, and documentation of high quality mathematical software. He has contributed to the design and implementation of many open source software packages and systems.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt; &lt;em&gt;Why are you excited to be winning the SIAM/ACM Prize in CSE?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; The list of people who have been awarded this prize is truly amazing, and to be included in that list is humbling and a great honor, as it validates the work we have been doing in a major way.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt; &lt;em&gt;Could you tell us a bit about the research that won you the prize?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; I have been involved in the design and development of high performance mathematical software for the past 35 years, especially regarding linear algebra libraries for sequential, parallel, vector, and accelerated computers. Of course, the work that led to this award could not have been achieved without the help, support, collaboration, and interactions of many people over the years. I have had the good fortune of working on a number of high profile projects: in the area of mathematical software, EISPACK, LINPACK, LAPACK, ScaLAPACK, ATLAS and today with PLASMA, MAGMA, and SLATE; community de facto standards such as the BLAS, MPI, and PVM; performance analysis and benchmarking tools such as the PAPI, LINPACK benchmark, the Top500, and HPCG benchmarks; and the software repository netlib, arguably the first open source repository for publicly available mathematical software.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt; &lt;em&gt;What does your research mean to the public?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; The work we have been involved with helps in forming the basic part of the fabric of computational science and high performance computing.&lt;/p&gt;
&lt;p&gt;This work can be directly integrated in many important technologies that can be used for large-scale computations in medical and health sciences, high performance computing for biomedical and biomechanical engineering, parallel computing in bioinformation and computational biology, modeling and simulation of materials sciences and processing controls, environmental sciences and physics, chemical and biochemical systems simulations, etc. (almost everywhere). Our work is developed with the support of the National Science Foundation and the U.S. Department of Energy. The software is freely available to the community.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt; &lt;em&gt;What does being a SIAM member mean to you?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; I’m actively involved in three professional societies, and SIAM is my “first” society. What I mean by that is, I was a member of SIAM before becoming a member of the other societies and I view myself as more closely aligned to the SIAM family. SIAM has had the longest, most significant influence on my work, and therefore I feel a special connection and sense of gratitude to the SIAM family.&lt;/p&gt;

</description>
<pubDate>Wed, 23 Jan 2019 12:52:01 +0000</pubDate>
<dc:creator>yarapavan</dc:creator>
<og:title>January Prize Spotlight: Jeff Bezanson, Steven L. Brunton, Jack Dongarra, Stefan Karpinski, and Viral B. Shah</og:title>
<og:description>Congratulations to these five members of the SIAM community who were recently awarded the James H. Wilkinson Prize for Numerical Software, SIAG/CSE Early Career Prize, and SIAM/ACM Prize in Computational Science and Engineering. Jeff Bezanson, Stefan Karpinski, and Viral B. Shah - James H. Wilkinson Prize for Numerical Software Steven L. Brunton - SIAG/CSE Early Career Prize Jack Dongarra - SIAM/ACM Prize in Computational Science and Engineering Jeff Bezanson, Stefan...</og:description>
<og:url>https://sinews.siam.org/Details-Page/january-prize-spotlight-jeff-bezanson-steven-l-brunton-jack-dongarra-stefan-karpinski-and-viral-b-shah</og:url>
<og:type>article</og:type>
<og:image>https://sinews.siam.org/Portals/SiNews2/EasyDNNnews/3697/3697Awards.png</og:image>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://sinews.siam.org/Details-Page/january-prize-spotlight-jeff-bezanson-steven-l-brunton-jack-dongarra-stefan-karpinski-and-viral-b-shah</dc:identifier>
</item>
<item>
<title>Mendeley encrypts users&amp;#039; database after Zotero provides an importer</title>
<link>https://www.zotero.org/support/kb/mendeley_import</link>
<guid isPermaLink="true" >https://www.zotero.org/support/kb/mendeley_import</guid>
<description>&lt;div class=&quot;plugin_translation&quot;&gt;&lt;span&gt;Translations of this page:&lt;/span&gt;
&lt;/div&gt;

&lt;div class=&quot;level1&quot; readability=&quot;12&quot;&gt;
&lt;p&gt;Zotero includes support for directly importing a Mendeley database into Zotero via File → “Import…”, but due to recent changes by Elsevier, the company that produces the Mendeley software, some extra steps may be required.&lt;/p&gt;
&lt;/div&gt;
&lt;h2 class=&quot;sectionedit2&quot; id=&quot;mendeley_database_encryption&quot;&gt;Mendeley Database Encryption&lt;/h2&gt;
&lt;div class=&quot;level2&quot; readability=&quot;36.323529411765&quot;&gt;
&lt;p&gt;Mendeley 1.19 and later have begun encrypting the local database, making it unreadable by Zotero and other standard database tools. Elsevier made this change a few months after Zotero publicly announced work on an importer, despite having long touted the openness of its database format as a guarantee against lock-in and &lt;a href=&quot;https://service.elsevier.com/app/answers/detail/a_id/22098/kw/database/supporthub/mendeley/&quot; class=&quot;urlextern&quot; title=&quot;https://service.elsevier.com/app/answers/detail/a_id/22098/kw/database/supporthub/mendeley/&quot; rel=&quot;nofollow&quot;&gt;erroneously continuing to state&lt;/a&gt; in its documentation that the database can be accessed using standard tools. At the same time, Mendeley continues to import data from Zotero’s own open database, as it has since 2009.&lt;/p&gt;
&lt;p&gt;The &lt;a href=&quot;https://www.mendeley.com/release-notes/v1_19&quot; class=&quot;urlextern&quot; title=&quot;https://www.mendeley.com/release-notes/v1_19&quot; rel=&quot;nofollow&quot;&gt;Mendeley 1.19 release notes&lt;/a&gt; claimed that the encryption was for “improved security” on shared machines, yet applications rarely encrypt their local data files, as file protections are generally handled by the operating system with account permissions and full-disk encryption, and anyone using the same operating system account or an admin account can already install a keylogger to capture passwords. Elsevier later &lt;a href=&quot;https://twitter.com/mendeley_com/status/1006915998841221120&quot; class=&quot;urlextern&quot; title=&quot;https://twitter.com/mendeley_com/status/1006915998841221120&quot; rel=&quot;nofollow&quot;&gt;stated&lt;/a&gt; that the change was required by new European privacy regulations — a bizarre claim, given that those regulations are designed to give people control over their data and guarantee data portability, not the opposite — and continued to assert, falsely, that full local export was still possible, while &lt;a href=&quot;https://twitter.com/mendeley_com/status/1006919608471818240&quot; class=&quot;urlextern&quot; title=&quot;https://twitter.com/mendeley_com/status/1006919608471818240&quot; rel=&quot;nofollow&quot;&gt;repeatedly&lt;/a&gt; &lt;a href=&quot;https://twitter.com/MendeleySupport/status/1006920802120470528&quot; class=&quot;urlextern&quot; title=&quot;https://twitter.com/MendeleySupport/status/1006920802120470528&quot; rel=&quot;nofollow&quot;&gt;dismissing&lt;/a&gt; reports of the change as “#fakenews”.&lt;/p&gt;
&lt;p&gt;Direct access to the Mendeley database is the only local way to export the full contents of one’s own research. The export formats supported by Mendeley don’t contain folders, various metadata fields (date added, favorite, and others), or PDF annotations. Mendeley offers a web-based API, but it only contains uploaded data, so relying on it would mean that anyone wanting to export their own data would first need to upload all their data and files to Elsevier’s servers. The API is under Elsevier’s control and can be changed or discontinued at any time.&lt;/p&gt;
&lt;/div&gt;
&lt;h2 class=&quot;sectionedit3&quot; id=&quot;known_issues&quot;&gt;Known Issues&lt;/h2&gt;
&lt;div class=&quot;level2&quot; readability=&quot;8.8730158730159&quot;&gt;
&lt;p&gt;In addition to the database encryption discussed above, there are a few other issues to be aware of when importing from Mendeley.&lt;/p&gt;
&lt;ul readability=&quot;12.805425631431&quot;&gt;&lt;li class=&quot;level1 node&quot; readability=&quot;4.8658843252305&quot;&gt;
&lt;p&gt;Mendeley stores PDF annotations and highlights in its database rather than storing them in the file where they would be accessible to other PDF readers, so Zotero extracts annotations to a note stored under the item, with links back to the original page. Highlights are not imported. To embed annotations and highlights into the PDF files themselves so they can be imported into Zotero, you have a couple options:&lt;/p&gt;
&lt;ol readability=&quot;1.4383825417202&quot;&gt;&lt;li class=&quot;level2&quot; readability=&quot;6&quot;&gt;
&lt;p&gt;Mendeley provides an option to generate a PDF with annotations and highlights added back to the file. Prior to Mendeley 1.19.3, that option could only be run for one file at a time; in 1.19.3, it can be run for multiple files but doesn’t include highlights. In our testing, exported PDFs also don’t always contain the text of annotations. But if you’re able to satisfactorily export annotations and/or highlights, you could use that option for one or more files and then replace the imported files in Zotero (right-click on the item and choose “Show File”) with the annotated versions.&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;level2&quot; readability=&quot;-0.41256830601093&quot;&gt;
&lt;div class=&quot;li&quot; readability=&quot;8.2513661202186&quot;&gt;You can also try using the third-party &lt;a href=&quot;https://github.com/cycomanic/Menextract2pdf&quot; class=&quot;urlextern&quot; title=&quot;https://github.com/cycomanic/Menextract2pdf&quot; rel=&quot;nofollow&quot;&gt;Menextract2pdf&lt;/a&gt; script to write annotations and highlights back to the PDFs in Mendeley before importing into Zotero. See the &lt;a href=&quot;https://www.zotero.org/support/kb/mendeley_import#preserving_mendeley_annotations_and_highlights&quot; title=&quot;kb:mendeley_import ↵&quot; class=&quot;wikilink1&quot;&gt;instructions below&lt;/a&gt;.&lt;/div&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li class=&quot;level1&quot; readability=&quot;2&quot;&gt;
&lt;p&gt;It’s not possible to directly import group libraries. To import items in group libraries, simply copy the group items to a collection in your Mendeley library before importing. You can then create a Zotero group and drag imported collections or items to that group.&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;level1&quot; readability=&quot;7&quot;&gt;
&lt;p&gt;Mendeley allows any field to be added to any type. When importing into Zotero, if a field isn’t valid for a given item type, the field is placed into the Extra field. When possible, those will be used automatically in citations (e.g., Original Date), and future versions of Zotero will automatically convert those to any real fields that become available.&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;level1&quot; readability=&quot;6&quot;&gt;
&lt;p&gt;When using the Zotero word processor plugins, document citations created with Mendeley won’t currently be linked to imported citations in your Zotero database. Zotero's word processor plugins can, however, read Mendeley citations and their embedded metadata, so you can continue using the same documents with Zotero.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;
&lt;h2 class=&quot;sectionedit4&quot; id=&quot;the_import_process&quot;&gt;The Import Process&lt;/h2&gt;
&lt;div class=&quot;level2&quot; readability=&quot;67.736994219653&quot;&gt;
&lt;p&gt;&lt;strong&gt;If you have a Mendeley version older than 1.18:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Upgrade to Mendeley 1.18 using the &lt;a href=&quot;https://www.zotero.org/support/kb/mendeley_import#mendeley_118_installers&quot; title=&quot;kb:mendeley_import ↵&quot; class=&quot;wikilink1&quot;&gt;links below&lt;/a&gt; and then start the import in Zotero by going to File → “Import…” and choosing the “Mendeley” option.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;If you have Mendeley 1.18 and haven’t yet upgraded to Mendeley 1.19 or later:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Start the import in Zotero by going to File → “Import…” and choosing the “Mendeley” option.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;If you’ve already upgraded to 1.19 and have an automatic backup of your Mendeley SQLite database in the Mendeley data directory:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Locate your &lt;a href=&quot;https://service.elsevier.com/app/answers/detail/a_id/22098/kw/database/supporthub/mendeley/&quot; class=&quot;urlextern&quot; title=&quot;https://service.elsevier.com/app/answers/detail/a_id/22098/kw/database/supporthub/mendeley/&quot; rel=&quot;nofollow&quot;&gt;Mendeley data directory&lt;/a&gt; and look for a backupSlot1 (or higher) folder. If you see a database in the form &amp;lt;email&amp;gt;@www.mendeley.com.sqlite within one of the backup directories, copy it into the data directory one level up. Then start the import in Zotero by going to File → “Import…”, choosing the “Mendeley” option, and selecting that database.&lt;/p&gt;
&lt;p&gt;If the backupSlot&lt;em&gt;N&lt;/em&gt; folder contains an .sqlite filename with a long string of random characters, the backup has already been overwritten by the encrypted database. Check another backupSlot folder or use one of the methods below.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;If you’ve already upgraded to 1.19 and have a recent backup of your Mendeley SQLite database:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Start the import in Zotero by going to File → “Import…”. If you haven’t moved your backup files back into the Mendeley data directory, use the file option to select the &amp;lt;email&amp;gt;@www.mendeley.com.sqlite or online.sqlite database in your backup directory.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;If you’ve already upgraded to 1.19 and are not able to import from a recent backup of your Mendeley SQLite database:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;It's possible to recreate an unencrypted database by syncing from an older version of Mendeley Desktop. However, this requires syncing all data and files to Elsevier's servers before downgrading. Even syncing data alone isn't sufficient: Mendeley sync doesn't make any information about attached files available unless you actually sync the files themselves.&lt;/p&gt;
&lt;p&gt;If you don't want to sync any data to Elsevier's servers, your only option is to use one of the available export formats, such as BibTeX, to transfer your data to Zotero. As discussed above, you'll lose your folder structure and some other data.&lt;/p&gt;
&lt;p&gt;If you're syncing your library data but don't want to sync files, you'll need to manually relink files in Mendeley after downgrading or in Zotero after importing.&lt;/p&gt;
&lt;p&gt;(Note that at Zotero we strongly believe you should be fully in control of your own research data, and we don't think you should have to make these choices, but these are the available options given the design decisions Elsevier has made.)&lt;/p&gt;
&lt;p&gt;If you're comfortable syncing your data to Elsevier, or have already done so, here are the steps:&lt;/p&gt;
&lt;ol readability=&quot;0.94403892944039&quot;&gt;&lt;li class=&quot;level1&quot; readability=&quot;0&quot;&gt;
&lt;p&gt;Make sure you've synced all data and — if you want to avoid reassociating files manually — files to Elsevier's servers.&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;level1&quot; readability=&quot;-1.4102564102564&quot;&gt;

&lt;/li&gt;
&lt;li class=&quot;level1&quot;&gt;
&lt;p&gt;Download Mendeley 1.18.&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;level1&quot; readability=&quot;-1&quot;&gt;
&lt;p&gt;Perform a fresh sync to pull down your Mendeley data from the Elsevier servers.&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;level1&quot; readability=&quot;0&quot;&gt;
&lt;p&gt;Start the import in Zotero by going to File → “Import…” and choosing the “Mendeley” option.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;/div&gt;
&lt;h3 id=&quot;mendeley_118_installers&quot;&gt;Mendeley 1.18 installers&lt;/h3&gt;

&lt;h2 class=&quot;sectionedit5&quot; id=&quot;troubleshooting&quot;&gt;Troubleshooting&lt;/h2&gt;
&lt;div class=&quot;level2&quot; readability=&quot;11.390625&quot;&gt;
&lt;p&gt;Make sure you're running the latest version of Zotero available via Help → “Check for Updates…”.&lt;/p&gt;
&lt;p&gt;If you're running the latest version and something doesn’t come through how you expect or you run into any trouble, let us know in the &lt;a href=&quot;https://forums.zotero.org/&quot; class=&quot;urlextern&quot; title=&quot;https://forums.zotero.org/&quot; rel=&quot;nofollow&quot;&gt;Zotero Forums&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;h2 class=&quot;sectionedit6&quot; id=&quot;preserving_mendeley_annotations_and_highlights&quot;&gt;Preserving Mendeley Annotations and Highlights&lt;/h2&gt;
&lt;div class=&quot;level2&quot; readability=&quot;16.110878661088&quot;&gt;
&lt;p&gt;As &lt;a href=&quot;https://www.zotero.org/support/kb/mendeley_import#known_issues&quot; title=&quot;kb:mendeley_import ↵&quot; class=&quot;wikilink1&quot;&gt;noted above&lt;/a&gt;, Mendeley stores PDF annotations and highlights in its own database rather than in the PDF itself where they would be accessible to other PDF readers, and while Zotero will extract annotations to child notes with links back to the PDF, embedded annotations and highlights will not be imported.&lt;/p&gt;
&lt;p&gt;To use the third-party &lt;a href=&quot;https://github.com/cycomanic/Menextract2pdf&quot; class=&quot;urlextern&quot; title=&quot;https://github.com/cycomanic/Menextract2pdf&quot; rel=&quot;nofollow&quot;&gt;menextract2pdf&lt;/a&gt; script to save annotations and highlights back to all of the PDFs in your library before importing into Zotero, follow these steps:&lt;/p&gt;
&lt;/div&gt;
&lt;h3 id=&quot;macos_or_linux&quot;&gt;macOS or Linux&lt;/h3&gt;
&lt;div class=&quot;level3&quot;&gt;
&lt;ol readability=&quot;-0.47418967587035&quot;&gt;&lt;li class=&quot;level1&quot;&gt;
&lt;p&gt;Close Mendeley&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;level1&quot; readability=&quot;-1.3349282296651&quot;&gt;
&lt;div class=&quot;li&quot; readability=&quot;7.1196172248804&quot;&gt;Make a backup of your &lt;a href=&quot;https://service.elsevier.com/app/answers/detail/a_id/22098/kw/database/supporthub/mendeley/&quot; class=&quot;urlextern&quot; title=&quot;https://service.elsevier.com/app/answers/detail/a_id/22098/kw/database/supporthub/mendeley/&quot; rel=&quot;nofollow&quot;&gt;Mendeley data directory&lt;/a&gt;, including the &lt;code&gt;Downloaded&lt;/code&gt; folder that holds your PDF files (and other locations on your computer where you have PDF files you wish to save Mendeley annotations to)&lt;/div&gt;
&lt;/li&gt;
&lt;li class=&quot;level1&quot; readability=&quot;-1.8518518518519&quot;&gt;
&lt;div class=&quot;li&quot; readability=&quot;6.4814814814815&quot;&gt;Download and unzip the menextract2pdf script from &lt;a href=&quot;https://github.com/cycomanic/Menextract2pdf/archive/master.zip&quot; class=&quot;urlextern&quot; title=&quot;https://github.com/cycomanic/Menextract2pdf/archive/master.zip&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li class=&quot;level1 node&quot; readability=&quot;2&quot;&gt;
&lt;p&gt;Open Terminal, navigate to the unzipped Menextract2pdf folder, and run the following command (filling in the correct file paths):&lt;/p&gt;
&lt;ul&gt;&lt;li class=&quot;level2&quot; readability=&quot;-2&quot;&gt;
&lt;div class=&quot;li&quot; readability=&quot;7&quot;&gt;
&lt;pre class=&quot;code&quot;&gt;
menextract2pdf_overwrite.sh &quot;/Path/To/Mendeley/Data Folder/&quot; &quot;/Path/To/Mendeley/PDF/Folder/&quot;
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li class=&quot;level1 node&quot; readability=&quot;0.47575757575758&quot;&gt;
&lt;div class=&quot;li&quot; readability=&quot;10.784810126582&quot;&gt;For example, on macOS, if you have your Mendeley database in the &lt;a href=&quot;https://service.elsevier.com/app/answers/detail/a_id/22098/kw/database/supporthub/mendeley/&quot; class=&quot;urlextern&quot; title=&quot;https://service.elsevier.com/app/answers/detail/a_id/22098/kw/database/supporthub/mendeley/&quot; rel=&quot;nofollow&quot;&gt;default location&lt;/a&gt; and your PDFs stored in Mendeley's “Downloaded” folder, you would enter:&lt;/div&gt;
&lt;ul&gt;&lt;li class=&quot;level2&quot; readability=&quot;-1.5&quot;&gt;
&lt;div class=&quot;li&quot; readability=&quot;8&quot;&gt;
&lt;pre class=&quot;code&quot;&gt;
menextract2pdf_overwrite.sh &quot;/Users/&quot;Your Name&quot;/Library/Application Support/Mendeley Desktop&quot; &quot;/Users/&quot;Your Name&quot;/Library/Application Support/Mendeley Desktop/Downloaded/&quot;
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/div&gt;
&lt;h3 id=&quot;windows&quot;&gt;Windows&lt;/h3&gt;
&lt;div class=&quot;level3&quot;&gt;
&lt;ol readability=&quot;-0.46993865030675&quot;&gt;&lt;li class=&quot;level1&quot;&gt;

&lt;/li&gt;
&lt;li class=&quot;level1&quot;&gt;
&lt;p&gt;Close Mendeley&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;level1&quot; readability=&quot;-1.3349282296651&quot;&gt;
&lt;div class=&quot;li&quot; readability=&quot;7.1196172248804&quot;&gt;Make a backup of your &lt;a href=&quot;https://service.elsevier.com/app/answers/detail/a_id/22098/kw/database/supporthub/mendeley/&quot; class=&quot;urlextern&quot; title=&quot;https://service.elsevier.com/app/answers/detail/a_id/22098/kw/database/supporthub/mendeley/&quot; rel=&quot;nofollow&quot;&gt;Mendeley data directory&lt;/a&gt;, including the &lt;code&gt;Downloaded&lt;/code&gt; folder that holds your PDF files (and other locations on your computer where you have PDF files you wish to save Mendeley annotations to)&lt;/div&gt;
&lt;/li&gt;
&lt;li class=&quot;level1&quot; readability=&quot;-1.8518518518519&quot;&gt;
&lt;div class=&quot;li&quot; readability=&quot;6.4814814814815&quot;&gt;Download and unzip the menextract2pdf script from &lt;a href=&quot;https://github.com/cycomanic/Menextract2pdf/archive/master.zip&quot; class=&quot;urlextern&quot; title=&quot;https://github.com/cycomanic/Menextract2pdf/archive/master.zip&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li class=&quot;level1 node&quot; readability=&quot;2&quot;&gt;
&lt;p&gt;Open Command Prompt, navigate to the unzipped Menextract2pdf folder, and run the following command (filling in the correct file paths):&lt;/p&gt;
&lt;ul&gt;&lt;li class=&quot;level2&quot; readability=&quot;-2&quot;&gt;
&lt;div class=&quot;li&quot; readability=&quot;7&quot;&gt;
&lt;pre class=&quot;code&quot;&gt;
menextract2pdf_overwrite.bat &quot;C:\Path\To\Mendeley\Data Folder\&quot; &quot;C:\Path\To\Mendeley\PDF\Folder\&quot;
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li class=&quot;level1 node&quot; readability=&quot;0&quot;&gt;
&lt;div class=&quot;li&quot; readability=&quot;9.8108108108108&quot;&gt;For example, if you have your Mendeley database in the &lt;a href=&quot;https://service.elsevier.com/app/answers/detail/a_id/22098/kw/database/supporthub/mendeley/&quot; class=&quot;urlextern&quot; title=&quot;https://service.elsevier.com/app/answers/detail/a_id/22098/kw/database/supporthub/mendeley/&quot; rel=&quot;nofollow&quot;&gt;default location&lt;/a&gt; and your PDFs stored in Mendeley's “Downloaded” folder, you would enter:&lt;/div&gt;
&lt;ul&gt;&lt;li class=&quot;level2&quot; readability=&quot;-1.5&quot;&gt;
&lt;div class=&quot;li&quot; readability=&quot;8&quot;&gt;
&lt;pre class=&quot;code&quot;&gt;
menextract2pdf_overwrite.bat &quot;%LOCALAPPDATA%\Mendeley Ltd.\Mendeley Desktop\&quot; &quot;%LOCALAPPDATA%\Mendeley Ltd.\Mendeley Desktop\Downloaded\&quot;
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
<pubDate>Wed, 23 Jan 2019 11:47:11 +0000</pubDate>
<dc:creator>fantasticfears</dc:creator>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.zotero.org/support/kb/mendeley_import</dc:identifier>
</item>
<item>
<title>Chromecast Support for Firefox</title>
<link>https://hensm.github.io/fx_cast/</link>
<guid isPermaLink="true" >https://hensm.github.io/fx_cast/</guid>
<description>&lt;header class=&quot;main-header&quot;&gt;
&lt;h2 class=&quot;main-subtitle&quot;&gt;chromecast for firefox&lt;/h2&gt;
&lt;/header&gt;&lt;section class=&quot;description&quot; readability=&quot;10&quot;&gt;&lt;p&gt;Enables Chromecast support for casting web apps (like Netflix or BBC iPlayer), HTML5 video and screen/tab sharing.&lt;/p&gt;
&lt;p class=&quot;discription__disclaimer&quot;&gt;Requires a native bridge app to connect with receiver devices. Currently supported on Windows, macOS and Linux.&lt;/p&gt;
&lt;p class=&quot;discription__prerelease&quot;&gt;No full public release yet! Pre-release beta version is incomplete and likely buggy.&lt;/p&gt;
&lt;/section&gt;&lt;section class=&quot;download&quot;&gt;&lt;a class=&quot;download__ext btn btn--puffy btn--primary&quot; disabled=&quot;disabled&quot; title=&quot;No available download found&quot;&gt;&lt;img class=&quot;btn__icon&quot; src=&quot;https://hensm.github.io/fx_cast/icons/extension_light.svg&quot; alt=&quot;&quot;/&gt; Firefox Extension&lt;/a&gt;

&lt;/section&gt;</description>
<pubDate>Wed, 23 Jan 2019 07:41:04 +0000</pubDate>
<dc:creator>Benjamin_Dobell</dc:creator>
<dc:format>text/html</dc:format>
<dc:identifier>https://hensm.github.io/fx_cast/</dc:identifier>
</item>
</channel>
</rss>