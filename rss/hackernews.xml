<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=hnrss.org%2Fnewest%3Fpoints%3D200&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://hnrss.org/newest?points=200" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>Hacker News: Newest</title>
<link>https://news.ycombinator.com/newest</link>
<description>Hacker News RSS</description>
<item>
<title>AWS announces forks of Elasticsearch and Kibana</title>
<link>https://aws.amazon.com/blogs/opensource/stepping-up-for-a-truly-open-source-elasticsearch</link>
<guid isPermaLink="true" >https://aws.amazon.com/blogs/opensource/stepping-up-for-a-truly-open-source-elasticsearch</guid>
<description>&lt;p&gt;Last week, Elastic announced they will change their software licensing strategy, and will not release new versions of Elasticsearch and Kibana under the Apache License, Version 2.0 (ALv2). Instead, new versions of the software will be offered under the Elastic License (which limits how it can be used) or the Server Side Public License (which has requirements that make it &lt;a href=&quot;https://opensource.org/node/1099&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;unacceptable to many in the open source community&lt;/a&gt;). This means that Elasticsearch and Kibana will no longer be open source software. In order to ensure open source versions of both packages remain available and well supported, including in our own offerings, we are announcing today that AWS will step up to create and maintain a ALv2-licensed fork of open source Elasticsearch and Kibana.&lt;/p&gt;&lt;h2&gt;What this means for the Open Distro for Elasticsearch community&lt;/h2&gt;
&lt;p&gt;We launched &lt;a href=&quot;https://opendistro.github.io/for-elasticsearch/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Open Distro for Elasticsearch&lt;/a&gt; in 2019 to provide customers and developers with a fully featured Elasticsearch distribution that provides all of the freedoms of ALv2-licensed software. Open Distro for Elasticsearch is a 100% open source distribution that delivers functionality practically every Elasticsearch user or developer needs, including support for network encryption and access controls. In building Open Distro, we followed the recommended open source development practice of “&lt;a href=&quot;https://www.redhat.com/en/blog/what-open-source-upstream&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;upstream first&lt;/a&gt;.” All changes to Elasticsearch were sent as upstream pull requests (&lt;a href=&quot;https://github.com/elastic/elasticsearch/pull/42066&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;#42066&lt;/a&gt;, &lt;a href=&quot;https://github.com/elastic/elasticsearch/pull/42658&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;#42658&lt;/a&gt;, &lt;a href=&quot;https://github.com/elastic/elasticsearch/pull/43284&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;#43284&lt;/a&gt;, &lt;a href=&quot;https://github.com/elastic/elasticsearch/pull/43839&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;#43839&lt;/a&gt;, &lt;a href=&quot;https://github.com/elastic/elasticsearch/pull/53643&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;#53643&lt;/a&gt;, &lt;a href=&quot;https://github.com/elastic/elasticsearch/pull/57271&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;#57271&lt;/a&gt;, &lt;a href=&quot;https://github.com/elastic/elasticsearch/pull/59563&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;#59563&lt;/a&gt;, &lt;a href=&quot;https://github.com/elastic/elasticsearch/pull/61400&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;#61400&lt;/a&gt;, &lt;a href=&quot;https://github.com/elastic/elasticsearch/pull/64513&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;#64513&lt;/a&gt;), and we then included the “oss” builds offered by Elastic in our distribution. This ensured that we were collaborating with the upstream developers and maintainers, and not creating a “fork” of the software.&lt;/p&gt;
&lt;p&gt;Choosing to fork a project is not a decision to be taken lightly, but it can be the right path forward when the needs of a community diverge—as they have here. An important benefit of open source software is that when something like this happens, developers already have all the rights they need to pick up the work themselves, if they are sufficiently motivated. There are many success stories here, like the community-developed &lt;a href=&quot;https://en.wikipedia.org/wiki/Jenkins_(software)&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Jenkins CI&lt;/a&gt; tool.&lt;/p&gt;
&lt;p&gt;When AWS decides to offer a service based on an open source project, we ensure that we are equipped and prepared to maintain it ourselves if necessary. AWS brings years of experience working with these codebases, as well as making upstream code contributions to both Elasticsearch and &lt;a href=&quot;https://aws.amazon.com/blogs/opensource/amazon-giving-back-apache-lucene/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Apache Lucene&lt;/a&gt;, the core search library that Elasticsearch is built on—with more than 230 Lucene contributions in 2020 alone.&lt;/p&gt;
&lt;p&gt;Our forks of Elasticsearch and Kibana will be based on the latest ALv2-licensed codebases, version 7.10. We will publish new GitHub repositories in the next few weeks. In time, both will be included in the existing Open Distro distributions, replacing the ALv2 builds provided by Elastic. We’re in this for the long haul, and will work in a way that fosters healthy and sustainable open source practices—including implementing shared project governance with a community of contributors.&lt;/p&gt;
&lt;h2&gt;What this means for Amazon Elasticsearch Service customers&lt;/h2&gt;
&lt;p&gt;You can rest assured that neither Elastic’s license change, nor our decision to fork, will have any negative impact on the &lt;a href=&quot;https://aws.amazon.com/elasticsearch-service/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Amazon Elasticsearch Service (Amazon ES)&lt;/a&gt; you currently enjoy. Today, we offer 18 versions of Elasticsearch on Amazon ES, and none of these are affected by the license change.&lt;/p&gt;
&lt;p&gt;In the future, Amazon ES will be powered by the new fork of Elasticsearch and Kibana. We will continue to deliver new features, fixes, and enhancements. We are committed to providing compatibility to eliminate any need to update your client or application code. Just as we do today, we will provide you with a seamless upgrade path to new versions of the software.&lt;/p&gt;
&lt;p&gt;This change will not slow the velocity of enhancements we offer to our customers. If anything, a community-owned Elasticsearch codebase presents new opportunities for us to move faster in improving stability, scalability, resiliency, and performance.&lt;/p&gt;
&lt;h2&gt;What this means for the open source community&lt;/h2&gt;
&lt;p&gt;Developers embrace open source software for many reasons, perhaps the most important being the freedom to use that software where and how they wish.&lt;/p&gt;
&lt;p&gt;The term “open source” has had a &lt;a href=&quot;https://opensource.org/docs/osd&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;specific meaning&lt;/a&gt; since it was &lt;a href=&quot;https://opensource.org/history#:~:text=Coining%20%E2%80%9COpen%20Source%E2%80%9D,of%20the%20Netscape%20source%20code.&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;coined in 1998&lt;/a&gt;. Elastic’s assertions that the SSPL is “free and open” are misleading and wrong. They’re trying to claim the benefits of open source, while chipping away at the very definition of open source itself. Their choice of SSPL belies this. SSPL is a non-open source license designed to look like an open source license, blurring the lines between the two. As the &lt;a href=&quot;https://fedoraproject.org/wiki/Licensing/SSPL&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Fedora community states&lt;/a&gt;, “[to] consider the SSPL to be ‘Free’ or ‘Open Source’ causes [a] shadow to be cast across all other licenses in the FOSS ecosystem.”&lt;/p&gt;
&lt;p&gt;In April 2018, when Elastic co-mingled their proprietary licensed software with the ALv2 code, they promised in “&lt;a href=&quot;https://web.archive.org/web/20200120104750/https:/www.elastic.co/what-is/open-x-pack&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;We Opened X-Pack&lt;/a&gt;”: “We did not change the license of any of the Apache 2.0 code of Elasticsearch, Kibana, Beats, and Logstash — and we never will.” Last week, after reneging on this promise, Elastic updated that same page with &lt;a href=&quot;https://www.elastic.co/what-is/open-x-pack&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;a footnote&lt;/a&gt; that says “circumstances have changed.”&lt;/p&gt;
&lt;p&gt;Elastic knows what they’re doing is fishy. The community has told them this (e.g., see &lt;a href=&quot;https://anonymoushash.vmbrasseur.com/2021/01/14/elasticsearch-and-kibana-are-now-business-risks&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Brasseur&lt;/a&gt;, &lt;a href=&quot;https://twitter.com/QuinnyPig/status/1350205491750662146&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Quinn&lt;/a&gt;, &lt;a href=&quot;https://drewdevault.com/2021/01/19/Elasticsearch-does-not-belong-to-Elastic.html&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;DeVault&lt;/a&gt;, and &lt;a href=&quot;https://twitter.com/adamhjk/status/1349764557695139840&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Jacob&lt;/a&gt;). It’s also why they felt the need to write an additional blustery blog (on top of their initial license change blog) to try to explain their actions as “AWS made us do it.” Most folks aren’t fooled. We didn’t make them do anything. They believe that restricting their license will lock others out of offering managed Elasticsearch services, which will let Elastic build a bigger business. Elastic has a right to change their license, but they should also step up and own their own decision.&lt;/p&gt;
&lt;p&gt;In the meantime, we’re excited about the long-term journey we’ve embarked on with Open Distro for Elasticsearch. We look forward to providing a truly open source option for Elasticsearch and Kibana using the ALv2 license, and building and supporting this future with the community.&lt;/p&gt;
</description>
<pubDate>Thu, 21 Jan 2021 22:07:58 +0000</pubDate>
<dc:creator>ke4qqq</dc:creator>
<og:title>Stepping up for a truly open source Elasticsearch | Amazon Web Services</og:title>
<og:type>article</og:type>
<og:url>https://aws.amazon.com/blogs/opensource/stepping-up-for-a-truly-open-source-elasticsearch/</og:url>
<og:description>Last week, Elastic announced they will change their software licensing strategy, and will not release new versions of Elasticsearch and Kibana under the Apache License, Version 2.0 (ALv2). Instead, new versions of the software will be offered under the Elastic License (which limits how it can be used) or the Server Side Public License (which […]</og:description>
<og:image>https://d2908q01vomqb2.cloudfront.net/ca3512f4dfa95a03169c5a670a4c91a19b3077b4/2019/01/10/open-source-logo-800x400.jpg</og:image>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://aws.amazon.com/blogs/opensource/stepping-up-for-a-truly-open-source-elasticsearch/</dc:identifier>
</item>
<item>
<title>DeLorean considering all-electric reboot</title>
<link>https://www.newdelorean.com/nhtsa-releases-final-low-volume-manufacturing-rules/</link>
<guid isPermaLink="true" >https://www.newdelorean.com/nhtsa-releases-final-low-volume-manufacturing-rules/</guid>
<description>&lt;p&gt;National Highway Traffic Safety Administration (NHTSA) has completed a regulation permitting low volume motor vehicle manufacturers to begin selling replica cars that resemble vehicles produced at least 25 years ago. Congress enacted a DeLorean Motor Company-backed bill backed by the Specialty Equipment Market Association (SEMA) DeLorean Motor Company, and others into law in 2015, which streamlined requirements for small automakers, but implementation was delayed while awaiting the NHTSA regulations. Companies like DeLorean will now be able to apply for authorization to produce and sell vehicles under this program.&lt;/p&gt;
&lt;p&gt;The recent release of the final rule document was unexpected, and we’re very pleased to see it finally happen. Still, four years overdue with no clear idea of when (or if!) these would ever be released did certainly keep us from putting too many eggs in that stainless steel basket, so to speak.&lt;/p&gt;
&lt;p&gt;Some previous suppliers that we had lined up have gone out of business during the pandemic, others have been absorbed by larger companies that have made it clear low volume component production is not something they’re interested in pursuing. In that regard there will be a fair amount of work to be re-done. Perhaps worse, some “champions” we had at various suppliers have retired or moved on. In some cases this has left a void, where before there was a DeLorean fan, who rallied for us within their company and management.&lt;/p&gt;
&lt;p&gt;Additionally, certain staffing candidates that were on our short-list have long since moved on in and while unemployment has increased during 2020, many of the specialized roles that we require are still hard to fill.&lt;/p&gt;
&lt;p&gt;As mentioned before, in 2015 our planned engine had a life-cycle of emissions compliance through 2022. We had hoped to get into production by 2017 and get 3-4 years out of it before having to take on the engineering for a new powertrain. It’s believed that this engine has been extended through perhaps 2024 now, but it doesn’t seem like a good idea to plan around an engine so near its end-of-life.&lt;/p&gt;
&lt;p&gt;That said, with EV’s becoming more mainstream, we’ve been considering switching to an all-electric as the future. It certainly makes for an easier path through emissions maze which still looms large over any internal combustion engine. While an electric Cobra or Morgan may be a little extreme for their potential market, we’ve already seen that an EV DeLorean – as we displayed at the 2012 New York International Auto Show – is not such an “out there” idea.&lt;/p&gt;
&lt;p&gt;Most critically, financial markets have changed, and will change even more as the world navigates the continuing COVID crisis during the Biden administration. Will the financial support that we had lined up a few years ago to carry us through the final development and into production still be available?&lt;/p&gt;
&lt;p&gt;As the automotive brand with likely the highest name recognition across all demographics in spite of not having a new product in 40 years, we still believe that none of the above is insurmountable and believe that others will see value in it, as well.&lt;/p&gt;
&lt;p&gt;Stay tuned…&lt;/p&gt;

</description>
<pubDate>Thu, 21 Jan 2021 20:52:14 +0000</pubDate>
<dc:creator>evo_9</dc:creator>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.newdelorean.com/nhtsa-releases-final-low-volume-manufacturing-rules/</dc:identifier>
</item>
<item>
<title>Rust for Windows</title>
<link>https://github.com/microsoft/windows-rs</link>
<guid isPermaLink="true" >https://github.com/microsoft/windows-rs</guid>
<description>&lt;p&gt;&lt;a href=&quot;https://crates.io/crates/windows&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/a6278670181bdf3c8909a11e7143d5654b3d11e05d42b00deda1f117f7d5de12/68747470733a2f2f696d672e736869656c64732e696f2f6372617465732f762f77696e646f77732e737667&quot; alt=&quot;crates.io&quot; data-canonical-src=&quot;https://img.shields.io/crates/v/windows.svg&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://docs.rs/windows&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/6b4f7993545306b4c209fcbcf5e9a5e395f045bd285079ce0f02e39f3006fc2d/68747470733a2f2f646f63732e72732f77696e646f77732f62616467652e737667&quot; alt=&quot;docs.rs&quot; data-canonical-src=&quot;https://docs.rs/windows/badge.svg&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/microsoft/windows-rs/actions&quot;&gt;&lt;img src=&quot;https://github.com/microsoft/windows-rs/workflows/Build%20and%20Test/badge.svg?event=push&quot; alt=&quot;Build and Test&quot;/&gt;&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;Rust for Windows&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;windows&lt;/code&gt; crate lets you call any Windows API past, present, and future using code generated on the fly directly from the metadata describing the API and right into your Rust package where you can call them as if they were just another Rust module.&lt;/p&gt;
&lt;p&gt;The Rust language projection follows in the tradition established by &lt;a href=&quot;https://github.com/microsoft/cppwinrt&quot;&gt;C++/WinRT&lt;/a&gt; of building language projections for Windows using standard languages and compilers, providing a natural and idiomatic way for Rust developers to call Windows APIs.&lt;/p&gt;
&lt;h2&gt;Getting started&lt;/h2&gt;
&lt;p&gt;Start by adding the following to your Cargo.toml file:&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-toml&quot; readability=&quot;7&quot;&gt;
&lt;pre&gt;
[&lt;span class=&quot;pl-en&quot;&gt;dependencies&lt;/span&gt;]
&lt;span class=&quot;pl-smi&quot;&gt;windows&lt;/span&gt; = &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;0.2.1&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;

[&lt;span class=&quot;pl-en&quot;&gt;build-dependencies&lt;/span&gt;]
&lt;span class=&quot;pl-smi&quot;&gt;windows&lt;/span&gt; = &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;0.2.1&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will allow Cargo to download, build, and cache Windows support as a package. Next, specify which types you need inside of a &lt;code&gt;build.rs&lt;/code&gt; build script and the &lt;code&gt;windows&lt;/code&gt; crate will generate the necessary bindings:&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-rust&quot; readability=&quot;10&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;pl-k&quot;&gt;fn&lt;/span&gt; &lt;span class=&quot;pl-en&quot;&gt;main&lt;/span&gt;() {
    windows&lt;span class=&quot;pl-k&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;pl-en&quot;&gt;build!&lt;/span&gt;(
        windows&lt;span class=&quot;pl-k&quot;&gt;::&lt;/span&gt;data&lt;span class=&quot;pl-k&quot;&gt;::&lt;/span&gt;xml&lt;span class=&quot;pl-k&quot;&gt;::&lt;/span&gt;dom&lt;span class=&quot;pl-k&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;pl-k&quot;&gt;*&lt;/span&gt;
        windows&lt;span class=&quot;pl-k&quot;&gt;::&lt;/span&gt;win32&lt;span class=&quot;pl-k&quot;&gt;::&lt;/span&gt;system_services&lt;span class=&quot;pl-k&quot;&gt;::&lt;/span&gt;{CreateEventW, SetEvent, WaitForSingleObject}
        windows&lt;span class=&quot;pl-k&quot;&gt;::&lt;/span&gt;win32&lt;span class=&quot;pl-k&quot;&gt;::&lt;/span&gt;windows_programming&lt;span class=&quot;pl-k&quot;&gt;::&lt;/span&gt;CloseHandle
    );
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Finally, make use of any Windows APIs as needed.&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-rust&quot; readability=&quot;20&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;pl-k&quot;&gt;mod&lt;/span&gt; bindings {
    &lt;span class=&quot;pl-k&quot;&gt;::&lt;/span&gt;windows&lt;span class=&quot;pl-k&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;pl-en&quot;&gt;include_bindings!&lt;/span&gt;();
}

&lt;span class=&quot;pl-k&quot;&gt;use&lt;/span&gt; bindings&lt;span class=&quot;pl-k&quot;&gt;::&lt;/span&gt;{
    windows&lt;span class=&quot;pl-k&quot;&gt;::&lt;/span&gt;data&lt;span class=&quot;pl-k&quot;&gt;::&lt;/span&gt;xml&lt;span class=&quot;pl-k&quot;&gt;::&lt;/span&gt;dom&lt;span class=&quot;pl-k&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;pl-k&quot;&gt;*&lt;/span&gt;,
    windows&lt;span class=&quot;pl-k&quot;&gt;::&lt;/span&gt;win32&lt;span class=&quot;pl-k&quot;&gt;::&lt;/span&gt;system_services&lt;span class=&quot;pl-k&quot;&gt;::&lt;/span&gt;{CreateEventW, SetEvent, WaitForSingleObject},
    windows&lt;span class=&quot;pl-k&quot;&gt;::&lt;/span&gt;win32&lt;span class=&quot;pl-k&quot;&gt;::&lt;/span&gt;windows_programming&lt;span class=&quot;pl-k&quot;&gt;::&lt;/span&gt;CloseHandle,
};

&lt;span class=&quot;pl-k&quot;&gt;fn&lt;/span&gt; &lt;span class=&quot;pl-en&quot;&gt;main&lt;/span&gt;() -&amp;gt; windows::&lt;span class=&quot;pl-k&quot;&gt;Result&lt;/span&gt;&amp;lt;()&amp;gt; {
    &lt;span class=&quot;pl-k&quot;&gt;let&lt;/span&gt; doc &lt;span class=&quot;pl-k&quot;&gt;=&lt;/span&gt; XmlDocument&lt;span class=&quot;pl-k&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;pl-en&quot;&gt;new&lt;/span&gt;()?;
    doc.&lt;span class=&quot;pl-en&quot;&gt;load_xml&lt;/span&gt;(&lt;span class=&quot;pl-s&quot;&gt;&quot;&amp;lt;html&amp;gt;hello world&amp;lt;/html&amp;gt;&quot;&lt;/span&gt;)?;

    &lt;span class=&quot;pl-k&quot;&gt;let&lt;/span&gt; root &lt;span class=&quot;pl-k&quot;&gt;=&lt;/span&gt; doc.&lt;span class=&quot;pl-en&quot;&gt;document_element&lt;/span&gt;()?;
    &lt;span class=&quot;pl-c1&quot;&gt;assert!&lt;/span&gt;(root.&lt;span class=&quot;pl-en&quot;&gt;node_name&lt;/span&gt;()? &lt;span class=&quot;pl-k&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;pl-s&quot;&gt;&quot;html&quot;&lt;/span&gt;);
    &lt;span class=&quot;pl-c1&quot;&gt;assert!&lt;/span&gt;(root.&lt;span class=&quot;pl-en&quot;&gt;inner_text&lt;/span&gt;()? &lt;span class=&quot;pl-k&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;pl-s&quot;&gt;&quot;hello world&quot;&lt;/span&gt;);

    &lt;span class=&quot;pl-k&quot;&gt;unsafe&lt;/span&gt; {
        &lt;span class=&quot;pl-k&quot;&gt;let&lt;/span&gt; event &lt;span class=&quot;pl-k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;pl-en&quot;&gt;CreateEventW&lt;/span&gt;(
            std&lt;span class=&quot;pl-k&quot;&gt;::&lt;/span&gt;ptr&lt;span class=&quot;pl-k&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;pl-en&quot;&gt;null_mut&lt;/span&gt;(),
            &lt;span class=&quot;pl-c1&quot;&gt;true&lt;/span&gt;.&lt;span class=&quot;pl-en&quot;&gt;into&lt;/span&gt;(),
            &lt;span class=&quot;pl-c1&quot;&gt;false&lt;/span&gt;.&lt;span class=&quot;pl-en&quot;&gt;into&lt;/span&gt;(),
            std&lt;span class=&quot;pl-k&quot;&gt;::&lt;/span&gt;ptr&lt;span class=&quot;pl-k&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;pl-en&quot;&gt;null&lt;/span&gt;(),
        );

        &lt;span class=&quot;pl-en&quot;&gt;SetEvent&lt;/span&gt;(event).&lt;span class=&quot;pl-en&quot;&gt;ok&lt;/span&gt;()?;
        &lt;span class=&quot;pl-en&quot;&gt;WaitForSingleObject&lt;/span&gt;(event, &lt;span class=&quot;pl-c1&quot;&gt;0&lt;/span&gt;);
        &lt;span class=&quot;pl-en&quot;&gt;CloseHandle&lt;/span&gt;(event).&lt;span class=&quot;pl-en&quot;&gt;ok&lt;/span&gt;()?;
    }

    &lt;span class=&quot;pl-c1&quot;&gt;Ok&lt;/span&gt;(())
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To reduce build time, use a &lt;code&gt;bindings&lt;/code&gt; crate rather simply a module. This will allow Cargo to cache the results and build your project far more quickly.&lt;/p&gt;
&lt;p&gt;There is an experimental &lt;a href=&quot;https://github.com/microsoft/windows-docs-rs&quot;&gt;documentation generator&lt;/a&gt; for the Windows API. The documentation &lt;a href=&quot;https://microsoft.github.io/windows-docs-rs/&quot; rel=&quot;nofollow&quot;&gt;is published here&lt;/a&gt;. This can be useful to figure out how the various Windows APIs map to Rust modules and which &lt;code&gt;use&lt;/code&gt; paths you need to use from within the &lt;code&gt;build&lt;/code&gt; macro.&lt;/p&gt;
&lt;p&gt;For a more complete example, take a look at Robert Mikhayelyan's &lt;a href=&quot;https://github.com/robmikh/minesweeper-rs&quot;&gt;Minesweeper&lt;/a&gt;. More simple examples &lt;a href=&quot;https://github.com/kennykerr/samples-rs&quot;&gt;can be found here&lt;/a&gt;.&lt;/p&gt;
</description>
<pubDate>Thu, 21 Jan 2021 18:37:30 +0000</pubDate>
<dc:creator>dsr12</dc:creator>
<og:image>https://avatars.githubusercontent.com/u/6154722?s=400&amp;v=4</og:image>
<og:type>object</og:type>
<og:title>microsoft/windows-rs</og:title>
<og:url>https://github.com/microsoft/windows-rs</og:url>
<og:description>Rust for Windows. Contribute to microsoft/windows-rs development by creating an account on GitHub.</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://github.com/microsoft/windows-rs</dc:identifier>
</item>
<item>
<title>Retiring Tucows Downloads</title>
<link>https://tucows.com/retired/</link>
<guid isPermaLink="true" >https://tucows.com/retired/</guid>
<description>&lt;p&gt;&lt;strong&gt;&lt;em&gt;A note to Tucows Downloads visitors:&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;All good things…&lt;/p&gt;
&lt;p&gt;We have made the difficult decision to retire the Tucows Downloads site. We’re pleased to say that much of the software and other assets that made up the Tucows Downloads library have been transferred to our friends at the &lt;a href=&quot;https://archive.org&quot;&gt;Internet Archive&lt;/a&gt; for posterity. &lt;/p&gt;
&lt;p&gt;The shareware downloads bulletin board system (BBS) that would become Tucows Downloads was founded back in 1993 on a library computer in Flint, MI. What started as a place for people in the know to download software became &lt;em&gt;the&lt;/em&gt; place to download software on the burgeoning Internet. Far more quickly than anyone could have imagined.&lt;/p&gt;
&lt;p&gt;A lot has changed since those early years. Tucows has grown and evolved as a business. It’s been a long time since Tucows has been TUCOWS, which stood for The Ultimate Collection of Winsock Software. &lt;/p&gt;
&lt;p&gt;Today, Tucows is the second-largest domain name registrar in the world behind Go Daddy and the largest wholesaler of domain names in the world with customers like Shopify and other global website builder platforms. &lt;a href=&quot;https://www.hover.com/&quot;&gt;Hover&lt;/a&gt; offers domain names and email at retail to help people brand their life online. &lt;a href=&quot;https://opensrs.com/&quot;&gt;OpenSRS&lt;/a&gt; (and along the way our acquisitions of Enom, Ascio and EPAG) are the SaaS platforms upon which tens of thousands of customers have built their own domain registration businesses, registering tens of millions of domains on behalf of their customers. &lt;a href=&quot;https://ting.com/internet&quot;&gt;Ting Internet&lt;/a&gt; is building fiber-optic networks all over the U.S. At the same time, we’re building the Mobile Services Enabler SaaS platform that is powering DISH’s entry into the US mobile market. &lt;/p&gt;
&lt;p&gt;Point is, we’re keeping busy.&lt;/p&gt;
&lt;p&gt;For the past several years, history, well sentimentality, has been the only reason to keep Tucows Downloads around. We talked about shutting the site down before. Most seriously in 2016 when instead, we &lt;a href=&quot;https://www.tucows.com/blog/2016/05/03/tucows-cuts-the-crap/&quot;&gt;decided to go ad-free&lt;/a&gt;, keeping the site up as a public service.&lt;/p&gt;
&lt;p&gt;Today is different. Tucows Downloads is old. Old sites are a maintenance challenge and therefore a risk. Maintaining the Tucows Downloads site pulls people away from the work that moves our businesses forward.&lt;/p&gt;
&lt;p&gt;Tucows Downloads has had an incredible run. Retiring it is the right move but that doesn’t alter the fact that it will always hold a special place in hearts and our story. We’re thankful to the thousands of software developers who used Tucows Downloads to get their software in front of millions of people, driving billions of downloads over more than 25 years.&lt;/p&gt;
&lt;p&gt;Thank you.&lt;/p&gt;&lt;p&gt;Sincerely, &lt;br/&gt;Elliot Noss&lt;br/&gt;CEO, Tucows&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;A note to Tucows Downloads Authors/Developers&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;If you’re a developer who used the Tucows Author Resource Center (ARC) as part of your software dissemination, to buy code signing or other services, we’re happy to help with the transition. &lt;/p&gt;
&lt;p&gt;Any certificates purchased through ARC remain valid. If you’re looking to buy or renew code signing certificates, we invite you to go straight to the source; &lt;a href=&quot;https://sectigo.com/&quot;&gt;Sectigo&lt;/a&gt; was our supplier and will be happy to be yours too.&lt;br/&gt;Feel free to reach out to us at &lt;a href=&quot;mailto:help@tucows.com&quot;&gt;help@tucows.com&lt;/a&gt; if we can help with anything at all.&lt;/p&gt;
</description>
<pubDate>Thu, 21 Jan 2021 18:36:41 +0000</pubDate>
<dc:creator>andrewdutton</dc:creator>
<og:type>website</og:type>
<og:image>https://app.jobvite.com/logo/tucowslogoonblue_1573162159821.png</og:image>
<og:title>Tucows | Retiring Tucows Downloads.</og:title>
<og:description>Tucows is a tech company headquartered in Toronto, Canada since 1993. Tucows offers mobile, fiber Internet and domain name services as Ting, Hover, OpenSRS, Enom, Epag and Ascio.</og:description>
<og:url>https://www.tucows.com/retired/</og:url>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://tucows.com/retired/</dc:identifier>
</item>
<item>
<title>The database servers powering Let&amp;#039;s Encrypt</title>
<link>https://letsencrypt.org/2021/01/21/next-gen-database-servers.html</link>
<guid isPermaLink="true" >https://letsencrypt.org/2021/01/21/next-gen-database-servers.html</guid>
<description>&lt;p&gt;Let’s Encrypt helps to protect a huge portion of the Web by providing TLS certificates to more than &lt;a href=&quot;https://letsencrypt.org/stats/&quot;&gt;235 million websites&lt;/a&gt;. A database is at the heart of how Let’s Encrypt manages certificate issuance. If this database isn’t performing well enough, it can cause API errors and timeouts for our subscribers. Database performance is the single most critical factor in our ability to scale while meeting service level objectives. In late 2020, we upgraded our database servers and we’ve been very happy with the results.&lt;/p&gt;&lt;h2 id=&quot;what-exactly-are-we-doing-with-these-servers&quot;&gt;What exactly are we doing with these servers?&lt;/h2&gt;
&lt;p&gt;Our CA software, &lt;a href=&quot;https://github.com/letsencrypt/boulder&quot;&gt;Boulder&lt;/a&gt;, uses MySQL-style schemas and queries to manage subscriber accounts and the entire certificate issuance process. It’s designed to work with a single MySQL, MariaDB, or Percona database. We currently use MariaDB, with the InnoDB database engine.&lt;/p&gt;
&lt;p&gt;We run the CA against a single database in order to minimize complexity. Minimizing complexity is good for security, reliability, and reducing maintenance burden. We have a number of replicas of the database active at any given time, and we direct some read operations to replica database servers to reduce load on the primary.&lt;/p&gt;
&lt;p&gt;One consequence of this design is that our database machines need to be pretty powerful. Eventually we may need to shard or break the single database into multiple databases, but hardware advancements have allowed us to avoid that so far.&lt;/p&gt;
&lt;h2 id=&quot;hardware-specifications&quot;&gt;Hardware Specifications&lt;/h2&gt;
&lt;p&gt;The previous generation of database hardware was powerful but it was regularly being pushed to its limits. For the next generation, we wanted to more than double almost every performance metric in the same 2U form factor. In order to pull that off, we needed AMD EPYC chips and Dell’s &lt;a href=&quot;https://www.dell.com/en-us/work/shop/cty/pdp/spd/poweredge-r7525/&quot;&gt;PowerEdge R7525&lt;/a&gt; was ideal. Here are the specifications:&lt;/p&gt;
&lt;div&gt;
&lt;table readability=&quot;3.8206896551724&quot;&gt;&lt;tr&gt;&lt;td/&gt;
&lt;td&gt;&lt;strong&gt;Previous Generation&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Next Generation&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;3.4747474747475&quot;&gt;&lt;td&gt;&lt;strong&gt;CPU&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;2x Intel Xeon E5-2650&lt;br/&gt;Total 24 cores / 48 threads&lt;/td&gt;
&lt;td&gt;2x &lt;a href=&quot;https://www.amd.com/en/products/cpu/amd-epyc-7452&quot;&gt;AMD EPYC 7542&lt;/a&gt;&lt;br/&gt;Total 64 cores / 128 threads&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Memory&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;1TB 2400MT/s&lt;/td&gt;
&lt;td&gt;2TB 3200MT/s&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;4&quot;&gt;&lt;td&gt;&lt;strong&gt;Storage&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;24x 3.8TB Samsung PM883&lt;br/&gt;SATA SSD&lt;br/&gt;560/540 MB/s read/write&lt;/td&gt;
&lt;td&gt;24x 6.4TB Intel P4610&lt;br/&gt;NVMe SSD&lt;br/&gt;3200/3200 MB/s read/write&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;&lt;/div&gt;
&lt;img src=&quot;https://letsencrypt.org/images/2021.01.21-next-gen-db-chassis.jpg&quot; width=&quot;600&quot; alt=&quot;Dell PowerEdge R7525 Chassis&quot;/&gt; Dell PowerEdge R7525 internals. The two silver rectangles in the middle are the CPUs. The RAM sticks, each 64GB, are above and below the CPUs. The 24x NVMe drives are in the front of the server, on the far left.
&lt;p&gt;By going with AMD EPYC, we were able to get 64 physical CPU cores while keeping clock speeds high: 2.9GHz base with 3.4GHz boost. More importantly, EPYC provides 128 PCIe v4.0 lanes, which allows us to put 24 NVMe drives in a single machine. NVMe is incredibly fast (~5.7x faster than the SATA SSDs in our previous-gen database servers) because it uses PCIe instead of SATA. However, PCIe lanes are typically very limited: modern consumer chips typically have only 16 lanes, and Intel’s Xeon chips have 48. By providing 128 PCI lanes per chip (v4.0, no less), AMD EPYC has made it possible to pack large numbers of NVMe drives into a single machine. We’ll talk more about NVMe later.&lt;/p&gt;
&lt;h2 id=&quot;performance-impact&quot;&gt;Performance Impact&lt;/h2&gt;
&lt;p&gt;We’ll start by looking at our median time to process a request because it best reflects subscribers’ experience. Before the upgrade, we turned around the median API request in ~90 ms. The upgrade decimated that metric to ~9 ms!&lt;/p&gt;
&lt;p class=&quot;text-center&quot;&gt;&lt;img src=&quot;https://letsencrypt.org/images/2021.01.21-next-gen-db-api-latency.png&quot; alt=&quot;API Latency&quot;/&gt;&lt;/p&gt;
&lt;p&gt;We can clearly see how our old CPUs were reaching their limit. In the week before we upgraded our primary database server, its CPU usage (from /proc/stat) averaged over 90%:&lt;/p&gt;
&lt;p class=&quot;text-center&quot;&gt;&lt;img src=&quot;https://letsencrypt.org/images/2021.01.21-next-gen-db-cpu-before.png&quot; alt=&quot;CPU Usage Before Upgrade&quot;/&gt;&lt;/p&gt;
&lt;p&gt;The new AMD EPYC CPUs sit at about 25%. You can see in this graph where we promoted the new database server from replica (read-only) to primary (read/write) on September 15.&lt;/p&gt;
&lt;p class=&quot;text-center&quot;&gt;&lt;img src=&quot;https://letsencrypt.org/images/2021.01.21-next-gen-db-cpu-after.png&quot; alt=&quot;CPU Usage After Upgrade&quot;/&gt;&lt;/p&gt;
&lt;p&gt;The upgrade greatly reduced our overall database latency. The average query response time (from INFORMATION_SCHEMA) used to be ~0.45ms.&lt;/p&gt;
&lt;p class=&quot;text-center&quot;&gt;&lt;img src=&quot;https://letsencrypt.org/images/2021.01.21-next-gen-db-db-latency-before.png&quot; alt=&quot;Database Latency Before Upgrade&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Queries now average &lt;em&gt;three times faster&lt;/em&gt;, about 0.15ms.&lt;/p&gt;
&lt;p class=&quot;text-center&quot;&gt;&lt;img src=&quot;https://letsencrypt.org/images/2021.01.21-next-gen-db-db-latency-after.png&quot; alt=&quot;Database Latency After Upgrade&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;openzfs-and-nvme&quot;&gt;OpenZFS and NVMe&lt;/h2&gt;
&lt;p&gt;NVMe drives are becoming increasingly popular because of their incredible performance. Up until recently, though, it was nearly impossible to get many of them in a single machine because NVMe uses PCIe lanes. Those were very limited: Intel’s Xeon processors come with just 48 PCIe v3 lanes, and a number of those are used up by the chipset and add-on cards such as network adapters and GPUs. You can’t fit many NVMe drives in the remaining lanes.&lt;/p&gt;
&lt;p&gt;AMD’s latest generation of EPYC processors come with 128 PCIe lanes - more than double what Intel offers - and they’re PCIe v4! This is enough to pack a 2U server full of NVMe drives (24 in our case).&lt;/p&gt;
&lt;p&gt;Once you have a server full of NVMe drives, you have to decide how to manage them. Our previous generation of database servers used hardware RAID in a RAID-10 configuration, but there is no effective hardware RAID for NVMe, so we needed another solution. One option was software RAID (Linux mdraid), but we got several recommendations for OpenZFS and decided to give it a shot. We’ve been very happy with it!&lt;/p&gt;
&lt;p&gt;There wasn’t a lot of information out there about how best to set up and optimize OpenZFS for a pool of NVMe drives and a database workload, so we want to share what we learned. You can find detailed information about our setup in &lt;a href=&quot;https://github.com/letsencrypt/openzfs-nvme-databases&quot;&gt;this GitHub repository&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;This database upgrade was necessary as more people rely on Let’s Encrypt for the security and privacy that TLS/SSL provides. The equipment is quite expensive and it was a sizable undertaking for our SRE team to plan and execute the transition, but we gained a lot through the process.&lt;/p&gt;
&lt;h2 id=&quot;support-let-s-encrypt&quot;&gt;Support Let’s Encrypt&lt;/h2&gt;
&lt;p&gt;We depend on contributions from our supporters in order to provide our services. If your company or organization would like to &lt;a href=&quot;https://letsencrypt.org/become-a-sponsor/&quot;&gt;sponsor&lt;/a&gt; Let’s Encrypt please email us at &lt;a href=&quot;mailto:sponsor@letsencrypt.org&quot;&gt;sponsor@letsencrypt.org&lt;/a&gt;. We ask that you make an &lt;a href=&quot;https://letsencrypt.org/donate/&quot;&gt;individual contribution&lt;/a&gt; if it is within your means.&lt;/p&gt;
</description>
<pubDate>Thu, 21 Jan 2021 17:25:08 +0000</pubDate>
<dc:creator>jaas</dc:creator>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://letsencrypt.org/2021/01/21/next-gen-database-servers.html</dc:identifier>
</item>
<item>
<title>How We Ported Linux to the M1</title>
<link>https://corellium.com/blog/linux-m1</link>
<guid isPermaLink="true" >https://corellium.com/blog/linux-m1</guid>
<description>&lt;h3&gt;1. Apple special sauce&lt;/h3&gt;&lt;p&gt;When Apple released their desktop products with the M1 processor in November 2020, quite a few people in the tech community were surprised by the excellent performance of these systems. But those who have been following the development of Apple phone chipsets closely knew that the evolutionary path Apple followed would result in a powerful 64-bit ARM processor.&lt;/p&gt;
&lt;p&gt;At Corellium, we've been tracking the Apple mobile ecosystem since iPhone 6, released in 2014 with two 64-bit cores. Since then, Apple has been focusing their energy on building faster chips, preferring to improve single-threaded performance over throwing more cores on the chip. This approach was enabled by their in-house hardware design team, and resulted in unique parts with a broad feature set, leading the industry in terms of architectural features.&lt;/p&gt;
&lt;p&gt;It also made Apple silicon rather distinct from all other 64-bit ARM hardware in terms of both CPU core and peripherals. Our Corellium virtualization platform has been providing security researchers with unparalleled insight into how operating systems and programs work on Apple ARM processors. But in the process of developing our virtualization system, we also gain knowledge about the hardware we are modeling, and this knowledge can be best refined by testing it against real hardware - which we have only been able to do with the emergence of checkm8, an exploit that let us load programs onto Apple smartphones. This led directly to the &lt;a href=&quot;https://projectsandcastle.org/&quot;&gt;Sandcastle project&lt;/a&gt;, where we built a kernel port to the A10 processor in early 2020.&lt;/p&gt;
&lt;p&gt;So when Apple decided to allow installing custom kernels on the Macs with M1 processor, we were very happy to try building another Linux port to further our understanding of the hardware platform. As we were creating a model of the processor for our security research product, we were working on the Linux port in parallel.&lt;/p&gt;
&lt;h3&gt;2. Starting the port&lt;/h3&gt;
&lt;p&gt;Many components of the M1 are shared with Apple mobile SoCs, which gave us a good running start. But when writing Linux drivers, it became very apparent how non-standard Apple SoCs really are. Our virtual environment is extremely flexible in terms of models it can accommodate; but on the Linux side, the 64-bit ARM world has largely settled on a well-defined set of building blocks and firmware interfaces - nearly none of which were used on the M1.&lt;/p&gt;
&lt;p&gt;To start with, Apple CPUs boot the operating system kernel in a different way. The bootloader, traditionally called iBoot, loads an executable object file in a format called Mach-O, optionally compressed and wrapped in a signed ASN.1 based wrapper format called IMG4. For comparison, normal Linux on 64-bit ARM starts as a flat binary image (optionally compressed and put in one of the few container formats), or a Windows-style &quot;PE&quot; executable on UEFI platforms.&lt;/p&gt;
&lt;p&gt;But the real surprises start when further CPU cores are brought up. On other 64-bit ARM systems, this is done by calling the firmware through an interface called PSCI (a few systems use poll-tables, but the firmware is still responsible for them). But on M1, CPU cores start at an address specified by a MMIO register (set to a specific offset within the kernel image, then locked, by the bootloader), and simply begin running the kernel.&lt;/p&gt;
&lt;p&gt;If that wasn't enough, Apple designed their own interrupt controller, the Apple Interrupt Controller (AIC), not compatible with either of the major ARM GIC standards. And not only that: the timer interrupts - normally connected to a regular per-CPU interrupt on ARM - are instead routed to the FIQ, an abstruse architectural feature, seen more frequently in the old 32-bit ARM days. Naturally, Linux kernel did not support delivering any interrupts via the FIQ path, so we had to add that.&lt;/p&gt;
&lt;p&gt;When you try to get multiple processors in a system to talk to each other, you have to provide a set of inter-processor interrupts (IPIs). On older Apple SoCs, those were handled similarly to IRQs, by executing MMIO accesses to the AIC. But on newer ones, Apple uses a set of processor core registers to dispatch and acknowledge IPIs, and they are - again - delivered as FIQs. So the FIQ support was really quite important. Fortunately, our work on virtual models in our security research product has prepared us for this.&lt;/p&gt;
&lt;p&gt;After working out a few more hardware quirks, and adding a pre-loader that acts as a wrapper for Linux and provides a trampoline for starting processor cores, we could set a framebuffer and were greeted with the sight of eight penguins representing the eight cores of the M1.&lt;/p&gt;
&lt;h3&gt;3. Need input!&lt;/h3&gt;
&lt;p&gt;Unfortunately, since we do not have a UART cable for the M1 Macs, we had to find another way to add a keyboard (and maybe even a mouse). There are fundamentally three paths to do that on the M1 Mac Mini: the built-in USB host in the M1 chip (serves the Thunderbolt/USB ports), the xHCI USB host on PCIe (serves the type A ports) and Bluetooth.&lt;/p&gt;
&lt;p&gt;While we won't get into the details of Apple Bluetooth, we'll note it uses a non-standard PCIe-based protocol that is supported in our virtualization product, and would require not only bringing up PCIe ports on the M1 chip, but also writing a custom kernel driver for this protocol. That made it seem like the worst choice for getting this done quickly.&lt;/p&gt;
&lt;p&gt;This means we had a choice between bringing up PCIe and using the standard kernel xHCI driver, or bringing up the built-in USB controller. Apple has been using the Synopsys DWC3 dual-role USB controller for a while in their chips, and it has a Linux kernel driver. Unfortunately, Apple is also in the habit of adding custom logic around the controller, so this ended up being a fair bit of work.&lt;/p&gt;
&lt;p&gt;Both the PCIe and the built-in DWC3 USB controller on M1 use IOMMUs, called DARTs. Apple has been refining their DART design in a consistent, evolutionary way, resulting in an excellent, full-featured IOMMU. The last version even has support for sub-page memory protection, rarely seen elsewhere. (We had a &lt;a href=&quot;https://corellium.com/blog/mobile-physical-memory-security&quot;&gt;blog post on IOMMUs&lt;/a&gt; and other similar devices last month.)&lt;/p&gt;
&lt;p&gt;To actually connect the USB port inside the M1 to the USB type-C connectors on the back of the Mac Mini, we had to interact with a chip on I2C (which means GPIO and I2C drivers) which has customized firmware. We've seen the protocol for these while building our virtualized models; nothing is a big surprise if you have a bird's eye view of the system.&lt;/p&gt;
&lt;p&gt;After a few days of figuring out the details of USB, we were finally able to connect an external USB hub and connect a keyboard, mouse and a Flash drive, opening the possibility for running a normal desktop Linux distribution.&lt;/p&gt;
&lt;h2&gt;Tutorial&lt;/h2&gt;
&lt;h3&gt;1. Download the Ubuntu rootfs&lt;/h3&gt;
&lt;p&gt;The first step to booting Linux on your Mac Mini M1 is to download the Ubuntu POC rootfs &lt;a href=&quot;https://assets.checkra.in/downloads/corellium/4512cab8116bf89f1a230eb003db51365b2c112a1e1d66583a1e4cdbfc0ddba3/ubuntu-20.10-preinstalled-desktop-arm64+raspi.img.bz2&quot;&gt;available here&lt;/a&gt;. We used a Raspberry Pi image because it was a live USB boot image, so we only had to make minor modifications to boot it.&lt;/p&gt;
&lt;h3&gt;2. Extract the image&lt;/h3&gt;
&lt;p&gt;You will need a minimum 16G external USB drive. Extract the image by typing:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;tar -xjvf ubuntu-20.10-preinstalled-desktop-arm64+raspi.img.bz2&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Then, use disk utility to locate the name of the external disk. Finally, copy the image to the USB drive using:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;sudo dd if=ubuntu-20.10-preinstalled-desktop-arm64+raspi.img of=/dev/rYOURUSBDISK bs=1m&lt;/em&gt;&lt;/p&gt;
&lt;h3&gt;3. Connect to the Mac&lt;/h3&gt;
&lt;p&gt;Connect your USB drive to the Mac Mini M1 using a dongle via the USB C port. The USB A ports are not currently supported.&lt;/p&gt;
&lt;h3&gt;4. Boot into 1TR&lt;/h3&gt;
&lt;p&gt;To boot into 1TR (the one true recovery OS), turn off your Mac Mini M1 and then hold Power until you see &quot;loading options&quot;. Once it loads, you can select the terminal option from the menu bar at the top.&lt;/p&gt;
&lt;h3&gt;5. Install the Custom Kernel&lt;/h3&gt;
&lt;p&gt;The next step is to install the custom kernel. We have made a script that makes this step easier for you. You can run it by typing:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;/bin/bash -c &quot;$(curl -fsSL &lt;a href=&quot;https://downloads.corellium.info/linuxsetup.sh&quot;&gt;https://downloads.corellium.info/linuxsetup.sh&lt;/a&gt;)&quot;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The script will prompt you for your username and password. One you see it print &quot;Kernel installed&quot; it's safe to type &lt;em&gt;reboot&lt;/em&gt;.&lt;/p&gt;
&lt;h3&gt;6. Login&lt;/h3&gt;
&lt;p&gt;Once you're booted, you'll be prompted for a login. The username is &quot;pi&quot; and the password is &quot;raspberry.&quot; The root password is also &quot;raspberry.&quot;&lt;/p&gt;
&lt;h3&gt;7. Reverting to MacOS&lt;/h3&gt;
&lt;p&gt;To revert to booting MacOS, in 1TR open terminal and type &lt;em&gt;bputil -n&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;------&lt;/p&gt;
&lt;p&gt;&lt;em&gt;If you're interested in supporting our work on open source projects like these, please consider &lt;a href=&quot;https://supporters.eff.org/donate/join-eff-4&quot;&gt;donating on our behalf to the EFF&lt;/a&gt;, who work tirelessly to defend security researchers and protect the digital rights of users and developers. You should also consider supporting the work being done by the folks over at &lt;a href=&quot;https://asahilinux.org/&quot;&gt;Asahi Linux&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;We'd like to extend a very special thanks to the engineers behind PongoOS for contributing their expertise and collaboration. We're looking forward to updating with a version that uses PongoOS as the bootloader!&lt;/em&gt;&lt;/p&gt;
</description>
<pubDate>Thu, 21 Jan 2021 15:33:43 +0000</pubDate>
<dc:creator>easton</dc:creator>
<og:image>https://images.prismic.io/corellium/149cd274-12f3-4438-a764-d7a438099be6_2021-01-20-232045.jpeg?auto=compress,format</og:image>
<og:title>How We Ported Linux to the M1</og:title>
<og:description>A brief overview of our approach to porting Linux to the Apple Mac Mini M1 and a tutorial for installing our Ubuntu POC</og:description>
<og:url>localhost:3000/blog/linux-m1</og:url>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://corellium.com/blog/linux-m1</dc:identifier>
</item>
<item>
<title>Over 700k paintings from the Rijksmuseum online copyright free</title>
<link>https://www.ianvisits.co.uk/blog/2021/01/21/over-700000-paintings-from-the-rijksmuseum-online-copyright-free/</link>
<guid isPermaLink="true" >https://www.ianvisits.co.uk/blog/2021/01/21/over-700000-paintings-from-the-rijksmuseum-online-copyright-free/</guid>
<description>&lt;p&gt;Amsterdam’s &lt;a href=&quot;https://www.rijksmuseum.nl/en&quot;&gt;Rijksmuseum&lt;/a&gt; has put over 700,000 digitised copies of its huge art collection online, and is making them available to reuse as public domain&lt;/p&gt;
&lt;p&gt;It’s not a new feature, but it’s not that well known, and it was revamped last November. The images are being released under Creative Commons 1.0 Universal (CC0 1.0) Public Domain Dedication – which is essentially copyright and royalty free.&lt;/p&gt;
&lt;div id=&quot;attachment_41076&quot; class=&quot;wp-caption aligncenter&quot; readability=&quot;34&quot;&gt;&lt;a href=&quot;https://www.ianvisits.co.uk/blog/wp-content/uploads/2021/01/Rijksmuseum-03.jpg&quot;&gt;&lt;img aria-describedby=&quot;caption-attachment-41076&quot; loading=&quot;lazy&quot; class=&quot;size-full wp-image-41076&quot; src=&quot;https://www.ianvisits.co.uk/blog/wp-content/uploads/2021/01/Rijksmuseum-03.jpg&quot; alt=&quot;&quot; width=&quot;1800&quot; height=&quot;1248&quot; srcset=&quot;https://www.ianvisits.co.uk/blog/wp-content/uploads/2021/01/Rijksmuseum-03.jpg 1800w, https://www.ianvisits.co.uk/blog/wp-content/uploads/2021/01/Rijksmuseum-03-600x416.jpg 600w, https://www.ianvisits.co.uk/blog/wp-content/uploads/2021/01/Rijksmuseum-03-1024x710.jpg 1024w, https://www.ianvisits.co.uk/blog/wp-content/uploads/2021/01/Rijksmuseum-03-300x208.jpg 300w, https://www.ianvisits.co.uk/blog/wp-content/uploads/2021/01/Rijksmuseum-03-768x532.jpg 768w, https://www.ianvisits.co.uk/blog/wp-content/uploads/2021/01/Rijksmuseum-03-1536x1065.jpg 1536w, https://www.ianvisits.co.uk/blog/wp-content/uploads/2021/01/Rijksmuseum-03-100x69.jpg 100w, https://www.ianvisits.co.uk/blog/wp-content/uploads/2021/01/Rijksmuseum-03-150x104.jpg 150w, https://www.ianvisits.co.uk/blog/wp-content/uploads/2021/01/Rijksmuseum-03-200x139.jpg 200w, https://www.ianvisits.co.uk/blog/wp-content/uploads/2021/01/Rijksmuseum-03-450x312.jpg 450w, https://www.ianvisits.co.uk/blog/wp-content/uploads/2021/01/Rijksmuseum-03-900x624.jpg 900w&quot; sizes=&quot;(max-width: 1800px) 100vw, 1800px&quot;/&gt;&lt;/a&gt;
&lt;p id=&quot;caption-attachment-41076&quot; class=&quot;wp-caption-text&quot;&gt;City Walls in Winter, Willem Schellinks, c. 1650 – c. 1670&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The Rijksstudio, as the online gallery is called was funded by the BankGiro Lottery, the Netherlands culture lottery that provides long-term support for institutions.&lt;/p&gt;
&lt;p&gt;You can browse and search the Rijksstudio by genrea, dates or artists, and even if you’re just browsing for pleasure, the website photos are of a high resolution quality.&lt;/p&gt;
&lt;p&gt;The collection contains more than 2,000 paintings from the Dutch Golden Age by notable painters such as Jacob van Ruisdael, Frans Hals, Johannes Vermeer, Jan Steen, Rembrandt, and Rembrandt’s pupils.&lt;/p&gt;
&lt;p&gt;Each of the paintings, photographs, and drawings they’ve scanned has detailed information about the subject and the artist, along with some history such as when and where it was acquired.&lt;/p&gt;
&lt;p&gt;The Rijksmuseum requires you to open an account on their website to download anything, but in exchange, the downloaded graphics are high resolution jpegs. You can even see brush strokes in some of the images I downloaded to test this.&lt;/p&gt;
&lt;div id=&quot;attachment_41074&quot; class=&quot;wp-caption aligncenter&quot; readability=&quot;34&quot;&gt;&lt;a href=&quot;https://www.ianvisits.co.uk/blog/wp-content/uploads/2021/01/Rijksmuseum-01.jpg&quot;&gt;&lt;img aria-describedby=&quot;caption-attachment-41074&quot; loading=&quot;lazy&quot; class=&quot;size-full wp-image-41074&quot; src=&quot;https://www.ianvisits.co.uk/blog/wp-content/uploads/2021/01/Rijksmuseum-01.jpg&quot; alt=&quot;&quot; width=&quot;1800&quot; height=&quot;1000&quot; srcset=&quot;https://www.ianvisits.co.uk/blog/wp-content/uploads/2021/01/Rijksmuseum-01.jpg 1800w, https://www.ianvisits.co.uk/blog/wp-content/uploads/2021/01/Rijksmuseum-01-600x333.jpg 600w, https://www.ianvisits.co.uk/blog/wp-content/uploads/2021/01/Rijksmuseum-01-1024x569.jpg 1024w, https://www.ianvisits.co.uk/blog/wp-content/uploads/2021/01/Rijksmuseum-01-300x167.jpg 300w, https://www.ianvisits.co.uk/blog/wp-content/uploads/2021/01/Rijksmuseum-01-768x427.jpg 768w, https://www.ianvisits.co.uk/blog/wp-content/uploads/2021/01/Rijksmuseum-01-1536x853.jpg 1536w, https://www.ianvisits.co.uk/blog/wp-content/uploads/2021/01/Rijksmuseum-01-100x56.jpg 100w, https://www.ianvisits.co.uk/blog/wp-content/uploads/2021/01/Rijksmuseum-01-150x83.jpg 150w, https://www.ianvisits.co.uk/blog/wp-content/uploads/2021/01/Rijksmuseum-01-200x111.jpg 200w, https://www.ianvisits.co.uk/blog/wp-content/uploads/2021/01/Rijksmuseum-01-450x250.jpg 450w, https://www.ianvisits.co.uk/blog/wp-content/uploads/2021/01/Rijksmuseum-01-900x500.jpg 900w&quot; sizes=&quot;(max-width: 1800px) 100vw, 1800px&quot;/&gt;&lt;/a&gt;
&lt;p id=&quot;caption-attachment-41074&quot; class=&quot;wp-caption-text&quot;&gt;Zoomed in to full size – Portrait of a Girl Dressed in Blue, Johannes Cornelisz. Verspronck, 1641&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;In addition, professionals have an option to request a free TIFF file with colour reference and tailored advice.&lt;/p&gt;
&lt;p&gt;The Rijksstudio, in English, is &lt;a href=&quot;https://www.rijksmuseum.nl/en/rijksstudio&quot;&gt;&lt;strong&gt;here&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The British Museum also released nearly 2 million images from their archive online &lt;a href=&quot;https://www.ianvisits.co.uk/blog/2020/04/28/british-museum-makes-1-9-million-images-available-for-free/&quot;&gt;last year&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&quot;attachment_41075&quot; class=&quot;wp-caption aligncenter&quot; readability=&quot;34&quot;&gt;&lt;a href=&quot;https://www.ianvisits.co.uk/blog/wp-content/uploads/2021/01/Rijksmuseum-02.jpg&quot;&gt;&lt;img aria-describedby=&quot;caption-attachment-41075&quot; loading=&quot;lazy&quot; class=&quot;size-full wp-image-41075&quot; src=&quot;https://www.ianvisits.co.uk/blog/wp-content/uploads/2021/01/Rijksmuseum-02.jpg&quot; alt=&quot;&quot; width=&quot;1800&quot; height=&quot;1202&quot; srcset=&quot;https://www.ianvisits.co.uk/blog/wp-content/uploads/2021/01/Rijksmuseum-02.jpg 1800w, https://www.ianvisits.co.uk/blog/wp-content/uploads/2021/01/Rijksmuseum-02-600x401.jpg 600w, https://www.ianvisits.co.uk/blog/wp-content/uploads/2021/01/Rijksmuseum-02-1024x684.jpg 1024w, https://www.ianvisits.co.uk/blog/wp-content/uploads/2021/01/Rijksmuseum-02-300x200.jpg 300w, https://www.ianvisits.co.uk/blog/wp-content/uploads/2021/01/Rijksmuseum-02-768x513.jpg 768w, https://www.ianvisits.co.uk/blog/wp-content/uploads/2021/01/Rijksmuseum-02-1536x1026.jpg 1536w, https://www.ianvisits.co.uk/blog/wp-content/uploads/2021/01/Rijksmuseum-02-100x67.jpg 100w, https://www.ianvisits.co.uk/blog/wp-content/uploads/2021/01/Rijksmuseum-02-150x100.jpg 150w, https://www.ianvisits.co.uk/blog/wp-content/uploads/2021/01/Rijksmuseum-02-200x134.jpg 200w, https://www.ianvisits.co.uk/blog/wp-content/uploads/2021/01/Rijksmuseum-02-450x301.jpg 450w, https://www.ianvisits.co.uk/blog/wp-content/uploads/2021/01/Rijksmuseum-02-900x601.jpg 900w&quot; sizes=&quot;(max-width: 1800px) 100vw, 1800px&quot;/&gt;&lt;/a&gt;
&lt;p id=&quot;caption-attachment-41075&quot; class=&quot;wp-caption-text&quot;&gt;Straat in Londen, The London Stereoscopic Company, 1895 – 1900&lt;/p&gt;
&lt;/div&gt;
</description>
<pubDate>Thu, 21 Jan 2021 15:14:02 +0000</pubDate>
<dc:creator>edward</dc:creator>
<og:url>https://www.ianvisits.co.uk/blog/2021/01/21/over-700000-paintings-from-the-rijksmuseum-online-copyright-free/</og:url>
<og:type>website</og:type>
<og:title>Over 700,000 paintings from the Rijksmuseum online copyright free</og:title>
<og:description>Amsterdam's Rijksmuseum has put over 700,000 digitised copies of its huge art collection online, and is making them available to reuse as public domain</og:description>
<og:image>https://www.ianvisits.co.uk/blog/wp-content/uploads/2021/01/Rijksmuseum-04.jpg</og:image>
<dc:language>en-GB</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.ianvisits.co.uk/blog/2021/01/21/over-700000-paintings-from-the-rijksmuseum-online-copyright-free/</dc:identifier>
</item>
<item>
<title>Bitcoincore.org removes Satoshi&amp;#039;s whitepaper from website after threats from CSW</title>
<link>https://bitcoin.org/en/posts/regarding-csw</link>
<guid isPermaLink="true" >https://bitcoin.org/en/posts/regarding-csw</guid>
<description>&lt;p&gt;Yesterday both Bitcoin.org and Bitcoincore.org received allegations of copyright infringement of the Bitcoin whitepaper by lawyers representing Craig Steven Wright. In this letter, they claim Craig owns the copyright to the paper, the Bitcoin name, and ownership of bitcoin.org. They also claim he is Satoshi Nakamoto, the pseudonymous creator of Bitcoin, and the original owner of bitcoin.org. Bitcoin.org and Bitcoincore.org were both asked to take down the whitepaper. We believe these claims are without merit, and refuse to do so.&lt;/p&gt;&lt;p&gt;Unfortunately, without consulting us, Bitcoin Core developers scrambled to remove the Bitcoin whitepaper from bitcoincore.org, in response to these allegations of copyright infringement, lending credence to these false claims. The Bitcoin Core website was modified to remove references to the whitepaper, their local copy of the whitepaper PDF was deleted, and with less than 2 hours of public review, &lt;a href=&quot;https://github.com/bitcoin-core/bitcoincore.org/pull/740&quot;&gt;this change was merged&lt;/a&gt;. By surrendering in this way, the Bitcoin Core project has lent ammunition to Bitcoin’s enemies, engaged in self-censorship, and compromised its integrity. This surrender will no doubt be weaponized to make new false claims, like that the Bitcoin Core developers “know” CSW to be Satoshi Nakamoto and this is why they acted in this way.&lt;/p&gt;
&lt;p&gt;The Bitcoin whitepaper was included in the original &lt;a href=&quot;https://web.archive.org/web/20091127010808/http://sourceforge.net/projects/bitcoin/files/&quot;&gt;Bitcoin project files&lt;/a&gt; with the project clearly &lt;a href=&quot;https://web.archive.org/web/20091129231620/https://sourceforge.net/projects/bitcoin/&quot;&gt;published under the MIT license&lt;/a&gt; by Satoshi Nakamoto. We believe there is no doubt we have the legal right to host the Bitcoin whitepaper. Furthermore, Satoshi Nakamoto has a known &lt;a href=&quot;https://bitcoin.org/satoshinakamoto.asc&quot;&gt;PGP public key&lt;/a&gt;, therefore it is cryptographically possible for someone to verify themselves to be Satoshi Nakamoto. Unfortunately, Craig has been unable to do this.&lt;/p&gt;
&lt;p&gt;We will continue hosting the Bitcoin whitepaper and won’t be silenced or intimidated. Others hosting the whitepaper should follow our lead in resisting these false allegations.&lt;/p&gt;
&lt;p class=&quot;post-meta&quot;&gt;Posted to the &lt;a href=&quot;https://bitcoin.org/en/blog&quot;&gt;Bitcoin.org Site Blog&lt;/a&gt; on 21 January 2021 by &lt;a href=&quot;https://github.com/cobra-bitcoin&quot;&gt;Cøbra&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Thu, 21 Jan 2021 14:07:07 +0000</pubDate>
<dc:creator>wildrice</dc:creator>
<og:image>https://bitcoin.org/img/icons/opengraph.png?1611216350</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://bitcoin.org/en/posts/regarding-csw</dc:identifier>
</item>
<item>
<title>New Intel CEO Making Waves: Rehiring Retired CPU Architects</title>
<link>https://www.anandtech.com/show/16438/new-intel-ceo-making-waves-rehiring-retired-cpu-architects</link>
<guid isPermaLink="true" >https://www.anandtech.com/show/16438/new-intel-ceo-making-waves-rehiring-retired-cpu-architects</guid>
<description>&lt;p&gt;We’re following the state of play with Intel’s new CEO, Pat Gelsinger, very closely. Even as an Intel employee for 30 years, rising to the rank of CTO, then taking 12 years away from the company, his arrival has been met with praise across the spectrum given his background and previous successes. He isn’t even set to take his new role until February 15&lt;sup&gt;th&lt;/sup&gt;, however his return is already causing a stir with Intel’s current R&amp;amp;D teams.&lt;/p&gt;
&lt;p&gt;News in the last 24 hours, based on public statements, states that former Intel Senior Fellow Glenn Hinton, who lists being the lead architect of Intel’s Nehalem CPU core in his list of achievements, is coming out of retirement to re-join the company. (The other lead architect of Nehalem are Ronak Singhal and Per Hammerlund - Ronak is still at Intel, working on next-gen processors, while Per has been at Apple for five years.)&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a href=&quot;https://images.anandtech.com/doci/16438/DSC01343.jpg&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://images.anandtech.com/doci/16438/DSC01343_575px.jpg&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Hinton is an old Intel hand, with 35 years of experience, leading microarchitecture development of Pentium 4, one of three senior architects of Intel’s P6 processor design (which led to Pentium Pro, P2, P3), and ultimately one of the drivers to Intel’s Core architecture which is still at the forefront of Intel’s portfolio today. He also a lead microarchitect for Intel’s i960 CA, the world’s first super-scalar microprocessor. Hinton holds more than 90+ patents from 8 CPU designs from his endeavors. Hinton spent another 10+ years at Intel after Nehalem, but Nehalem is listed in many places as his primary public achievement at Intel.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a href=&quot;https://images.anandtech.com/doci/16438/Glenn%20LI-2.png&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://images.anandtech.com/doci/16438/Glenn%20LI-2_575px.png&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;On his social media posts, Hinton states that he will be working on ‘an exciting high performance CPU project’. In the associated comments also states that ‘if it wasn’t a fun project I wouldn’t have come back – as you know, retirement is pretty darn nice’. Glenn also discloses that he has been pondering the move since November, and Gelsinger’s re-hiring helped finalize that decision. His peers also opine that Glenn is probably not the only ex-Intel architect that might be heading back to the company. We know a few architects and specialists that have left Intel in recent years to join Intel's competitors, such as AMD and Apple.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a href=&quot;https://images.anandtech.com/doci/16438/Glenn%20LI.png&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://images.anandtech.com/doci/16438/Glenn%20LI_575px.png&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;There are a few key things to note here worth considering.&lt;/p&gt;
&lt;p&gt;First is that coming out of retirement for a big CPU project isn’t a trivial thing, especially for an Intel Senior Fellow. Given Intel’s successes, one would assume that the financial situation is not the main driver here, but the opportunity to work on something new and exciting. Plus, these sorts of projects take years of development, at least three, and thus Glenn is signing on for a long term despite already having left to retire.&lt;/p&gt;
&lt;p&gt;Second point is reiterating that last line – whatever project Glenn is working on, it will be a long term project. Assuming that Glenn is talking about a fresh project within Intel’s R&amp;amp;D ecosystem, it will be 3-5 years before we see the fruits of the labor, which also means creating a design aimed at what could be a variety of process node technologies. Glenn’s expertise as lead architect is quite likely applicable for any stage of an Intel R&amp;amp;D design window, but is perhaps best served from the initial stages. The way Glenn seems to put it, this might be a black-ops style design. It also doesn't specify if this is x86, leaving that door open to speculation.&lt;/p&gt;
&lt;p&gt;Third here is to recognize that Intel has a number of processor design teams in-house and despite the manufacturing process delays, they haven’t been idle. We’ve been seeing refresh after refresh of Skylake lead Intel's portfolio, and while the first iterations of the 10nm Cove cores come to market, Intel’s internal design teams would have been working on the next generation, and the next generation after that – the only barrier to deployment would have been manufacturing. I recall a discussion with Intel’s engineers around Kaby Lake time, when I asked about Intel’s progress on IPC – I requested a +10% gen-on-gen increase over the next two years at the time, and I was told that those designs were done and baked – they were already working on the ones beyond that. Those designs were likely Ice/Tiger Lake, and so Intel’s core design teams have been surging ahead despite manufacturing issues, and I wonder if there’s now a 3-4 year (or more) delay on some of these designs. If Glenn is hinting at a project beyond that, then we could be waiting even longer.&lt;/p&gt;
&lt;p&gt;Fourth and finally, one of the critical elements listed by a number of analysts on the announcement of Gelsinger’s arrival was that he wouldn’t have much of an effect until 3+ years down the line, because of how product cycles work. I rejected that premise outright, stating that Pat can come in and change elements of Intel’s culture immediately, and could sit in the room with the relevant engineers and discuss product design on a level that Bob Swan cannot. Pat has the opportunity to arrange the leadership structure and instill new confidence in those structures, some of which may have caused key architects in the past to retire, instead of build on exciting projects.&lt;/p&gt;
&lt;p&gt;As we can see, Pat is already having an effect before his name is even on the door at HQ.&lt;/p&gt;
&lt;p&gt;Today is also Intel’s end-of-year financial disclosure, at 5pm ET. We are expecting Intel’s current CEO, Bob Swan, to talk through what looks to be another record breaking year of revenue, and likely the state of play for Intel's own 7nm process node technologies. That last point is somewhat thrown into doubt given the new CEO announcement and if Gelsinger is on the call. It is unknown if Gelsinger will participate.&lt;/p&gt;
&lt;h3&gt;Related Reading&lt;/h3&gt;

</description>
<pubDate>Thu, 21 Jan 2021 13:53:10 +0000</pubDate>
<dc:creator>rbanffy</dc:creator>
<og:title>New Intel CEO Making Waves: Rehiring Retired CPU Architects</og:title>
<og:type>article</og:type>
<og:url>https://www.anandtech.com/show/16438/new-intel-ceo-making-waves-rehiring-retired-cpu-architects</og:url>
<og:image>https://images.anandtech.com/doci/16438/nehalem_678x452.jpg</og:image>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.anandtech.com/show/16438/new-intel-ceo-making-waves-rehiring-retired-cpu-architects</dc:identifier>
</item>
<item>
<title>Raspberry Pi Pico and RP2040 Microcontroller</title>
<link>https://www.raspberrypi.org/products/raspberry-pi-pico/</link>
<guid isPermaLink="true" >https://www.raspberrypi.org/products/raspberry-pi-pico/</guid>
<description>&lt;p&gt;From controlling appliances to operating a light display, Raspberry Pi Pico puts the technology that underpins countless everyday operations into your hands.&lt;/p&gt;
&lt;p&gt;Programmable in C and MicroPython, Pico is adaptable to a vast range of applications and skill levels, and getting started is as easy as dragging and dropping a file.&lt;/p&gt;
&lt;p&gt;More experienced users can take advantage of Raspberry Pi Pico’s rich peripheral set, including SPI, I2C, and eight Programmable I/O (PIO) state machines for custom peripheral support.&lt;/p&gt;
</description>
<pubDate>Thu, 21 Jan 2021 07:00:05 +0000</pubDate>
<dc:creator>schappim</dc:creator>
<og:type>website</og:type>
<og:description>The new, flexible $4 microcontroller board from Raspberry Pi</og:description>
<og:image>https://www.raspberrypi.org/homepage-9df4b/homepage-9df4b/static/opengraph-4f161fecfe846a0ecb0b52045238c4ae.png</og:image>
<og:title>Buy a Raspberry Pi Pico – Raspberry Pi</og:title>
<dc:language>en-GB</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.raspberrypi.org/products/raspberry-pi-pico/</dc:identifier>
</item>
</channel>
</rss>