<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=hnrss.org%2Fnewest%3Fpoints%3D200&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://hnrss.org/newest?points=200" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>Hacker News: Newest</title>
<link>https://news.ycombinator.com/newest</link>
<description>Hacker News RSS</description>
<item>
<title>The Game UI Database, a comprehensive reference of game interface design</title>
<link>https://www.gameuidatabase.com/</link>
<guid isPermaLink="true" >https://www.gameuidatabase.com/</guid>
<description>[unable to retrieve full-text content]
&lt;p&gt;Article URL: &lt;a href=&quot;https://www.gameuidatabase.com/&quot;&gt;https://www.gameuidatabase.com/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Comments URL: &lt;a href=&quot;https://news.ycombinator.com/item?id=25315524&quot;&gt;https://news.ycombinator.com/item?id=25315524&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Points: 385&lt;/p&gt;
&lt;p&gt;# Comments: 71&lt;/p&gt;
</description>
<pubDate>Sat, 05 Dec 2020 16:07:22 +0000</pubDate>
<dc:creator>homarp</dc:creator>
<og:type>website</og:type>
<og:description>A comprehensive screenshot reference Tool for game interface designers.  Explore over 320 games and 11,000 individual images, and filter by screen type, material, layout, texture, shapes, patterns, genre and more!</og:description>
<og:url>https://www.gameuidatabase.com/</og:url>
<og:image>http://www.gameuidatabase.com/metaimg.jpg</og:image>
<og:title>Game UI Database</og:title>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.gameuidatabase.com/</dc:identifier>
</item>
<item>
<title>Apple’s “Extended Dynamic Range” Brings HDR to Non-HDR Displays</title>
<link>https://prolost.com/blog/edr</link>
<guid isPermaLink="true" >https://prolost.com/blog/edr</guid>
<description>&lt;div class=&quot;sqs-layout sqs-grid-12 columns-12&quot; data-layout-label=&quot;Post Body&quot; data-type=&quot;item&quot; data-updated-on=&quot;1607102281154&quot; id=&quot;item-5fca6f2a6cb6d01b09c3d2ed&quot;&gt;
&lt;div class=&quot;row sqs-row&quot;&gt;
&lt;div class=&quot;col sqs-col-12 span-12&quot;&gt;
&lt;div class=&quot;sqs-block markdown-block sqs-block-markdown&quot; data-block-type=&quot;44&quot; id=&quot;block-79098d3df779face80aa&quot;&gt;
&lt;div class=&quot;sqs-block-content&quot;&gt;
&lt;p&gt;Apple caused quite a stir with the announcement of their &lt;a href=&quot;https://www.apple.com/pro-display-xdr/&quot;&gt;Pro Display XDR&lt;/a&gt;, a High Dynamic Range display that occupies a convoluted space in the market. It seeks to be both a Very Nice Computer Display, and a reference HDR video monitor — but by most measures it’s far too expensive to be the former, and &lt;a href=&quot;https://www.imore.com/damning-pro-display-xdr-review-says-it-cant-compete-reference-monitors&quot;&gt;not quite up to the rarified specs&lt;/a&gt; of the latter. Confusingly, it also outperforms some HDR displays costing considerably more, by some metrics. It’s currently the only display-only device Apple makes, and it’s simultaneously ludicrously expensive and a too-good-to-be-true deal. Suffice it to say that while there may be very few people for whom the Pro Display XDR is the unquestionably right choice, they know who they are, and they don’t need the internet’s advice about it.&lt;/p&gt;
&lt;p&gt;When I watched the &lt;a href=&quot;https://youtu.be/psL_5RIBqnY&quot;&gt;announcement&lt;/a&gt; of this display, I was curious how Apple would handle an HDR video monitor that was also tasked with the mundane duty of showing your email and your web browser. Was Apple planning on rendering the 255-255-255&lt;sup data-preserve-html-node=&quot;true&quot;&gt;1&lt;/sup&gt; “white” of Google’s home page at one brightness level, and the HDR overbrights from a video clip at a much brighter level, right next to each other, on the same display?&lt;/p&gt;
&lt;h2 id=&quot;hdr-in-situ&quot;&gt;HDR In Situ&lt;/h2&gt;
&lt;p&gt;The answer is a resounding “yes,” and the effect is both impressive and a bit unnerving. Below is a photo of a Pro Display XDR casually presenting the Finder thumbnail of an &lt;a href=&quot;https://en.wikipedia.org/wiki/Hybrid_Log-Gamma&quot;&gt;HLG&lt;/a&gt; clip I shot on my Sony a7RIV. The sky is radically brighter than the “white” pixels above it.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sqs-block image-block sqs-block-image&quot; data-block-type=&quot;5&quot; id=&quot;block-yui_3_17_2_1_1607106816661_7403&quot;&gt;
&lt;div class=&quot;sqs-block-content&quot;&gt;
&lt;div class=&quot; image-block-outer-wrapper layout-caption-below design-layout-inline combination-animation-none individual-animation-none individual-text-animation-none&quot; data-test=&quot;image-block-inline-outer-wrapper&quot;&gt;
&lt;div class=&quot; image-block-wrapper has-aspect-ratio&quot; data-animation-role=&quot;image&quot;&gt;&lt;noscript&gt;
&lt;p&gt;&lt;img src=&quot;https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/1607106860733-5Y95Q4R2HXX6AGICJRA4/ke17ZwdGBToddI8pDm48kPTrHXgsMrSIMwe6YW3w1AZ7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0k5fwC0WRNFJBIXiBeNI5fKTrY37saURwPBw8fO2esROAxn-RKSrlQamlL27g22X2A/APC_2758.jpg&quot; alt=&quot;The screenshot of the thumbnail reveals where HDR values are clipped at “white.”&quot;/&gt;&lt;/p&gt;
&lt;/noscript&gt;&lt;img class=&quot;thumb-image&quot; data-src=&quot;https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/1607106860733-5Y95Q4R2HXX6AGICJRA4/ke17ZwdGBToddI8pDm48kPTrHXgsMrSIMwe6YW3w1AZ7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0k5fwC0WRNFJBIXiBeNI5fKTrY37saURwPBw8fO2esROAxn-RKSrlQamlL27g22X2A/APC_2758.jpg&quot; data-image=&quot;https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/1607106860733-5Y95Q4R2HXX6AGICJRA4/ke17ZwdGBToddI8pDm48kPTrHXgsMrSIMwe6YW3w1AZ7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0k5fwC0WRNFJBIXiBeNI5fKTrY37saURwPBw8fO2esROAxn-RKSrlQamlL27g22X2A/APC_2758.jpg&quot; data-image-dimensions=&quot;2500x1406&quot; data-image-focal-point=&quot;0.5,0.5&quot; alt=&quot;The screenshot of the thumbnail reveals where HDR values are clipped at “white.”&quot; data-load=&quot;false&quot; data-image-id=&quot;5fca81270e456138b04aa8f2&quot; data-type=&quot;image&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;image-caption&quot;&gt;
&lt;p class=&quot;&quot;&gt;The screenshot of the thumbnail reveals where HDR values are clipped at “white.”&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sqs-block markdown-block sqs-block-markdown&quot; data-block-type=&quot;44&quot; id=&quot;block-yui_3_17_2_1_1607106816661_7680&quot;&gt;
&lt;div class=&quot;sqs-block-content&quot;&gt;
&lt;p&gt;The photo, of course, cannot capture how startling this is in person. It’s like strolling through an art gallery and stumbling onto a painting with its own backlight.&lt;/p&gt;
&lt;p&gt;It’s one thing to see HDR video on an &lt;a href=&quot;https://amzn.to/39ICDXp&quot;&gt;HDR TV&lt;/a&gt;, where the entire image appears simply brighter and richer. It’s another thing to see this kind of imagery presented in the long-familiar context of a computer screen full of folder icons and file names. It’s probably the right way to handle HDR in an SDR world, but it’s strange and new, and possibly unique to Apple.&lt;/p&gt;
&lt;p&gt;It also seems to be an important part of Apple’s ongoing display strategy. The company, long known for shipping high quality, color-accurate displays, is not reserving this HDR-in-an-SDR-world experience for folks shelling out $6,000 for a computer monitor. It’s also part of how all iPhone OLED displays are defined as HDR. Here you can see HDR video shot with an iPhone 12 Pro Max rendering the sky out my studio window as brighter that the “white” background of the Photos app:&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;sqs-block markdown-block sqs-block-markdown&quot; data-block-type=&quot;44&quot; id=&quot;block-yui_3_17_2_1_1607106958232_7747&quot;&gt;
&lt;div class=&quot;sqs-block-content&quot;&gt;
&lt;p&gt;Apple is commoditizing and normalizing HDR on their most popular platform, both in capture and display. And they’re not doing it just by making iPhone screens brighter. They’re making the &lt;em&gt;right&lt;/em&gt; pixels the &lt;em&gt;right&lt;/em&gt; brightness. It’s an impressive technical feat made all the more admirable by how natural it feels in practice.&lt;/p&gt;
&lt;h2 id=&quot;elderly-displays-rejoice&quot;&gt;Elderly Displays Rejoice&lt;/h2&gt;
&lt;p&gt;So Apple has a method of showing HDR and SDR content together on the same screen. It works on every display Apple bills as “HDR,” even though the phones are performing the stunt using a different underlying technology than the 32″ Mac display. The XDR uses “local dimming” to light up an array of LEDs brighter behind the HDR pixels, as needed. The OLED displays drive each pixel to the desired brightness individually.&lt;/p&gt;
&lt;p&gt;Apple groups all this under one umbrella they call &lt;em&gt;EDR,&lt;/em&gt; or Extended Dynamic Range. And even as they tout EDR as a selling point of their professional display and flagship iPhones, Apple has also quietly extended it to older Macs that were never advertised as being HDR-capable.&lt;/p&gt;
&lt;p&gt;From &lt;a href=&quot;https://developer.apple.com/documentation/metal/drawable_objects/displaying_hdr_content_in_a_metal_layer&quot;&gt;Apple’s developer documentation&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Some Macs can process pixel data with a wider range of pixel values and send those extended values to the display. In macOS, the ability to process larger pixel values and display them is referred to as extended dynamic range (EDR). When you configure a Metal layer to support extended values, you can provide pixel values — and therefore brightness levels — that exceed the normal SDR range in order to display HDR content.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;“Some Macs” is not limited to those connected to a Pro Display XDR. It includes my 2019 16″ MacBook Pro, and even my three-year-old iMac Pro. I think the limiting factors may be P3-gamut displays on Macs running Catalina or later. If you have such a Mac, you can try this at home.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;row sqs-row&quot;&gt;

&lt;div class=&quot;col sqs-col-6 span-6&quot;&gt;
&lt;div class=&quot;sqs-block image-block sqs-block-image&quot; data-aspect-ratio=&quot;49.45652173913043&quot; data-block-type=&quot;5&quot; id=&quot;block-yui_3_17_2_1_1607108631939_61389&quot;&gt;
&lt;div class=&quot;sqs-block-content&quot;&gt;
&lt;div class=&quot; image-block-outer-wrapper layout-caption-below design-layout-inline combination-animation-none individual-animation-none individual-text-animation-none&quot; data-test=&quot;image-block-inline-outer-wrapper&quot;&gt;
&lt;div class=&quot; image-block-wrapper has-aspect-ratio&quot; data-animation-role=&quot;image&quot;&gt;&lt;noscript&gt;
&lt;p&gt;&lt;img src=&quot;https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/1607114796511-6MT2W7FXKVRP3HY8AGQY/ke17ZwdGBToddI8pDm48kDUWCWIt5XDeaao5TiQveShZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVGuj380BfPFXHEgxLRR69qboYNBlS_hCp8yUmXfwsGbBJu3E9Ef3XsXP1C_826c-iU/Screen+Shot+2020-12-04+at+12.41.40+PM.png&quot; alt=&quot;Two HDR clips, one shot in Dolby BT.2020 with an iPhone 12 Pro Max, the other shot in HLG with a Sony a7RIV . In both the Finder and Quicktime Player on Catalina, the highlights in these clips should be visibly brighter than UI “white.”&quot;/&gt;&lt;/p&gt;
&lt;/noscript&gt;&lt;img class=&quot;thumb-image&quot; data-src=&quot;https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/1607114796511-6MT2W7FXKVRP3HY8AGQY/ke17ZwdGBToddI8pDm48kDUWCWIt5XDeaao5TiQveShZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVGuj380BfPFXHEgxLRR69qboYNBlS_hCp8yUmXfwsGbBJu3E9Ef3XsXP1C_826c-iU/Screen+Shot+2020-12-04+at+12.41.40+PM.png&quot; data-image=&quot;https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/1607114796511-6MT2W7FXKVRP3HY8AGQY/ke17ZwdGBToddI8pDm48kDUWCWIt5XDeaao5TiQveShZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVGuj380BfPFXHEgxLRR69qboYNBlS_hCp8yUmXfwsGbBJu3E9Ef3XsXP1C_826c-iU/Screen+Shot+2020-12-04+at+12.41.40+PM.png&quot; data-image-dimensions=&quot;436x216&quot; data-image-focal-point=&quot;0.5,0.5&quot; alt=&quot;Two HDR clips, one shot in Dolby BT.2020 with an iPhone 12 Pro Max, the other shot in HLG with a Sony a7RIV . In both the Finder and Quicktime Player on Catalina, the highlights in these clips should be visibly brighter than UI “white.”&quot; data-load=&quot;false&quot; data-image-id=&quot;5fcaa02cfdef016eae88e143&quot; data-type=&quot;image&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;image-caption&quot;&gt;
&lt;p class=&quot;&quot;&gt;Two HDR clips, one shot in Dolby BT.2020 with an iPhone 12 Pro Max, the other shot in HLG with a &lt;a href=&quot;https://amzn.to/3oq9GDs&quot;&gt;Sony a7RIV&lt;/a&gt;. In both the Finder and Quicktime Player on Catalina, the highlights in these clips should be visibly brighter than UI “white.”&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;div class=&quot;sqs-block markdown-block sqs-block-markdown&quot; data-block-type=&quot;44&quot; id=&quot;block-yui_3_17_2_1_1607106958232_23990&quot;&gt;
&lt;div class=&quot;sqs-block-content&quot;&gt;
&lt;p&gt;If the Pro Display XDR is like finding a gallery painting with its own backlight, seeing HDR pixels popping off a Mac display you’ve known to be SDR for three years is like discovering a painting that’s been hanging in your house forever suddenly has backlight button.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sqs-block image-block sqs-block-image&quot; data-block-type=&quot;5&quot; id=&quot;block-yui_3_17_2_1_1607106958232_35198&quot;&gt;
&lt;div class=&quot;sqs-block-content&quot;&gt;
&lt;div class=&quot; image-block-outer-wrapper layout-caption-below design-layout-inline combination-animation-none individual-animation-none individual-text-animation-none&quot; data-test=&quot;image-block-inline-outer-wrapper&quot;&gt;
&lt;div class=&quot; image-block-wrapper has-aspect-ratio&quot; data-animation-role=&quot;image&quot;&gt;&lt;noscript&gt;
&lt;p&gt;&lt;img src=&quot;https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/1607107051142-ORQ0N5ZSGH9884QNH8RF/ke17ZwdGBToddI8pDm48kPTrHXgsMrSIMwe6YW3w1AZ7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0k5fwC0WRNFJBIXiBeNI5fKTrY37saURwPBw8fO2esROAxn-RKSrlQamlL27g22X2A/APC_0255.jpg&quot; alt=&quot;Here’s another HDR clip happily blasting its whiter-than-white values on my non-HDR iMac Pro screen.&quot;/&gt;&lt;/p&gt;
&lt;/noscript&gt;&lt;img class=&quot;thumb-image&quot; data-src=&quot;https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/1607107051142-ORQ0N5ZSGH9884QNH8RF/ke17ZwdGBToddI8pDm48kPTrHXgsMrSIMwe6YW3w1AZ7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0k5fwC0WRNFJBIXiBeNI5fKTrY37saURwPBw8fO2esROAxn-RKSrlQamlL27g22X2A/APC_0255.jpg&quot; data-image=&quot;https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/1607107051142-ORQ0N5ZSGH9884QNH8RF/ke17ZwdGBToddI8pDm48kPTrHXgsMrSIMwe6YW3w1AZ7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0k5fwC0WRNFJBIXiBeNI5fKTrY37saURwPBw8fO2esROAxn-RKSrlQamlL27g22X2A/APC_0255.jpg&quot; data-image-dimensions=&quot;2500x1406&quot; data-image-focal-point=&quot;0.5,0.5&quot; alt=&quot;Here’s another HDR clip happily blasting its whiter-than-white values on my non-HDR iMac Pro screen.&quot; data-load=&quot;false&quot; data-image-id=&quot;5fca81e80e456138b04acfbb&quot; data-type=&quot;image&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;image-caption&quot;&gt;
&lt;p class=&quot;&quot;&gt;Here’s another HDR clip happily blasting its whiter-than-white values on my non-HDR iMac Pro screen.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sqs-block markdown-block sqs-block-markdown&quot; data-block-type=&quot;44&quot; id=&quot;block-yui_3_17_2_1_1607106958232_35474&quot;&gt;
&lt;div class=&quot;sqs-block-content&quot;&gt;
&lt;p&gt;So add a third method of displaying EDR content to Apple’s roster: On these non-HDR displays, Apple has remapped “white” to something less than 255-255-255, leaving headroom for HDR vales, should they be called for. The operating system is complicit in this trickery, so the Digital Color Meter eyedropper shows “white” as 255, as do screenshots.&lt;sup data-preserve-html-node=&quot;true&quot;&gt;2&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;With Catalina, Apple quietly changed what “white” means for millions of Macs, and none of us noticed.&lt;/p&gt;
&lt;p&gt;Think of it this way: This EDR display philosophy is so important to Apple that they are willing to spend battery life on it. When you map “white” down to gray, you have to drive the LED backlight brighter for the same perceived screen brightness, using more power. Apple has your laptop doing this all the time, on the off chance that some HDR pixels come along to occupy that headroom (or not: see update below). It’s a huge flex, and a strong sign of Apple’s commitment to an HDR future.&lt;/p&gt;
&lt;p&gt;It also means that when you adjust your display brightness, macOS is commensurately adjusting the amount of headroom available for overbrights. Max out the brightness slowly and you can watch the HDR values gradually get pinched against the UI “white” as the headroom shrinks, until HDR white and Google white meet. Conversely, the lower your display brightness, the more headroom there is for EDR, although there will never be as much as on the Pro Display XDR, or even an iPhone 12 Pro.&lt;/p&gt;
&lt;p&gt;This variance in EDR capabilities across Apple devices is where a defining feature of HDR display comes into play. HDR standards like Dolby Vision were designed to accommodate screens of varying maximum brightness. The content is display independent, and when macOS goes to render it, it first asks the display how bright it can go, and then builds a bespoke lookup for that output brightness, correctly displaying the content within the available range.&lt;/p&gt;
&lt;p&gt;Apple handling this all for developers is a new kind of leg-up in the fraught field of color management. It’s actually trivial to display HDR content correctly on a semi-recent Mac. Apps such as &lt;a href=&quot;https://www.blackmagicdesign.com/products/davinciresolve/&quot;&gt;DaVinci Resolve&lt;/a&gt;, &lt;a href=&quot;https://affinity.serif.com/en-us/photo/&quot;&gt;Affinity Photo&lt;/a&gt;, and of course &lt;a href=&quot;https://www.apple.com/final-cut-pro/&quot;&gt;Final Cut Pro&lt;/a&gt; already do it, and you can expect to see it in Red Giant and Maxon tools as well.&lt;/p&gt;
&lt;p&gt;Apple sells one very expensive, very capable HDR display — and literally millions of iPhones, iPads, and Macs that are also pretty darn good at it.&lt;/p&gt;
&lt;h2 id=&quot;it-s-an-hdr-world&quot;&gt;It’s an HDR World&lt;/h2&gt;
&lt;p&gt;I’ve been &lt;a href=&quot;https://prolost.com/blog/hdrtv&quot;&gt;critical&lt;/a&gt; of HDR as a creative tool. My North Star is the look of film, with its glorious highlight rolloff. Trying to sell me “brighter” was like screaming at me in the front row of a Metallica concert that the sound could go louder.&lt;/p&gt;
&lt;p&gt;In the &lt;a href=&quot;https://www.rogerdeakins.com/lighting-2/sicario-grading-for-hdr/&quot;&gt;words&lt;/a&gt; of the great Roger Deakins:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If you create a balance of light and dark on set you expect that balance to be maintained throughout the process. I personally resent being told my work looks ‘better’ with brighter whites and more saturation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;That was him talking about &lt;em&gt;Sicario,&lt;/em&gt; five years ago. Since then, he’s shot a number of films, including &lt;em&gt;Blade Runner 2049,&lt;/em&gt; which, damnit, takes artful creative advantage of HDR exhibition. For the most part, like &lt;em&gt;Sicario,&lt;/em&gt; it intentionally occupies a narrow band of the available dynamic range. But at key parts of the story, certain colors eek outside of that self-imposed SDR container, to great effect. In a very emotional scene, brilliant pinks and purples explode off the screen — colors that not only had been absent from the film before that moment, but seemed altogether outside the spectrum of the story’s palette. Such a moment would not be possible without HDR.&lt;/p&gt;
&lt;p&gt;Or would it? While there are certainly colors that digital projection can uniquely display, in many ways digital cinematography is still chasing the tremendous dynamic range and color fidelity of celluloid film. Properly projected film &lt;sup data-preserve-html-node=&quot;true&quot;&gt;3&lt;/sup&gt; is, by any measure, HDR. So maybe I should warm up to digital’s latest efforts to live up to this legacy.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sqs-block image-block sqs-block-image&quot; data-block-type=&quot;5&quot; id=&quot;block-yui_3_17_2_1_1607108631939_113484&quot;&gt;
&lt;div class=&quot;sqs-block-content&quot;&gt;
&lt;div class=&quot; image-block-outer-wrapper layout-caption-below design-layout-inline combination-animation-none individual-animation-none individual-text-animation-none&quot; data-test=&quot;image-block-inline-outer-wrapper&quot;&gt;
&lt;div class=&quot; image-block-wrapper has-aspect-ratio&quot; data-animation-role=&quot;image&quot;&gt;&lt;noscript&gt;
&lt;p&gt;&lt;img src=&quot;https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/1607115418483-QWMJ03RWTEQDT94J66WA/ke17ZwdGBToddI8pDm48kNaCHh8gu7UaOhw3CKkZ2n57gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0vZK8F5UM-P0xbG1-i6I6zV_m7Q78QNPW1Q-iag6KzdqzbXCEbEjNHUYpYarwZONjw/image-asset.png&quot; alt=&quot;How much more orange could it be? The answer is none. None more orange.&quot;/&gt;&lt;/p&gt;
&lt;/noscript&gt;&lt;img class=&quot;thumb-image&quot; data-src=&quot;https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/1607115418483-QWMJ03RWTEQDT94J66WA/ke17ZwdGBToddI8pDm48kNaCHh8gu7UaOhw3CKkZ2n57gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0vZK8F5UM-P0xbG1-i6I6zV_m7Q78QNPW1Q-iag6KzdqzbXCEbEjNHUYpYarwZONjw/image-asset.png&quot; data-image=&quot;https://images.squarespace-cdn.com/content/v1/53f4e093e4b085e4457080e1/1607115418483-QWMJ03RWTEQDT94J66WA/ke17ZwdGBToddI8pDm48kNaCHh8gu7UaOhw3CKkZ2n57gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0vZK8F5UM-P0xbG1-i6I6zV_m7Q78QNPW1Q-iag6KzdqzbXCEbEjNHUYpYarwZONjw/image-asset.png&quot; data-image-dimensions=&quot;2500x1038&quot; data-image-focal-point=&quot;0.5,0.5&quot; alt=&quot;How much more orange could it be? The answer is none. None more orange.&quot; data-load=&quot;false&quot; data-image-id=&quot;5fcaa299bd325b40b5dc37ba&quot; data-type=&quot;image&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;image-caption&quot;&gt;
&lt;p class=&quot;&quot;&gt;How much more orange could it be? The answer is none. None more orange.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sqs-block markdown-block sqs-block-markdown&quot; data-block-type=&quot;44&quot; id=&quot;block-yui_3_17_2_1_1607108631939_113760&quot;&gt;
&lt;div class=&quot;sqs-block-content&quot;&gt;
&lt;h2 id=&quot;hug-don-t-reject&quot;&gt;Hug, Don’t Reject&lt;/h2&gt;
&lt;p&gt;HDR presentation joins the rich catalog of film techniques that can have a profound affect on audiences so long as they are not overused; alongside extreme close-ups, aggressive surround mixes, handheld camera work, fart jokes, and, well, just about every filmmaking tool from color to sound.&lt;/p&gt;
&lt;p&gt;I suppose I knew this reality was coming. I guess I just wasn’t expecting to see it on my laptop screen, glaring at me between my email and my grocery list.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;sqs-block markdown-block sqs-block-markdown&quot; data-block-type=&quot;44&quot; id=&quot;block-yui_3_17_2_1_1607209254797_98100&quot;&gt;
&lt;div class=&quot;sqs-block-content&quot;&gt;
&lt;h2 id=&quot;update-2020-12-05&quot;&gt;Update 2020-12-05&lt;/h2&gt;
&lt;p&gt;There’s good evidence that I’m wrong about EDR being speculatively on all the time on non-HDR Apple displays. Michael Fortin &lt;a href=&quot;https://michelf.ca/blog/2020/brighter-than-white-edr-on-macs/&quot;&gt;writes&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;When the [EDR] preview first appears on screen, it is rendered normally, in SDR. It then progressively becomes brighter over the span of one or two seconds. Brighter than the surrounding white. This appears to be the EDR system firing up: slowly cranking up the display brightness at the same time as it darkens the standard white point for everything but the video. Those two operations are done in tandem so well that you don’t perceive any change on screen other than the video becoming brighter.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I &lt;a href=&quot;https://twitter.com/5tu/status/1334220408900390912?s=20&quot;&gt;noted&lt;/a&gt; this transition animation on Twitter, but it's that “so well” part that tricked me — it is very hard to see UI white change at all during this EDR ramp-up, which feels impossible. More evidence: The screenshot borders I mention &lt;a href=&quot;https://twitter.com/5tu/status/1334291188279517184?s=20&quot;&gt;here&lt;/a&gt; are only EDR-white when there are other EDR pixels on the screen. The seamlessness of this transition completely fooled me, and serves as spectacular testament to how dialed-in Apple’s software and hardware are on matters of color.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;


&lt;div class=&quot;sqs-block markdown-block sqs-block-markdown&quot; data-block-type=&quot;44&quot; id=&quot;block-yui_3_17_2_1_1607102282517_5105&quot;&gt;
&lt;div class=&quot;sqs-block-content&quot;&gt;
&lt;ol&gt;&lt;li&gt;
&lt;p&gt;I don’t love using this simplistic 8-bit nomenclature for RGB color values, but in this context I’m doing so to invoke an old-school familiarity (echoed by the Digital Color Meter app). Between high-bit-depth P3 displays, display color management, software calibration, and &lt;a href=&quot;https://support.apple.com/en-us/HT208909&quot;&gt;True Tone&lt;/a&gt;, it’s probably been a very long time since “white” in a Mac UI was truly 255-255-255.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If EDR reminds you of &lt;a href=&quot;https://twitter.com/5tu/status/996166970666962944&quot;&gt;eLin&lt;/a&gt;, congrats on being old. And cool.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Something that, sadly, few people have ever seen.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
<pubDate>Sat, 05 Dec 2020 15:23:29 +0000</pubDate>
<dc:creator>mattparcher</dc:creator>
<og:title>Apple’s “EDR” Brings High Dynamic Range to Non-HDR Displays — Prolost</og:title>
<og:url>https://prolost.com/blog/edr</og:url>
<og:type>article</og:type>
<og:image>http://static1.squarespace.com/static/53f4e093e4b085e4457080e1/53f4ecffe4b048248b205988/5fca6f2a6cb6d01b09c3d2ed/1607211243815/HDRshades_01_CV_Cut_01_HDR.jpg?format=1500w</og:image>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://prolost.com/blog/edr</dc:identifier>
</item>
<item>
<title>Your Smart TV is probably ignoring your PiHole</title>
<link>https://labzilla.io/blog/force-dns-pihole</link>
<guid isPermaLink="true" >https://labzilla.io/blog/force-dns-pihole</guid>
<description>&lt;p&gt;If you’re using PiHole on your network to block ads and prevent your various smart devices from sending tracking information to their manufacturers, &lt;strong&gt;you might be surprised to find out that some of these devices are using a sneaky tactic to bypass your PiHole entirely.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Smart devices manufacturers often “hard-code” in a public DNS server, like Google’s 8.8.8.8, and their devices ignore whatever DNS server is assigned by your router - such as your PiHole.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/2001.08288.pdf&quot;&gt;Nearly 70% of smart TVs and 46% of game consoles&lt;/a&gt; were found to contain hardcoded DNS settings - allowing them to simply ignore your local network’s DNS server entirely. On average, Smart TVs generate an average of 60 megabytes of outgoing Internet traffic &lt;em&gt;per day&lt;/em&gt;, all the while bypassing tools like PiHole.&lt;/p&gt;
&lt;h2 id=&quot;force-all-dns-queries-through-pihole&quot;&gt;Force all DNS queries through PiHole&lt;/h2&gt;
&lt;p&gt;Fortunately, with a few simple firewall rules, you can intercept these hardcoded DNS queries and redirect them to your PiHole. These instructions are for pfSense, however you should be able to adapt them for Sophos XG, Ubiquiti EdgeRouter, etc.&lt;/p&gt;
&lt;h3 id=&quot;create-nat-rules&quot;&gt;Create NAT Rules&lt;/h3&gt;
&lt;p&gt;Log in to your pfSense admin interface, and navigate to &lt;em&gt;Firewall&lt;/em&gt; &amp;gt; &lt;em&gt;NAT&lt;/em&gt; &amp;gt; &lt;em&gt;Port Forward&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;We’re going to create two Port Forward NAT rules - one to redirect any DNS queries originating from devices on the LAN to PiHole, and another to allow PiHole to commmunicate with external DNS servers. We will also create an additional outbound NAT rule that will make this process invisible to any clients on the network with hardcoded DNS.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NAT Rule 1: Redirect DNS queries to PiHole&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Click the &lt;em&gt;Add&lt;/em&gt; button to create your first new NAT Port Forward rule.&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Interface:&lt;/strong&gt; LAN&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Protcol:&lt;/strong&gt; TCP/UDP&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Source:&lt;/strong&gt; LAN net (you may need to click the blue show advanced button to see this option)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Destination - Invert match:&lt;/strong&gt; Checked&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Destination - Type:&lt;/strong&gt; Single host or alias&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Destination - Address/mask:&lt;/strong&gt; Your PiHole’s IP address&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Destination Port Range - From:&lt;/strong&gt; DNS&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Destination Port Range - To:&lt;/strong&gt; DNS&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Redirect Target IP:&lt;/strong&gt; Your PiHole’s IP address&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Redirect Target Port:&lt;/strong&gt; DNS&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Description:&lt;/strong&gt; Intercept any outgoing DNS queries and redirect them to PiHole.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;NAT Rule 2: Exempt PiHole from DNS query redirects&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Click the &lt;em&gt;Add&lt;/em&gt; button to create your second new NAT Port Forward rule.&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;No RDR (NOT):&lt;/strong&gt; Checked&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Interface:&lt;/strong&gt; LAN&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Protcol:&lt;/strong&gt; TCP/UDP&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Source - Type:&lt;/strong&gt; Single host or alias&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Source - Address/Mask:&lt;/strong&gt; Your PiHole’s IP address&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Destination:&lt;/strong&gt; Any&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Destination Port Range - From:&lt;/strong&gt; DNS&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Destination Port Range - From:&lt;/strong&gt; DNS&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Description:&lt;/strong&gt; Allow PiHole to reach external DNS servers&lt;/li&gt;
&lt;/ul&gt;&lt;p class=&quot;warning&quot;&gt;&lt;strong&gt;Note:&lt;/strong&gt; pfSense (and most other firewalls) process rules from top to bottom. Make sure you drag the second rule exempting PiHole from DNS query redirects &lt;em&gt;above&lt;/em&gt; the first rule we created - otherwise PiHole will not be able to contact external DNS servers.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NAT Rule 3: Prevent clients from giving unexpected source errors&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Finally, we need to create an outbound NAT rule. Navigate to &lt;em&gt;Firewall&lt;/em&gt; &amp;gt; &lt;em&gt;NAT&lt;/em&gt; &amp;gt; &lt;em&gt;Outbound&lt;/em&gt;.&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Interface:&lt;/strong&gt; LAN&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Address Family:&lt;/strong&gt; IPv4+IPv6&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Protocol:&lt;/strong&gt; any&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Source - Type:&lt;/strong&gt; Network&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Source - Network for the outbound NAT mapping:&lt;/strong&gt; Your internal LAN network&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Destination - Type:&lt;/strong&gt; Network&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Destination - Network for the outbound NAT Mappings:&lt;/strong&gt; Your PiHole’s IP Address&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Destination Port Range:&lt;/strong&gt; 53&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Translation:&lt;/strong&gt; Interface Address&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Description:&lt;/strong&gt; Prevents hardcoded DNS clients from giving unexpected source error after DNS redirected to PiHole.&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;test-it-out&quot;&gt;Test it out&lt;/h3&gt;
&lt;p&gt;You can easily test to make sure your DNS redirection is working properly.&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;Create a new, temporary internal DNS entry on your network (“piholetest.example.com”), and point it to 10.0.1.1. You can do this right from PiHole under &lt;em&gt;Local DNS Records&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Manually set your computer’s DNS server to &lt;em&gt;1.1.1.1&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Open a terminal window (or command promt on Windows), and run &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nslookup piholetest.example.com&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If you set this up correctly, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nslookup&lt;/code&gt; should return 10.0.1.1. Your computer &lt;em&gt;thinks&lt;/em&gt; it’s receiving DNS records from 1.1.1.1, while in reality they are coming from your PiHole.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt; macbookpro:~ labzilla$ nslookup piholetest.example.com
 Server:                1.1.1.1
 Address:       1.1.1.1#53
        
 Name:  piholetest.example.com
 Address: 10.0.1.1
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You can further demonstate this by temporarily disabling the first NAT rule we created, and running the same &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nslookup piholetest.example.com&lt;/code&gt; command:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt; macbookpro:~ labzilla$ nslookup piholetest.example.com
 Server:                1.1.1.1
 Address:       1.1.1.1#53
        
 ** server can't find piholetest.example.com: NXDOMAIN 
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;As “piholetest.example.com” doesn’t exist on the public Internet, the real 1.1.1.1 server has no record to provide - resulting in your &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nslookup&lt;/code&gt; request returning a NXDOMAIN error.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;strong&gt;Don’t forget to revert your computer’s DNS settings back to their original value, and reenable any firewall rules you temporary disabled while testing.&lt;/strong&gt;&lt;/p&gt;
</description>
<pubDate>Sat, 05 Dec 2020 11:38:12 +0000</pubDate>
<dc:creator>giuliomagnifico</dc:creator>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://labzilla.io/blog/force-dns-pihole</dc:identifier>
</item>
<item>
<title>72% of smart TVs and 46% of game consoles hardcode DNS settings</title>
<link>https://labzilla.io/blog/force-dns-pihole</link>
<guid isPermaLink="true" >https://labzilla.io/blog/force-dns-pihole</guid>
<description>&lt;p&gt;If you’re using PiHole on your network to block ads and prevent your various smart devices from sending tracking information to their manufacturers, &lt;strong&gt;you might be surprised to find out that some of these devices are using a sneaky tactic to bypass your PiHole entirely.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Smart devices manufacturers often “hard-code” in a public DNS server, like Google’s 8.8.8.8, and their devices ignore whatever DNS server is assigned by your router - such as your PiHole.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/2001.08288.pdf&quot;&gt;Nearly 70% of smart TVs and 46% of game consoles&lt;/a&gt; were found to contain hardcoded DNS settings - allowing them to simply ignore your local network’s DNS server entirely. On average, Smart TVs generate an average of 60 megabytes of outgoing Internet traffic &lt;em&gt;per day&lt;/em&gt;, all the while bypassing tools like PiHole.&lt;/p&gt;
&lt;h2 id=&quot;force-all-dns-queries-through-pihole&quot;&gt;Force all DNS queries through PiHole&lt;/h2&gt;
&lt;p&gt;Fortunately, with a few simple firewall rules, you can intercept these hardcoded DNS queries and redirect them to your PiHole. These instructions are for pfSense, however you should be able to adapt them for Sophos XG, Ubiquiti EdgeRouter, etc.&lt;/p&gt;
&lt;h3 id=&quot;create-nat-rules&quot;&gt;Create NAT Rules&lt;/h3&gt;
&lt;p&gt;Log in to your pfSense admin interface, and navigate to &lt;em&gt;Firewall&lt;/em&gt; &amp;gt; &lt;em&gt;NAT&lt;/em&gt; &amp;gt; &lt;em&gt;Port Forward&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;We’re going to create two Port Forward NAT rules - one to redirect any DNS queries originating from devices on the LAN to PiHole, and another to allow PiHole to commmunicate with external DNS servers. We will also create an additional outbound NAT rule that will make this process invisible to any clients on the network with hardcoded DNS.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NAT Rule 1: Redirect DNS queries to PiHole&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Click the &lt;em&gt;Add&lt;/em&gt; button to create your first new NAT Port Forward rule.&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Interface:&lt;/strong&gt; LAN&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Protcol:&lt;/strong&gt; TCP/UDP&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Source:&lt;/strong&gt; LAN net (you may need to click the blue show advanced button to see this option)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Destination - Invert match:&lt;/strong&gt; Checked&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Destination - Type:&lt;/strong&gt; Single host or alias&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Destination - Address/mask:&lt;/strong&gt; Your PiHole’s IP address&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Destination Port Range - From:&lt;/strong&gt; DNS&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Destination Port Range - To:&lt;/strong&gt; DNS&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Redirect Target IP:&lt;/strong&gt; Your PiHole’s IP address&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Redirect Target Port:&lt;/strong&gt; DNS&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Description:&lt;/strong&gt; Intercept any outgoing DNS queries and redirect them to PiHole.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;NAT Rule 2: Exempt PiHole from DNS query redirects&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Click the &lt;em&gt;Add&lt;/em&gt; button to create your second new NAT Port Forward rule.&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;No RDR (NOT):&lt;/strong&gt; Checked&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Interface:&lt;/strong&gt; LAN&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Protcol:&lt;/strong&gt; TCP/UDP&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Source - Type:&lt;/strong&gt; Single host or alias&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Source - Address/Mask:&lt;/strong&gt; Your PiHole’s IP address&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Destination:&lt;/strong&gt; Any&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Destination Port Range - From:&lt;/strong&gt; DNS&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Destination Port Range - From:&lt;/strong&gt; DNS&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Description:&lt;/strong&gt; Allow PiHole to reach external DNS servers&lt;/li&gt;
&lt;/ul&gt;&lt;p class=&quot;warning&quot;&gt;&lt;strong&gt;Note:&lt;/strong&gt; pfSense (and most other firewalls) process rules from top to bottom. Make sure you drag the second rule exempting PiHole from DNS query redirects &lt;em&gt;above&lt;/em&gt; the first rule we created - otherwise PiHole will not be able to contact external DNS servers.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NAT Rule 3: Prevent clients from giving unexpected source errors&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Finally, we need to create an outbound NAT rule. Navigate to &lt;em&gt;Firewall&lt;/em&gt; &amp;gt; &lt;em&gt;NAT&lt;/em&gt; &amp;gt; &lt;em&gt;Outbound&lt;/em&gt;.&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Interface:&lt;/strong&gt; LAN&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Address Family:&lt;/strong&gt; IPv4+IPv6&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Protocol:&lt;/strong&gt; any&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Source - Type:&lt;/strong&gt; Network&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Source - Network for the outbound NAT mapping:&lt;/strong&gt; Your internal LAN network&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Destination - Type:&lt;/strong&gt; Network&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Destination - Network for the outbound NAT Mappings:&lt;/strong&gt; Your PiHole’s IP Address&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Destination Port Range:&lt;/strong&gt; 53&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Translation:&lt;/strong&gt; Interface Address&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Description:&lt;/strong&gt; Prevents hardcoded DNS clients from giving unexpected source error after DNS redirected to PiHole.&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;test-it-out&quot;&gt;Test it out&lt;/h3&gt;
&lt;p&gt;You can easily test to make sure your DNS redirection is working properly.&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;Create a new, temporary internal DNS entry on your network (“piholetest.example.com”), and point it to 10.0.1.1. You can do this right from PiHole under &lt;em&gt;Local DNS Records&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Manually set your computer’s DNS server to &lt;em&gt;1.1.1.1&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Open a terminal window (or command promt on Windows), and run &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nslookup piholetest.example.com&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If you set this up correctly, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nslookup&lt;/code&gt; should return 10.0.1.1. Your computer &lt;em&gt;thinks&lt;/em&gt; it’s receiving DNS records from 1.1.1.1, while in reality they are coming from your PiHole.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt; macbookpro:~ labzilla$ nslookup piholetest.example.com
 Server:                1.1.1.1
 Address:       1.1.1.1#53
        
 Name:  piholetest.example.com
 Address: 10.0.1.1
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You can further demonstate this by temporarily disabling the first NAT rule we created, and running the same &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nslookup piholetest.example.com&lt;/code&gt; command:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt; macbookpro:~ labzilla$ nslookup piholetest.example.com
 Server:                1.1.1.1
 Address:       1.1.1.1#53
        
 ** server can't find piholetest.example.com: NXDOMAIN 
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;As “piholetest.example.com” doesn’t exist on the public Internet, the real 1.1.1.1 server has no record to provide - resulting in your &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nslookup&lt;/code&gt; request returning a NXDOMAIN error.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;strong&gt;Don’t forget to revert your computer’s DNS settings back to their original value, and reenable any firewall rules you temporary disabled while testing.&lt;/strong&gt;&lt;/p&gt;
</description>
<pubDate>Sat, 05 Dec 2020 10:46:35 +0000</pubDate>
<dc:creator>boramalper</dc:creator>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://labzilla.io/blog/force-dns-pihole</dc:identifier>
</item>
<item>
<title>Radicle: A peer-to-peer alternative to GitHub</title>
<link>http://radicle.xyz#/beta</link>
<guid isPermaLink="true" >http://radicle.xyz#/beta</guid>
<description>&lt;p&gt;If you'd like to stay updated about product releases, project updates, and other announcements, hand us your e-mail and we'll keep you in the loop.&lt;/p&gt;
&lt;p&gt;For updates, follow us on &lt;a href=&quot;https://twitter.com/radicle&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;Twitter&lt;/span&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;form action=&quot;https://xyz.us2.list-manage.com/subscribe/post?u=6c7bba7ab992717860dcec6eb&amp;amp;id=f960345a90&quot; method=&quot;post&quot; id=&quot;mc-embedded-subscribe-form&quot; name=&quot;mc-embedded-subscribe-form&quot; class=&quot;validate&quot; novalidate=&quot;&quot; autocomplete=&quot;off&quot;&gt;


&lt;button type=&quot;submit&quot;&gt;Join&lt;/button&gt;&lt;/form&gt;
&lt;p class=&quot;small&quot;&gt;Radicle is a project supported by The Radicle Foundation. &lt;a href=&quot;mailto:hello@radicle.foundation&quot;&gt;Email us&lt;/a&gt;.&lt;/p&gt;
&lt;p class=&quot;small&quot;&gt;Read about our &lt;a href=&quot;https://radicle.xyz/terms.html&quot;&gt;Terms &amp;amp; Conditions&lt;/a&gt; &amp;amp; &lt;a href=&quot;https://radicle.xyz/privacy.html&quot;&gt;Privacy Policy&lt;/a&gt;.&lt;/p&gt;
&lt;p class=&quot;small&quot;&gt;GIF artwork credits: &lt;a href=&quot;https://www.instagram.com/render_fruit&quot; target=&quot;_blank&quot;&gt;Render Fruit&lt;/a&gt;, &lt;a href=&quot;https://www.instagram.com/kotutohum.gif&quot; target=&quot;_blank&quot;&gt;kotutohum&lt;/a&gt;, &lt;a href=&quot;http://echinopsisfreak.com/&quot; target=&quot;_blank&quot;&gt;Greg Krehel&lt;/a&gt;, &lt;a href=&quot;https://en.wikipedia.org/wiki/Ghost_in_the_Shell_(1995_film)&quot; target=&quot;_blank&quot;&gt;Ghost in the Shell&lt;/a&gt;.&lt;/p&gt;
</description>
<pubDate>Sat, 05 Dec 2020 09:13:23 +0000</pubDate>
<dc:creator>dweberz</dc:creator>
<og:title>Radicle - Peer-to-peer code collaboration</og:title>
<og:image>https://radicle.xyz/img/social-share.jpg</og:image>
<og:description>Radicle is a peer-to-peer stack for building software together.</og:description>
<dc:format>text/html</dc:format>
<dc:identifier>https://radicle.xyz/</dc:identifier>
</item>
<item>
<title>We read the paper that forced Timnit Gebru out of Google</title>
<link>https://www.technologyreview.com/2020/12/04/1013294/google-ai-ethics-research-paper-forced-out-timnit-gebru</link>
<guid isPermaLink="true" >https://www.technologyreview.com/2020/12/04/1013294/google-ai-ethics-research-paper-forced-out-timnit-gebru</guid>
<description>&lt;p&gt;Many details of the exact sequence of events that led up to Gebru’s departure are not yet clear; both she and Google have declined to comment beyond their posts on social media. But MIT Technology Review obtained a copy of the research paper from  one of the co-authors, Emily M. Bender, a professor of computational linguistics at the University of Washington. Though Bender asked us not to publish the paper itself because the authors didn’t want such an early draft circulating online, it gives some insight into the questions Gebru and her colleagues were raising about AI that might be causing Google concern.&lt;/p&gt;
&lt;p&gt;Titled “On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?” the paper lays out the risks of large language models—AIs trained on staggering amounts of text data. These have grown &lt;a href=&quot;https://www.technologyreview.com/2019/02/16/66080/ai-natural-language-processing-explained/&quot;&gt;increasingly popular&lt;/a&gt;—and &lt;a href=&quot;https://www.technologyreview.com/2019/06/06/239031/training-a-single-ai-model-can-emit-as-much-carbon-as-five-cars-in-their-lifetimes/&quot;&gt;increasingly large&lt;/a&gt;—in the last three years. They are now extraordinarily good, under the right conditions, at producing what looks like convincing, meaningful new text—and sometimes at estimating meaning from language. But, says the introduction to the paper, “we ask whether enough thought has been put into the potential risks associated with developing them and strategies to mitigate these risks.”&lt;/p&gt;
&lt;h3&gt;The paper&lt;/h3&gt;
&lt;p&gt;The paper, which builds off the work of other researchers, presents the history of natural-language processing, an overview of four main risks of large language models, and suggestions for further research. Since the conflict with Google seems to be over the risks, we’ve focused on summarizing those here. &lt;/p&gt;
&lt;h4&gt;Environmental and financial costs&lt;/h4&gt;
&lt;p&gt;Training large AI models consumes a lot of computer processing power, and hence a lot of electricity. Gebru and her coauthors refer to a 2019 paper from Emma Strubell and her collaborators on &lt;a href=&quot;https://www.technologyreview.com/2019/06/06/239031/training-a-single-ai-model-can-emit-as-much-carbon-as-five-cars-in-their-lifetimes/&quot;&gt;the carbon emissions and financial costs&lt;/a&gt; of large language models. It found that their energy consumption and carbon footprint have been exploding since 2017, as models have been fed more and more data.&lt;/p&gt;

&lt;p&gt;Strubell’s study found that one language model with a particular type of “neural architecture search” (NAS) method would have produced the equivalent of 626,155 pounds (284 metric tons) of carbon dioxide—about the lifetime output of five average American cars. A version of Google’s language model, BERT, which underpins &lt;a href=&quot;https://blog.google/products/search/search-language-understanding-bert/&quot;&gt;the company’s search engine&lt;/a&gt;, produced 1,438 pounds of CO2 equivalent in Strubell’s estimate—nearly the same as a roundtrip flight between New York City and San Francisco.&lt;/p&gt;

&lt;p&gt;Gebru’s draft paper points out that the sheer resources required to build and sustain such large AI models means they tend to benefit wealthy organizations, while climate change hits marginalized communities hardest. “It is past time for researchers to prioritize energy efficiency and cost to reduce negative environmental impact and inequitable access to resources,” they write.&lt;/p&gt;
&lt;h4&gt;Massive data, inscrutable models&lt;/h4&gt;
&lt;p&gt;Large language models are also trained on exponentially increasing amounts of text. This means researchers have sought to collect all the data they can from the internet, so there's a risk that racist, sexist, and otherwise abusive language ends up in the training data.&lt;/p&gt;
&lt;p&gt;An AI model taught to view racist language as normal is obviously bad. The researchers, though, point out a couple of more subtle problems. One is that shifts in language play an important role in social change; the MeToo and Black Lives Matter movements, for example, have tried to establish a new anti-sexist and anti-racist vocabulary. An AI model trained on vast swaths of the internet won’t be attuned to the nuances of this vocabulary and won’t produce or interpret language in line with these new cultural norms.&lt;/p&gt;
&lt;p&gt;It will also fail to capture the language and the norms of countries and peoples that have less access to the internet and thus a smaller linguistic footprint online. The result is that AI-generated language will be homogenized, reflecting the practices of the richest countries and communities.&lt;/p&gt;
&lt;p&gt;Moreover, because the training datasets are so large, it’s hard to audit them to check for these embedded biases. “A methodology that relies on datasets too large to document is therefore inherently risky,” the researchers conclude. “While documentation allows for potential accountability, [...] undocumented training data perpetuates harm without recourse.”&lt;/p&gt;
&lt;h4&gt;Research opportunity costs&lt;/h4&gt;
&lt;p&gt;The researchers summarize the third challenge as the risk of “misdirected research effort.” Though most AI researchers acknowledge that large language models &lt;a href=&quot;https://www.technologyreview.com/2020/07/20/1005454/openai-machine-learning-language-generator-gpt-3-nlp/&quot;&gt;don’t actually &lt;em&gt;understand&lt;/em&gt; language&lt;/a&gt; and are merely excellent at &lt;em&gt;manipulating&lt;/em&gt; it, Big Tech can make money from models that manipulate language more accurately, so it keeps investing in them. “This research effort brings with it an opportunity cost,” Gebru and her colleagues write. Not as much effort goes into working on AI models that might achieve understanding, or that achieve good results with smaller, more carefully curated datasets (and thus also use less energy).&lt;/p&gt;
&lt;h4&gt;Illusions of meaning&lt;/h4&gt;
&lt;p&gt;The final problem with large language models, the researchers say, is that because they’re so good at mimicking real human language, it’s easy to use them to fool people. There have been a few high-profile cases, such as the &lt;a href=&quot;https://www.technologyreview.com/2020/08/14/1006780/ai-gpt-3-fake-blog-reached-top-of-hacker-news/&quot;&gt;college student&lt;/a&gt; who churned out AI-generated self-help and productivity advice on a blog, which went viral.&lt;/p&gt;
&lt;p&gt;The dangers are obvious: AI models could be used to generate misinformation about an election or the covid-19 pandemic, for instance. They can also go wrong inadvertently when used for machine translation. The researchers bring up an example: In 2017, Facebook &lt;a href=&quot;https://www.theguardian.com/technology/2017/oct/24/facebook-palestine-israel-translates-good-morning-attack-them-arrest&quot;&gt;mistranslated&lt;/a&gt; a Palestinian man’s post, which said “good morning” in Arabic, as “attack them” in Hebrew, leading to his arrest.&lt;/p&gt;
&lt;h3&gt;Why it matters&lt;/h3&gt;
&lt;p&gt;Gebru and Bender’s paper has six co-authors, four of whom are Google researchers. Bender asked to avoid disclosing their names for fear of repercussions. (Bender, by contrast, is a tenured professor: “I think this is underscoring the value of academic freedom,” she says.)&lt;/p&gt;
&lt;p&gt;The paper’s goal, Bender says, was to take stock of the landscape of current research in natural-language processing. “We are working at a scale where the people building the things can't actually get their arms around the data,” she said. “And because the upsides are so obvious, it's particularly important to step back and ask ourselves, what are the possible downsides? … How do we get the benefits of this while mitigating the risk?”&lt;/p&gt;
&lt;p&gt;In his internal email, Dean, the Google AI head, said one reason the paper “didn’t meet our bar” was that it “ignored too much relevant research.” Specifically, he said it didn’t mention more recent work on how to make large language models more energy-efficient and mitigate problems of bias. &lt;/p&gt;
&lt;p&gt;However, the six collaborators drew on a wide breadth of scholarship. The paper’s citation list, with 128 references, is notably long. “It's the sort of work that no individual or even pair of authors can pull off,” Bender said. “It really required this collaboration.” &lt;/p&gt;
&lt;p&gt;The version of the paper we saw does also nod to several research efforts on reducing the size and computational costs of large language models, and on measuring the embedded bias of models. It argues, however, that these efforts have not been enough. “I'm very open to seeing what other references we ought to be including,” Bender said.&lt;/p&gt;
&lt;p&gt;Nicolas Le Roux, a Google AI researcher in the Montreal office, later &lt;a href=&quot;https://twitter.com/le_roux_nicolas/status/1334601960972906496&quot;&gt;noted on Twitter&lt;/a&gt; that the reasoning in Dean’s email was unusual. “My submissions were always checked for disclosure of sensitive material, never for the quality of the literature review,” he said.&lt;/p&gt;
</description>
<pubDate>Sat, 05 Dec 2020 03:20:18 +0000</pubDate>
<dc:creator>DarkContinent</dc:creator>
<og:url>https://www.technologyreview.com/2020/12/04/1013294/google-ai-ethics-research-paper-forced-out-timnit-gebru/</og:url>
<og:type>article</og:type>
<og:title>We read the paper that forced Timnit Gebru out of Google. Here’s what it says</og:title>
<og:description>The company's star ethics researcher highlighted the risks of large language models, which are key to Google's business.</og:description>
<og:image>https://wp.technologyreview.com/wp-content/uploads/2020/12/transglobal-copy-1-e1607136614490.jpg?resize=1200,600</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.technologyreview.com/2020/12/04/1013294/google-ai-ethics-research-paper-forced-out-timnit-gebru</dc:identifier>
</item>
<item>
<title>This is Real, That&amp;#039;s Not</title>
<link>https://streetlifesolutions.blogspot.com/2020/12/this-is-real-thats-not.html</link>
<guid isPermaLink="true" >https://streetlifesolutions.blogspot.com/2020/12/this-is-real-thats-not.html</guid>
<description>&lt;p&gt;
&lt;h3 class=&quot;post-title entry-title&quot;&gt;This is Real. That's Not.&lt;/h3&gt;
&lt;/p&gt;&lt;div id=&quot;post-body-6447840497099398952&quot; readability=&quot;187.90834473324&quot;&gt;We all grow up in our own little bubble. Getting perspective on ourselves and/or our own lives is one of the harder things to do in life.&lt;p&gt;I've always liked the following movie scene, but it took on new meaning for me after I was homeless:
&lt;/p&gt;&lt;p align=&quot;center&quot;&gt;&lt;iframe allow=&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/rlHlKi2dATw&quot; width=&quot;560&quot;&gt;[embedded content]&lt;/iframe&gt;&lt;br/&gt;Most of us go through life...knowing only that one little station to which we were born...&lt;br/&gt;you...have had the rare privilege of escaping your bonds for just a spell...&lt;/p&gt;
&lt;br/&gt;I was on the street about a year before it dawned on me how upper class my mother's expectations were. It took even longer for me to begin to comprehend how well off my parents had actually been at one time.&lt;p&gt;While I was growing up, my parents always conveyed this narrative of &quot;We are just plain folks with blue collar jobs.&quot; I was a child, so I believed what I was told and it took a stint &quot;on skid row&quot; to get a clue that this wasn't the whole story.&lt;/p&gt;&lt;p&gt;I actively and intentionally used my time on the street as a means to gain insight into things about myself and my own life, especially in areas that weren't working well. Being homeless was a somewhat unique opportunity to get feedback on where my circumstances ended and where &quot;I&quot; began.&lt;/p&gt;&lt;p&gt;Growing up, I kind of thought &quot;Most people are just nice.&quot; I had no means to figure out how much was &lt;em&gt;natural charm&lt;/em&gt;, how much was me dressing well and the like and how much was people deferring to me because I was one of the highest ranked students in my school and so forth.&lt;/p&gt;&lt;p&gt;Being homeless taught me that, no, most people absolutely are not &lt;em&gt;just nice&lt;/em&gt;. It also taught me that I actually can be charming and smooth talking.&lt;/p&gt;&lt;p&gt;It turns out that's a real skill that I have and it has real value. It wasn't simply about me thinking I knew how to ask nicely but really being deferred to by others because of my station in life.&lt;/p&gt;&lt;p&gt;Another interesting thing is that even while homeless people tended to read me as upper class. I was often mistaken for a tourist at first glance.&lt;/p&gt;&lt;p&gt;My casual attire of t-shirts and sweat pants was read to mean that I was on vacation, not sleeping in a tent in a patch of woods as my only housing. People had to see me a few times to realize I had &lt;em&gt;habits&lt;/em&gt; like a homeless person and wasn't simply taking a break from more upper class attire.&lt;/p&gt;&lt;p&gt;While homeless, I belonged for a time to a toxic, classist forum called Metafilter. The mods there actively encouraged others to bully me and plenty of people embraced that edict with enthusiasm.&lt;/p&gt;&lt;p&gt;One woman who bullied me on Metafilter with more persistence than the norm was an ER doctor with mommy issues. Another real toxic asshole that stands out in my memory was an American man pursuing his PhD in Europe.&lt;/p&gt;&lt;p&gt;The best of the best of the best, sir!&lt;/p&gt;&lt;p&gt;I eventually concluded that in addition to the people there being generally warped and unhealthy individuals who were all too willing to behave abusively to someone who had nothing, I scared the hell out of them. They didn't want to believe that someone &quot;like them&quot; could end up homeless.&lt;/p&gt;&lt;p&gt;I still read as too upper class. I had too much education. I was too articulate. I was too well traveled. I wasn't an addict or a teen mom.&lt;/p&gt;&lt;p&gt;They wanted to believe that getting a good education and coming from a good home and so forth would guarantee their safety from the horrors of street life. I flew too much in the face of this delusion to be at all acceptable.&lt;/p&gt;&lt;p&gt;Rather than have compassion for &quot;one of their own&quot; who was &quot;down on their luck,&quot; they actively harassed me and ultimately banned me. These are people who like to brag about what wonderful people they are.&lt;/p&gt;&lt;p&gt;I recently spoke with a woman from an even more upper class background than mine -- someone who only attended private schools growing up -- and she is currently homeless. She soon was actively insulting me, unwilling to believe that I was really &quot;her equal&quot; in any real sense.&lt;/p&gt;&lt;p&gt;This post is being written because of that conversation. She kept saying things like &quot;I have a graduate degree!&quot; and &quot;I understand numbers and finance!&quot;&lt;/p&gt;&lt;p&gt;She tried to insist that my offer to point her in the direction of gig work was unhelpful as she had some minimum income requirements to pay her student loans etc. Although she had reached out to me, it was as if she believed that I hadn't been through some of the exact same things myself while homeless.&lt;/p&gt;&lt;p&gt;In reality, her story had quite a few details that sounded exactly like mine. I got back into housing a few weeks after I made my last student loan payment.&lt;/p&gt;&lt;p&gt;Being homeless apparently flew in the face of all the stuff she believed about how life was supposed to work. She seemed to believe that an education would protect her. She seemed to believe that being &quot;smart&quot; would protect her. Etc.&lt;/p&gt;&lt;p&gt;If you are homeless and come from an upper class background, I will suggest that repeating all the things you believe about how life is &lt;em&gt;supposed to work&lt;/em&gt; will not magically make them true and thereby fix your problems. Being verbally abusive to me because I don't have the kinds of answers you want won't either.&lt;/p&gt;&lt;p&gt;I encourage you to see this as a heavy dose of reality concerning where your mental models are broken. The only cure for what ails you is to start getting over your delusions and start adjusting your mental models to come up with a more accurate understanding of reality.&lt;/p&gt;&lt;p&gt;If you are upper class and not currently homeless, please take this post as one more message from some random internet stranger that, no, you are not magically exempt from the possibility of ending up on the street. If you are American and don't like that fact, taking it out on &quot;the messenger&quot; also won't fix the fact that America does a poor job of providing its citizens with a safety net in comparison to most developed countries.&lt;/p&gt;&lt;p&gt;The title of this post is from an old interview with Elizabeth Taylor. She was talking about what she got out of making her first movie while still a child.&lt;/p&gt;&lt;p&gt;She talked about how powerfully it shaped her mental models of the world to have that experience at a young age and how that positively impacted her life as an adult to have it very clear in her mind from an early age that &quot;This is real. That's not.&quot;&lt;/p&gt;&lt;p&gt;While homeless, my hypothesis was that my life was broken at least in part because my mental models were broken. I sought to fix my mental models as a means to fix my life.&lt;/p&gt;&lt;p&gt;I did manage to get myself back into housing on my own efforts without being &quot;rescued&quot; by anyone nor going through some kind of program. I see that as evidence of the accuracy of my hypothesis.&lt;/p&gt;&lt;p&gt;Though I'm sure someone will read this and feel compelled to assert that &quot;Correlation does not prove causation&quot; and then link to &lt;a href=&quot;https://xkcd.com/552/&quot;&gt;some XKCD strip.&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://news.ycombinator.com/item?id=25310779&quot;&gt;Hacker News Discussion&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;</description>
<pubDate>Sat, 05 Dec 2020 01:39:11 +0000</pubDate>
<dc:creator>DoreenMichele</dc:creator>
<og:url>https://streetlifesolutions.blogspot.com/2020/12/this-is-real-thats-not.html</og:url>
<og:title>This is Real. That's Not.</og:title>
<og:description>We all grow up in our own little bubble. Getting perspective on ourselves and/or our own lives is one of the harder things to do in life. ...</og:description>
<og:image>https://lh4.googleusercontent.com/proxy/ow9l3MSl1QD-Gd682IB-20L3mHa_nCmTuatL7dMkhYh39HEngreAxalhxbEDg0bPKdyYoALZD2CVis51HNrolwfdCXU=w1200-h630-n-k-no-nu</og:image>
<dc:format>text/html</dc:format>
<dc:identifier>https://streetlifesolutions.blogspot.com/2020/12/this-is-real-thats-not.html</dc:identifier>
</item>
<item>
<title>Teddit: a free and open-source Reddit front end focused on privacy</title>
<link>https://teddit.net/</link>
<guid isPermaLink="true" >https://teddit.net/</guid>
<description>[unable to retrieve full-text content]
&lt;p&gt;Article URL: &lt;a href=&quot;https://teddit.net/&quot;&gt;https://teddit.net/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Comments URL: &lt;a href=&quot;https://news.ycombinator.com/item?id=25310206&quot;&gt;https://news.ycombinator.com/item?id=25310206&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Points: 628&lt;/p&gt;
&lt;p&gt;# Comments: 264&lt;/p&gt;
</description>
<pubDate>Sat, 05 Dec 2020 00:20:12 +0000</pubDate>
<dc:creator>oftenwrong</dc:creator>
<dc:format>text/html</dc:format>
<dc:identifier>https://teddit.net/</dc:identifier>
</item>
<item>
<title>Sight restored by turning back the epigenetic clock</title>
<link>https://www.nature.com/articles/d41586-020-03119-1</link>
<guid isPermaLink="true" >https://www.nature.com/articles/d41586-020-03119-1</guid>
<description>&lt;div class=&quot;content position-relative cleared clear mq1200-padded&quot; data-component=&quot;article-container&quot; role=&quot;main&quot;&gt;
&lt;header class=&quot;article-item__header clear cleared pull--both&quot;&gt;&lt;div class=&quot;article__type&quot;&gt;NEWS AND VIEWS
&lt;div class=&quot;ml10 article__date&quot;&gt;&lt;time itemprop=&quot;datePublished&quot;&gt;02 December 2020&lt;/time&gt;&lt;/div&gt;
&lt;/div&gt;


&lt;div class=&quot;article-item__teaser-text&quot;&gt;Neurons progressively deteriorate with age and lose resilience to injury. It emerges that treatment with three transcription factors can re-endow neurons in the mature eye with youthful characteristics and the capacity to regenerate.&lt;/div&gt;
&lt;/header&gt;
&lt;div class=&quot;bordered-container clear cleared pull--both&quot;&gt;
&lt;div id=&quot;author-affiliations&quot; class=&quot;tab-group text14&quot; role=&quot;tablist&quot; data-test=&quot;author-affiliations&quot; data-tab-group=&quot;&quot;&gt;
&lt;div class=&quot;cleared&quot;&gt;
&lt;div id=&quot;author-affiliation-news-0&quot; class=&quot;tab-box js-box-wrapper&quot;&gt;
&lt;h3 id=&quot;author-affiliation-news-0-head&quot; data-track=&quot;click&quot; data-track-label=&quot;view author info&quot; class=&quot;sans-serif strong tab tab-skin ma0&quot; role=&quot;tab&quot; aria-controls=&quot;author-affiliation-news-0-content&quot; data-tooltip=&quot;Show author information&quot;&gt;&lt;strong class=&quot;icon icon-right-top icon-mail-12x9-blue pr15 js-no-scroll&quot;&gt;Andrew D. Huberman&lt;/strong&gt;&lt;/h3&gt;
&lt;div id=&quot;author-affiliation-news-0-content&quot; class=&quot;tab-content pin-right grid grid-12 last&quot; role=&quot;tabpanel&quot;&gt;
&lt;div class=&quot;pa10&quot; aria-labelledby=&quot;author-affiliation-news-0-head&quot;&gt;
&lt;div class=&quot;clear cleared&quot;&gt;
&lt;div class=&quot;align-left&quot;&gt;
&lt;div&gt;Andrew D. Huberman is in the Department of Neurobiology and the Department of Ophthalmology, Stanford University School of Medicine, Stanford, California 94305, USA.&lt;/div&gt;
&lt;a href=&quot;https://www.nature.com/articles/d41586-020-03119-1/email/correspondent/c1/new&quot; data-track=&quot;click&quot; data-track-label=&quot;contact author&quot; class=&quot;icon icon-left icon-mail-12x9-blue pl15 js-no-scroll&quot; rel=&quot;nofollow&quot;&gt;Contact&lt;/a&gt;&lt;/div&gt;
&lt;div class=&quot;align-right&quot;&gt;
&lt;h4 class=&quot;sans-serif&quot;&gt;Search for this author in:&lt;/h4&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;


&lt;div class=&quot;align-left&quot;&gt;
&lt;div class=&quot;article__body cleared&quot;&gt;
&lt;p&gt;Ageing has negative consequences for all the cells and organs in our bodies. Our brains are no exception. Neurons in the developing brain form circuits that can adapt to change and regenerate in response to injury. These capacities have long been known&lt;sup&gt;&lt;a href=&quot;https://www.nature.com/articles/d41586-020-03119-1#ref-CR1&quot; data-track=&quot;click&quot; data-action=&quot;anchor-link&quot; data-track-label=&quot;go to reference&quot; data-track-category=&quot;references&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; to diminish over time, but the molecular shifts that underlie this deterioration have remained mysterious. Lu &lt;em&gt;et al&lt;/em&gt;.&lt;sup&gt;&lt;a href=&quot;https://www.nature.com/articles/d41586-020-03119-1#ref-CR2&quot; data-track=&quot;click&quot; data-action=&quot;anchor-link&quot; data-track-label=&quot;go to reference&quot; data-track-category=&quot;references&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; show in &lt;a href=&quot;https://www.nature.com/articles/s41586-020-2975-4&quot; data-track=&quot;click&quot; data-label=&quot;https://www.nature.com/articles/s41586-020-2975-4&quot; data-track-category=&quot;body text link&quot;&gt;a paper in &lt;em&gt;Nature&lt;/em&gt;&lt;/a&gt; that neurons of the eye can be programmed to revert to a youthful state in which they reacquire their ability to resist injury and to regenerate. The authors’ findings shed light on mechanisms of ageing and point to a potent therapeutic target for age-related neuronal diseases.&lt;/p&gt;
&lt;aside class=&quot;recommended pull pull--left sans-serif&quot; data-label=&quot;Related&quot;&gt;&lt;a href=&quot;https://www.nature.com/articles/s41586-020-2975-4&quot; data-track=&quot;click&quot; data-track-label=&quot;recommended article&quot;&gt;&lt;img class=&quot;recommended__image&quot; alt=&quot;&quot; src=&quot;https://media.nature.com/w400/magazine-assets/d41586-020-03119-1/d41586-020-03119-1_18641080.jpg&quot;/&gt;&lt;/a&gt;

&lt;/aside&gt;&lt;p&gt;Retinal ganglion cells (RGCs) reside in the eyes and thus outside the skull, but they are bona fide brain neurons. They initially develop as part of the forebrain. Subsequently, RGCs extend projections called axons out of the eye to make connections with neurons in the brain itself. These axons — which join together to form the optic nerve — survive and regenerate if they are damaged early in development, but not after they reach maturity&lt;sup&gt;&lt;a href=&quot;https://www.nature.com/articles/d41586-020-03119-1#ref-CR3&quot; data-track=&quot;click&quot; data-action=&quot;anchor-link&quot; data-track-label=&quot;go to reference&quot; data-track-category=&quot;references&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;sup&gt;,&lt;/sup&gt;&lt;sup&gt;&lt;a href=&quot;https://www.nature.com/articles/d41586-020-03119-1#ref-CR4&quot; data-track=&quot;click&quot; data-action=&quot;anchor-link&quot; data-track-label=&quot;go to reference&quot; data-track-category=&quot;references&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;. Evidence indicates&lt;sup&gt;&lt;a href=&quot;https://www.nature.com/articles/d41586-020-03119-1#ref-CR3&quot; data-track=&quot;click&quot; data-action=&quot;anchor-link&quot; data-track-label=&quot;go to reference&quot; data-track-category=&quot;references&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;sup&gt;,&lt;/sup&gt;&lt;sup&gt;&lt;a href=&quot;https://www.nature.com/articles/d41586-020-03119-1#ref-CR5&quot; data-track=&quot;click&quot; data-action=&quot;anchor-link&quot; data-track-label=&quot;go to reference&quot; data-track-category=&quot;references&quot;&gt;5&lt;/a&gt;&lt;/sup&gt; that this shift is intrinsic to RGCs, rather than reflecting changes in the surrounding cells.&lt;/p&gt;
&lt;p&gt;Myriad studies have searched for factors that can prevent or promote RGC survival and regeneration. A handful of such factors have been identified that can endow mature RGCs with some degree of survival and regenerative capacity — but not enough to fully maintain or restore vision after damage to the opticnerve&lt;sup&gt;&lt;a href=&quot;https://www.nature.com/articles/d41586-020-03119-1#ref-CR4&quot; data-track=&quot;click&quot; data-action=&quot;anchor-link&quot; data-track-label=&quot;go to reference&quot; data-track-category=&quot;references&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;Lu &lt;em&gt;et al.&lt;/em&gt; asked whether it is possible to revert RGCs to a younger ‘age’, and whether doing so would allow the cells to regenerate. They infected RGCs in mice with adeno-associated viruses. These harmless viruses had been genetically engineered to induce expression of three of the ‘Yamanaka factors’ — a group of four transcription factors (Oct4, Sox2, Klf4 and c-Myc) that can trigger mature cell types to adopt an immature state&lt;sup&gt;&lt;a href=&quot;https://www.nature.com/articles/d41586-020-03119-1#ref-CR6&quot; data-track=&quot;click&quot; data-action=&quot;anchor-link&quot; data-track-label=&quot;go to reference&quot; data-track-category=&quot;references&quot;&gt;6&lt;/a&gt;&lt;/sup&gt;. Such an approach normally comes with hazards &lt;em&gt;in vivo&lt;/em&gt;: Yamanaka factors can cause cells to adopt unwanted new identities and characteristics, leading to tumours or death&lt;sup&gt;&lt;a href=&quot;https://www.nature.com/articles/d41586-020-03119-1#ref-CR7&quot; data-track=&quot;click&quot; data-action=&quot;anchor-link&quot; data-track-label=&quot;go to reference&quot; data-track-category=&quot;references&quot;&gt;7&lt;/a&gt;&lt;/sup&gt;. Fortunately, Lu and co-workers found that they could circumvent these hazards by expressing just Oct4, Sox2 and Klf4 (together called OSK).&lt;/p&gt;
&lt;p&gt;The authors tested the infected RGCs’ ability to regenerate if the cells’ axons were crushed. They found that the OSK-expressing viruses triggered RGC regeneration and long-distance axon extension following damage to the optic nerve (Fig. 1), with no apparent alterations to RGC identity, formation of retinal tumours or any other ill effects.&lt;/p&gt;
&lt;div class=&quot;embed intensity--high&quot;&gt;&lt;img class=&quot;figure__image&quot; alt=&quot;Figure 1&quot; data-src=&quot;//media.nature.com/lw800/magazine-assets/d41586-020-03119-1/d41586-020-03119-1_18634230.png&quot;/&gt;&lt;noscript&gt;
&lt;p&gt;&lt;img class=&quot;&quot; alt=&quot;Figure 1&quot; src=&quot;https://media.nature.com/lw800/magazine-assets/d41586-020-03119-1/d41586-020-03119-1_18634230.png&quot;/&gt;&lt;/p&gt;
&lt;/noscript&gt;
&lt;p class=&quot;figure__caption sans-serif&quot;&gt;&lt;span class=&quot;mr10&quot;&gt;&lt;strong&gt;Figure 1 | Restoring vision in mice.&lt;/strong&gt; Retinal ganglion cells (RGCs) transmit visual information from the eye to the brain along projections called axons. Damage to the RGC axons prevents transmission of this information, leading to sight loss. Lu &lt;em&gt;et al.&lt;/em&gt;&lt;sup&gt;&lt;a href=&quot;https://www.nature.com/articles/d41586-020-03119-1#ref-CR2&quot; data-track=&quot;click&quot; data-action=&quot;anchor-link&quot; data-track-label=&quot;go to reference&quot; data-track-category=&quot;references&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; report that treatment of damaged RGCs with a transcription-factor cocktail called OSK restores the cells to a youthful state, leading to axon regeneration and restoration of sight in mice.&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;OSK expression had beneficial effects on RGC axon regeneration in both young and aged mice. In some cases, the regenerated axons extended all the way from the eye to the optic chiasm (the location at the base of the brain at which the optic nerves from each eye cross to the opposite brain hemisphere). It is notable that the effects of OSK are seen in older animals, because studies of RGC regeneration are often conducted in relatively young animals, which have a residual natural regenerative ability. Thus, the evidence suggests that Lu and colleagues’ approach can fully restore long-distance regenerative capacity in mature RGCs — a milestone for the field.&lt;/p&gt;
&lt;p&gt;Almost all techniques previously used to enhance RGC survival and axon regrowth had to be performed before optic-nerve damage&lt;sup&gt;&lt;a href=&quot;https://www.nature.com/articles/d41586-020-03119-1#ref-CR4&quot; data-track=&quot;click&quot; data-action=&quot;anchor-link&quot; data-track-label=&quot;go to reference&quot; data-track-category=&quot;references&quot;&gt;4&lt;/a&gt;&lt;/sup&gt; — a restriction incompatible with using a technique therapeutically. Excitingly, Lu and colleagues showed that they could induce OSK expression at different time points — even after axon injury — and still improve RGC survival and regeneration. These effects were not limited to optic-nerve injury; OSK expression also effectively reversed RGC and vision loss in a mouse model of glaucoma (the most common cause of human blindness). Expression of OSK in RGCs after axon and vision loss (but before the RGCs died) fully restored vision in these animals. The same was true for wild-type old mice: OSK allowed old mice to regain youthful eyesight.&lt;/p&gt;
&lt;aside class=&quot;recommended pull pull--left sans-serif&quot; data-label=&quot;Related&quot;&gt;&lt;a href=&quot;https://www.nature.com/articles/nature22493&quot; data-track=&quot;click&quot; data-track-label=&quot;recommended article&quot;&gt;&lt;img class=&quot;recommended__image&quot; alt=&quot;&quot; src=&quot;https://media.nature.com/w400/magazine-assets/d41586-020-03119-1/d41586-020-03119-1_15297290.jpg&quot;/&gt;&lt;/a&gt;

&lt;/aside&gt;&lt;p&gt;Why might reprogramming old RGCs to a younger state promote regeneration and restore vision? An emerging model in the field of ageing is that, over time, cells accumulate epigenetic noise — molecular changes that alter patterns of gene expression&lt;sup&gt;&lt;a href=&quot;https://www.nature.com/articles/d41586-020-03119-1#ref-CR8&quot; data-track=&quot;click&quot; data-action=&quot;anchor-link&quot; data-track-label=&quot;go to reference&quot; data-track-category=&quot;references&quot;&gt;8&lt;/a&gt;&lt;/sup&gt;, including transcriptional changes and shifts in the patterns of methyl groups on DNA. Collectively, these changes cause cells to lose their identity and so to lose the DNA-, RNA- and protein-expression patterns that once promoted their youthful resilience&lt;sup&gt;&lt;a href=&quot;https://www.nature.com/articles/d41586-020-03119-1#ref-CR9&quot; data-track=&quot;click&quot; data-action=&quot;anchor-link&quot; data-track-label=&quot;go to reference&quot; data-track-category=&quot;references&quot;&gt;9&lt;/a&gt;&lt;/sup&gt;&lt;sup&gt;,&lt;/sup&gt;&lt;sup&gt;&lt;a href=&quot;https://www.nature.com/articles/d41586-020-03119-1#ref-CR10&quot; data-track=&quot;click&quot; data-action=&quot;anchor-link&quot; data-track-label=&quot;go to reference&quot; data-track-category=&quot;references&quot;&gt;10&lt;/a&gt;&lt;/sup&gt;. Given the growing excitement about DNA methylation as a marker of cell age, the authors asked whether OSK expression somehow counteracts the negative effects of ageing or axon injury on DNA methylation.&lt;/p&gt;
&lt;p&gt;The RNA components of a cell’s protein-synthesizing machine, called the ribosome, are encoded by ribosomal DNA genes that steadily accrue methyl marks with age. The ribosomal ‘DNA methylation clock’ is therefore considered to be a reliable estimate of cell age&lt;sup&gt;&lt;a href=&quot;https://www.nature.com/articles/d41586-020-03119-1#ref-CR11&quot; data-track=&quot;click&quot; data-action=&quot;anchor-link&quot; data-track-label=&quot;go to reference&quot; data-track-category=&quot;references&quot;&gt;11&lt;/a&gt;&lt;/sup&gt;. Lu &lt;em&gt;et al.&lt;/em&gt; found that damaging the axons of RGCs accelerated ribosomal DNA methylation in a way that mimicked accelerated cellular ageing, whereas OSK expression counteracted that acceleration, indicating that tissue injury in general might be a form of accelerated ageing.&lt;/p&gt;
&lt;aside class=&quot;recommended pull pull--left sans-serif&quot; data-label=&quot;Related&quot;&gt;&lt;a href=&quot;https://www.nature.com/articles/nature17305&quot; data-track=&quot;click&quot; data-track-label=&quot;recommended article&quot;&gt;&lt;img class=&quot;recommended__image&quot; alt=&quot;&quot; src=&quot;https://media.nature.com/w400/magazine-assets/d41586-020-03119-1/d41586-020-03119-1_18641082.jpg&quot;/&gt;&lt;/a&gt;

&lt;/aside&gt;&lt;p&gt;The group also tested whether the removal of DNA methylation is required for OSK to regenerate axons or restore vision in old mice. The TET enzymes (TET1, TET2 and TET3) catalyse the removal of DNA methylation&lt;sup&gt;&lt;a href=&quot;https://www.nature.com/articles/d41586-020-03119-1#ref-CR12&quot; data-track=&quot;click&quot; data-action=&quot;anchor-link&quot; data-track-label=&quot;go to reference&quot; data-track-category=&quot;references&quot;&gt;12&lt;/a&gt;&lt;/sup&gt;. The authors showed that OSK induced expression of &lt;em&gt;TET1&lt;/em&gt; and &lt;em&gt;TET2&lt;/em&gt; genes, and that reducing TET1 and TET2 production blocked the effects of OSK on RGC regeneration and vision restoration in old mice. Thus, changes in DNA methylation seem essential for the effects of OSK. Indeed, Lu &lt;em&gt;et al.&lt;/em&gt; found that OSK restored youthful DNA-methylation patterns across a broad set of genes involved in neuron survival, outgrowth and connectivity. These patterns occur at chromosomal regions that have high levels of PRC2 — a protein complex that alters methylation during development and ageing&lt;sup&gt;&lt;a href=&quot;https://www.nature.com/articles/d41586-020-03119-1#ref-CR13&quot; data-track=&quot;click&quot; data-action=&quot;anchor-link&quot; data-track-label=&quot;go to reference&quot; data-track-category=&quot;references&quot;&gt;13&lt;/a&gt;&lt;/sup&gt;. Going forward, it will be important to determine the exact extent to which the positive effects of OSK are mediated by resetting DNA-methylation patterns, and the downstream mechanisms that guide the cellular reset.&lt;/p&gt;
&lt;p&gt;Are Lu and colleagues’ findings likely to be relevant to humans? The authors found that OSK expression enhanced axon regrowth and cell survival in human neurons &lt;em&gt;in vitro&lt;/em&gt;. The effects of OSK in people remain to be tested, but the existing results suggest that OSK is likely to reprogram brain neurons across species.&lt;/p&gt;
&lt;p&gt;Future research should also address whether OSK expression can have the same remarkable effects on neurons elsewhere in the brain and spinal cord. Given that RGCs are bona fide brain neurons, there is good reason to think they will. As such, the current findings are bound to ignite great excitement, not only in the field of vision restoration but also in those looking to understand epigenetic reprogramming of neurons and other cell types generally. For decades, it was argued that understanding normal neural developmental processes would one day lead to the tools to repair the aged or damaged brain. Lu and colleagues’ work makes it clear: that era has now arrived.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;span class=&quot;emphasis&quot;&gt;Nature&lt;/span&gt; &lt;span&gt;&lt;strong&gt;588&lt;/strong&gt;, 34-36 (2020)&lt;/span&gt;&lt;/p&gt;


&lt;div id=&quot;references&quot; class=&quot;references&quot; data-toggle=&quot;anchor-links-section&quot; data-label=&quot;References&quot; data-concertina=&quot;true&quot;&gt;
&lt;section aria-labelledby=&quot;Bib1&quot;&gt;&lt;div class=&quot;serif article-section js-article-section cleared clear&quot; id=&quot;Bib1-section&quot;&gt;
&lt;h2 class=&quot;js-section-title section-title strong position-relative tighten-line-height background-gray-light pt20 pb6 pl0 pr20 standard-space-below small-space-above mq640-pt10 mq640-pb10 mq640-pl20 mq640-mt0 mq640-ml-20 mq640-mr-20 extend-left&quot; id=&quot;Bib1&quot;&gt;References&lt;/h2&gt;
&lt;div class=&quot;pl20 mq875-pl0 js-collapsible-section&quot; id=&quot;Bib1-content&quot;&gt;
&lt;div data-container-section=&quot;references&quot;&gt;
&lt;ol class=&quot;clean-list ma0 standard-space-below indented-list&quot; data-test=&quot;references-list&quot;&gt;&lt;li class=&quot;small-space-below border-gray-medium border-bottom-1 position-relative js-ref-item&quot; itemprop=&quot;citation&quot; itemscope=&quot;itemscope&quot; itemtype=&quot;http://schema.org/Article&quot; data-test=&quot;citation&quot;&gt;&lt;span class=&quot;indented-counter serif h2 tighten-line-height text-right position-absolute grade-c-hide&quot;&gt;1.&lt;/span&gt;
&lt;p class=&quot;tiny-space-below&quot; id=&quot;ref-CR1&quot;&gt;D.-B., D. &lt;em&gt;Nature&lt;/em&gt; &lt;strong&gt;125&lt;/strong&gt;, 230–231 (1930).&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;small-space-below border-gray-medium border-bottom-1 position-relative js-ref-item&quot; itemprop=&quot;citation&quot; itemscope=&quot;itemscope&quot; itemtype=&quot;http://schema.org/Article&quot; data-test=&quot;citation&quot;&gt;&lt;span class=&quot;indented-counter serif h2 tighten-line-height text-right position-absolute grade-c-hide&quot;&gt;2.&lt;/span&gt;
&lt;p class=&quot;tiny-space-below&quot; id=&quot;ref-CR2&quot;&gt;Lu, Y. &lt;em&gt;et al.&lt;/em&gt; &lt;em&gt;Nature&lt;/em&gt; &lt;strong&gt;588&lt;/strong&gt;, 124–129 (2020).&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;small-space-below border-gray-medium border-bottom-1 position-relative js-ref-item&quot; itemprop=&quot;citation&quot; itemscope=&quot;itemscope&quot; itemtype=&quot;http://schema.org/Article&quot; data-test=&quot;citation&quot;&gt;&lt;span class=&quot;indented-counter serif h2 tighten-line-height text-right position-absolute grade-c-hide&quot;&gt;3.&lt;/span&gt;
&lt;p class=&quot;tiny-space-below&quot; id=&quot;ref-CR3&quot;&gt;Goldberg, J. L., Klassen, M. P., Hua, Y. &amp;amp; Barres, B. A. &lt;em&gt;Science&lt;/em&gt; &lt;strong&gt;296&lt;/strong&gt;, 1860–1864 (2002).&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;small-space-below border-gray-medium border-bottom-1 position-relative js-ref-item&quot; itemprop=&quot;citation&quot; itemscope=&quot;itemscope&quot; itemtype=&quot;http://schema.org/Article&quot; data-test=&quot;citation&quot;&gt;&lt;span class=&quot;indented-counter serif h2 tighten-line-height text-right position-absolute grade-c-hide&quot;&gt;4.&lt;/span&gt;
&lt;p class=&quot;tiny-space-below&quot; id=&quot;ref-CR4&quot;&gt;Laha, B., Stafford, B. K. &amp;amp; Huberman, A. &lt;em&gt;D. Science&lt;/em&gt; &lt;strong&gt;356&lt;/strong&gt;, 1031–1034 (2017).&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;small-space-below border-gray-medium border-bottom-1 position-relative js-ref-item&quot; itemprop=&quot;citation&quot; itemscope=&quot;itemscope&quot; itemtype=&quot;http://schema.org/Article&quot; data-test=&quot;citation&quot;&gt;&lt;span class=&quot;indented-counter serif h2 tighten-line-height text-right position-absolute grade-c-hide&quot;&gt;5.&lt;/span&gt;
&lt;p class=&quot;tiny-space-below&quot; id=&quot;ref-CR5&quot;&gt;Horsburgh, G. M., Lund, R. D. &amp;amp; Hankin, M. H. &lt;em&gt;J. Comp. Neurol.&lt;/em&gt; &lt;strong&gt;327&lt;/strong&gt;, 323–340 (1993).&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;small-space-below border-gray-medium border-bottom-1 position-relative js-ref-item&quot; itemprop=&quot;citation&quot; itemscope=&quot;itemscope&quot; itemtype=&quot;http://schema.org/Article&quot; data-test=&quot;citation&quot;&gt;&lt;span class=&quot;indented-counter serif h2 tighten-line-height text-right position-absolute grade-c-hide&quot;&gt;6.&lt;/span&gt;
&lt;p class=&quot;tiny-space-below&quot; id=&quot;ref-CR6&quot;&gt;Takahashi, K. &amp;amp; Yamanaka, S. &lt;em&gt;Cell&lt;/em&gt; &lt;strong&gt;126&lt;/strong&gt;, 663–676 (2006).&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;small-space-below border-gray-medium border-bottom-1 position-relative js-ref-item&quot; itemprop=&quot;citation&quot; itemscope=&quot;itemscope&quot; itemtype=&quot;http://schema.org/Article&quot; data-test=&quot;citation&quot;&gt;&lt;span class=&quot;indented-counter serif h2 tighten-line-height text-right position-absolute grade-c-hide&quot;&gt;7.&lt;/span&gt;
&lt;p class=&quot;tiny-space-below&quot; id=&quot;ref-CR7&quot;&gt;Abad, M. &lt;em&gt;et al.&lt;/em&gt; &lt;em&gt;Nature&lt;/em&gt; &lt;strong&gt;502&lt;/strong&gt;, 340–345 (2013).&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;small-space-below border-gray-medium border-bottom-1 position-relative js-ref-item&quot; itemprop=&quot;citation&quot; itemscope=&quot;itemscope&quot; itemtype=&quot;http://schema.org/Article&quot; data-test=&quot;citation&quot;&gt;&lt;span class=&quot;indented-counter serif h2 tighten-line-height text-right position-absolute grade-c-hide&quot;&gt;8.&lt;/span&gt;
&lt;p class=&quot;tiny-space-below&quot; id=&quot;ref-CR8&quot;&gt;Oberdoerffer, P. &lt;em&gt;et al.&lt;/em&gt; &lt;em&gt;Cell&lt;/em&gt; &lt;strong&gt;135&lt;/strong&gt;, 907–918 (2008)&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;small-space-below border-gray-medium border-bottom-1 position-relative js-ref-item&quot; itemprop=&quot;citation&quot; itemscope=&quot;itemscope&quot; itemtype=&quot;http://schema.org/Article&quot; data-test=&quot;citation&quot;&gt;&lt;span class=&quot;indented-counter serif h2 tighten-line-height text-right position-absolute grade-c-hide&quot;&gt;9.&lt;/span&gt;
&lt;p class=&quot;tiny-space-below&quot; id=&quot;ref-CR9&quot;&gt;López-Otín, C., Blasco, M. A., Partridge, L., Serrano, M. &amp;amp; Kroemer, G. &lt;em&gt;Cell&lt;/em&gt; &lt;strong&gt;153&lt;/strong&gt;, 1194–1217 (2013).&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;small-space-below border-gray-medium border-bottom-1 position-relative js-ref-item&quot; itemprop=&quot;citation&quot; itemscope=&quot;itemscope&quot; itemtype=&quot;http://schema.org/Article&quot; data-test=&quot;citation&quot;&gt;&lt;span class=&quot;indented-counter serif h2 tighten-line-height text-right position-absolute grade-c-hide&quot;&gt;10.&lt;/span&gt;
&lt;p class=&quot;tiny-space-below&quot; id=&quot;ref-CR10&quot;&gt;Horvath, S. &lt;em&gt;Genome Biol.&lt;/em&gt; &lt;strong&gt;14&lt;/strong&gt;, 3156 (2013).&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;small-space-below border-gray-medium border-bottom-1 position-relative js-ref-item&quot; itemprop=&quot;citation&quot; itemscope=&quot;itemscope&quot; itemtype=&quot;http://schema.org/Article&quot; data-test=&quot;citation&quot;&gt;&lt;span class=&quot;indented-counter serif h2 tighten-line-height text-right position-absolute grade-c-hide&quot;&gt;11.&lt;/span&gt;
&lt;p class=&quot;tiny-space-below&quot; id=&quot;ref-CR11&quot;&gt;Wang, M. &amp;amp; Lemos, B. &lt;em&gt;Genome Res.&lt;/em&gt; &lt;strong&gt;29&lt;/strong&gt;, 325–333 (2019).&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;small-space-below border-gray-medium border-bottom-1 position-relative js-ref-item&quot; itemprop=&quot;citation&quot; itemscope=&quot;itemscope&quot; itemtype=&quot;http://schema.org/Article&quot; data-test=&quot;citation&quot;&gt;&lt;span class=&quot;indented-counter serif h2 tighten-line-height text-right position-absolute grade-c-hide&quot;&gt;12.&lt;/span&gt;
&lt;p class=&quot;tiny-space-below&quot; id=&quot;ref-CR12&quot;&gt;Rasmussen, K. D. &amp;amp; Helin, K. &lt;em&gt;Genes Dev.&lt;/em&gt; &lt;strong&gt;30&lt;/strong&gt;, 733–750 (2016).&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;small-space-below border-gray-medium border-bottom-1 position-relative js-ref-item&quot; itemprop=&quot;citation&quot; itemscope=&quot;itemscope&quot; itemtype=&quot;http://schema.org/Article&quot; data-test=&quot;citation&quot;&gt;&lt;span class=&quot;indented-counter serif h2 tighten-line-height text-right position-absolute grade-c-hide&quot;&gt;13.&lt;/span&gt;
&lt;p class=&quot;tiny-space-below&quot; id=&quot;ref-CR13&quot;&gt;Laugesen, A., Højfeld, J. W. &amp;amp; Helin, K. &lt;em&gt;Mol. Cell&lt;/em&gt; &lt;strong&gt;74&lt;/strong&gt;, 8–18 (2019).&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;p class=&quot;hide-print text-right&quot;&gt;&lt;a href=&quot;https://www.nature.com/articles/d41586-020-03119-1-references.ris&quot; class=&quot;text14 sans-serif strong&quot; data-track=&quot;click&quot; data-track-action=&quot;download citation references&quot; data-track-label=&quot;link&quot;&gt;Download references&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/section&gt;&lt;/div&gt;
&lt;aside class=&quot;c-latest-content mt40 hide-print&quot; data-simple-tab=&quot;&quot; data-tab-group=&quot;&quot; data-component-id=&quot;latest-news&quot; data-track=&quot;in-view&quot; data-track-action=&quot;in-view&quot; data-track-category=&quot;latest content&quot; data-track-label=&quot;visible&quot;&gt;&lt;div id=&quot;latest-content&quot; role=&quot;tablist&quot;&gt;
&lt;p class=&quot;strong&quot;&gt;Latest on:&lt;/p&gt;
&lt;div class=&quot;cleared&quot;&gt;

&lt;div id=&quot;latest-content-1&quot; class=&quot;c-latest-content__container&quot; data-container=&quot;&quot;&gt;
&lt;p id=&quot;latest-content-1-head&quot; class=&quot;c-latest-content__category c-latest-content__switch&quot; data-switch=&quot;&quot; role=&quot;tab&quot; aria-controls=&quot;latest-content-1-content&quot; data-track=&quot;click&quot; data-track-label=&quot;latest tag (rank:1)&quot;&gt;Regeneration&lt;/p&gt;

&lt;/div&gt;
&lt;div id=&quot;latest-content-2&quot; class=&quot;c-latest-content__container&quot; data-container=&quot;&quot;&gt;
&lt;p id=&quot;latest-content-2-head&quot; class=&quot;c-latest-content__category c-latest-content__switch&quot; data-switch=&quot;&quot; role=&quot;tab&quot; aria-controls=&quot;latest-content-2-content&quot; data-track=&quot;click&quot; data-track-label=&quot;latest tag (rank:2)&quot;&gt;Neuroscience&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/aside&gt;&lt;div class=&quot;js-jobs-career-wrapper&quot;&gt;
&lt;section class=&quot;section__jobs-career u-highlighted-section--light cleared&quot; data-track=&quot;in-view&quot; data-track-action=&quot;in-view&quot; data-track-category=&quot;career&quot; data-track-label=&quot;visible&quot;&gt;&lt;div class=&quot;u-container c-component&quot;&gt;
&lt;h3 class=&quot;u-serif c-component__title&quot;&gt;&lt;a data-track=&quot;click&quot; data-track-action=&quot;section-link&quot; data-track-category=&quot;career&quot; data-track-label=&quot;jobs list title&quot; href=&quot;https://www.nature.com/naturecareers/&quot; class=&quot;js-job-title-link&quot;&gt;Jobs from Nature Careers&lt;/a&gt;&lt;/h3&gt;
&lt;ul class=&quot;u-flex u-flex--wrap u-clean-list mb0&quot;&gt;&lt;li class=&quot;u-flex u-col u-col--lg-4-4 u-flex--wrap&quot;&gt;
&lt;ul class=&quot;u-flex u-flex--wrap u-clean-list mb0&quot;&gt;&lt;li class=&quot;u-flex u-col&quot;&gt;
&lt;/li&gt;
&lt;li class=&quot;u-flex u-col pa10&quot;&gt;
&lt;ul class=&quot;u-flex u-flex--wrap mb0 u-clean-list c-card__article-list--career&quot;&gt;&lt;li class=&quot;u-flex u-col&quot;&gt;
&lt;div class=&quot;c-card c-card--regular c-card--career u-flex&quot;&gt;
&lt;div class=&quot;c-card__container u-flex u-flex-align-items--flex-start&quot;&gt;
&lt;div class=&quot;c-card__copy u-flex__content u-col&quot;&gt;
&lt;h3 class=&quot;c-card__title c-card__title--career u-serif u-text17 u-font-weight--regular&quot;&gt;Assistant Professor in Condensed Matter Physics&lt;/h3&gt;
&lt;p class=&quot;mb10&quot;&gt;The University of British Columbia (UBC)&lt;/p&gt;
&lt;p&gt;Vancouver, Canada&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li class=&quot;u-flex u-col&quot;&gt;
&lt;div class=&quot;c-card c-card--regular c-card--career u-flex&quot;&gt;
&lt;div class=&quot;c-card__container u-flex u-flex-align-items--flex-start&quot;&gt;
&lt;div class=&quot;c-card__copy u-flex__content u-col&quot;&gt;
&lt;h3 class=&quot;c-card__title c-card__title--career u-serif u-text17 u-font-weight--regular&quot;&gt;PhD position (m/f/x) in glacial modeling&lt;/h3&gt;
&lt;p class=&quot;mb10&quot;&gt;Helmholtz Centre Potsdam - German Research Centre for Geosciences (GFZ)&lt;/p&gt;
&lt;p&gt;Potsdam, Germany&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li class=&quot;u-flex u-col&quot;&gt;
&lt;div class=&quot;c-card c-card--regular c-card--career u-flex&quot;&gt;
&lt;div class=&quot;c-card__container u-flex u-flex-align-items--flex-start&quot;&gt;
&lt;div class=&quot;c-card__copy u-flex__content u-col&quot;&gt;
&lt;h3 class=&quot;c-card__title c-card__title--career u-serif u-text17 u-font-weight--regular&quot;&gt;52638: Student Mathematics, Computer Science, Engineering or similar - Application and extension of a method for data-driven turbulence modeling&lt;/h3&gt;
&lt;p class=&quot;mb10&quot;&gt;German Aerospace Center (DLR)&lt;/p&gt;
&lt;p&gt;Göttingen, Germany&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li class=&quot;u-flex u-col&quot;&gt;
&lt;div class=&quot;c-card c-card--regular c-card--career u-flex&quot;&gt;
&lt;div class=&quot;c-card__container u-flex u-flex-align-items--flex-start&quot;&gt;
&lt;div class=&quot;c-card__copy u-flex__content u-col&quot;&gt;
&lt;h3 class=&quot;c-card__title c-card__title--career u-serif u-text17 u-font-weight--regular&quot;&gt;Schichtleiterin/Schichtleiter BER II / Nachbetrieb (w/m/d)&lt;/h3&gt;
&lt;p class=&quot;mb10&quot;&gt;Helmholtz-Zentrum Berlin for Materials and Energy (HZB)&lt;/p&gt;
&lt;p&gt;Berlin, Germany&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;
&lt;/section&gt;&lt;/div&gt;
&lt;div class=&quot;nature-briefing nature-briefing-box mt0 cleared hide-print&quot; data-component-id=&quot;nature-briefing-box&quot; data-track=&quot;in-view&quot; data-track-action=&quot;in-view&quot; data-track-category=&quot;nature briefing&quot; data-track-label=&quot;inPage box visible&quot;&gt;
&lt;div class=&quot;nature-briefing-box__header pa20&quot;&gt;

&lt;p class=&quot;nature-briefing-box__standfirst mb0 sans-serif tighten-line-height&quot;&gt;An essential round-up of science news, opinion and analysis, delivered to your inbox every weekday.&lt;/p&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;aside class=&quot;article__aside align-right&quot;&gt;&lt;div class=&quot;related-content shrink--aside hide-print&quot;&gt;
&lt;h3 class=&quot;aside__title sans-serif&quot;&gt;Related Articles&lt;/h3&gt;
&lt;/div&gt;

&lt;div id=&quot;div-gpt-ad-right-2&quot; class=&quot;div-gpt-ad medium-rectangle advert js-ad text-center hide-print grade-c-hide&quot; data-gpt-unitpath=&quot;/285/nature.com/article&quot; data-gpt-sizes=&quot;300x250&quot; data-gpt-targeting=&quot;pos=right;artid=/articles/d41586-020-03119-1;path=/articles/d41586-020-03119-1&quot; data-ad-type=&quot;right&quot;&gt;&lt;noscript&gt;
&lt;p&gt;&lt;a href=&quot;https://pubads.g.doubleclick.net/gampad/jump?iu=/285/nature.com/article&amp;amp;sz=300x250&amp;amp;c=-422348040&amp;amp;t=pos%3Dright%26artid%3D/articles/d41586-020-03119-1&quot;&gt;&lt;img data-test=&quot;gpt-advert-fallback-img&quot; src=&quot;https://pubads.g.doubleclick.net/gampad/ad?iu=/285/nature.com/article&amp;amp;sz=300x250&amp;amp;c=-422348040&amp;amp;t=pos%3Dright%26artid%3D/articles/d41586-020-03119-1&quot; alt=&quot;Advertisement&quot; width=&quot;300&quot; height=&quot;250&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/noscript&gt;&lt;/div&gt;

&lt;/aside&gt;&lt;/div&gt;
</description>
<pubDate>Fri, 04 Dec 2020 20:46:39 +0000</pubDate>
<dc:creator>evo_9</dc:creator>
<og:url>https://www.nature.com/articles/d41586-020-03119-1</og:url>
<og:type>article</og:type>
<og:title>Sight restored by turning back the epigenetic clock</og:title>
<og:description>Resetting the methylation clock rejuvenates old retinal ganglion cells.</og:description>
<og:image>https://media.nature.com/lw1024/magazine-assets/d41586-020-03119-1/d41586-020-03119-1_18634232.png</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.nature.com/articles/d41586-020-03119-1</dc:identifier>
</item>
<item>
<title>About Google&amp;#039;s approach to research publication – Jeff Dean</title>
<link>https://docs.google.com/document/d/1f2kYWDXwhzYnq8ebVtuk9CqQqz7ScqxhSIxeYGrWjK0/preview?pru=AAABdlNwLxs*PKCOHN-Ks0PI5nFrljenMg</link>
<guid isPermaLink="true" >https://docs.google.com/document/d/1f2kYWDXwhzYnq8ebVtuk9CqQqz7ScqxhSIxeYGrWjK0/preview?pru=AAABdlNwLxs*PKCOHN-Ks0PI5nFrljenMg</guid>
<description>&lt;p&gt;&lt;span&gt;I understand the concern over Timnit Gebru’s resignation from Google.  She’s done a great deal to move the field forward with her research.  I wanted to share the email I sent to Google Research and some thoughts on our research process.&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;Here’s the email I sent to the Google Research team on Dec. 3, 2020:&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;Hi everyone,&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;I’m sure many of you have seen that Timnit Gebru is no longer working at Google. This is a difficult moment, especially given the important research topics she was involved in, and how deeply we care about responsible AI research as an org and as a company.&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;Because there’s been a lot of speculation and misunderstanding on social media, I wanted to share more context about how this came to pass, and assure you we’re here to support you as you continue the research you’re all engaged in.&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;Timnit co-authored a paper with four fellow Googlers as well as some external collaborators that needed to go through our review process (as is the case with all externally submitted papers).  We’ve approved dozens of papers that Timnit and/or the other Googlers have authored and then published, but as you know, papers often require changes during the internal review process (or are even deemed unsuitable for submission).  Unfortunately, this particular paper was only shared with a day’s notice before its deadline — we require two weeks for this sort of review — and then instead of awaiting reviewer feedback, it was approved for submission and submitted.&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;A cross functional team then reviewed the paper as part of our regular process and the authors were informed that it didn’t meet our bar for publication and were given feedback about why.  It ignored too much relevant research — for example, it talked about the environmental impact of large models, but disregarded subsequent research showing much greater efficiencies.  Similarly, it raised concerns about bias in language models, but didn’t take into account recent research to mitigate these issues.  We acknowledge that the authors were extremely disappointed with the decision that Megan and I ultimately made, especially as they’d already submitted the paper.&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;Timnit responded with an email requiring that a number of conditions be met in order for her to continue working at Google, including revealing the identities of every person who Megan and I had spoken to and consulted as part of the review of the paper and the exact feedback.  Timnit wrote that if we didn’t meet these demands, she would leave Google and work on an end date.  We accept and respect her decision to resign from Google.&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;Given Timnit's role as a respected researcher and a manager in our Ethical AI team, I feel badly that Timnit has gotten to a place where she feels this way about the work we’re doing.  I also feel badly that hundreds of you received an email just this week from Timnit telling you to stop work on critical DEI programs.  &lt;/span&gt;&lt;span&gt;Please don’t.&lt;/span&gt;&lt;span&gt;  I understand the frustration about the pace of progress, but we have important work ahead and we need to keep at it.&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;I know we all genuinely share Timnit’s passion to make AI more equitable and inclusive.  No doubt, wherever she goes after Google, she’ll do great work and I look forward to reading her papers and seeing what she accomplishes.&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;Thank you for reading and for all the important work you continue to do.&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;-Jeff&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;span&gt;I’ve also received questions about our research and review process, so I wanted to share more here.  I'm going to be talking with our research teams, especially those on the Ethical AI team and our many other teams focused on responsible AI, so they know that we strongly support these important streams of research.  And to be clear, we are deeply committed to continuing our research on topics that are of particular importance to individual and intellectual diversity  -- from unfair social and technical bias in ML models, to the paucity of representative training data, to involving social context in AI systems.  That work is critical and I want our research programs to deliver more work on these topics -- not less.&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;In my email above, I detailed some of what happened with this particular paper.  But let me give a better sense of the overall research review process.  It’s more than just a single approver or immediate research peers; it’s a process where we engage a wide range of researchers, social scientists, ethicists, policy &amp;amp; privacy advisors, and human rights specialists from across Research and Google overall.  These reviewers ensure that, for example, the research we publish paints a full enough picture and takes into account the latest relevant research we’re aware of, and of course that it adheres to our&lt;/span&gt; &lt;span&gt;&lt;a href=&quot;https://www.google.com/url?q=https://ai.google/principles&amp;amp;sa=D&amp;amp;ust=1607220088722000&amp;amp;usg=AOvVaw3W8jRUj44UhHR4Y5Tj18FT&quot;&gt;AI Principles&lt;/a&gt;&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;Those research review processes have helped improve many of our publications and research applications. While more than 1,000 projects each year turn into published papers, there are also many that don’t end up in a publication.  That’s okay, and we can still carry forward constructive parts of a project to inform future work.  There are many ways we share our research; e.g. publishing a paper, open-sourcing code or models or data or colabs, creating demos, working directly on products, etc.&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;This paper surveyed valid concerns with large language models, and in fact many teams at Google are actively working on these issues. We’re engaging the authors to ensure their input informs the work we’re doing, and I’m confident it will have a positive impact on many of our research and product efforts.&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;But the paper itself had some important gaps that prevented us from being comfortable putting Google affiliation on it.  For example, it didn’t include important findings on how models can be made more efficient and actually reduce overall environmental impact, and it didn’t take into account some recent work at Google and elsewhere on mitigating bias in language models.   Highlighting risks without pointing out methods for researchers and developers to understand and mitigate those risks misses the mark on helping with these problems.  As always, feedback on paper drafts generally makes them stronger when they ultimately appear.&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;We have a strong track record of publishing work that challenges the status quo -- for example, we’ve had more than 200 publications focused on responsible AI development in the last year alone.  Just a few examples of research we’re engaged in that tackles challenging issues:&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;I’m proud of the way Google Research provides the flexibility and resources to explore many avenues of research.  Sometimes those avenues run perpendicular to one another.  This is by design.  The exchange of diverse perspectives, even contradictory ones, is good for science and good for society.  It’s also good for Google.  That exchange has enabled us not only to tackle ambitious problems, but to do so responsibly.&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;Our aim is to rival peer-reviewed journals in terms of the rigor and thoughtfulness in how we review research before publication.  To give a sense of that rigor, this blog post captures some of the detail in one facet of review, which is when a research topic has broad societal implications and requires particular AI Principles review -- though it isn’t the full story of how we evaluate all of our research, it gives a sense of the detail involved:&lt;/span&gt; &lt;span&gt;&lt;a href=&quot;https://www.google.com/url?q=https://blog.google/technology/ai/update-work-ai-responsible-innovation/&amp;amp;sa=D&amp;amp;ust=1607220088725000&amp;amp;usg=AOvVaw2Hw9AIKxTUWH8dZmvWpEOG&quot;&gt;https://blog.google/technology/ai/update-work-ai-responsible-innovation/&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;We’re actively working on improving our paper review processes, because we know that too many checks and balances can become cumbersome.  We will always prioritize ensuring our research is responsible and high-quality, but we’re working to make the process as streamlined as we can so it’s more of a pleasure doing research here.&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;A final, important note -- we evaluate the substance of research separately from who’s doing it.  But to ensure our research reflects a fuller breadth of global experiences and perspectives in the first place, we’re also committed to making sure Google Research is a place where every Googler can do their best work.  We’re pushing hard on our efforts to improve representation and inclusiveness across Google Research, because we know this will lead to better research and a better experience for everyone here.&lt;/span&gt;&lt;/p&gt;

</description>
<pubDate>Fri, 04 Dec 2020 20:14:21 +0000</pubDate>
<dc:creator>yigitdemirag</dc:creator>
<og:title>About Google's approach to research publication</og:title>
<og:type>article</og:type>
<og:url>https://docs.google.com/document/d/1f2kYWDXwhzYnq8ebVtuk9CqQqz7ScqxhSIxeYGrWjK0/preview?_escaped_fragment_&amp;usp=embed_facebook</og:url>
<og:image>https://lh6.googleusercontent.com/R-hbj52xO6YRt_mtrh0prR0ndh0mJoxBb0as6J7RitDR8may6aBOxrkmFjNdDL0njtH5ni1y2w=w1200-h630-p</og:image>
<og:description>About Google's approach to research publication I understand the concern over Timnit Gebru’s resignation from Google. She’s done a great deal to move the field forward with her research. I wanted to share the email I sent to Google Research and some thoughts on our research process. Here’s th...</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://docs.google.com/document/d/1f2kYWDXwhzYnq8ebVtuk9CqQqz7ScqxhSIxeYGrWjK0/preview?_escaped_fragment_=</dc:identifier>
</item>
</channel>
</rss>