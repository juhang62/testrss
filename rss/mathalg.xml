<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed43.com%2Fmathalg-jtks.xml&amp;max=5&amp;links=preserve&amp;exc=1" />
<atom:link rel="alternate" title="Source URL" href="http://feed43.com/mathalg-jtks.xml" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fmathalg-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fmathalg-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1" />
<title>算法与数学之美</title>
<link>http://www.jintiankansha.me/column/c9dZ5TM2aS</link>
<description>算法与数学之美 - 今天看啥</description>
<ttl>360</ttl>
<item>
<title>LeCun台大演讲：AI最大缺陷是缺乏常识，无监督学习突破困境</title>
<link>http://www.jintiankansha.me/t/xVj6falqU3</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/xVj6falqU3</guid>
<description>&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;&lt;img class=&quot;__bg_gif&quot; data-ratio=&quot;0.0609375&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_gif/951TjTgiabkyYNr2mLLFgV8rAcf8TKrhVVxPz4sJSdjDum3ia43TqSj6sPicZVQ5XqpfDhulibnGRdeLqAhyHf8TWw/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;640&quot; /&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;LeCun表示，深度学习的特点在于“整个程序都是可训练的”，监督学习存在两大问题&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;span&gt;近日，在台湾大学，卷积神经网络之父、FacebookAI 研究院院长 Yann LeCun 以「Deep Learning and the Path to AI」为题，对深度学习目前的发展现状和面临的最大挑战、以及应对方法进行了综述和分析。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;6 月 29 日，台湾大学。卷积神经网络之父、FacebookAI 研究院院长 Yann LeCun 以「Deep Learning and the Path to AI」为题，对深度学习目前的发展现状和面临的最大挑战、以及应对方法进行了综述和分析。新智元结合台湾大学在 Facebook 上公布的视频、台湾科技媒体 iThome 的报道，以及 Yann LeCun 今年早些时候在爱丁堡大学的演讲资料，为您综合介绍。&lt;/span&gt;&lt;/p&gt;
&lt;h3&gt;&lt;span&gt; 深度学习的特点在于“整个程序都是可训练的” &lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;&lt;span&gt;演讲从模式识别（Pattern Recognition）的起源说起。1957年，Perceptron 诞生，成为第一个 LearningMachine。LeCun 说，目前的机器学习算法大多衍生自 Perceptron的概念。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;从那时起，模式识别的标准模型就可以分为 3 步走：1.程序被输入一张图像，通过特征提取，将图像特征转换为多个向量；2. 输入这些向量到可训练的分类器中；3.程序输出识别结果。 &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;他表示，机器学习算法其实就是误差校正（Error correction），通过调整权重，来进行特征提取。也就是说，如果输入一张图，算法识别后，结果值低于预期类别的值，工程师就将输入的图增加 Positive 的权重，减少 Negative 的权重，来校正误差。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.7328125&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/951TjTgiabkyibhvGLgaqX9NkLdhIcdPwRHDvlCfdeTsJFLGoJhUZUeWkd8qdBJ6Gdz4HDia30e6luu0VcvQwD55w/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;深度学习是当今最广泛使用的模式识别方法。LeCun 认为深度学习的特点在于“整个程序都是可训练的”。他解释，构建深度学习的模型不是用手动调整特征提取的参数来训练分类器，而是建立一群像小型瀑布般的可训练的模组。 &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.75&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/951TjTgiabkyibhvGLgaqX9NkLdhIcdPwRDKBtRwiavXZ8W1GGqprCkN4G5QzZNlS1uAbdP2GNyUSIGviaFsunSx7g/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;当开发人员将原始的影像输入系统后，会先经过初步的特征提取器，产生代表的数值，在这一个阶段可能会先识别出一些基本的纹理，接下来这些纹理的组合会再被拿来识别更具体的特征，像是物件的形体或是类别，整个训练的过程就是不断地经过一层又一层这样的模型，每一层都是可训练的，所以我们称这个算法为深度学习或是端到端训练（End to End Running）。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;LeCun 解释，深度学习模型之所以工作良好，是因为现在的影像都是自然景象加上其他物体，也就是混合型的图像，而每个物体又由不同的特征所组成，会有不同的轮廓和纹路，图片的像素也是一个问题，因此，可以将影像分级成像素、边缘、轮廓、元件和物件等，初级的特征提取会先侦测出影像中最基本的轮廓，比如明显的纹路和色块，进一步的特征提取则是将上一层的结果组合再一起，拼成一个形体，最后再拼成一个物体。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.74375&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/951TjTgiabkyibhvGLgaqX9NkLdhIcdPwRtnHktCNT9sJXeTvI42x2Ts0EvqD4NGSSnUv2J2t4VIxVjHpYDLws0g/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;这种分层式的组合架构（Hierarchical Compositionality）其实不只适用于影像，LeCun说明，它对文字、语音、动作或是任何自然的信号都适用，这种方式参考了人脑的运作模式。大脑中的视觉中枢，也是用类似分层式的组合架构来运行，当人类看到影像后，由视网膜进入到视丘后方外侧膝状体，再到大脑中主要的视觉中枢，最后来到颞叶皮质，人类看图像也是由大脑经过多层的结构，在100毫秒内就能识别图片。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.753125&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/951TjTgiabkyibhvGLgaqX9NkLdhIcdPwRibFtLAKx0bB6aiboAG4AsoYpvibz5H1AIe3wljPjs3ueF9Bf7k4opNic2A/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;深度学习的问题在于如何训练，在1980年代中期，误差反向传播算法（Back Propagation Algorithm）开始流行，但其实误差反向传播算法很早就被提出来，只是当时没有受到重视。误差反向传播算法一开始先经过简单线性分类，再将这些结果带到非线性的线性整流函数（Rectified Linear Unit，ReLU），线性整流函数就是找到要调整参数的方向，来减少错误判断，不过现在都已经有可用的套件或是框架，像是Torch、TensorFlow 或是 Theano等，还有一些套件是可用来计算输出结果和预期结果之间的误差。 &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Yann LeCun认为，现在要撰写机器学习算法并不难，用 3 行 Python 就可以完成，不过这还停留在监督式学习阶段，所谓的监督式学习就是输入大量的训练样本，每一套训练样本都已经经过人工标注出原始图片和对应的预期结果。以影像处理为例，训练集由多个(X,Y)参数组成，X就是影像的像素，Y则是预设的识别结果类别，像是车子、桌子等，之后再用大量的测试集来测试程序，若判断结果正确，不用调整，若判断有误则调整程序中的参数。&lt;/span&gt;&lt;/p&gt;
&lt;h3&gt;&lt;span&gt; 监督式机器学习存在二大问题 &lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;&lt;span&gt;因此，Yann LeCun表示，监督式的机器学习就是功能优化（Function Optimization），资料输入和输出的关系通过可调整的参数来优化，经由调整参数的方式，将结果的错误率降至最低，其中，调整参数的方式有很多种，很多人都会用梯度下降算法（Stochastic Gradient Descent），梯度下降算法可以找到最适合的回归模型系数．即时地根据输入的资料动态调整模型。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.7453125&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/951TjTgiabkyibhvGLgaqX9NkLdhIcdPwRBNGFFz4KcAUibsyYicezrZmIYEynxzEQwRa3TicGib6Ay7icCSYxIYHYD1g/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;身为「卷积神经网络之父」的 Yann LeCun 也介绍了卷积神经网络（Convolutional Neural Network，CNN），卷积网络就是将输入的影像像素矩阵经过一层过滤器，挑选出特征，再透过池化层（PoolingLayer），针对输入特征矩阵压缩，让特征矩阵变小，降低计算的复杂度。CNN影像和语音识别都有很好的成效，不仅如此，还能识别街上移动的路人、街景的物体，Facebook 也用 CNN 来识别 Facebook 用户上传的照片，他表示一天 Facebook 就有10亿以上的照片，可以准确地识别物体的类别，像是人还是狗、猫等，还能识别照片的主题，像是婚礼或是生日派对等。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.709375&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/951TjTgiabkyibhvGLgaqX9NkLdhIcdPwRGCRNuN8yflPIoFEghzYPZXYDStTqiahOX8YmzKSsIpOczzA2bTX8uPg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt;  不过，Yann LeCun提出，监督式的机器学习有2大问题，第一是要如何建立复杂的算法来解决复杂的问题，第二则是手动调整参数的知识和经验都是来自于不同任务，许多工程师想要处理的领域，像是影像识别、语音识别都需要建置不同模型，因此，监督式机器学习可以在训练过的专案上有很好的表现，但是没有训练过的资料，程序就无法辨别，简单来说，如果要程序识别椅子，不可能训练所有椅子的特征资料。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;事实上，Yann LeCun 表示现实中有种机器具备数百万的调整钮（Knob），这些调整钮就像机器学习中的参数和 Perceptron 的权重一样，可以用上百万的训练样本来训练模型，最后分类出上千种的类别，但是，每一个特征的识别都必须经过数十亿次的操作，因此，可想而知，现今大家所使用的神经网络是非常复杂的，如此庞大的运作不可能在一般的 CPU 上执行，“我们面对的是非常大规模的优化问题。”他说。&lt;/span&gt;&lt;/p&gt;
&lt;h3&gt;&lt;span&gt; AI系统的架构 &lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;&lt;span&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.7375&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/951TjTgiabkyibhvGLgaqX9NkLdhIcdPwROjuyBm1KMZGv0wtbAZIzr9OfUlW2um7Puck7QtHjnqflTw84NN2Z4Q/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;AI系统的架构大致上可以分为感知（Perception）、触发器（Agent）和目标（Objective）3个模组，先由感知器侦测真实世界的数据，像是影像、语音等，这些数据经由触发器，会依据状态触发目标，执行相对应的程序并产生结果，其中触发器就是AI 的精髓，触发器必须要负责规划、预测等智能工作，而目标则是由本能和固定的两个元件所组成，以视觉识别（VisualIdentity）系统为例，经由感知收集影像数据，透过触发器触发分析情绪的程序，再判断影片中的人是开心还是不开心。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.7484375&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/951TjTgiabkyibhvGLgaqX9NkLdhIcdPwRtIla4sn8AH6SLVDEePRR7kHR4HOS0ZgRJ16yFdWOKwJq8kdQaldARA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;AI 架构中的触发器（Agent）主要负责预测和规划，运作过程又可分为模拟器（Simulator）、执行器（Actor）、回馈器（Critic），模拟器接收到状态后，传送给执行器，执行器就会启动相对应的动作，并同时对模拟器提出要求，启动相对应的动作之后送到回馈器，经由回馈器分析要採取的动作，决定后才送往目标（Objective）执行。&lt;/span&gt;&lt;/p&gt;
&lt;h3&gt;&lt;span&gt; AI 最大局限是没有人类的“常识” &lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;&lt;span&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.7453125&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/951TjTgiabkyibhvGLgaqX9NkLdhIcdPwRjzul6kZu1KIBRE8PxicD2Wpttfpcd1uwX7MicdUmQZu0yaq7Af8MY7sg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;市场上 AI 好像无所不能，但其实，Yann LeCun个人认为，AI 还是有些局限，像是机器必须会观察状态、了解很多背景知识、世界运行的定律，以及精确地判断、规划等，其中，Yann LeCun 认为 AI 最大的局限是无法拥有人类的「常识」。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.7390625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/951TjTgiabkyibhvGLgaqX9NkLdhIcdPwRMvSn3e0ank0JX5juNO99AL2J0dbIg1avBAkaM6dhYBnz20wbuNwkMw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;由于目前比较好的AI应用都是采用监督式学习，能够准确识别人工标示过的物体，也有些好的成果是用强化学习（Reinforcement Learning）的方式，但是强化学习需要大量地收集资料来训练模型，Yann LeCun表示，对应到现实社会中的问题，监督式学习不足以成为“真的”AI。 &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;他指出，人类的学习是建立在与事物互动的过程，许多都是人类自行体会、领悟出对事物的理解，不需要每件事都要教导，举例来说，若有个物体被前面的物体挡住，人类会知道后面的物体依然存在的事实，或是物体没有另一个物体支撑就会掉落的事实。 &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;“人脑就是推理引擎！”他说明，人类靠着观察建立内部分析模型，当人类遇到一件新的事物，就能用这些既有的模型来推测，因为生活中人类接触到大量的事物和知识，而建立了“常识”。这些常识可以带领人类做出一些程序无法达到的能力，像是人类可以只看一半的脸就能想像另外一半脸，或是可以从过去的事件推测未来等。 &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;他举例，若人类看到一张战利品放不下行李箱的图片，再看到一个句子说：”这些战利品放不下行李箱，因为它太小了。“人类能够很清楚地知道“它”指的是行李箱，人类也因为知道整个社会和世界运行的规则，当没有太多的信息时，人类可以依照因果关系自动补足空白的信息。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;无监督式学习是突破 AI 困境的关键，采用无监督学习的对抗训练让 AI 拥有真正自我学习的能力。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;如何让 AI 拥有人类的常识？Yann LeCun认为要用无监督式学习。他又称之为预测学习，他将现今机器学习的方式分为强化式、监督式和无监督式学习，并以黑森林蛋糕来比喻。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.75&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/951TjTgiabkyibhvGLgaqX9NkLdhIcdPwR3sCuibr9JicM8z0UiaCziay1G7MuSp9ibPdEULd1pDnsfqGunAlrgETQOpw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;强化学习是蛋糕上不可或缺的樱桃，所需要资料量可能大约只有几个Bits，监督式学习是蛋糕外部的糖衣，需要10到10,000个Bits的资料量，而无监督学习则是需要数百万个Bits，无监督学习被他比喻为黑森林蛋糕，因为无监督学习的预测能力像拥有黑魔法一样神奇，不过，他也强调黑森林蛋糕必须搭配樱桃，樱桃不是可选择的配料，而是必要的，意味着无监督学习与强化学习相辅相成，缺一不可。 &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Yann LeCun认为，程序还是很难在不确定性的情况下，正确地预测，举例来说，如果一只直立的笔，没有支撑之后，程序可以判断出笔会倒下，但是无法预测会倒向哪一个方向。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;因此，他表示，对抗训练（Adversarial Training）是可以让 AI 程序拥有自学能力的方法，他解释，对抗训练就是让两个网络相互博奕，由生成器（Generator）和判别器（Discriminator）组成，生成器随机地从训练集中挑选真实数据和干扰噪音，产生新的训练样本，判别器再用与真实数据比对的方式，判断出数据的真实性，如此一来，生成器与判别器可以交互学习自动优化预测能力，创造最佳的预测模型。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;————&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;编辑 ∑ Pluto&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;来源：新智元&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;更多精彩：&lt;/span&gt;&lt;/strong&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;☞&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI4NTY3OTU3MA==&amp;amp;mid=2247484097&amp;amp;idx=1&amp;amp;sn=9566979109fefc1907edad8a0b67cb27&amp;amp;chksm=ebe9c87cdc9e416ac5246da86ef23e6b45671441511a210554a965eb8c5a5ad210f72834a141&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;泰勒定理的奇闻轶事&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;☞&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI4NTY3OTU3MA==&amp;amp;mid=2247484094&amp;amp;idx=1&amp;amp;sn=1a93ee4b182b6fd3a74bd4b93d205d9e&amp;amp;chksm=ebe9c803dc9e4115ae1e90d7e64af1ccb0687cb77237d45fdc5039f771ec122da2d9b7ece9fd&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;丘成桐：漫谈微分几何&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;☞&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI4NTY3OTU3MA==&amp;amp;mid=2247484092&amp;amp;idx=1&amp;amp;sn=56e2befc4cbcc6e0a138c41c0a445451&amp;amp;chksm=ebe9c801dc9e4117126f5df3938fe5b93ce10ca4bb00692fe16e906e64620c14754895e24d9c&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;Leibniz 如何想出微积分？（一）&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;☞&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI4NTY3OTU3MA==&amp;amp;mid=2247484090&amp;amp;idx=1&amp;amp;sn=c4778f29071d0388f6f7d5d25b2207d3&amp;amp;chksm=ebe9c807dc9e4111784b02ad43ed7b9958a0da5108c9db84a659f2b1d853a4a982bcef72aacc&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;线性相关和秩的物理意义&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;☞&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI4NTY3OTU3MA==&amp;amp;mid=2247484087&amp;amp;idx=1&amp;amp;sn=466ad19b059aa635a0ae282adca9342e&amp;amp;chksm=ebe9c80adc9e411c38ec3006c5bc2f622b4d7d6a3887f356db114ed3b79f0bf957a43b79eb75&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;数学史上你认为最丑陋的公式是什么？&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;☞&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI4NTY3OTU3MA==&amp;amp;mid=2247484083&amp;amp;idx=2&amp;amp;sn=107822b9a73eba79d34ba6a8488b13a6&amp;amp;chksm=ebe9c80edc9e411812d049bdd6ca8d4607688e815c8ba92c504748fdbbeab852f3166371eb9d&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;陶哲轩谈什么是好的数学&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;☞&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI4NTY3OTU3MA==&amp;amp;mid=2247484080&amp;amp;idx=1&amp;amp;sn=b754ee91c37493f3cff118a925f3d7d8&amp;amp;chksm=ebe9c80ddc9e411bc25ceef06631a406d7eafc73bb913f697b533c67665396e55565d1675bcd&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;田渊栋：数学的用处（下篇）&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;☞&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI4NTY3OTU3MA==&amp;amp;mid=2247484029&amp;amp;idx=1&amp;amp;sn=d85a35df3ebd0884f3cb60536c5ccf75&amp;amp;chksm=ebe9c8c0dc9e41d6b43a3918624d8885f91c9af2346c2163c54c090c80c58ab844872278635c&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;你绝对没想过原来数学家这么流氓，一言不合就进行暴力证明&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;☞&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI4NTY3OTU3MA==&amp;amp;mid=2247484037&amp;amp;idx=1&amp;amp;sn=16e68092098b573bfff13f69c28b6285&amp;amp;chksm=ebe9c838dc9e412e4f0eceece3372c28256508af1f77d714dd1a7b8fd7f20de71e01d77bc836&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;世界上最牛的五篇博士论文&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;☞&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI4NTY3OTU3MA==&amp;amp;mid=2247484082&amp;amp;idx=2&amp;amp;sn=85da1e76707c8c1a9120cbbcf1da9aca&amp;amp;chksm=ebe9c80fdc9e411984cf41a248860de6982e8c9d291f25fe4420fbf43c38b138a2ea38bd644a&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;数学中有哪些巧合让人眼前一亮？&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;☞&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI4NTY3OTU3MA==&amp;amp;mid=2247484014&amp;amp;idx=1&amp;amp;sn=5b94b17a277a0e25581d58a2582b5d0a&amp;amp;chksm=ebe9c8d3dc9e41c57f2137c285ac44ec24f6e20029158351588cf519b022ba65f417a0710fac&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;算法立功！清华毕业教授美国被抢车，警察无能为力自己用“贪心算法”找回&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;☞&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI4NTY3OTU3MA==&amp;amp;mid=2247483984&amp;amp;idx=2&amp;amp;sn=620b603edf54785adeeae775b5cf7325&amp;amp;chksm=ebe9c8eddc9e41fba6883062a4b82f05d17d8292771a397d2fafdad2b1a77062472e95e13405&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;学术史上的奇文：怎样用数学抓狮子&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;☞&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI4NTY3OTU3MA==&amp;amp;mid=2247483968&amp;amp;idx=1&amp;amp;sn=098491812586b1806465ef2c7f055b39&amp;amp;chksm=ebe9c8fddc9e41eb88a15c509a228568da5cdbfe4eeda595941c9bd5d25a135fef17a239fc00&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;台大教授的反思：最难的一课 我们却没教给学生&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt; &lt;p&gt;&lt;span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI4NTY3OTU3MA==&amp;amp;mid=2247483962&amp;amp;idx=1&amp;amp;sn=13ebe38d0b455b43c525284f550f1eda&amp;amp;chksm=ebe9c887dc9e4191bbe4c64d9027a27e94b01aaa6ae8435e2e5846374b3b94b8a8c46ddaaecb&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;☞&lt;/span&gt;麻省理工学院(MIT)研究生学习指导—— 怎样做研究生&lt;/a&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI4NTY3OTU3MA==&amp;amp;mid=2247483957&amp;amp;idx=1&amp;amp;sn=f97ade0ac2643a31e2859f2f0186509f&amp;amp;chksm=ebe9c888dc9e419e8623cf164d9d5964ffcf80d6ac1c90c9cbe721533ec0848495bcab82e5be&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;☞&lt;/span&gt;分享 数学，常识和运气 ——投资大师詹姆斯·西蒙斯2010年在MIT的讲座&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;算法数学之美微信公众号欢迎赐稿&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;稿件涉及数学、物理、算法、计算机、编程等相关领域，经采用我们将奉上稿酬。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;投稿邮箱：math_alg@163.com&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Mon, 25 Mar 2019 15:50:41 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/xVj6falqU3</dc:identifier>
</item>
<item>
<title>鬲融：从唐山走出的国际杰出青年学者</title>
<link>http://www.jintiankansha.me/t/WHNbHBQhc3</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/WHNbHBQhc3</guid>
<description>&lt;p&gt;&lt;span&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.0609375&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_gif/951TjTgiabkyYNr2mLLFgV8rAcf8TKrhVVxPz4sJSdjDum3ia43TqSj6sPicZVQ5XqpfDhulibnGRdeLqAhyHf8TWw/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;640&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;在日前获得美国2019年斯隆研究奖的126名青年学者中，有一位曾就读于唐山一中的青年学者，他主要是因为在“非凸优化”问题上的成就而获奖。这位青年学者就是美国杜克大学助理教授鬲融。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;据了解，斯隆研究奖素有“诺奖风向标”的美誉，旨在奖励杰出青年学者。该奖项自1955年设立以来，已有47位获奖人获得诺贝尔奖，17位获奖人获得数学菲尔兹奖。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;鬲融1987年生于唐山市，2002年至2004年就读于唐山一中。他学习成绩优异，在高一、高二历次学科考试中均名列年级第一，曾获得我省中学生物理奥林匹克竞赛一等奖，连续两次获得全国青少年信息学奥林匹克竞赛金牌，并在2004年第16届国际中学生信息学奥林匹克竞赛中获金牌。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;“他自律性极强，就像一个钟摆，一年365天雷打不动坚持学习。”曾是鬲融的竞赛教练的唐山一中教师王学红评价说。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;信息学竞赛离不开电脑。据王学红回忆，鬲融把电脑作为学习伙伴，刻苦钻研程序。在高强度的学习日程中，他的放松方式仅仅是上体育课、跑跑步。2004年国际奥赛前夕，他在网站上同外国选手比拼试题，成绩名列前茅。在进入国家集训队后，鬲融总是认真完成老师给的作业。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;“这个孩子的智商非常高，很多东西一看就懂，一点就透，老师们课上讲的内容他早就已经会了，但他听课永远是班里最认真的，最虚心的。” 鬲融高中时的班主任鲁子顺回忆道，在刚获得国际金牌后，鬲融又像往常一样走进教室，坐在座位上，依然是课堂上听讲最认真的，仿佛所有事情都不曾发生过。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;在唐山一中的求学经历，为鬲融以后的科学研究奠定了坚实基础。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;2004年，鬲融被保送到清华大学，进入“清华学堂计算机科学实验班”。大学4年中，他的成绩经常排在计算机科学系第一名，并获得清华大学特等奖学金。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;“母校情深，师恩难忘。”鬲融对唐山一中、对恩师、对家乡有着深厚感情。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;在被保送到清华大学后，鬲融多次回到唐山一中指导学弟学妹。受其影响，唐山一中先后有20余人入选信息学奥林匹克省队，50余人获得省信息学竞赛一等奖。每个寒暑假，他都要去看望唐山一中的老师。他把在国际性竞赛中获金牌的成绩首先归功于班主任鲁子顺和竞赛教练王学红。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;2008年，鬲融从清华大学毕业后，前往美国留学。鬲融在美国刚开始读博士的时候，研究的方向是计算机科学近似算法，后来转到理论机器学习方向。他曾获得普林斯顿大学博士学位，并在微软研究院从事博士后研究。从2015年开始，鬲融在美国杜克大学任教。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;“目前，从事计算机科学应用方向研究的人才很多，但理论研究的人才相对较少。我希望做好理论研究，为应用技术的发展提供理论支持。”鬲融说。 &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;————&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;编辑 ∑Pluto&lt;/span&gt;&lt;/p&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;p&gt;&lt;span&gt;来源：河北新闻网&lt;/span&gt;&lt;/p&gt;
&lt;section&gt;&lt;section class=&quot;&quot; powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section helvetica=&quot;&quot; neue=&quot;&quot; pingfang=&quot;&quot; sc=&quot;&quot; hiragino=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; microsoft=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; px=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; display:=&quot;&quot; inline-block=&quot;&quot; top=&quot;&quot; solid=&quot;&quot; overflow-wrap:=&quot;&quot; break-word=&quot;&quot; important=&quot;&quot;&gt;&lt;section class=&quot;&quot; powered-by=&quot;xiumi.us&quot;&gt;&lt;section readability=&quot;2.7516891891892&quot;&gt;&lt;section readability=&quot;5.5033783783784&quot;&gt;&lt;section helvetica=&quot;&quot; neue=&quot;&quot; pingfang=&quot;&quot; sc=&quot;&quot; hiragino=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; microsoft=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; px=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; display:=&quot;&quot; inline-block=&quot;&quot; top=&quot;&quot; solid=&quot;&quot; overflow-wrap:=&quot;&quot; break-word=&quot;&quot; important=&quot;&quot;&gt;&lt;section class=&quot;&quot; powered-by=&quot;xiumi.us&quot;&gt;&lt;section readability=&quot;1.5&quot;&gt;&lt;section readability=&quot;3&quot;&gt;&lt;p&gt;&lt;span&gt;微信公众号“算法数学之美”，由算法与数学之美团队打造的另一个公众号，欢迎大家扫码关注！&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p pingfang=&quot;&quot; sc=&quot;&quot; hiragino=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; microsoft=&quot;&quot; yahei=&quot;&quot; wenquanyi=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; helvetica=&quot;&quot; neue=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; px=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; text-align:=&quot;&quot; justify=&quot;&quot; em=&quot;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;1&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/951TjTgiabkyjQVC3BFiaFKQ4DJqz2xhrwkzeCPbjQdnnG8678fRf1sxc2ZQtvtVib2dqWUkeopYtmgckINoOoGoQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;258&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;更多精彩：&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;☞&lt;/span&gt;&lt;span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI4NTY3OTU3MA==&amp;amp;mid=2247483726&amp;amp;idx=1&amp;amp;sn=e5e008fb68a7d837546d0ac5b5438042&amp;amp;chksm=ebe9cbf3dc9e42e5d625b2da6b9b3866dff9f08d442d8106f4cbf035d8602e1fdda86eec6476&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;如何向5岁小孩解释什么是支持向量机（SVM）？&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;☞&lt;/span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI4NTY3OTU3MA==&amp;amp;mid=2247483726&amp;amp;idx=2&amp;amp;sn=18272b7eaa172794b51c30d0a2dd9c48&amp;amp;chksm=ebe9cbf3dc9e42e5ddf9a189822a2fa099543a631ad63a1d6ed0158b51c76212eb65ebbfe71b&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;自然底数e的意义是什么？&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI4NTY3OTU3MA==&amp;amp;mid=2247483715&amp;amp;idx=1&amp;amp;sn=9069dadf4bbce2aa34bd64b85a69dcee&amp;amp;chksm=ebe9cbfedc9e42e81c27d72da15c0dbf848e505946f231051b8b4033d0941bc6f51cef32790e&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;☞&lt;/span&gt;费马大定理，集惊险与武侠于一体&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;☞&lt;/span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI4NTY3OTU3MA==&amp;amp;mid=2247483715&amp;amp;idx=2&amp;amp;sn=55a16f37c89b27994b263e0dc9837561&amp;amp;chksm=ebe9cbfedc9e42e842deb581ea62b750cedd839abd58c2db3261bf9fbcd172a2cf18512e4d2d&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;简单的解释，让你秒懂“最优化” 问题&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI4NTY3OTU3MA==&amp;amp;mid=2247483676&amp;amp;idx=1&amp;amp;sn=2366a39bca3ef42a6e868e91ea718813&amp;amp;chksm=ebe9cba1dc9e42b70c7e147b9e43828c1a7c68401f442890471a06e5cf0704437f9813ca0e0f&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;☞&lt;/span&gt;一分钟看懂一维空间到十维空间&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;☞ &lt;/span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI4NTY3OTU3MA==&amp;amp;mid=2247483661&amp;amp;idx=1&amp;amp;sn=d822666a054ba70b37dfb06d14c60f3a&amp;amp;chksm=ebe9cbb0dc9e42a6c476f7f81095b772aa45d960bf516f60c5b2e1155c9093696222cea0a83d&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;本科、硕士和博士到底有什么区别？&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;☞&lt;/span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI4NTY3OTU3MA==&amp;amp;mid=2247483654&amp;amp;idx=1&amp;amp;sn=7d0d05c78cd01df91495f1d14609cbce&amp;amp;chksm=ebe9cbbbdc9e42add13cfe99f3383745fa5c059df705a3a9e28644d073dff804569af94970e3&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;小波变换通俗解释&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;☞&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI4NTY3OTU3MA==&amp;amp;mid=2247483654&amp;amp;idx=4&amp;amp;sn=ce88086b650c601bdbf57ecfe5a490a1&amp;amp;chksm=ebe9cbbbdc9e42adfaf0e4ee644d254835c830ef47663315b70a39a2b47e6a7cf10d0826b88d&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;微积分必背公式&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;☞&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI4NTY3OTU3MA==&amp;amp;mid=2247483654&amp;amp;idx=3&amp;amp;sn=ceaec6043bb0e8a851033482f8f572bf&amp;amp;chksm=ebe9cbbbdc9e42ad30fd38383cf1caa609ac6e81964da17277f8e2a7f17a933cd11e0f3840c8&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;影响计算机算法世界的十位大师&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;☞&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI4NTY3OTU3MA==&amp;amp;mid=2247483654&amp;amp;idx=2&amp;amp;sn=bf439d56bc7d42083708fa76434a6025&amp;amp;chksm=ebe9cbbbdc9e42ad9e5f2b3c1952e620e0e3d4452aae25b611e7e54be8678b0d80e002e7be6d&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;数据挖掘之七种常用的方法&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;算法数学之美微信公众号欢迎赐稿&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;稿件涉及数学、物理、算法、计算机、编程等相关领域，经采用我们将奉上稿酬。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;投稿邮箱：math_alg@163.com&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Mon, 25 Mar 2019 15:50:43 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/WHNbHBQhc3</dc:identifier>
</item>
<item>
<title>回归、分类与聚类：三大方向剖解机器学习算法的优缺点</title>
<link>http://www.jintiankansha.me/t/DSoWnR2x4S</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/DSoWnR2x4S</guid>
<description>&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.0609375&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_gif/951TjTgiabkyibhvGLgaqX9NkLdhIcdPwR25icvKqfV9L0leq4zoIuDGk5MVNXKRO7bZg9KgWg9ozC6icfRIWtSQKg/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;640&quot;/&gt;&lt;/p&gt;
&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;129&quot; data-source-title=&quot;&quot;&gt;
&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;section&gt;在本教程中，作者对现代机器学习算法进行一次简要的实战梳理。虽然类似的总结有很多，但是它们都没有真正解释清楚每个算法在实践中的好坏，而这正是本篇梳理希望完成的。因此本文力图基于实践中的经验，讨论每个算法的优缺点。而机器之心也在文末给出了这些算法的具体实现细节。&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;span&gt;对机器学习算法进行分类不是一件容易的事情，总的来看，有如下几种方式：生成与判别、参数与非参数、监督与非监督等等。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;然而，就实践经验来看，这些都不是实战过程中最有效的分类算法的方式。因为对于应用机器学习而言，开发者一般会在脑海中有一个最终目标，比如预测一个结果或是对你的观察进行分类。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;因此，我们想介绍另一种对算法进行分类的路数，其基于机器学习任务来分类。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;没有免费午餐定理&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;在机器学习中，有个定理被称为「没有免费的午餐」。简而言之，就是说没有一个算法可以完美解决所有问题，而且这对于监督学习（即对预测的建模）而言尤其如此。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;举个例子，你不能说神经网络就一定任何时候都比决策树优秀，反过来也是。这其中存在很多影响因素，比如你数据集的规模和结构。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;fr-fic fr-dib medium-zoom-image&quot; data-ratio=&quot;0.6223776223776224&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/951TjTgiabkyapBXJlicTQfzNp33LespkExdWWEVhSkxuVqnAsrXfLuzkRl6VOHDrGE3lAWLBKhcCKZ1zOibBsicsg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;572&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;所以，当你使用一个固定的数据测试集来评估性能，挑选最适合算法时，你应该针对你的问题尝试多种不同的算法。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;当然，你所使用的算法必须要适合于你试图解决的问题，这也就有了如何选择正确的机器学习任务这一问题。做个类比，如果你需要打扫你的房子，你可能会用吸尘器、扫帚或者是拖把，但是你绝不会掏出一把铲子然后开始挖地。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; 机器学习任务 &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;在本次梳理中，我们将涵盖目前「三大」最常见机器学习任务：&lt;/span&gt;&lt;/p&gt;
&lt;ol class=&quot; list-paddingleft-2&quot;&gt;&lt;li&gt;
&lt;p&gt;&lt;span&gt;回归方法&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span&gt;分类方法&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span&gt;聚类方法&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;span&gt;说明：&lt;/span&gt;&lt;/p&gt;
&lt;ul class=&quot; list-paddingleft-2&quot; readability=&quot;0&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span&gt;本文的梳理不会涵盖具体领域的问题，比如自然语言处理。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;&lt;span&gt;本文也不会对每个算法都进行梳理。因为现有太多算法，而且新的算法也层出不穷。然而，这份清单将向读者展现对每个任务而言目前具有代表性的算法概览。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;span&gt;1、回归方法&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;回归方法是一种对数值型连续随机变量进行预测和建模的监督学习算法。使用案例一般包括房价预测、股票走势或测试成绩等连续变化的案例。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;回归任务的特点是标注的数据集具有数值型的目标变量。也就是说，每一个观察样本都有一个数值型的标注真值以监督算法。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;1.1 线性回归（正则化）&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;线性回归是处理回归任务最常用的算法之一。该算法的形式十分简单，它期望使用一个超平面拟合数据集（只有两个变量的时候就是一条直线）。如果数据集中的变量存在线性关系，那么其就能拟合地非常好。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;fr-fic fr-dib medium-zoom-image&quot; data-ratio=&quot;0.697986577181208&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/951TjTgiabkyapBXJlicTQfzNp33LespkEUV54J7VibrHGqdy07sDvicEXbuIYibWwQVENo79RWLIPlfnwdmMFCzCAA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;596&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;在实践中，简单的线性回归通常被使用正则化的回归方法（LASSO、Ridge 和 Elastic-Net）所代替。正则化其实就是一种对过多回归系数采取惩罚以减少过拟合风险的技术。当然，我们还得确定惩罚强度以让模型在欠拟合和过拟合之间达到平衡。&lt;/span&gt;&lt;/p&gt;
&lt;ul class=&quot; list-paddingleft-2&quot; readability=&quot;3&quot;&gt;&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;&lt;span&gt;优点：线性回归的理解与解释都十分直观，并且还能通过正则化来降低过拟合的风险。另外，线性模型很容易使用随机梯度下降和新数据更新模型权重。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;&lt;span&gt;缺点：线性回归在变量是非线性关系的时候表现很差。并且其也不够灵活以捕捉更复杂的模式，添加正确的交互项或使用多项式很困难并需要大量时间。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span&gt;Python 实现：http://scikit-learn.org/stable/modules/linear_model.html &lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span&gt;R 实现：https://cran.r-project.org/web/packages/glmnet/index.html &lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;span&gt;1.2 回归树（集成方法）&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;回归树（决策树的一种）通过将数据集重复分割为不同的分支而实现分层学习，分割的标准是最大化每一次分离的信息增益。这种分支结构让回归树很自然地学习到非线性关系。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;fr-fic fr-dib medium-zoom-image&quot; data-ratio=&quot;0.9251247920133111&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/951TjTgiabkyapBXJlicTQfzNp33LespkEOyoKcu3tRl6R2SvkQ96ia7Q6sYYcIP9mJTeqYtOx7iaOgjzmHtublPsw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;601&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;集成方法，如随机森林（RF）或梯度提升树（GBM）则组合了许多独立训练的树。这种算法的主要思想就是组合多个弱学习算法而成为一种强学习算法，不过这里并不会具体地展开。在实践中 RF 通常很容易有出色的表现，而 GBM 则更难调参，不过通常梯度提升树具有更高的性能上限。&lt;/span&gt;&lt;/p&gt;
&lt;ul class=&quot; list-paddingleft-2&quot; readability=&quot;4.5&quot;&gt;&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;&lt;span&gt;优点：决策树能学习非线性关系，对异常值也具有很强的鲁棒性。集成学习在实践中表现非常好，其经常赢得许多经典的（非深度学习）机器学习竞赛。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;span&gt;缺点：无约束的，单棵树很容易过拟合，因为单棵树可以保留分支（不剪枝），并直到其记住了训练数据。集成方法可以削弱这一缺点的影响。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span&gt;随机森林 Python 实现：http://scikit-learn.org/stable/modules/ensemble.html#random-forests&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span&gt;随机森林 R 实现：https://cran.r-project.org/web/packages/randomForest/index.html&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span&gt;梯度提升树 Python 实现：http://scikit-learn.org/stable/modules/ensemble.html#classification&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt;  梯度提升树 R 实现：https://cran.r-project.org/web/packages/gbm/index.html&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;span&gt;1.3 深度学习&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;深度学习是指能学习极其复杂模式的多层神经网络。该算法使用在输入层和输出层之间的隐藏层对数据的中间表征建模，这也是其他算法很难学到的部分。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;fr-fic fr-dib medium-zoom-image&quot; data-ratio=&quot;0.496875&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/951TjTgiabkyapBXJlicTQfzNp33LespkEoCFtXgqrZ3kjx1ciag5OUFNACjHxpibiaf2df3MO07VIr9tNtEEjpbpMw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;640&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;深度学习还有其他几个重要的机制，如卷积和 drop-out 等，这些机制令该算法能有效地学习到高维数据。然而深度学习相对于其他算法需要更多的数据，因为其有更大数量级的参数需要估计。&lt;/span&gt;&lt;/p&gt;
&lt;ul class=&quot; list-paddingleft-2&quot; readability=&quot;4&quot;&gt;&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;&lt;span&gt;优点：深度学习是目前某些领域最先进的技术，如计算机视觉和语音识别等。深度神经网络在图像、音频和文本等数据上表现优异，并且该算法也很容易对新数据使用反向传播算法更新模型参数。它们的架构（即层级的数量和结构）能够适应于多种问题，并且隐藏层也减少了算法对特征工程的依赖。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;&lt;span&gt;缺点：深度学习算法通常不适合作为通用目的的算法，因为其需要大量的数据。实际上，深度学习通常在经典机器学习问题上并没有集成方法表现得好。另外，其在训练上是计算密集型的，所以这就需要更富经验的人进行调参（即设置架构和超参数）以减少训练时间。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span&gt;Python 资源：https://keras.io/&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span&gt;R 资源：http://mxnet.io/ &lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;span&gt;1.4 最近邻算法&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;最近邻算法是「基于实例的」，这就意味着其需要保留每一个训练样本观察值。最近邻算法通过搜寻最相似的训练样本来预测新观察样本的值。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;而这种算法是内存密集型，对高维数据的处理效果并不是很好，并且还需要高效的距离函数来度量和计算相似度。在实践中，基本上使用正则化的回归或树型集成方法是最好的选择。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;2、分类方法&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;分类方法是一种对离散型随机变量建模或预测的监督学习算法。使用案例包括邮件过滤、金融欺诈和预测雇员异动等输出为类别的任务。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;许多回归算法都有与其相对应的分类算法，分类算法通常适用于预测一个类别（或类别的概率）而不是连续的数值。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;2.1 Logistic 回归（正则化）&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Logistic 回归是与线性回归相对应的一种分类方法，且该算法的基本概念由线性回归推导而出。Logistic 回归通过 Logistic 函数（即 Sigmoid 函数）将预测映射到 0 到 1 中间，因此预测值就可以看成某个类别的概率。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;fr-fic fr-dib medium-zoom-image&quot; data-ratio=&quot;0.6895973154362416&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/951TjTgiabkyapBXJlicTQfzNp33LespkEKEicq7mOp3NDO8DWhJWtia65qLADGcqRHzoYS0lqM5niaPJYKfXxFgkkw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;596&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;该模型仍然还是「线性」的，所以只有在数据是线性可分（即数据可被一个超平面完全分离）时，算法才能有优秀的表现。同样 Logistic 模型能惩罚模型系数而进行正则化。&lt;/span&gt;&lt;/p&gt;
&lt;ul class=&quot; list-paddingleft-2&quot; readability=&quot;1.5&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;span&gt;优点：输出有很好的概率解释，并且算法也能正则化而避免过拟合。Logistic 模型很容易使用随机梯度下降和新数据更新模型权重。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span&gt;缺点：Logistic 回归在多条或非线性决策边界时性能比较差。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span&gt;Python 实现：http://scikit-learn.org/stable/modules/linear_model.html#logistic-regression&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span&gt;R 实现：https://cran.r-project.org/web/packages/glmnet/index.html&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;span&gt;2.2 分类树（集成方法）&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;与回归树相对应的分类算法是分类树。它们通常都是指决策树，或更严谨一点地称之为「分类回归树（CART）」，这也就是非常著名的 CART 的算法。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;fr-fic fr-dib medium-zoom-image&quot; data-ratio=&quot;0.6903225806451613&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/951TjTgiabkyapBXJlicTQfzNp33LespkESEiacf1CxTtXJT6WdWgsqaDtsp0gTkWBd0hEak04dFa7eiciaah4HgYAQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;465&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;em&gt;简单的随机森林&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ul class=&quot; list-paddingleft-2&quot; readability=&quot;4.5&quot;&gt;&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;&lt;span&gt;优点：同回归方法一样，分类树的集成方法在实践中同样表现十分优良。它们通常对异常数据具有相当的鲁棒性和可扩展性。因为它的层级结构，分类树的集成方法能很自然地对非线性决策边界建模。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;span&gt;缺点：不可约束，单棵树趋向于过拟合，使用集成方法可以削弱这一方面的影响。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span&gt;随机森林 Python 实现：http://scikit-learn.org/stable/modules/ensemble.html#regression&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span&gt;随机森林 R 实现：https://cran.r-project.org/web/packages/randomForest/index.html&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span&gt;梯度提升树 Python 实现：http://scikit-learn.org/stable/modules/ensemble.html#classification&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span&gt;梯度提升树 R 实现：https://cran.r-project.org/web/packages/gbm/index.html&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;span&gt;2.3 深度学习&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;深度学习同样很容易适应于分类问题。实际上，深度学习应用地更多的是分类任务，如图像分类等。&lt;/span&gt;&lt;/p&gt;
&lt;ul class=&quot; list-paddingleft-2&quot; readability=&quot;1.5&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span&gt;优点：深度学习非常适用于分类音频、文本和图像数据。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;span&gt;缺点：和回归问题一样，深度神经网络需要大量的数据进行训练，所以其也不是一个通用目的的算法。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span&gt;Python 资源：https://keras.io/&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span&gt;R 资源：http://mxnet.io/ &lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;span&gt;2.4 支持向量机&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;支持向量机（SVM）可以使用一个称之为核函数的技巧扩展到非线性分类问题，而该算法本质上就是计算两个称之为支持向量的观测数据之间的距离。SVM 算法寻找的决策边界即最大化其与样本间隔的边界，因此支持向量机又称为大间距分类器。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;img class=&quot;fr-fic fr-dib medium-zoom-image&quot; data-ratio=&quot;0.45483870967741935&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/951TjTgiabkyapBXJlicTQfzNp33LespkEDpEsuazKgxQDJ377IxdddzpJQlMqHttN62xy7sNT2ic65icnU4Sz1qAA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;620&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;em&gt;支持向量机中的核函数采用非线性变换，将非线性问题变换为线性问题&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;例如，SVM 使用线性核函数就能得到类似于 logistic 回归的结果，只不过支持向量机因为最大化了间隔而更具鲁棒性。因此，在实践中，SVM 最大的优点就是可以使用非线性核函数对非线性决策边界建模。&lt;/span&gt;&lt;/p&gt;
&lt;ul class=&quot; list-paddingleft-2&quot; readability=&quot;2.5&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;span&gt;优点：SVM 能对非线性决策边界建模，并且有许多可选的核函数形式。SVM 同样面对过拟合有相当大的鲁棒性，这一点在高维空间中尤其突出。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;&lt;span&gt;缺点：然而，SVM 是内存密集型算法，由于选择正确的核函数是很重要的，所以其很难调参，也不能扩展到较大的数据集中。目前在工业界中，随机森林通常优于支持向量机算法。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span&gt;Python 实现：http://scikit-learn.org/stable/modules/svm.html#classification&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span&gt;R 实现：https://cran.r-project.org/web/packages/kernlab/index.html&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;span&gt;2.5 朴素贝叶斯&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;朴素贝叶斯（NB）是一种基于贝叶斯定理和特征条件独立假设的分类方法。本质上朴素贝叶斯模型就是一个概率表，其通过训练数据更新这张表中的概率。为了预测一个新的观察值，朴素贝叶斯算法就是根据样本的特征值在概率表中寻找最大概率的那个类别。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;之所以称之为「朴素」，是因为该算法的核心就是特征条件独立性假设（每一个特征之间相互独立），而这一假设在现实世界中基本是不现实的。&lt;/span&gt;&lt;/p&gt;
&lt;ul class=&quot; list-paddingleft-2&quot; readability=&quot;2&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;span&gt;优点：即使条件独立性假设很难成立，但朴素贝叶斯算法在实践中表现出乎意料地好。该算法很容易实现并能随数据集的更新而扩展。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;span&gt;缺点：因为朴素贝叶斯算法太简单了，所以其也经常被以上列出的分类算法所替代。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span&gt;Python 实现：http://scikit-learn.org/stable/modules/naive_bayes.html&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span&gt;R 实现：https://cran.r-project.org/web/packages/naivebayes/index.html&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;span&gt;3、聚类&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;聚类是一种无监督学习任务，该算法基于数据的内部结构寻找观察样本的自然族群（即集群）。使用案例包括细分客户、新闻聚类、文章推荐等。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;因为聚类是一种无监督学习（即数据没有标注），并且通常使用数据可视化评价结果。如果存在「正确的回答」（即在训练集中存在预标注的集群），那么分类算法可能更加合适。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;3.1 K 均值聚类&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;K 均值聚类是一种通用目的的算法，聚类的度量基于样本点之间的几何距离（即在坐标平面中的距离）。集群是围绕在聚类中心的族群，而集群呈现出类球状并具有相似的大小。聚类算法是我们推荐给初学者的算法，因为该算法不仅十分简单，而且还足够灵活以面对大多数问题都能给出合理的结果。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;fr-fic fr-dib medium-zoom-image&quot; data-ratio=&quot;0.6950757575757576&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/951TjTgiabkyapBXJlicTQfzNp33LespkEUfVTGIQV2reksiaYV7K1fxegBJcSfK5q5RfkhgUAM984BL7058OekUw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;528&quot;/&gt;&lt;/p&gt;
&lt;ul class=&quot; list-paddingleft-2&quot; readability=&quot;3&quot;&gt;&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;&lt;span&gt;优点：K 均值聚类是最流行的聚类算法，因为该算法足够快速、简单，并且如果你的预处理数据和特征工程十分有效，那么该聚类算法将拥有令人惊叹的灵活性。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;&lt;span&gt;缺点：该算法需要指定集群的数量，而 K 值的选择通常都不是那么容易确定的。另外，如果训练数据中的真实集群并不是类球状的，那么 K 均值聚类会得出一些比较差的集群。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span&gt;Python 实现：http://scikit-learn.org/stable/modules/clustering.html#k-means&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span&gt;R 实现：https://stat.ethz.ch/R-manual/R-devel/library/stats/html/kmeans.html&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;span&gt;3.2 Affinity Propagation 聚类&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;AP 聚类算法是一种相对较新的聚类算法，该聚类算法基于两个样本点之间的图形距离（graph distances）确定集群。采用该聚类方法的集群拥有更小和不相等的大小。&lt;/span&gt;&lt;/p&gt;
&lt;ul class=&quot; list-paddingleft-2&quot; readability=&quot;2.5&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;span&gt;优点：该算法不需要指出明确的集群数量（但是需要指定「sample preference」和「damping」等超参数）。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;&lt;span&gt;缺点：AP 聚类算法主要的缺点就是训练速度比较慢，并需要大量内存，因此也就很难扩展到大数据集中。另外，该算法同样假定潜在的集群是类球状的。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span&gt;Python 实现：http://scikit-learn.org/stable/modules/clustering.html#affinity-propagation&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span&gt;R 实现：https://cran.r-project.org/web/packages/apcluster/index.html&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;span&gt;3.3 层次聚类（Hierarchical / Agglomerative）&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;层次聚类是一系列基于以下概念的聚类算法：&lt;/span&gt;&lt;/p&gt;
&lt;ol class=&quot; list-paddingleft-2&quot; readability=&quot;0&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span&gt;最开始由一个数据点作为一个集群&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span&gt;对于每个集群，基于相同的标准合并集群&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span&gt;重复这一过程直到只留下一个集群，因此就得到了集群的层次结构。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;img class=&quot;fr-fic fr-dib medium-zoom-image&quot; data-ratio=&quot;0.521875&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/951TjTgiabkyapBXJlicTQfzNp33LespkEqfLVAVAUXlQcYlmEfrDbGyYd9SWORh4mQpBwAbN8cMEGWXuv2sYoUg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;640&quot;/&gt;&lt;/p&gt;
&lt;ul class=&quot; list-paddingleft-2&quot; readability=&quot;2&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;span&gt;优点：层次聚类最主要的优点是集群不再需要假设为类球形。另外其也可以扩展到大数据集。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;span&gt;缺点：有点像 K 均值聚类，该算法需要设定集群的数量（即在算法完成后需要保留的层次）。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span&gt;Python 实现：http://scikit-learn.org/stable/modules/clustering.html#hierarchical-clustering&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt;  R 实现：https://stat.ethz.ch/R-manual/R-devel/library/stats/html/hclust.html&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;span&gt;3.4 DBSCAN&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;DBSCAN 是一个基于密度的算法，它将样本点的密集区域组成一个集群。最近还有一项被称为 HDBSCAN 的新进展，它允许改变密度集群。&lt;/span&gt;&lt;/p&gt;
&lt;ul class=&quot; list-paddingleft-2&quot; readability=&quot;2&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;span&gt;优点：DBSCAN 不需要假设集群为球状，并且它的性能是可扩展的。此外，它不需要每个点都被分配到一个集群中，这降低了集群的异常数据。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;span&gt;缺点：用户必须要调整「epsilon」和「min_sample」这两个定义了集群密度的超参数。DBSCAN 对这些超参数非常敏感。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span&gt;Python 实现：http://scikit-learn.org/stable/modules/clustering.html#dbscan&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span&gt;R 实现：https://cran.r-project.org/web/packages/dbscan/index.html&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;span&gt; 结语 &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;本文从回归问题、分类问题和聚类问题三个角度下初步了解了各个算法的优缺点，也基本了解了那些算法到底是什么。但以上每一个算法都有更多的概念和细节没有展现出来，我们不能知道它们的损失函数是什么、训练目标是什么、权重更新策略是什么等等一些列问题。因此我们希望能从机器之心历来文章中搜寻一些，为有兴趣的读者提供这些算法的具体细节。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;线性回归：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;决策树（集成方法）：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;支持向量机：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;深度学习：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;聚类算法：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;最后，不论是基本概念还是具体算法，最重要的就是实践。不实践这些算法就永远不能发现哪些地方没有掌握，因此希望本文能有助于各位读者实践自己的算法。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;原文地址：&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;em&gt;https://elitedatascience.com/machine-learning-algorithms#regression&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;————&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;编辑 ∑Pluto&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;span&gt;来源：机器之心&lt;/span&gt;&lt;/p&gt;
&lt;section&gt;&lt;section class=&quot;&quot; powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section helvetica=&quot;&quot; neue=&quot;&quot; pingfang=&quot;&quot; sc=&quot;&quot; hiragino=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; microsoft=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; px=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; display:=&quot;&quot; inline-block=&quot;&quot; top=&quot;&quot; solid=&quot;&quot; overflow-wrap:=&quot;&quot; break-word=&quot;&quot; important=&quot;&quot;&gt;&lt;section class=&quot;&quot; powered-by=&quot;xiumi.us&quot;&gt;&lt;section readability=&quot;2.7516891891892&quot;&gt;&lt;section readability=&quot;5.5033783783784&quot;&gt;&lt;section helvetica=&quot;&quot; neue=&quot;&quot; pingfang=&quot;&quot; sc=&quot;&quot; hiragino=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; microsoft=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; px=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; display:=&quot;&quot; inline-block=&quot;&quot; top=&quot;&quot; solid=&quot;&quot; overflow-wrap:=&quot;&quot; break-word=&quot;&quot; important=&quot;&quot;&gt;&lt;section class=&quot;&quot; powered-by=&quot;xiumi.us&quot;&gt;&lt;section readability=&quot;1.5&quot;&gt;&lt;section readability=&quot;3&quot;&gt;&lt;p&gt;&lt;span&gt;微信公众号“算法数学之美”，由算法与数学之美团队打造的另一个公众号，欢迎大家扫码关注！&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p pingfang=&quot;&quot; sc=&quot;&quot; hiragino=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; microsoft=&quot;&quot; yahei=&quot;&quot; wenquanyi=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; helvetica=&quot;&quot; neue=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; px=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; text-align:=&quot;&quot; justify=&quot;&quot; em=&quot;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;1&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;258&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/951TjTgiabkyjQVC3BFiaFKQ4DJqz2xhrwkzeCPbjQdnnG8678fRf1sxc2ZQtvtVib2dqWUkeopYtmgckINoOoGoQ/640?wx_fmt=jpeg&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;更多精彩：&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;☞&lt;/span&gt;&lt;span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI4NTY3OTU3MA==&amp;amp;mid=2247483726&amp;amp;idx=1&amp;amp;sn=e5e008fb68a7d837546d0ac5b5438042&amp;amp;chksm=ebe9cbf3dc9e42e5d625b2da6b9b3866dff9f08d442d8106f4cbf035d8602e1fdda86eec6476&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;如何向5岁小孩解释什么是支持向量机（SVM）？&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;☞&lt;/span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI4NTY3OTU3MA==&amp;amp;mid=2247483726&amp;amp;idx=2&amp;amp;sn=18272b7eaa172794b51c30d0a2dd9c48&amp;amp;chksm=ebe9cbf3dc9e42e5ddf9a189822a2fa099543a631ad63a1d6ed0158b51c76212eb65ebbfe71b&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;自然底数e的意义是什么？&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI4NTY3OTU3MA==&amp;amp;mid=2247483715&amp;amp;idx=1&amp;amp;sn=9069dadf4bbce2aa34bd64b85a69dcee&amp;amp;chksm=ebe9cbfedc9e42e81c27d72da15c0dbf848e505946f231051b8b4033d0941bc6f51cef32790e&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;☞&lt;/span&gt;费马大定理，集惊险与武侠于一体&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;☞&lt;/span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI4NTY3OTU3MA==&amp;amp;mid=2247483715&amp;amp;idx=2&amp;amp;sn=55a16f37c89b27994b263e0dc9837561&amp;amp;chksm=ebe9cbfedc9e42e842deb581ea62b750cedd839abd58c2db3261bf9fbcd172a2cf18512e4d2d&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;简单的解释，让你秒懂“最优化” 问题&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI4NTY3OTU3MA==&amp;amp;mid=2247483676&amp;amp;idx=1&amp;amp;sn=2366a39bca3ef42a6e868e91ea718813&amp;amp;chksm=ebe9cba1dc9e42b70c7e147b9e43828c1a7c68401f442890471a06e5cf0704437f9813ca0e0f&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;☞&lt;/span&gt;一分钟看懂一维空间到十维空间&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;p&gt;&lt;span&gt;☞ &lt;/span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI4NTY3OTU3MA==&amp;amp;mid=2247483661&amp;amp;idx=1&amp;amp;sn=d822666a054ba70b37dfb06d14c60f3a&amp;amp;chksm=ebe9cbb0dc9e42a6c476f7f81095b772aa45d960bf516f60c5b2e1155c9093696222cea0a83d&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;本科、硕士和博士到底有什么区别？&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;☞&lt;/span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI4NTY3OTU3MA==&amp;amp;mid=2247483654&amp;amp;idx=1&amp;amp;sn=7d0d05c78cd01df91495f1d14609cbce&amp;amp;chksm=ebe9cbbbdc9e42add13cfe99f3383745fa5c059df705a3a9e28644d073dff804569af94970e3&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;小波变换通俗解释&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;☞&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI4NTY3OTU3MA==&amp;amp;mid=2247483654&amp;amp;idx=4&amp;amp;sn=ce88086b650c601bdbf57ecfe5a490a1&amp;amp;chksm=ebe9cbbbdc9e42adfaf0e4ee644d254835c830ef47663315b70a39a2b47e6a7cf10d0826b88d&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;微积分必背公式&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;☞&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI4NTY3OTU3MA==&amp;amp;mid=2247483654&amp;amp;idx=3&amp;amp;sn=ceaec6043bb0e8a851033482f8f572bf&amp;amp;chksm=ebe9cbbbdc9e42ad30fd38383cf1caa609ac6e81964da17277f8e2a7f17a933cd11e0f3840c8&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;影响计算机算法世界的十位大师&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;☞&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI4NTY3OTU3MA==&amp;amp;mid=2247483654&amp;amp;idx=2&amp;amp;sn=bf439d56bc7d42083708fa76434a6025&amp;amp;chksm=ebe9cbbbdc9e42ad9e5f2b3c1952e620e0e3d4452aae25b611e7e54be8678b0d80e002e7be6d&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;数据挖掘之七种常用的方法&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;算法数学之美微信公众号欢迎赐稿&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;稿件涉及数学、物理、算法、计算机、编程等相关领域，经采用我们将奉上稿酬。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;投稿邮箱：math_alg@163.com&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Sun, 24 Mar 2019 14:07:10 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/DSoWnR2x4S</dc:identifier>
</item>
</channel>
</rss>